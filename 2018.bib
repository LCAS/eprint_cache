@article{lincoln37426,
          volume = {34},
          number = {6},
           month = {December},
          author = {F.J. Comin and C. Saaj and S.M. Mustaza and R. Saaj},
            note = {cited By 0},
           title = {Safe Testing of Electrical Diathermy Cutting Using a New Generation Soft Manipulator},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Transactions on Robotics},
             doi = {10.1109/TRO.2018.2861898},
           pages = {1659--1666},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37426/},
        abstract = {The first demonstration of a pneumatic soft continuum robot is integrated in series with a rigid robot arm, safely performing teleoperated diathermic tissue-cutting. The rigid arm autonomously maintains a safe tool contact force, while the soft arm manually follows the desired cutting path. Ex-vivo experimentation demonstrates submillimetric deviations from target paths.}
}

@inproceedings{lincoln34433,
       booktitle = {NeurIPS Workshop on Conversational AI},
           month = {December},
           title = {A Study on Dialogue Reward Prediction for Open-Ended Conversational Agents},
          author = {Heriberto Cuayahuitl and Seonghan Ryu and Donghyeon Lee and Jihie Kim},
       publisher = {arXiv},
            year = {2018},
        keywords = {ARRAY(0x56321342fcd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34433/},
        abstract = {The amount of dialogue history to include in a conversational agent is often underestimated and/or set in an empirical and thus possibly naive way. This suggests that principled investigations into optimal context windows are urgently needed given that the amount of dialogue history and corresponding representations can play an important role in the overall performance of a conversational system. This paper studies the amount of history required by conversational agents for reliably predicting dialogue rewards. The task of dialogue reward prediction is chosen for investigating the effects of varying amounts of dialogue history and their impact on system performance. Experimental results using a dataset of 18K human-human dialogues report that lengthy  dialogue histories of at least 10 sentences are preferred (25 sentences being the best in our experiments) over short ones, and that lengthy histories are useful for training dialogue reward predictors with strong positive correlations between target dialogue rewards and predicted ones.}
}

@inproceedings{lincoln33104,
           month = {December},
          author = {Huatian Wang and Shigang Yue and Jigen Peng and Paul Baxter and Chun Zhang and Zhihua Wang},
       booktitle = {ICANN 2018},
           title = {A Model for Detection of Angular Velocity of Image Motion Based on the Temporal Tuning of the Drosophila},
       publisher = {Springer, Cham},
             doi = {https://doi.org/10.1007/978-3-030-01421-6\_4},
           pages = {37--46},
            year = {2018},
        keywords = {ARRAY(0x56321342fcb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33104/},
        abstract = {We propose a new bio-plausible model based on the visual systems of Drosophila for estimating angular velocity of image motion in insects? eyes. The model implements both preferred direction motion enhancement and non-preferred direction motion suppression which is discovered in Drosophila?s visual neural circuits recently to give a stronger directional selectivity. In addition, the angular velocity detecting model (AVDM) produces a response largely independent of the spatial frequency in grating experiments which enables insects to estimate the flight speed in cluttered environments. This also coincides with the behaviour experiments of honeybee flying through tunnels with stripes of different spatial frequencies.}
}

@inproceedings{lincoln33846,
       booktitle = {IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS},
           month = {December},
           title = {Performance of a Visual Fixation Model in an Autonomous Micro Robot Inspired by Drosophila Physiology},
          author = {Qinbing Fu and Nicola Bellotto and Cheng Hu and Shigang Yue},
            year = {2018},
        keywords = {ARRAY(0x563213432078)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33846/},
        abstract = {In nature, lightweight and low-powered insects are ideal model systems to study motion perception strategies. Understanding the underlying characteristics and functionality of insects? visual systems is not only attractive to neural system modellers, but also critical in providing effective solutions to future robotics. This paper presents a novel modelling of dynamic vision system inspired by Drosophila physiology for mimicking fast motion tracking and a closed-loop behavioural response to ?xation. The proposed model was realised on embedded system in an autonomous micro robot which has limited computational resources. A monocular camera was applied as the only motion sensing modality. Systematic experiments including open-loop and closed-loop bio-robotic tests validated the proposed visual ?xation model: the robot showed motion tracking and ?xation behaviours similarly to insects; the image processing frequency can maintain 25 {$\sim$} 45Hz. Arena tests also demonstrated a successful following behaviour aroused by ?xation in navigation.}
}

@article{lincoln37427,
          volume = {152},
           month = {November},
          author = {W. Lewinger and F. Comin and M. Matthews and C. Saaj},
            note = {cited By 0},
           title = {Earth analogue testing and analysis of Martian duricrust properties},
            year = {2018},
         journal = {Acta Astronautica},
             doi = {10.1016/j.actaastro.2018.05.025},
           pages = {567--579},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37427/},
        abstract = {Previous and current Mars rover missions have noted a nearly ubiquitous presence of duricrusts on the planet surface. Duricrusts are thin, brittle layers of cemented regolith that cover the underlying terrain. In some cases, the duricrust hides safe or relatively safe underneath the top soil. However, as was observed by both Mars exploration rovers, Spirit and Opportunity, such crusts can also hide loose, untrafficable terrain, leading to Spirit becoming permanently incapacitated in 2009. Whilst several reports of the Martian surface have indicated the presence of duricrusts, none have been able to provide details on the physical properties of the material, which may indicate the level of safe traversability of duricrust terrains. This paper presents the findings of testing terrestrially-created duricrusts with simulated Martian soil properties, in order to determine the properties of such duricrusts and to discover what level of hazard that they may represent (e.g. can vehicles traverse the duricrust surface without penetration to lower sub-surface soils?). Combinations of elements that have been observed in the Martian soil were used as the basis for forming the laboratory-created duricrusts. Variations in duricrust thickness, water content, and the iron oxide compound were investigated. As was observed throughout the testing process, duricrusts behave in a rather brittle fashion and are easily destroyed by low surface pressures. This indicates that duricrusts are not safe for traversing and they present a definite hazard for travelling on the Martian landscape when utilising only visual terrain classification, as the surface appearance is not necessarily representative of what may be lying beneath.}
}

@article{lincoln43299,
          volume = {5},
           month = {November},
          author = {James O?Keeffe and Danesh Tarapore and Alan Millard and Jon Timmis},
           title = {Adaptive Online Fault Diagnosis in Autonomous Robot Swarms},
         journal = {Frontiers in Robotics and AI},
             doi = {10.3389/frobt.2018.00131},
           pages = {131},
            year = {2018},
        keywords = {ARRAY(0x5632134320c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43299/},
        abstract = {Previous work has shown that robot swarms are not always tolerant to the failure of individual robots, particularly those that have only partially failed and continue to contribute to collective behaviors. A case has been made for an active approach to fault tolerance in swarm robotic systems, whereby the swarm can identify and resolve faults that occur during operation. Existing approaches to active fault tolerance in swarms have so far omitted fault diagnosis, however we propose that diagnosis is a feature of active fault tolerance that is necessary if swarms are to obtain long-term autonomy. This paper presents a novel method for fault diagnosis that attempts to imitate some of the observed functions of natural immune system. The results of our simulated experiments show that our system is flexible, scalable, and improves swarm tolerance to various electro-mechanical faults in the cases examined.}
}

@article{lincoln46155,
          volume = {55},
           month = {November},
          author = {Giacomo Picardi and Cecilia Laschi and Marcello Calisti},
           title = {Model-based open loop control of a multigait legged underwater robot},
         journal = {Mechatronics},
             doi = {10.1016/j.mechatronics.2018.09.006},
           pages = {162--170},
            year = {2018},
        keywords = {ARRAY(0x56321343a7c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46155/},
        abstract = {In this paper a model-based open loop control of SILVER, a multigait legged underwater vehicle for the benthic zone exploration, is presented. The contributions of underwater environment are taken into account by resorting to a recently introduced fundamental model of monopedal underwater hopping locomotion on which the tuning of a completely open loop control algorithm for dynamic gaits is based. The design of the robot and the control algorithm of each gait are presented along with experimental results which demonstrate on-spot static and dynamic rotation, and forward locomotion by crawling, walking and hopping. Moreover, for the first time the behavior of multi-legged underwater robots is grounded to the fundamental monopedal model. SILVER is the first underwater legged robot capable of performing dynamic self-stabilizing hopping gaits together with static gaits and precise foot placement. Thanks to its unique features the category of underwater legged robots has the potential to be a very versatile and valuable alternative to the existing technology for the exploration of the seabed.}
}

@inproceedings{lincoln42420,
       booktitle = {2018 IEEE Symposium Series on Computational Intelligence (SSCI)},
           month = {November},
           title = {Biological Goal Seeking},
          author = {E. P. Kerr and P.J. Vance and D. Kerr and S.A. Coleman and Gautham Das and T.M. McGinnity and D.P. Moyes and T. Delbruck},
            year = {2018},
             doi = {10.1109/SSCI.2018.8628696},
        keywords = {ARRAY(0x563213432000)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42420/},
        abstract = {Obstacle avoidance is a critical aspect of control for a mobile robot when navigating towards a goal in an unfamiliar environment. Where traditional methods for obstacle avoidance depend heavily on path planning to reach a specific goal location whilst avoiding obstacles, the method proposed uses an adaption of a potential fields algorithm to successfully avoid obstacles whilst the robot is being guided to a non-specific goal location. Details of a generalised finite state machine based control algorithm that enable the robot to pursue a dynamic goal location, whilst avoiding obstacles and without the need for specific path planning, are presented. We have developed a novel potential fields algorithm for obstacle avoidance for use within Robot Operating Software (ROS) and made it available for download within the open source community. We evaluated the control algorithm in a high-speed predator-prey scenario in which the predator could successfully catch the moving prey whilst avoiding collision with all obstacles within the environment.}
}

@inproceedings{lincoln33089,
       booktitle = {21st IEEE International Conference on Intelligent Transportation Systems},
           month = {November},
           title = {Predicting pedestrian road-crossing assertiveness for autonomous vehicle control},
          author = {F Camara and O Giles and M Rothmuller and PH Rasmussen and A Vendelbo-Larsen and G Markkula and Y-M Lee and N Merat and Charles Fox},
       publisher = {IEEE},
            year = {2018},
        keywords = {ARRAY(0x563213432018)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33089/},
        abstract = {Autonomous vehicles (AVs) must interact with other
road users including pedestrians. Unlike passive environments,
pedestrians are active agents having their own utilities and
decisions, which must be inferred and predicted by AVs in order
to control interactions with them and navigation around them.
In particular, when a pedestrian wishes to cross the road in
front of the vehicle at an unmarked crossing, the pedestrian
and AV must compete for the space, which may be considered
as a game-theoretic interaction in which one agent must yield
to the other. To inform AV controllers in this setting, this study
collects and analyses data from real-world human road crossings
to determine what features of crossing behaviours are predictive
about the level of assertiveness of pedestrians and of the eventual
winner of the interactions. It presents the largest and most
detailed data set of its kind known to us, and new methods to
analyze and predict pedestrian-vehicle interactions based upon
it. Pedestrian-vehicle interactions are decomposed into sequences
of independent discrete events. We use probabilistic methods ?
regression and decision tree regression ? and sequence analysis
to analyze sets and sub-sequences of actions used by both
pedestrians and human drivers while crossing at an intersection,
to find common patterns of behaviour and to predict the winner
of each interaction. We report on the particular features found
to be predictive and which can thus be integrated into game-
theoretic AV controllers to inform real-time interactions.}
}

@article{lincoln34106,
          volume = {5},
          number = {6},
           month = {November},
          author = {Khaled Goher and Sulaiman Fadlallah},
           title = {PID, BFO-optimized PID, and PD-FLC control of a two-wheeled machine with two-direction handling mechanism: a comparative study},
       publisher = {SpringerOpen},
            year = {2018},
         journal = {Robotics and Biomimetics},
             doi = {10.1186/s40638-018-0089-3},
        keywords = {ARRAY(0x56321343a7f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34106/},
        abstract = {In this paper; three control approaches are utilized in order to control the stability of a novel five-degrees-of-freedom two-wheeled robotic machine designed for industrial applications that demand a limited-space working environment. Proportional?integral?derivative (PID) control scheme, bacterial foraging optimization of PID control method, and fuzzy logic control method are applied to the wheeled machine to obtain the optimum control strategy that provides the best system stabilization performance. According to simulation results, considering multiple motion scenarios, the PID controller optimized by bacterial foraging optimization method outperformed the other two control methods in terms of minimum overshoot, rise time, and applied input forces.}
}

@article{lincoln31536,
          volume = {106},
           month = {October},
          author = {Qinbing Fu and Cheng Hu and Jigen Peng and Shigang Yue},
           title = {Shaping the collision selectivity in a looming sensitive neuron model with parallel ON and OFF pathways and spike frequency adaptation},
       publisher = {Elsevier for European Neural Network Society (ENNS)},
            year = {2018},
         journal = {Neural Networks},
             doi = {10.1016/j.neunet.2018.04.001},
           pages = {127--143},
        keywords = {ARRAY(0x56321343a810)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31536/},
        abstract = {Shaping the collision selectivity in vision-based artificial collision-detecting systems is still an open challenge. This paper presents a novel neuron model of a locust looming detector, i.e. the lobula giant movement detector (LGMD1), in order to provide effective solutions to enhance the collision selectivity of looming objects over other visual challenges. We propose an approach to model the biologically plausible mechanisms of ON and OFF pathways and a biophysical mechanism of spike frequency adaptation (SFA) in the proposed LGMD1 visual neural network. The ON and OFF pathways can separate both dark and light looming features for parallel spatiotemporal computations. This works effectively on perceiving a potential collision from dark or light objects that approach; such a bio-plausible structure can also separate LGMD1's collision selectivity to its neighbouring looming detector -- the LGMD2.The SFA mechanism can enhance the LGMD1's collision selectivity to approaching objects rather than receding and translating stimuli, which is a significant improvement compared with similar LGMD1 neuron models. The proposed framework has been tested using off-line tests of synthetic and real-world stimuli, as well as on-line bio-robotic tests. The enhanced collision selectivity of the proposed model has been validated in systematic experiments. The computational simplicity and robustness of this work have also been verified by the bio-robotic tests, which demonstrates potential in building neuromorphic sensors for collision detection in both a fast and reliable manner.}
}

@inproceedings{lincoln34105,
       booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
           month = {October},
           title = {Cut to the Chase: A Context Zoom-in Network for Reading Comprehension},
          author = {Satish Indurthi and Seunghak Yu and Seohyun Back and Heriberto Cuayahuitl},
       publisher = {Association for Computational Linguistics},
            year = {2018},
        keywords = {ARRAY(0x56321343a840)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34105/},
        abstract = {In recent years many deep neural networks have been proposed to solve Reading Comprehension (RC) tasks. Most of these models suffer from reasoning over long documents and do not trivially generalize to cases where the answer is not present as a span in a given document. We present a novel neural-based architecture that is capable of extracting relevant regions based on a given question-document pair and generating a well-formed answer. To show the effectiveness of our architecture, we conducted several experiments on the recently proposed and challenging RC dataset ?NarrativeQA?. The proposed architecture outperforms state-of-the-art results (Tay et al., 2018) by 12.62\% (ROUGE-L) relative improvement.}
}

@article{lincoln32558,
          volume = {3},
          number = {4},
           month = {October},
          author = {Li Sun and Zhi Yan and Anestis Zaganidis and Cheng Zhao and Tom Duckett},
           title = {Recurrent-OctoMap: Learning State-based Map Refinement for Long-Term Semantic Mapping with 3D-Lidar Data},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2856268},
           pages = {3749--3756},
        keywords = {ARRAY(0x56321343a858)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32558/},
        abstract = {This paper presents a novel semantic mapping approach, Recurrent-OctoMap, learned from long-term 3D
Lidar data. Most existing semantic mapping approaches focus on improving semantic understanding of single frames, rather than 3D refinement of semantic maps (i.e. fusing semantic observations). The most widely-used approach for 3D semantic map refinement is a Bayes update, which fuses the consecutive predictive probabilities following a Markov-Chain model. Instead, we propose a learning approach to fuse the semantic features, rather than simply fusing predictions from a classifier. In our approach, we represent and maintain our 3D map as an OctoMap, and model each cell as a recurrent neural network (RNN), to obtain a Recurrent-OctoMap. In this case, the semantic mapping process can be formulated as a sequenceto-sequence encoding-decoding problem. Moreover, in order to extend the duration of observations in our Recurrent-OctoMap, we developed a robust 3D localization and mapping system for successively mapping a dynamic environment using more than two weeks of data, and the system can be trained and deployed with arbitrary memory length. We validate our approach on the ETH long-term 3D Lidar dataset [1]. The experimental results show that our proposed approach outperforms the conventional ?Bayes update? approach.}
}

@article{lincoln32390,
          volume = {3},
          number = {4},
           month = {October},
          author = {Anestis Zaganidis and Li Sun and Tom Duckett and Grzegorz Cielniak},
           title = {Integrating Deep Semantic Segmentation Into 3-D Point Cloud Registration},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2848308},
           pages = {2942--2949},
        keywords = {ARRAY(0x56321343a888)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32390/},
        abstract = {Point cloud registration is the task of aligning 3D scans of the same environment captured from different poses. When semantic information is available for the points, it can be used as a prior in the search for correspondences to improve registration. Semantic-assisted Normal Distributions Transform (SE-NDT) is a new registration algorithm that reduces the complexity of the problem by using the semantic information to partition the point cloud into a set of normal distributions, which are then registered separately. In this paper we extend the NDT registration pipeline by using PointNet, a deep neural network for segmentation and classification of point clouds, to learn and predict per-point semantic labels. We also present the Iterative Closest Point (ICP) equivalent of the algorithm, a special case of Multichannel Generalized ICP. We evaluate the performance of SE-NDT against the state of the art in point cloud registration on the publicly available classification data set Semantic3d.net. We also test the trained classifier and algorithms on dynamic scenes, using a sequence from the public dataset KITTI. The experiments demonstrate the improvement of the registration in terms of robustness, precision and speed, across a range of initial registration errors, thanks to the inclusion of semantic information.}
}

@inproceedings{lincoln47571,
          volume = {11163},
           month = {October},
          author = {Zakaria Maamar and Khouloud Boukadi and Emir Ugljanin and Thar Baker and Muhammad Asim and Mohammed Al-Khafajiy and Djamal Benslimane and Hasna El Alaoui El Abdallaoui},
       booktitle = {Model and Data Engineering},
           title = {Thing Federation as a Service: Foundations and Demonstration},
       publisher = {Springer},
            year = {2018},
         journal = {Thing Federation as a Service: Foundations and Demonstration},
             doi = {10.1007/978-3-030-00856-7\_12},
           pages = {184--197},
        keywords = {ARRAY(0x56321343a8b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47571/},
        abstract = {This paper presents the design and implementation guidelines of thing federation-as-a-service. The large and growing number of things compliant with the Internet-of-Things (IoT) principles need to be ?harnessed? so, that, things? collective over individual behaviors prevail. A federation gathers necessary things together according to the needs and requirements of the situation that this federation is tasked to handle. Two types of federations exist: planned whose things are all known at design-time and ad-hoc whose things are known after a competitive selection at run-time. In this paper, federations handle situations about emergency services that involve different stakeholders with different backgrounds raising the complexity of ensuring a successful delivery of these services. A system for patient emergency transfer following a tunnel closure is implemented demonstrating the technical doability of thing federation-as-a-service.}
}

@inproceedings{lincoln34847,
           month = {October},
          author = {Jiannan Zhao and Cheng Hu and Chun Zhang and Zhihua Wang and Shigang Yue},
       booktitle = {2018 International Joint Conference on Neural Networks (IJCNN)},
           title = {A Bio-inspired Collision Detector for Small Quadcopter},
       publisher = {IEEE},
             doi = {10.1109/IJCNN.2018.8489298},
           pages = {1--7},
            year = {2018},
        keywords = {ARRAY(0x56321343a8e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34847/},
        abstract = {The sense and avoid capability enables insects to fly versatilely and robustly in dynamic and complex environment. Their biological principles are so practical and efficient that inspired we human imitating them in our flying machines. In this paper, we studied a novel bio-inspired collision detector and its application on a quadcopter. The detector is inspired from Lobula giant movement detector (LGMD) neurons in the locusts, and modeled into an STM32F407 Microcontroller Unit (MCU).
Compared to other collision detecting methods applied on quadcopters, we focused on enhancing the collision accuracy in a bio-inspired way that can considerably increase the computing efficiency during an obstacle detecting task even in complex and dynamic environment. We designed the quadcopter's responding operation to imminent  collisions and tested this bio-inspired system in an indoor arena. The observed results from the experiments demonstrated that the LGMD collision detector is feasible to work as a vision module for the quadcopter's collision avoidance task.}
}

@inproceedings{lincoln33782,
       booktitle = {9th International Gas Turbine Conference},
           month = {October},
           title = {Performance analysis of a twin-shaft gas turbine with fault in the variable stator guide vane system of the axial compressor},
          author = {Samuel Cruz-Manzo and Sepehr Maleki and Vili Panov and Festus Agbonzikilo and Yu Zhang and Anthony Latimer},
            year = {2018},
        keywords = {ARRAY(0x56321343a918)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33782/},
        abstract = {In this study, an analysis of the performance of a twin-shaft industrial gas turbine (IGT) with a fault in the mechanism of the compressor that changes the position of variable stator guide vanes (VSGVs) is carried out. Measured field data of a twin-shaft engine denoting a difference (offset) between the demanded inlet guide vane (IGV) angle and the measured IGV angle in the axial compressor have been considered for the analysis. A validated Simulink model which simulates the performance of the twin-shaft engine has been considered for the analysis of the fault in the VSGV system. The Simulink model architecture comprises an axial compressor module and considers an multi-stage compressor performance map at optimal conditions (new \& clean). The results demonstrate that it is possible to predict the physical parameters such as pressure and temperature measured across the different stations of the engine during the offset of the IGV angle. The effect of the IGV offset on the compressor performance is discussed as well. The change in compressor air flow and compressor efficiency at different IGV offset is discussed, as during a low power engine operation and fault within the VSGV system, the surge line may drift close to the compressor running operation line.}
}

@article{lincoln32371,
          volume = {3},
          number = {4},
           month = {October},
          author = {Petra Bosilj and Tom Duckett and Grzegorz Cielniak},
           title = {Analysis of morphology-based features for classification of crop and weeds in precision agriculture},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2848305},
           pages = {2950--2956},
        keywords = {ARRAY(0x56321343a948)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32371/},
        abstract = {Determining the types of vegetation present in an image is a core step in many precision agriculture tasks. In this paper, we focus on pixel-based approaches for classification of crops versus weeds, especially for complex cases involving overlapping plants and partial occlusion. We examine the benefits of multi-scale and content-driven morphology-based descriptors called Attribute Profiles. These are compared to state-of-the art keypoint descriptors with a fixed neighbourhood previously used in precision agriculture, namely Histograms of Oriented Gradients and Local Binary Patterns. The proposed classification technique is especially advantageous when coupled with morphology-based segmentation on a max-tree structure, as the same representation can be re-used for feature extraction. The robustness of the approach is demonstrated by an experimental evaluation on two datasets with different crop types. The proposed approach compared favourably to state-of-the-art approaches without an increase in computational complexity, while being able to provide descriptors at a higher resolution.}
}

@inproceedings{lincoln36200,
       booktitle = {IROS 2018 Workshop on Human/Robot in the Loop Machine Learning},
           month = {October},
           title = {From Evaluating to Teaching: Rewards and Challenges of Human Control for Learning Robots},
          author = {Emmanuel Senft and Severin Lemaignan and Paul Baxter and Tony Belpaeme},
       publisher = {Imperial College London},
            year = {2018},
        keywords = {ARRAY(0x56321343a978)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36200/},
        abstract = {Keeping a human in a robot learning cycle can provide many advantages to improve the learning process. However, most of these improvements are only available when the human teacher is in complete control of the robot?s behaviour, and not just providing feedback. This human control can make the learning process safer, allowing the robot to learn in high-stakes interaction scenarios especially social ones. Furthermore, it allows faster learning as the human guides the robot to the relevant parts of the state space and can provide additional information to the learner. This information can also enable the
learning algorithms to learn for wider world representations, thus increasing the generalisability of a deployed system. Additionally, learning from end users improves the precision of the final policy as it can be specifically tailored to many situations. Finally, this progressive teaching might create trust between the learner and the teacher, easing the deployment of the autonomous robot. However, with such control comes a range of challenges. Firstly, the rich communication between the robot and the teacher needs to be handled by an interface, which may require complex features. Secondly, the teacher needs to be embedded within the robot action selection cycle, imposing time constraints, which increases the cognitive load on the teacher. Finally, given a cycle of interaction between the robot and the teacher, any mistakes made by the teacher can be propagated to the robot?s policy. Nevertheless, we are are able to show that empowering the teacher with ways to control a robot?s behaviour has the potential to drastically improve both the learning process (allowing robots to learn in a wider range of environments) and the experience of the teacher.}
}

@inproceedings{lincoln32541,
       booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {October},
           title = {Multisensor Online Transfer Learning for 3D LiDAR-based Human Detection with a Mobile Robot},
          author = {Zhi Yan and Li Sun and Tom Duckett and Nicola Bellotto},
       publisher = {IEEE},
            year = {2018},
        keywords = {ARRAY(0x56321343a9a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32541/},
        abstract = {Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new ?trajectory probability?. Our framework uses this probability to check whether new detections belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.}
}

@incollection{lincoln39233,
          volume = {140},
           month = {September},
          author = {Sofia Papadaki and Georgios Banias and Charisios Achillas and Dimitris Aidonis and Dimitris Folinas and Dionysis Bochtis and Stamatis Papangelou},
       booktitle = {Dynamics of Disasters},
           title = {A Humanitarian Logistics Case Study for the Intermediary Phase Accommodation Center for Refugees and Other Humanitarian Disaster Victims},
       publisher = {Springer},
            year = {2018},
             doi = {doi:10.1007/978-3-319-97442-2\_8},
           pages = {157--202},
        keywords = {ARRAY(0x56321343a9d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39233/},
        abstract = {The growing and uncontrollable stream of refugees from Middle East and North Africa has created considerable pressure to governments and societies all over Europe. To establish the theoretical framework, the concept of humanitarian logistics is briefly examined in this paper. Historical data from the nineteenth century onwards illuminates the fact that this influx is not a novelty in the European continent and the interpretation of statistical data highlights the characteristics and particularities of the current refugee wave, as well as the possible repercussions these could inflict both to hosting societies and to displaced populations. Finally, a review of European and national legislation and policies shows that measures taken so far are disjointed and that no complete but at the same time fair and humanitarian management strategy exists.

Within this context, the paper elaborates on the development of a compact accommodation center made of shipping containers, to function as one of the initial stages in adaptation before full social integration of the displaced populations. It aims at maximizing the respect for human rights and values while minimizing the impact on society and on the environment. Some of the humanitarian and ecological issues discussed are: integration of medical, educational, religious and social functions within the unit, optimal land utilization, renewable energy use, and waste management infrastructures. Creating added value for the ?raw? material (shipping containers) and prolonging the unit?s life span by enabling transformation and change of use, transportation and reuse, and finally end-of-life dismantlement and recycling also lie within the scope of the project.

The overall goal is not only to address the current needs stemming from the refugee crisis, but also to develop a project versatile enough to be adapted for implementation on further social groups in need of support. The paper?s results could serve as a useful tool for governments and organizations to better plan ahead and respond fast and efficiently not only in regard to the present humanitarian emergency, but also in any possible similar major disaster situation, including the potential consequences of climate change.}
}

@inproceedings{lincoln33422,
       booktitle = {The 27th International Conference on Artificial Neural Networks},
           month = {September},
           title = {A Feedback Neural Network for Small Target Motion Detection in Cluttered Backgrounds},
          author = {Hongxin Wang and Jigen Peng and Shigang Yue},
       publisher = {IEEE},
            year = {2018},
        keywords = {ARRAY(0x56321343aa08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33422/},
        abstract = {Small target motion detection is critical for insects to search for and track mates or prey which always appear as small dim speckles in the visual field. A class of specific neurons, called small target motion detectors (STMDs), has been characterized by exquisite sensitivity for small target motion. Understanding and analyzing visual pathway of STMD neurons are beneficial to design artificial visual systems for small target motion detection. Feedback loops have been widely identified in visual neural circuits and play an important role in target detection. However, if there exists a feedback loop in the STMD visual pathway or if a feedback loop could significantly improve the detection performance of STMD neurons, is unclear. In this paper, we propose a feedback neural network for small target motion detection against naturally cluttered backgrounds. In order to form a feedback loop, model output is temporally delayed and relayed to previous neural layer as feedback signal. Extensive experiments showed that the significant improvement of the proposed feedback neural network over the existing STMD-based models for small target motion detection.}
}

@incollection{lincoln34108,
       booktitle = {Robotics},
           month = {September},
           title = {System Identification and HSDBC-Optimized PID Control of a Portable Lower-Limb Rehabilitation Device},
          author = {Sulaiman Fadlallah and Khaled Goher},
       publisher = {World Scientfic},
            year = {2018},
        keywords = {ARRAY(0x56321343aa38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34108/},
        abstract = {The present paper introduces a novel portable leg rehabilitation system (PLRS) that is developed to provide the user with the necessary rehabilitation exercises for both the knee and ankle in addition to the portability feature to overcome the hardships associated with both effort and cost of hospitals and rehabilitation clinics? steady sessions. Prior realizing the actual prototype, the proposed configuration was visualized using SolidWorks including its main components. Aiming to control the developed system, and given the fact that tuning controller parameters is not an easy task, Hybrid Spiral-Dynamics Bacteria-Chemotaxis (HSDBC) algorithm has been applied on the proposed control strategy in order to obtain a satisfactory performance. The obtained system performance was satisfactory in terms of desired elevation and settling time.}
}

@article{lincoln34138,
          volume = {18},
          number = {9},
           month = {September},
          author = {Cheng Zhao and Li Sun and Pulak Purkait and Tom Duckett and Rustam Stolkin},
           title = {Dense RGB-D Semantic Mapping with Pixel-Voxel Neural Network},
       publisher = {Multidisciplinary Digital Publishing Institute},
            year = {2018},
         journal = {Sensors},
             doi = {10.3390/s18093099},
           pages = {3099},
        keywords = {ARRAY(0x56321343aa68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34138/},
        abstract = {In this paper, a novel Pixel-Voxel network is proposed for dense 3D semantic mapping, which can perform dense 3D mapping while simultaneously recognizing and labelling the semantic category each point in the 3D map. In our approach, we fully leverage the advantages of different modalities. That is, the PixelNet can learn the high-level contextual information from 2D RGB images, and the VoxelNet can learn 3D geometrical shapes from the 3D point cloud. Unlike the existing architecture that fuses score maps from different modalities with equal weights, we propose a softmax weighted fusion stack that adaptively learns the varying contributions of PixelNet and VoxelNet and fuses the score maps according to their respective confidence levels. Our approach achieved competitive results on both the SUN RGB-D and NYU V2 benchmarks, while the runtime of the proposed system is boosted to around 13 Hz, enabling near-real-time performance using an i7 eight-cores PC with a single Titan X GPU.}
}

@inproceedings{lincoln31675,
           month = {September},
          author = {R. Pinsler and R. Akrour and T. Osa and J. Peters and G. Neumann},
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
           title = {Sample and feedback efficient hierarchical reinforcement learning from human preferences},
       publisher = {IEEE},
             doi = {10.1109/ICRA.2018.8460907},
           pages = {596--601},
            year = {2018},
        keywords = {ARRAY(0x56321343aa98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31675/},
        abstract = {While reinforcement learning has led to promising results in robotics, defining an informative reward function can sometimes prove to be challenging. Prior work considered including the human in the loop to jointly learn the reward function and the optimal policy. Generating samples from a physical robot and requesting human feedback are both taxing efforts for which efficiency is critical. In contrast to prior work, in this paper we propose to learn reward functions from both the robot and the human perspectives in order to improve on both efficiency metrics. On one side, learning a reward function from the human perspective increases feedback efficiency by assuming that humans rank trajectories according to an outcome space of reduced dimensionaltiy. On the other side, learning a reward function from the robot perspective circumvents the need for learning a dynamics model while retaining the sample efficiency of model-based approaches. We provide an algorithm that incorporates bi-perspective reward learning into a general hierarchical reinforcement learning framework and demonstrate the merits of our approach on a toy task and a simulated robot grasping task.}
}

@article{lincoln31956,
           month = {September},
           title = {3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data},
          author = {Li Sun and Zhi Yan and Sergi Molina Mellado and Marc Hanheide and Tom Duckett},
       publisher = {IEEE},
            year = {2018},
             doi = {10.1109/icra.2018.8461228},
         journal = {International Conference on Robotics and Automation (ICRA) 2018},
        keywords = {ARRAY(0x56321343aac8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31956/},
        abstract = {This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service
robots. While most previously reported methods are based on learning of 2D positions in monocular camera images,
our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-PoseLSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.}
}

@article{lincoln31131,
          volume = {11},
          number = {3},
           month = {September},
          author = {Ayse Kucukyilmaz and Yiannis Demiris},
           title = {Learning shared control by demonstration for personalized wheelchair assistance},
       publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
            year = {2018},
         journal = {IEEE Transactions on Haptics},
             doi = {10.1109/TOH.2018.2804911},
           pages = {431--442},
        keywords = {ARRAY(0x56321343aaf8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31131/},
        abstract = {An emerging research problem in assistive robotics is the design of methodologies that allow robots to provide personalized assistance to users. For this purpose, we present a method to learn shared control policies from demonstrations offered by a human assistant. We train a Gaussian process (GP) regression model to continuously regulate the level of assistance between the user and the robot, given the user's previous and current actions and the state of the environment. The assistance policy is learned after only a single human demonstration, i.e. in one-shot. Our technique is evaluated in a one-of-a-kind experimental study, where the machine-learned shared control policy is compared to human assistance. Our analyses show that our technique is successful in emulating human shared control, by matching the location and amount of offered assistance on different trajectories. We observed that the effort requirement of the users were comparable between human-robot and human-human settings. Under the learned policy, the jerkiness of the user's joystick movements dropped significantly, despite a significant increase in the jerkiness of the robot assistant's commands. In terms of performance, even though the robotic assistance increased task completion time, the average distance to obstacles stayed in similar ranges to human assistance.}
}

@article{lincoln34496,
          volume = {18},
          number = {3},
           month = {September},
          author = {Wang-Su Jeon and Grzegorz Cielniak and Rhee Sang-Yong},
           title = {Semantic Segmentation Using Trade-Off and Internal Ensemble},
            year = {2018},
         journal = {International Journal of Fuzzy Logic and Intelligent Systems},
             doi = {10.5391/IJFIS.2018.18.3.196},
           pages = {196--203},
        keywords = {ARRAY(0x56321343ab28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34496/},
        abstract = {The computer vision consists of image classification, image segmentation, object detection, and tracking, etc. Among them, image segmentation is the most basic technique of the computer vision, which divides an image into foreground and background. This paper proposes an ensemble model using a concept of physical perception for image segmentation. Practically two connected models, the DeepLab and a modified VGG model, get feedback each other in the training process. On inference processing, we combine the results of two parallel models and execute an atrous spatial pyramid pooling (ASPP) and post-processing by using conditional random field (CRF). The proposed model shows better performance than the DeepLab in local area and about 1\% improvement on average on comparison of pixel-by-pixel.}
}

@article{lincoln32981,
          volume = {32},
          number = {18},
           month = {September},
          author = {T. Osa and J. Peters and Gerhard Neumann},
           title = {Hierarchical Reinforcement Learning of Multiple Grasping Strategies with Human Instructions},
       publisher = {Taylor \& Francis},
            year = {2018},
         journal = {Advanced Robotics},
             doi = {10.1080/01691864.2018.1509018},
           pages = {955--968},
        keywords = {ARRAY(0x56321343ab58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32981/},
        abstract = {Grasping is an essential component for robotic manipulation and has been investigated for decades. Prior work on grasping often assumes that a sufficient amount of training data is available for learning and planning robotic grasps. However, since constructing such an exhaustive training dataset is very challenging in practice, it is desirable that a robotic system can autonomously learn and improves its grasping strategy. In this paper, we address this problem using reinforcement learning. Although recent work has presented autonomous data collection through trial and error, such methods are often limited to a single grasp type, e.g., vertical pinch grasp. We present a hierarchical policy search approach for learning multiple grasping strategies. Our framework autonomously constructs a database of grasping motions and point clouds of objects to learn multiple grasping types autonomously. We formulate the problem of selecting the grasp location and grasp policy as a bandit problem, which can be interpreted as a variant of active learning. We applied our reinforcement learning to grasping both rigid and deformable objects. The experimental results show that our framework autonomously learns and improves its performance through trial and error and can grasp previously unseen objects with a high accuracy.}
}

@article{lincoln37443,
          volume = {15},
          number = {5},
           month = {August},
          author = {S.M. Mustaza and C Saaj and F.J. Comin and W.A. Albukhanajer and D. Mahdi and C. Lekakou},
            note = {cited By 1},
           title = {Stiffness Control for Soft Surgical Manipulators},
       publisher = {World Scientific},
            year = {2018},
         journal = {International Journal of Humanoid Robotics},
             doi = {10.1142/S0219843618500214},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37443/},
        abstract = {Tunable stiffness control is critical for undertaking surgical procedures using soft manipulators. However, active stiffness control in soft continuum manipulators is very challenging and has been rarely realized for real-time surgical applications. Low stiffness at the tip is much preferred for safe navigation of the robot in restricted spaces inside the human body. On the other hand, high stiffness at the tip is demanded for efficiently operating surgical instruments. In this paper, the manipulability and characteristics of a class of soft hyper-redundant manipulator, fabricated using Ecoflex-0050TM silicone, is discussed and a new methodology is introduced to actively tune the stiffness matrix, in real-time, for disturbance rejection and stiffness control. Experimental results are used to derive a more accurate description of the characteristics of the soft manipulator, capture the varying stiffness effects of the actuated arm and consequently offer a more accurate response using closed loop feedback control in real-time. The novel results presented in this paper advances the state-of-the-art of tunable stiffness control in soft continuum manipulators for real-time applications.}
}

@article{lincoln32842,
          volume = {10994},
           month = {August},
          author = {Cheng Hu and Qinbing Fu and Tian liu and Shigang Yue},
       booktitle = {Manoonpong P., Larsen J., Xiong X., Hallam J., Triesch J. (eds) From Animals to Animats 15. SAB 2018. Lecture Notes in Computer Science},
           title = {A Hybrid Visual-Model Based Robot Control Strategy for Micro Ground Robots},
       publisher = {Springer, Cham},
            year = {2018},
         journal = {SAB 2018: From Animals to Animats 15},
             doi = {10.1007/978-3-319-97628-0\_14},
           pages = {162--174},
        keywords = {ARRAY(0x56321343abb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32842/},
        abstract = {This paper proposed a hybrid vision-based robot control strategy for micro ground robots by mediating two vision models from mixed categories: a bio-inspired collision avoidance model and a segmentation based target following model. The implemented model coordination strategy is described as a probabilistic model using ?nite state machine (FSM) that allows the robot to switch behaviours adapting to the acquired visual information. Experiments demonstrated the stability and convergence of the embedded hybrid system by real robots, including the studying of collective behaviour by a swarm of such robots with environment mediation. This research enables micro robots to run visual models with more complexity. Moreover, it showed the possibility to realize aggregation behaviour on micro robots by utilizing vision as the only sensing modality from non-omnidirectional cameras.}
}

@article{lincoln32296,
          volume = {2018},
          number = {10965},
           month = {August},
          author = {Khaled Elgeneidy and Pengcheng Liu and Simon Pearson and Niels Lohse and Gerhard Neumann},
           title = {Printable Soft Grippers with Integrated Bend Sensing for Handling of Crops},
       publisher = {Springer},
            year = {2018},
         journal = {Towards Autonomous Robotic Systems (TAROS) Conference},
             doi = {10.1007/978-3-319-96728-8},
           pages = {479--480},
        keywords = {ARRAY(0x56321343abe8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32296/},
        abstract = {Handling delicate crops without damaging or bruising is a challenge facing the au-tomation of tasks within the agri-food sector, which encourages the utilization of soft grippers that are inherently safe and passively compliant. In this paper we present a brief overview of the development of a printable soft gripper integrated with printable bend sensors. The softness of the gripper fingers allows delicate crops to be grasped gently, while the bend sensors are calibrated to measure bending and detect contact. This way the soft gripper not only benefits from the passive compliance of its soft fingers, but also demonstrates a sensor-guided approach for improved grasp control.}
}

@article{lincoln32850,
          volume = {3},
          number = {4},
           month = {July},
          author = {Francesco Del Duchetto and Ayse Kucukyilmaz and Luca Iocchi and Marc Hanheide},
            note = {{\copyright} 2018 IEEE},
           title = {Don't Make the Same Mistakes Again and Again: Learning Local Recovery Policies for Navigation from Human Demonstrations},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2861080},
           pages = {4084--4091},
        keywords = {ARRAY(0x56321343ac18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32850/},
        abstract = {In this paper, we present a human-in-the-loop learning framework for mobile robots to generate effective local policies in order to recover from navigation failures in long-term autonomy. We present an analysis of failure and recovery cases derived from long-term autonomous operation of a mobile robot, and propose a two-layer learning framework that allows to detect and recover from such navigation failures. Employing a learning by demonstration (LbD) approach, our framework can incrementally learn to autonomously recover from situations it initially needs humans to help with. The learning framework allows for both real-time failure detection and regression using Gaussian processes (GPs). Our empirical results on two different failure scenarios indicate that given 40 failure state observations, the true positive rate of the failure detection model exceeds 90\%, ending with successful recovery actions in more than 90\% of all detected cases.}
}

@inproceedings{lincoln47570,
           month = {July},
          author = {Mohamed Sellami and Mohammed Al-Khafajiy and Yacine Atif and Emir Ugljanin and Noura Faci and Thar Baker and Zakaria Maamar},
       booktitle = {Proceedings of the 13th International Conference on Software Technologies},
           title = {Cognitive Computing Meets the Internet of Things},
       publisher = {13th International Conference on Software Technologies},
             doi = {doi:10.5220/0006877507750780},
           pages = {775--780},
            year = {2018},
        keywords = {ARRAY(0x56321343ac48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47570/},
        abstract = {This paper discusses the blend of cognitive computing with the Internet-of-Things that should result into developing cognitive things. Today?s things are confined into a data-supplier role, which deprives them from being the technology of choice for smart applications development. Cognitive computing is about reasoning, learning, explaining, acting, etc. In this paper, cognitive things? features include functional and non-functional restrictions along with a 3 stage operation cycle that takes into account these restrictions during reasoning, adaptation, and learning. Some implementation details about cognitive things are included in this paper based on a water pipe case-study.}
}

@incollection{lincoln31671,
          volume = {10965},
           month = {July},
          author = {Qinbing Fu and Cheng Hu and Pengcheng Liu and Shigang Yue},
       booktitle = {M. Giuliani et al. (Eds.): TAROS 2018, LNAI},
           title = {Towards computational models of insect motion detectors for robot vision},
       publisher = {Springer International Publishing AG, part of Springer Nature 2018},
           pages = {465--467},
            year = {2018},
        keywords = {ARRAY(0x56321343ac78)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31671/},
        abstract = {In this essay, we provide a brief survey of computational models of insect motion detectors, and bio-robotic solutions to build fast and reliable motion-sensing systems for robot vision. Vision is an important sensing modality for autonomous robots, since it can extract abundant useful features from visually cluttered and dynamic environments. Fast development of computer vision technology facilitates the modeling of dynamic vision systems for mobile robots.}
}

@inproceedings{lincoln31679,
       booktitle = {19th Towards Autonomous Robotic Systems (TAROS) Conference},
           month = {July},
           title = {Towards real-time robotic motion planning for grasping in cluttered and uncertain environments},
          author = {Pengcheng Liu and Khaled Elgeneidy and Simon Pearson and Nazmul Huda and Gerhard Neumann},
       publisher = {Springer},
            year = {2018},
        keywords = {ARRAY(0x56321343aca8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31679/},
        abstract = {Adaptation to unorganized, congested and uncertain environment is a desirable capability but challenging task in development of robotic motion planning algorithms for object grasping. We have to make a tradeoff between coping with the environmental complexities using computational expensive approaches, and enforcing practical manipulation and grasping in real-time. In this paper, we present a brief overview and research objectives towards real-time motion planning for grasping in cluttered and uncertain environments. We present feasible ways in approaching this goal, in which key challenges and plausible solutions are discussed.}
}

@article{lincoln43298,
           month = {July},
           title = {ARDebug: An Augmented Reality
Tool for Analysing and Debugging
Swarm Robotic Systems},
          author = {Alan Millard and Richard Redpath and Jewers Alistair M. and Arndt Charlotte and Joyce Russell and Hilder James A. and McDaid Liam J. and Halliday David M.},
            year = {2018},
             doi = {10.3389/frobt.2018.00087},
         journal = {Frontiers in robotics and AI},
        keywords = {ARRAY(0x56321343acd8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43298/},
        abstract = {Despite growing interest in collective robotics over the past few years, analysing and
debugging the behaviour of swarm robotic systems remains a challenge due to the lack
of appropriate tools. We present a solution to this problem{--}ARDebug: an open-source,
cross-platform, and modular tool that allows the user to visualise the internal state of a
robot swarm using graphical augmented reality techniques. In this paper we describe the
key features of the software, the hardware required to support it, its implementation, and
usage examples. ARDebug is specifically designed with adoption by other institutions in
mind, and aims to provide an extensible tool that other researchers can easily integrate
with their own experimental infrastructure.}
}

@incollection{lincoln31672,
          volume = {10965},
           month = {July},
          author = {Cheng Hu and Qinbing Fu and Shigang Yue},
       booktitle = {Giuliani M., Assaf T., Giannaccini M. (eds) Towards Autonomous Robotic Systems. TAROS 2018. Lecture Notes in Computer Science},
          editor = {Manuel Giuliani and Tareq Assaf and Maria Elena Giannaccini},
           title = {Colias IV: The Affordable Micro Robot Platform with Bio-inspired Vision},
       publisher = {Springer},
            year = {2018},
             doi = {10.1007/978-3-319-96728-8\_17},
        keywords = {ARRAY(0x56321343ad08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31672/},
        abstract = {Vision is one of the most important sensing modalities for robots and has been realized on mostly large platforms. However for micro robots which are commonly utilized in swarm robotic studies, the visual ability is seldom applied or with only limited functions and resolution, due to the challenging requirements on the computation power and high data volume to deal with. This research has proposed the low-cost micro ground robot Colias IV, which is particularly designed to meet the requirements to allow embedded vision based tasks onboard, such as bio-inspired collision detection neural networks. Numerous of successful approaches have demonstrated that the proposed micro robot Colias IV to be a feasible platform for introducing visual based algorithms into swarm robotics.}
}

@inproceedings{lincoln40822,
           month = {July},
          author = {Philip J. Vance and Gautham Das and Sonya A. Coleman and Dermot Kerr and Emmett P. Kerr and Thomas M. McGinnity},
       booktitle = {2018 International Joint Conference on Neural Networks (IJCNN)},
           title = {Investigation into Sub-Receptive Fields of Retinal Ganglion Cells with Natural Images},
       publisher = {IEEE},
             doi = {10.1109/IJCNN.2018.8489324},
           pages = {1--8},
            year = {2018},
        keywords = {ARRAY(0x56321343ad38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40822/},
        abstract = {Determining the receptive field of a retinal ganglion cell is critically important when formulating a computational model that maps the relationship between the stimulus and response. This process is traditionally undertaken using reverse correlation to estimate the receptive field. By stimulating the retina with artificial stimuli, such as alternating checkerboards, bars or gratings and recording the neural response it is possible to estimate the cell?s receptive field by analysing the stimuli that produced the response. Artificial stimuli such as white noise is known to not stimulate the full range of the cell?s responses. By using natural image stimuli, it is possible to estimate the receptive field and obtain a resulting model that more accurately mimics the cells? responses to natural stimuli. This paper extends on previous work to seek further improvements in estimating a ganglion cell?s receptive field by considering that the receptive field can be divided into subunits. It is thought that these subunits may relate to receptive fields which are associated with bipolar retinal cells. The findings of this preliminary study show that by using subunits to define the receptive field we achieve a significant improvement over existing approaches when deriving computational models of the cell?s response.}
}

@inproceedings{lincoln31779,
       booktitle = {IEEE International Engineering in Medicine and Biology Conference},
           month = {July},
           title = {Thermal camera based physiological monitoring with an assistive robot},
          author = {Serhan Cosar and Zhi Yan and Feng Zhao and Tryphon Lambrou and Shigang Yue and Nicola Bellotto},
       publisher = {IEEE},
            year = {2018},
        keywords = {ARRAY(0x56321343ad68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31779/},
        abstract = {This paper presents a physiological monitoring system for assistive robots using a thermal camera. It is based on the detection of subtle changes in temperature observed on different parts of the face. First, we segment and estimate these face regions on thermal images. Then, by applying Fourier analysis on temperature data, we estimate respiration and heartbeat rate. This physiological monitoring system has been integrated in an assistive robot for elderly people at home, as part of the ENRICHME project. Its performance has been evaluated on a new thermal dataset for physiological monitoring, which is made publicly available for research purposes.}
}

@inproceedings{lincoln46151,
       booktitle = {2018 IEEE International Conference on Soft Robotics (RoboSoft)},
           month = {July},
           title = {Underwater soft jet propulsion based on a hoberman mechanism},
          author = {Saverio Iacoponi and Giacomo Picardi and Mrudul Chellapurath and Marcello Calisti and Laschi Cecilia},
            year = {2018},
           pages = {449--454},
             doi = {10.1109/ROBOSOFT.2018.8405367},
        keywords = {ARRAY(0x56321343ad98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46151/},
        abstract = {This paper presents the results of single pulsation tests aimed to evaluate the performance of a Hoberman sphere mechanism as an underwater jet propulsor. The tests were carried out in a fish tank and the position of the robot was visually tracked to estimate the speed and the contraction kinematic. Results suggest that, due to the great volume variation allowed by the Hoberman sphere, this system can reach similar performances in term of speed with respect to previous solutions, while it can improve the generated thrust.}
}

@article{lincoln32172,
          volume = {3},
          number = {4},
           month = {July},
          author = {Jaime Pulido Fentanes and Iain Gould and Tom Duckett and Simon Pearson and Grzegorz Cielniak},
           title = {3D Soil Compaction Mapping through Kriging-based Exploration with a Mobile Robot},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2849567},
           pages = {3066 --3072},
        keywords = {ARRAY(0x56321343adc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32172/},
        abstract = {This paper presents an automated method for creating spatial maps of soil condition with an outdoor mobile robot. Effective soil mapping on farms can enhance yields, reduce inputs and help protect the environment. Traditionally, data are collected manually at an arbitrary set of locations, then soil maps are constructed offline using kriging, a form of Gaussian process regression. This process is laborious and costly, limiting the quality and resolution of the resulting information. 
Instead, we propose to use an outdoor mobile robot for automatic collection of soil condition data, building soil maps online and also adapting the robot's exploration strategy on-the-fly based on the current quality of the map. We show how using kriging variance as a reward function for robotic exploration allows for both more efficient data collection and better soil models. This work presents the theoretical foundations for our proposal and an experimental comparison of exploration strategies using soil compaction data from a field generated with a mobile robot.}
}

@incollection{lincoln33007,
           month = {July},
          author = {Xuelong Sun and Michael Mangan and Shigang Yue},
            note = {This publication can be purchased online at https://www.springer.com/us/book/9783319959719},
       booktitle = {Biomimetic and Biohybrid Systems},
           title = {An Analysis of a Ring Attractor Model for Cue Integration},
       publisher = {Springer},
            year = {2018},
             doi = {https://doi.org/10.1007/978-3-319-95972-6\_49},
           pages = {459--470},
        keywords = {ARRAY(0x56321343adf8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33007/},
        abstract = {Animals and robots must constantly combine multiple streams of noisy information from their senses to guide their actions. Recently, it has been proposed that animals may combine cues optimally using a ring attractor neural network architecture inspired by the head direction system of rats augmented with a dynamic re-weighting mechanism. In this work we report that an older and simpler ring attractor network architecture, requiring no re-weighting property combines cues according to their certainty for moderate cue conflicts but converges on the most certain cue for larger conflicts. These results are consistent with observations in animal experiments that show sub-optimal cue integration and switching from cue integration to cue selection strategies. This work therefore demonstrates an alternative architecture for those seeking neural correlates of sensory integration in animals. In addition, performance is shown robust to noise and miniaturization and thus provides an efficient solution for artificial systems.}
}

@article{lincoln47563,
          volume = {1},
          number = {1},
           month = {July},
          author = {Bandar Aldawsari and Thar Baker and Muhammad Asim and Zakaria Maamar and Dhiya Al-Jumeily and Mohammed Al-Khafajiy},
           title = {A Survey of Resource Management Challenges in Multi-cloud Environment: Taxonomy and Empirical Analysis},
       publisher = {Azerbaijan State Oil and Industry University},
            year = {2018},
         journal = {Azerbaijan Journal of High Performance Computing},
             doi = {doi:10.32010/26166127.2018.1.1.51.65},
           pages = {51--65},
        keywords = {ARRAY(0x56321343ae28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47563/},
        abstract = {Cloud computing has seen a great deal of interest by researchers and  industrial  firms  since  its  first  coined.  Different  perspectives and  research  problems,  such  as  energy  efficiency,  security  and threats, to name but a few, have been dealt with and addressed from cloud computing perspective. However, cloud computing environment still encounters a major challenge of how to allocate and  manage  computational  resources  efficiently.  Furthermore, due to the different architectures and cloud computing networks and models used (i.e., federated clouds, VM migrations, cloud brokerage), the complexity of resource management in the cloud has been increased dramatically. Cloud providers and service consumers have the cloud brokers working as the intermediaries between them, and the confusion among the cloud computing parties (consumers, brokers, data centres and service providers) on who is responsible for managing the request of cloud resources is a key issue. In a traditional scenario, upon renting the various cloud resources from the providers, the cloud brokers engage in subletting and managing these resources to the service consumers. However, providers? usually deal with many brokers, and vice versa, and any dispute of any kind between the providers and the brokers will lead to service unavailability, in which  the  consumer  is  the  only  victim.  Therefore,  managing  cloud resources and services still needs a lot of attention and effort. This paper expresses the survey on the systems of the cloud brokerage resource management issues in multi-cloud environments.}
}

@book{lincoln34555,
           month = {June},
           title = {Green Supply Chain Management},
          author = {Charisios Achillas and Dionysis Bochtis and Dimitrios Aidonis and Dimitris Folinas},
       publisher = {Routledge},
            year = {2018},
        keywords = {ARRAY(0x56321343ae58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34555/},
        abstract = {Today, one of the top priorities of an organization?s modern corporate strategy is to portray itself as socially responsible and environmentally sustainable. As a focal point of sustainability initiatives, green supply chain management has emerged as a key strategy that can provide competitive advantages with significant parallel gains for company profitability. In designing a green supply chain, the intent is the adoption of comprehensive and cross-business sustainability principles, from the product conception stage to the end-of-life stage. In this context, green initiatives relate to tangible and intangible corporate benefits. Sustainability reports from numerous companies reveal that greening their supply chains has helped reduce operating cost, thus boosting effectiveness and efficiency while increasing sustainability of the business.

Green Supply Chain Management provides a strategic overview of sustainable supply chain management, shedding light on the theoretical background and key principles of the topic. Specifically, this book covers various thematic areas including benefits and impact of green supply chain management; enablers and barriers on supply chain operations; inbound and outbound logistics considerations; and production, packaging and reverse logistics under the notion of "greening". The ultimate aim of this textbook is to highlight the challenges in the implementation of green supply chain management in modern companies and to provide a roadmap for decision-making in real-life cases.

Combining chapter summaries and discussion questions, this book provides an accessible and student-friendly introduction to green supply change management and will be of great interest to students, scholars and practitioners in the fields of sustainable business and supply chain management.}
}

@article{lincoln31634,
          volume = {98},
           month = {June},
          author = {Petra Bosilj and Tom Duckett and Grzegorz Cielniak},
           title = {Connected attribute morphology for unified vegetation segmentation and classification in precision agriculture},
       publisher = {Elsevier},
            year = {2018},
         journal = {Computers in Industry},
             doi = {10.1016/j.compind.2018.02.003},
           pages = {226--240},
        keywords = {ARRAY(0x56321343ae88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31634/},
        abstract = {Discriminating value crops from weeds is an important task in precision agriculture. In this paper, we propose a novel image processing pipeline based on attribute morphology for both the segmentation and classification tasks. The commonly used approaches for vegetation segmentation often rely on thresholding techniques which reach their decisions globally. By contrast, the proposed method works with connected components obtained by image threshold decomposition, which are naturally nested in a hierarchical structure called the max-tree, and various attributes calculated from these regions. Image segmentation is performed by attribute filtering, preserving or discarding the regions based on their attribute value and allowing for the decision to be reached locally. This segmentation method naturally selects a collection of foreground regions rather than pixels, and the same data structure used for segmentation can be further reused to provide the features for classification, which is realised in our experiments by a support vector machine (SVM). We apply our methods to normalised difference vegetation index (NDVI) images, and demonstrate the performance of the pipeline on a dataset collected by the authors in an onion field, as well as a publicly available dataset for sugar beets. The results show that the proposed segmentation approach can segment the fine details of plant regions locally, in contrast to the state-of-the-art thresholding methods, while providing discriminative features which enable efficient and competitive classification rates for crop/weed discrimination.}
}

@article{lincoln41511,
          volume = {170},
           month = {June},
          author = {Junfeng Gao and David Nuyttens and Peter Lootens and Yong He and Jan Pieters},
           title = {Recognising weeds in a maize crop using a random forest machine-learning algorithm and near-infrared snapshot mosaic hyperspectral imagery},
       publisher = {Elsevier},
            year = {2018},
         journal = {Biosystems Engineering},
             doi = {10.1016/j.biosystemseng.2018.03.006},
           pages = {39--50},
        keywords = {ARRAY(0x56321343aeb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41511/},
        abstract = {This study explores the potential of a novel hyperspectral snapshot mosaic camera forweed and maize classification. The image processing, feature engineering and machinelearning techniques were discussed when developing an optimal classification model forthe three kinds of weeds and maize. A total set of 185 spectral features includingreflectance and vegetation index features was constructed. Subsequently, the principalcomponent analysis was used to reduce the redundancy of the constructed features, andthe first 5 principal components, explaining over 95\% variance ratio, were kept for furtheranalysis. Furthermore, random forests as one of machine learning techniques were builtfor developing the classifier with three different combinations of features. Accuracy-oriented feature reduction was performed when choosing the optimal number of fea-tures for building the classification model. Moreover, hyperparameter tuning wasexplored for the optimal selection of random forest model. The results showed that theoptimal random forest model with 30 important spectral features can achieve a meancorrect classification rate of 1.0, 0.789, 0.691 and 0.752 forZea mays,Convolvulus arvensis,RumexandCirsium arvense, respectively. The McNemar test showed an overall betterperformance of the optimal random forest model at the 0.05 significance level comparedto the k-nearest neighbours (KNN) model.}
}

@inproceedings{lincoln42421,
       booktitle = {4th International Conference on Event-Based Control, Communication and Signal Processing},
           month = {June},
           title = {PRED18: Dataset and Further Experiments with DAVIS Event Camera in Predator-Prey Robot Chasing},
          author = {Diederik Paul Moyes and Daniel Neil and Federico Corradi and Emmett Kerr and Philip Vance and Gautham Das and Sonya A. Coleman and Thomas M. McGinnity and Dermot Kerr and Tobi Delbruck},
            year = {2018},
        keywords = {ARRAY(0x56321343aee8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42421/},
        abstract = {Machine vision systems using convolutional neural networks (CNNs) for robotic applications are increasingly being developed. Conventional vision CNNs are driven by camera frames at constant sample rate, thus achieving a fixed latency and power consumption tradeoff. This paper describes further work on the first experiments of a closed-loop robotic system integrating a CNN together with a Dynamic and Active Pixel Vision Sensor (DAVIS) in a predator/prey scenario. The DAVIS, mounted on the predator Summit XL robot, produces frames at a fixed 15 Hz frame-rate and Dynamic Vision Sensor (DVS) histograms containing 5k ON and OFF events at a variable frame-rate ranging from 15-500 Hz depending on the robot speeds. In contrast to conventional frame-based systems, the latency and processing cost depends on the rate of change of the image. The CNN is trained offline on the 1.25h labeled dataset to recognize the position and size of the prey robot, in the field of view of the predator. During inference, combining the ten output classes of the CNN allows extracting the analog position vector of the prey relative to the predator with a mean 8.7\% error in angular estimation. The system is compatible with conventional deep learning technology, but achieves a variable latency-power tradeoff that adapts automatically to the dynamics. Finally, investigations on the robustness of the algorithm, a human performance comparison and a deconvolution analysis are also explored.}
}

@inproceedings{lincoln47569,
           month = {June},
          author = {Mohammed Al-Khafajiy and Lee Webster and Thar Baker and Atif Waraich},
       booktitle = {Proceedings of the 2nd International Conference on Future Networks and Distributed Systems},
           title = {Towards fog driven IoT healthcare: challenges and framework of fog computing in healthcare},
       publisher = {ACM},
             doi = {10.1145/3231053.3231062},
           pages = {1--7},
            year = {2018},
        keywords = {ARRAY(0x56321343af18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47569/},
        abstract = {As we are within the era of the internet of things (IoT) its increasing integration to our everyday lives means that the devices involved produce massive amounts of data every second from billions of devices. The current approach used to handle this data is cloud computing. However because of its requirement of data centres this can become infeasible for the processing of data from IoT due to distance between these IoT smart objects (e.g., sensors) and the data centre. If this data holds any importance to minimal delay then the travel time between the end device and the clouds data centre could affect the relevance of that data. Therefore, to deal with these issues a new network paradigm placed closer to the IoT end devices is introduced called "Fog computing" to help address these challenges. If introduced effectively then fog computing can lead to the improvements in the quality of service (QoS) offered to systems that require the processing of delay sensitive data like healthcare systems that could benefit from the quick processing of data from sensors to allow the monitoring of patients. This paper has a main focus on healthcare systems. An architecture containing three layers; things (i.e., sensors), fog nodes and a cloud data centre is proposed alongside a framework incorporating this architecture. This framework offers collaboration among fog nodes with optimal management of resources and job allocation, which is able to achieve a high QoS (i.e., low latency) within the scenario of a healthcare system.}
}

@inproceedings{lincoln31363,
       booktitle = {14th International Conference on Precision Agriculture},
           month = {June},
           title = {Rumex and Urtica detection in grassland by UAV},
          author = {Adam Binch and Nigel Cooke and Charles Fox},
       publisher = {14th International Conference on Precision Agriculture},
            year = {2018},
        keywords = {ARRAY(0x56321343af48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31363/},
        abstract = {. Previous work (Binch \& Fox, 2017) used autonomous ground robotic platforms to successfully detect Urtica (nettle) and Rumex (dock) weeds in grassland, to improve farm productivity and the environment through precision herbicide spraying. It assumed that ground robots swathe entire fields to both detect and spray weeds, but this is a slow process as the slow ground platform must drive over every square meter of the field even where there are no weeds. The present study examines a complimentary approach, using unmanned aerial vehicles (UAVs) to perform faster detections, in order to inform slower ground robots of weed location and direct them to spray them from the ground. In a controlled study, it finds that the existing state-of-the-art (Binch \& Fox, 2017) ground detection algorithm based on local binary patterns and support vector machines is easily re-usable from a UAV with 4K camera despite large differences in camera type, distance, perspective and motion, without retraining. The algorithm achieves 83-95\% accuracy on ground platform data with 1-3 independent views, and improves to 90\% from single views on aerial data. However this is only attainable at low altitudes up to 8 feet, speeds below 0.3m/s, and a vertical view angle, suggesting that autonomous or manual UAV swathing is required to cover fields, rather than use of a single high-altitude photograph. This demonstrates for the first time that combined aerial detection with ground spraying system is feasible for Rumex and Urtica in grassland, using UAVs to replace the swathing and detection of weeds then dispatching ground platforms to spray them at the detection sites (as spraying by UAV is illegal in EU countries). This reduces total time requires to spray as the UAV performs the survey stage faster than a ground platform.}
}

@techreport{lincoln32517,
           month = {June},
            type = {Other},
           title = {Agricultural Robotics: The Future of Robotic Agriculture},
          author = {Tom Duckett and Simon Pearson and Simon Blackmore and Bruce Grieve and Wen-Hua Chen and Grzegorz Cielniak and Jason Cleaversmith and Jian Dai and Steve Davis and Charles Fox and Pal From and Ioannis Georgilas and Richie Gill and Iain Gould and Marc Hanheide and Fumiya Iida and Lyudmila Mihalyova and Samia Nefti-Meziani and Gerhard Neumann and Paolo Paoletti and Tony Pridmore and Dave Ross and Melvyn Smith and Martin Stoelen and Mark Swainson and Sam Wane and Peter Wilson and Isobel Wright and Guang-Zhong Yang},
       publisher = {UK-RAS Network White Papers},
            year = {2018},
     institution = {UK-RAS Network White Papers},
        keywords = {ARRAY(0x56321343af78)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32517/},
        abstract = {Agri-Food is the largest manufacturing sector in the UK. It supports a food chain that generates over {\pounds}108bn p.a., with 3.9m employees in a truly international industry and exports {\pounds}20bn of UK manufactured goods. However, the global food chain is under pressure from population growth, climate change, political pressures affecting migration, population drift from rural to urban regions and the demographics of an aging global population. These challenges are recognised in the UK Industrial Strategy white paper and backed by significant investment via a Wave 2 Industrial Challenge Fund Investment ("Transforming Food Production: from Farm to Fork"). Robotics and Autonomous Systems (RAS) and associated digital technologies are now seen as enablers of this critical food chain transformation. To meet these challenges, this white paper reviews the state of the art in the application of RAS in Agri-Food production and explores research and innovation needs to ensure these technologies reach their full potential and deliver the necessary impacts in the Agri-Food sector.}
}

@misc{lincoln33091,
           month = {June},
           title = {Radio 4 interview, Farming Today, on agri-robotics},
          author = {Charles Fox},
       publisher = {BBC Radio 4},
            year = {2018},
         journal = {Farming Today},
        keywords = {ARRAY(0x56321343afa8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33091/},
        abstract = {Interview on Radio4 Farming today about the future of agricultural robotics.}
}

@inproceedings{lincoln40820,
          volume = {172},
           month = {June},
          author = {Monish Koshy and S. Sreevishnu and Anjai Krishnan and Gautham Das},
       booktitle = {International Conference on Design, Analysis, Manufacturing and Simulation (ICDAMS)},
           title = {Kinematic Design, Analysis and Simulation of a Hybrid Robot with Terrain and Aerial Locomotion Capability},
       publisher = {EDP Sciences},
            year = {2018},
         journal = {MATEC Web of Conferences},
             doi = {10.1051/matecconf/201817203008},
           pages = {03008},
        keywords = {ARRAY(0x56321343afd8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40820/},
        abstract = {Having only one type of locomotion mechanism limits the stability and locomotion capability of a mobile robot on irregular terrain surfaces. One of the possible solution to this is combining more than one locomotion mechanisms in the robot. In this paper, robotic platform composed of a quadruped module for terrain locomotion and quadrotor module for aerial locomotion is introduced. This design is inspired by the way which birds are using their wings and legs for stability in slopped and uneven surfaces. The main idea is to combine the two systems in such a way that the strengths of both subsystems are used, and the weakness of the either systems are covered. The ability of the robot to reach the target position quickly and to avoid large terrestrial obstacles by flying expands its application in various areas of search and rescue. The same platform can be used for detailed 3D mapping and aerial mapping which are very helpful in rescue operations. In particular, this paper presents kinematic design, analysis and simulation of such a robotic system. Simulation and verification of results are done using MATLAB.}
}

@inproceedings{lincoln40821,
          volume = {172},
           month = {June},
          author = {Monish Koshy and S. Sreevishnu and Anjai Krishnan and Gautham Das},
       booktitle = {International Conference on Design, Analysis, Manufacturing and Simulation (ICDAMS)},
           title = {Mechanical Design and Analysis of Hybrid Mobile Robot with Aerial and Terrain Locomotion Capability},
       publisher = {EDP Sciences},
            year = {2018},
         journal = {MATEC Web of Conferences},
             doi = {10.1051/matecconf/201817203007},
           pages = {03007},
        keywords = {ARRAY(0x56321343b008)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40821/},
        abstract = {Although different locomotion mechanisms are available, the use of only one locomotion system in a mobile robot restricts its application scenarios. Hybrid locomotion improves the maneuverability and flexibility of a robot. This paper introduces a hybrid locomotion mobile robot, a combination of quadruped and quadrotor system. The robot has a unique expediency to fly to remote places, then walk to perform close range operations in the field. The prime intention is to use the quadrotor to tackle large objects by flying over it. The four legs provide easy movements in uneven terrain. Thus, this robot can be used in erratic and dynamic environments where stability, maneuverability and flexibility are required. This system can be used as first responders in search and rescue missions, where it responds before human responders gets to the site and get the entire information of the area in detail (like spotting trapped ones, getting detailed 3D mapping etc.). This platform offers unique capabilities suited for search and rescue, disaster zone assistance and surveillances. This paper elucidates the mechanical design and analysis of a hybrid locomotion robot. The solid model of the robot was made using CATIA and further analysis like static analysis, computational fluid dynamics analysis and drop test analysis were performed in ANSYS.}
}

@inproceedings{lincoln32484,
       booktitle = {Proceedings of the 15th International Conference on Intelligent Autonomous Systems},
           month = {June},
           title = {Filtration analysis of pedestrian-vehicle interactions for autonomous vehicle control},
          author = {Fanta Camara and Charles Fox},
       publisher = {15th International Conference on Intelligent Autonomous Systems},
            year = {2018},
        keywords = {ARRAY(0x56321343b038)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32484/},
        abstract = {Abstract. Interacting with humans remains a challenge for autonomous
vehicles (AVs). When a pedestrian wishes to cross the road in front of the
vehicle at an unmarked crossing, the pedestrian and AV must compete
for the space, which may be considered as a game-theoretic interaction in
which one agent must yield to the other. To inform development of new
real-time AV controllers in this setting, this study collects and analy-
ses detailed, manually-annotated, temporal data from real-world human
road crossings as they interact with manual drive vehicles. It studies the
temporal orderings (filtrations) in which features are revealed to the ve-
hicle and their informativeness over time. It presents a new framework
suggesting how optimal stopping controllers may then use such data to
enable an AV to decide when to act (by speeding up, slowing down, or
otherwise signalling intent to the pedestrian) or alternatively, to continue
at its current speed in order to gather additional information from new
features, including signals from that pedestrian, before acting itself.}
}

@article{lincoln43297,
           month = {June},
           title = {The Need for Combining Implicit and
Explicit Communication in
Cooperative Robotic Systems},
          author = {Naomi Gildert and Alan Millard and Andrew Pomfret and Jon Timmis},
            year = {2018},
             doi = {10.3389/frobt.2018.00065},
         journal = {Frontiers in Robotics and AI},
        keywords = {ARRAY(0x56321343b068)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43297/},
        abstract = {As the number of robots used in warehouses and manufacturing increases, so too does
the need for robots to be able to manipulate objects, not only independently, but also
in collaboration with humans and other robots. Our ability to effectively coordinate our
actions with fellow humans encompasses several behaviours that are collectively referred
to as joint action, and has inspired advances in human-robot interaction by leveraging
our natural ability to interpret implicit cues. However, our capacity to efficiently coordinate
on object manipulation tasks remains an advantageous process that is yet to be fully
exploited in robotic applications. Humans achieve this form of coordination by combining
implicit communication (where information is inferred) and explicit communication (direct
communication through an established channel) in varying degrees according to the task
at hand. Although these two forms of communication have previously been implemented
in robotic systems, no system exists that integrates the two in a task-dependent adaptive
manner. In this paper, we review existing work on joint action in human-robot interaction,
and analyse the state-of-the-art in robot-robot interaction that could act as a foundation
for future cooperative object manipulation approaches. We identify key mechanisms that
must be developed in order for robots to collaborate more effectively, with other robots
and humans, on object manipulation tasks in shared autonomy spaces.}
}

@article{lincoln32874,
          volume = {140},
          number = {6},
           month = {June},
          author = {Pal From and Lars Grimstad and Marc Hanheide and Simon Pearson and Grzegorz Cielniak},
           title = {RASberry - Robotic and Autonomous Systems for Berry Production},
       publisher = {ASME},
            year = {2018},
         journal = {Mechanical Engineering Magazine Select Articles},
             doi = {10.1115/1.2018-JUN-6},
        keywords = {ARRAY(0x56321343b098)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32874/},
        abstract = {The soft fruit industry is facing unprecedented challenges due to its reliance of manual labour. We are presenting a newly launched robotics initiative which will help to address the issues faced by the industry and enable automation of the main processes involved in soft fruit production. The RASberry project (Robotics and Autonomous Systems for Berry Production) aims to develop autonomous fleets of robots for horticultural industry. To achieve this goal, the project will bridge several current technological gaps including the development of a mobile platform suitable for the strawberry fields, software components for fleet management, in-field navigation and mapping, long-term operation, and safe human-robot collaboration.
In this paper, we provide a general overview of the project, describe the main system components, highlight interesting challenges from a control point of view and then present three specific applications of the robotic fleets in soft fruit production. The applications demonstrate how robotic fleets can benefit the soft fruit industry by significantly decreasing production costs, addressing labour shortages and being the first step towards fully autonomous robotic systems for agriculture.}
}

@unpublished{lincoln39627,
       booktitle = {Amazing Technology Symposium},
           month = {June},
           title = {Design of a bendable and steerable robotic uterine elevator},
          author = {Chakravarthini M. Saaj and Seri Mustaza and Kavitha Madhuri and Simon Butler-Manuel},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39627/}
}

@article{lincoln32403,
          volume = {8},
          number = {4},
           month = {June},
          author = {Andrew Schofield and Iain Gilchrist and Marina Bloj and Ales Leonardis and Nicola Bellotto},
           title = {Understanding images in biological and computer vision},
       publisher = {The Royal Society},
            year = {2018},
         journal = {Interface Focus},
             doi = {10.1098/rsfs.2018.0027},
           pages = {1--3},
        keywords = {ARRAY(0x56321343b0f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32403/},
        abstract = {This issue of Interface Focus is a collection of papers arising out of a Royal Society Discussion meeting entitled ?Understanding images in biological and computer vision? held at Carlton Terrace on the 19th and 20th February, 2018. There is a strong tradition of inter-disciplinarity in the study of visual perception and visual cognition. Many of the great natural scientists including Newton [1], Young [2] and Maxwell (see [3]) were intrigued by the relationship between light, surfaces and perceived colour considering both physical and perceptual processes. Brewster [4] invented both the lenticular stereoscope and the binocular camera but also studied the perception of shape-from-shading. More recently, Marr's [5] description of visual perception as an information processing problem led to great advances in our understanding of both biological and computer vision: both the computer vision and biological vision communities have a Marr medal. The recent successes of deep neural networks in classifying the images that we see and the fMRI images that reveal the activity in our brains during the act of seeing are both intriguing. The links between machine vision systems and biology may at sometimes be weak but the similarity of some of the operations is nonetheless striking [6]. This two-day meeting brought together researchers from the fields of biological and computer vision, robotics, neuroscience, computer science and psychology to discuss the most recent developments in the field. The meeting was divided into four themes: vision for action, visual appearance, vision for recognition and machine learning.}
}

@unpublished{lincoln39626,
       booktitle = {14th International Symposium on Artificial Intelligence, Robotics and Automation in Space (i-SAIRAS 2018),},
           month = {June},
           title = {H{\ensuremath{\alpha}} Controller for a Free-flying Robotic Spacecraft},
          author = {Asma Seddaoui and Chakravarthini Mini Saaj},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39626/}
}

@article{lincoln41512,
          volume = {67},
           month = {May},
          author = {Junfeng Gao and wenzhi Liao and David Nuyttens and Peter Lootens and J{\"u}rgen Vangeyte and Aleksandra Pi{\v z}urica and Yong He and Jan G. Pieters},
           title = {Fusion of pixel and object-based features for weed mapping using unmanned aerial vehicle imagery},
       publisher = {Elsevier},
            year = {2018},
         journal = {International Journal of Applied Earth Observation and Geoinformation},
             doi = {10.1016/j.jag.2017.12.012},
           pages = {43--53},
        keywords = {ARRAY(0x56321343b158)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41512/},
        abstract = {The developments in the use of unmanned aerial vehicles (UAVs) and advanced imaging sensors provide new opportunities for ultra-high resolution (e.g., less than a 10cm ground sampling distance (GSD)) crop field monitoring and mapping in precision agriculture applications. In this study, we developed a strategy for inter- and intra-row weed detection in early season maize fields from aerial visual imagery. More specifically, the Hough transform algorithm (HT) was applied to the orthomosaicked images for inter-row weed detection. A semi-automatic Object-Based Image Analysis (OBIA) procedure was developed with Random Forests (RF) combined with feature selection techniques to classify soil, weeds and maize. Furthermore, the two binary weed masks generated from HT and OBIA were fused for accurate binary weed image. The developed RF classifier was evaluated by 5-fold cross validation, and it obtained an overall accuracy of 0.945, and Kappa value of 0.912. Finally, the relationship of detected weeds and their ground truth densities was quantified by a fitted linear model with a coefficient of determination of 0.895 and a root mean square error of 0.026. Besides, the importance of input features was evaluated, and it was found that the ratio of vegetation length and width was the most significant feature for the classification model. Overall, our approach can yield a satisfactory weed map, and we expect that the obtained accurate and timely weed map from UAV imagery will be applicable to realize site-specific weed management (SSWM) in early season crop fields for reducing spraying non-selective herbicides and costs.}
}

@inproceedings{lincoln32170,
       booktitle = {IEEE International Conference on Robotics and Automation, Workshop on Robotic Vision and Action in Agriculture},
           month = {May},
           title = {Discrete Event Simulations for Scalability Analysis of Robotic In-Field Logistics in Agriculture ? A Case Study},
          author = {Gautham Das and Grzegorz Cielniak and Pal From and Marc Hanheide},
            year = {2018},
        keywords = {ARRAY(0x56321343b188)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32170/},
        abstract = {Agriculture lends itself to automation due to its labour-intensive processes and the strain posed on workers in the domain. This paper presents a discrete event simulation (DES) framework allowing to rapidly assess different processes and layouts for in-field logistics operations employing a fleet of autonomous transportation robots supporting soft-fruit pickers. The proposed framework can help to answer pressing questions regarding the economic viability and scalability of such fleet operations, which we illustrate and discuss in the context of a specific case study considering strawberry picking operations. In particular, this paper looks into the effect of a robotic fleet in scenarios with different transportation requirements, as well as on the effect of allocation algorithms, all without requiring resource demanding field trials. The presented framework demonstrates a great potential for future development and optimisation of the efficient robotic fleet operations in agriculture.}
}

@inproceedings{lincoln32171,
       booktitle = {ICRA 2018 Workshop on Robotic Vision and Action in Agriculture},
           month = {May},
           title = {Soil Compaction Mapping Through Robot Exploration: A Study into Kriging Parameters},
          author = {Jaime Pulido Fentanes and Iain Gould and Tom Duckett and Simon Pearson and Grzegorz Cielniak},
       publisher = {IEEE},
            year = {2018},
        keywords = {ARRAY(0x56321343b1b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32171/},
        abstract = {Soil condition mapping is a manual, laborious and costly process which requires soil measurements to be taken at fixed, pre-defined locations, limiting the quality of the resulting information maps. For these reasons, we propose the use of an outdoor mobile robot equipped with an actuated soil probe for automatic mapping of soil condition, allowing for both, more efficient data collection and better soil models. The robot is building soil models on-line using standard geo-statistical methods such as kriging, and is using the quality of the model to drive the exploration. In this work, we take a closer look at the kriging process itself and how its parameters affect the exploration outcome. For this purpose, we employ soil compaction datasets collected from two real fields of varying characteristics and analyse how the parameters vary between fields and how they change during the exploration process. We particularly focus on the stability of the kriging parameters, their evolution over the exploration process and influence on the resulting soil maps.}
}

@inproceedings{lincoln31674,
       booktitle = {IEEE International Conference on Robotics and Automation},
           month = {May},
           title = {Learning robust policies for object manipulation with robot swarms},
          author = {G. H. W. Gebhardt and K. Daun and M. Schnaubelt and G. Neumann},
            year = {2018},
        keywords = {ARRAY(0x56321343b1e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31674/},
        abstract = {Swarm robotics investigates how a large population of robots with simple actuation and limited sensors can collectively solve complex tasks. One particular interesting application with robot swarms is autonomous object assembly.
Such tasks have been solved successfully with robot swarms that are controlled by a human operator using a light source.
In this paper, we present a method to solve such assembly tasks autonomously based on policy search methods. We split the assembly process in two subtasks: generating a high-level assembly plan and learning a low-level object movement policy.  The assembly policy plans the trajectories for each object and the object movement policy controls the trajectory execution.  Learning the object movement policy is challenging as it depends on the complex state of the swarm which consists of an individual state for each agent. To approach this problem, we introduce a representation of the swarm which is based on Hilbert space embeddings of distributions. This representation is invariant to the number of agents in the swarm as well as to the allocation of an agent to its position in the swarm.  These invariances make the learned policy robust to changes in the swarm and also reduce the search space for the policy search method significantly. We show that the resulting system is able to solve assembly tasks with varying object shapes in multiple simulation scenarios and evaluate the robustness of our representation to changes in the swarm size. Furthermore, we demonstrate that the policies learned in simulation are robust enough to be transferred to real robots.}
}

@inproceedings{lincoln30920,
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           month = {May},
           title = {Robust learning of object assembly tasks with an invariant representation of robot swarms},
          author = {G. H. W. Gebhardt and K. Daun and M. Schnaubelt and G. Neumann},
            year = {2018},
        keywords = {ARRAY(0x56321343b218)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30920/},
        abstract = {{--} Swarm robotics investigates how a large population of robots with simple actuation and limited sensors can collectively solve complex tasks. One particular interesting application with robot swarms is autonomous object assembly. Such tasks have been solved successfully with robot swarms that are controlled by a human operator using a light source. In this paper, we present a method to solve such assembly tasks autonomously based on policy search methods. We split the assembly process in two subtasks: generating a high-level assembly plan and learning a low-level object movement policy. The assembly policy plans the trajectories for each object and the object movement policy controls the trajectory execution.
Learning the object movement policy is challenging as it depends on the complex state of the swarm which consists of an individual state for each agent. To approach this problem, we introduce a representation of the swarm which is based on Hilbert space embeddings of distributions. This representation is invariant to the number of agents in the swarm as well as to the allocation of an agent to its position in the swarm.  These invariances make the learned policy robust to changes in the swarm and also reduce the search space for the policy search method significantly. We show that the resulting system is able to solve assembly tasks with varying object shapes in multiple simulation scenarios and evaluate the robustness of our representation to changes in the swarm size. Furthermore, we demonstrate that the policies learned in simulation are robust enough to be transferred to real robots.}
}

@inproceedings{lincoln31686,
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           month = {May},
           title = {Learning coupled forward-inverse models with combined prediction errors},
          author = {D. Koert and G. Maeda and G. Neumann and J. Peters},
            year = {2018},
        keywords = {ARRAY(0x56321343b248)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31686/},
        abstract = {Challenging tasks in unstructured environments require robots to learn complex models. Given a large amount of information, learning multiple simple models can offer an efficient alternative to a monolithic complex network. Training multiple models{--}that is, learning their parameters and their responsibilities{--}has been shown to be prohibitively hard as optimization is prone to local minima. To efficiently learn multiple models for different contexts, we thus develop a new algorithm based on expectation maximization (EM). In contrast to comparable concepts, this algorithm trains multiple modules of paired forward-inverse models by using the prediction errors of both forward and inverse models simultaneously.  In particular, we show that our method yields a substantial improvement over only considering the errors of the forward models on tasks where the inverse space contains multiple solutions}
}

@incollection{lincoln30916,
           month = {May},
          author = {Nicola Bellotto and Serhan Cosar and Zhi Yan},
       booktitle = {Encyclopedia of Robotics},
          editor = {M. H. Ang and O. Khatib and B. Siciliano},
           title = {Human detection and tracking},
       publisher = {Springer},
             doi = {10.1007/978-3-642-41610-1\_34-1},
            year = {2018},
        keywords = {ARRAY(0x56321343b278)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30916/},
        abstract = {In robotics, detecting and tracking moving objects is key to implementing useful and safe robot behaviours. Identifying which of the detected objects are humans is particularly important for domestic and public environments.
Typically the robot is required to collect environmental data of the surrounding area using its on-board sensors, estimating where humans are and where they are going to. Moreover, robots should detect and track humans accurately and as early as possible in order to have enough time to react accordingly}
}

@article{lincoln32026,
           month = {May},
          author = {Subhajit Basu and Adekemi Omotubora and Charles Fox},
           title = {Legal framework for small autonomous agricultural robots},
       publisher = {Springer},
         journal = {AI and Society},
             doi = {10.1007/s00146-018-0846-4},
           pages = {1--22},
            year = {2018},
        keywords = {ARRAY(0x56321343b2a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32026/},
        abstract = {Legal structures may form barriers to, or enablers of, adoption of precision agriculture management with small autonomous
agricultural robots. This article develops a conceptual regulatory framework for small autonomous agricultural robots, from
a practical, self-contained engineering guide perspective, sufficient to get working research and commercial agricultural
roboticists quickly and easily up and running within the law. The article examines the liability framework, or rather lack of
it, for agricultural robotics in EU, and their transpositions to UK law, as a case study illustrating general international legal
concepts and issues. It examines how the law may provide mitigating effects on the liability regime, and how contracts can
be developed between agents within it to enable smooth operation. It covers other legal aspects of operation such as the use
of shared communications resources and privacy in the reuse of robot-collected data. Where there are some grey areas in
current law, it argues that new proposals could be developed to reform these to promote further innovation and investment
in agricultural robots}
}

@article{lincoln40819,
          volume = {29},
          number = {5},
           month = {May},
          author = {Philip J. Vance and Gautham Das and Dermot Kerr and Sonya A. Coleman and T. Martin McGinnity and Tim Gollisch and Jian K. Liu},
           title = {Bioinspired Approach to Modeling Retinal Ganglion Cells Using System Identification Techniques},
            year = {2018},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
             doi = {10.1109/TNNLS.2017.2690139},
           pages = {1796--1808},
        keywords = {ARRAY(0x56321343b2d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40819/},
        abstract = {The processing capabilities of biological vision systems are still vastly superior to artificial vision, even though this has been an active area of research for over half a century. Current artificial vision techniques integrate many insights from biology yet they remain far-off the capabilities of animals and humans in terms of speed, power, and performance. A key aspect to modeling the human visual system is the ability to accurately model the behavior and computation within the retina. In particular, we focus on modeling the retinal ganglion cells (RGCs) as they convey the accumulated data of real world images as action potentials onto the visual cortex via the optic nerve. Computational models that approximate the processing that occurs within RGCs can be derived by quantitatively fitting the sets of physiological data using an input?output analysis where the input is a known stimulus and the output is neuronal recordings. Currently, these input?output responses are modeled using computational combinations of linear and nonlinear models that are generally complex and lack any relevance to the underlying biophysics. In this paper, we illustrate how system identification techniques, which take inspiration from biological systems, can accurately model retinal ganglion cell behavior, and are a viable alternative to traditional linear?nonlinear approaches.}
}

@inproceedings{lincoln32195,
           month = {May},
          author = {Andrey Postnikov and Argyrios Zolotas and Chris Bingham and Ibrahim Saleh and Corneliu Arsene and Simon Pearson and Ronald Bickerton},
       booktitle = {2017 European Modelling Symposium (EMS)},
           title = {Modelling of Thermostatically Controlled Loads to Analyse the Potential of Delivering FFR DSR with a Large Network of Compressor Packs},
       publisher = {IEEE},
             doi = {doi:10.1109/EMS.2017.37},
           pages = {163--167},
            year = {2018},
        keywords = {ARRAY(0x56321343b308)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32195/},
        abstract = {This paper presents preliminary work from a current study on large refrigeration pack network. In particular, the simulation model of a typical refrigeration system with a single pack of 6 compressor units operating as fixed volume displacement machines is presented, and the potential of delivering static FFR with a large population of such packs is studied. Tuning of the model is performed using experimental data collected at the Refrigeration Research Centre in Riseholme, Lincoln. The purpose of modelling is to monitor the essential dynamics of what resembles a typical supermarket convenience-type store and to measure the capacity of a massive refrigeration network to hold off a considerable amount of load in response to FFR DSR event. This study focuses on investigation of the aggregated response of 150 packs (approx. 1 MW capacity) with refrigeration cases on hysteresis and modulation control. The presented model captures interconnected dynamics (refrigerant flow in the system linked to temperature control and the system's refrigerant demand and to compressors' power consumption). Type of refrigerant used for simulation is R407F. Refrigerant properties such as specific enthalpy, pressure and temperature at different state points are computed on each time step of simulation with REFPROP.}
}

@unpublished{lincoln39628,
       booktitle = {Amazing Technology Symposium},
           month = {May},
           title = {Control of a soft robot for minimally invasive surgery},
          author = {Chakravarthini M. Saaj and Seri Mustaza},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39628/}
}

@article{lincoln31010,
          volume = {49},
          number = {4},
           month = {April},
          author = {Daqi Liu and Shigang Yue},
           title = {Event-driven continuous STDP learning with deep structure for visual pattern recognition},
       publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
            year = {2018},
         journal = {IEEE Transactions on Cybernetics},
             doi = {10.1109/tcyb.2018.2801476},
           pages = {1377--1390},
        keywords = {ARRAY(0x56321343b368)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31010/},
        abstract = {Human beings can achieve reliable and fast visual pattern recognition with limited time and learning samples. Underlying this capability, ventral stream plays an important role in object representation and form recognition. Modeling the ventral steam may shed light on further understanding the visual brain in humans and building artificial vision systems for pattern recognition. The current methods to model the mechanism of ventral stream are far from exhibiting fast, continuous and event-driven learning like the human brain. To create a visual system similar to ventral stream in human with fast learning capability, in this study, we propose a new spiking neural system with an event-driven continuous spike timing dependent plasticity (STDP) learning method using specific spiking timing sequences. Two novel continuous input mechanisms have been used to obtain the continuous input spiking pattern sequence. With the event-driven STDP learning rule, the proposed learning procedure will be activated if the neuron receive one pre- or post-synaptic spike event. The experimental results on MNIST database show that the proposed method outperforms all other methods in fast learning scenarios and most of the current models in exhaustive learning experiments.}
}

@book{lincoln33090,
           month = {April},
           title = {Data Science for Transport},
          author = {Charles Fox},
         address = {Germany},
       publisher = {Springer},
            year = {2018},
          series = {Springer Texts in Earth Science, Geography and Environment},
        keywords = {ARRAY(0x5632134336d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33090/},
        abstract = {The quantity, diversity and availability of transport data is increasing rapidly, requiring new skills in the management and interrogation of data and databases. Recent years have seen a new wave of 'big data', 'Data Science', and 'smart cities' changing the world, with the Harvard Business Review describing Data Science as the "sexiest job of the 21st century". Transportation professionals and researchers need to be able to use data and databases in order to establish quantitative, empirical facts, and to validate and challenge their mathematical models, whose axioms have traditionally often been assumed rather than rigorously tested against data. This book takes a highly practical approach to learning about Data Science tools and their application to investigating transport issues. The focus is principally on practical, professional work with real data and tools, including business and ethical issues.}
}

@inproceedings{lincoln33421,
       booktitle = {2017 Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)},
           month = {April},
           title = {An Improved LPTC Neural Model for Background Motion Direction Estimation},
          author = {Hongxin Wang and Jigen Peng and Shigang Yue},
       publisher = {IEEE},
            year = {2018},
             doi = {10.1109/DEVLRN.2017.8329786},
        keywords = {ARRAY(0x563213433700)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33421/},
        abstract = {A class of specialized neurons, called lobula plate tangential cells (LPTCs) has been shown to respond strongly to wide-field motion. The classic model, elementary motion detector (EMD) and its improved model, two-quadrant detector (TQD) have been proposed to simulate LPTCs. Although EMD and TQD can percept background motion, their outputs are so cluttered that it is difficult to discriminate actual motion direction of the background. In this paper, we propose a max operation mechanism to model a newly-found transmedullary neuron Tm9 whose physiological properties do not map onto EMD and TQD. This proposed max operation mechanism is able to improve the detection performance of TQD in cluttered background by filtering out irrelevant motion signals. We will demonstrate the functionality of this proposed mechanism in wide-field motion perception.}
}

@article{lincoln30386,
          volume = {50},
           month = {April},
          author = {Khaled Elgeneidy and Niels Lohse and Michael Jackson},
           title = {Bending angle prediction and control of soft pneumatic actuators with embedded flex sensors: a data-driven approach},
       publisher = {Elsevier for International Federation of Automatic Control (IFAC)},
            year = {2018},
         journal = {Mechatronics},
             doi = {10.1016/j.mechatronics.2017.10.005},
           pages = {234--247},
        keywords = {ARRAY(0x563213433730)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30386/},
        abstract = {In this paper, a purely data-driven modelling approach is presented for predicting and controlling the free bending angle response of a typical soft pneumatic actuator (SPA), embedded with a resistive flex sensor. An experimental setup was constructed to test the SPA at different input pressure values and orientations, while recording the resulting feedback from the embedded flex sensor and on-board pressure sensor. A calibrated high speed camera captures image frames during the actuation, which are then analysed using an image processing program to calculate the actual bending angle and synchronise it with the recorded sensory feedback. Empirical models were derived based on the generated experimental data using two common data-driven modelling techniques; regression analysis and artificial neural networks. Both techniques were validated using a new dataset at untrained operating conditions to evaluate their prediction accuracy. Furthermore, the derived empirical model was used as part of a closed-loop PID controller to estimate and control the bending angle of the tested SPA based on the real-time sensory feedback generated. The tuned PID controller allowed the bending SPA to accurately follow stepped and sinusoidal reference signals, even in the presence of pressure leaks in the pneumatic supply. This work demonstrates how purely data-driven models can be effectively used in controlling the bending of SPAs under different operating conditions, avoiding the need for complex analytical modelling and material characterisation. Ultimately, the aim is to create more controllable soft grippers based on such SPAs with embedded sensing capabilities, to be used in applications requiring both a ?soft touch? as well as a more controllable object manipulation.}
}

@unpublished{lincoln39629,
       booktitle = {8th Annual British and Irish Association of Robotic Gynaecological Surgeons},
           month = {April},
           title = {Gynaecological Endoscopic Uterine Elevator},
          author = {Chakravarthini M. Saaj and Seri Mustaza and Kavitha Madhuri and Simon Butler-Manuel},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39629/}
}

@article{lincoln38544,
          volume = {94},
           month = {March},
          author = {Andrea Cohen and Simon Parsons and Elizabeth Sklar and Peter McBurney},
            note = {cited By 1},
           title = {A characterization of types of support between structured arguments and their relationship with support in abstract argumentation},
       publisher = {Elsevier},
            year = {2018},
         journal = {International Journal of Approximate Reasoning},
             doi = {10.1016/j.ijar.2017.12.008},
           pages = {76--104},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38544/},
        abstract = {Argumentation is an important approach in artificial intelligence and multiagent systems, providing a basis for single agents to make rational decisions, and for groups of agents to reach agreements, as well as a mechanism to underpin a wide range of agent interactions. In such work, a crucial role is played by the notion of attack between arguments, and the notion of attack is well-studied. There is, for example, a range of different approaches to identifying which of a set of arguments should be accepted given the attacks between them. Less well studied is the notion of support between arguments, yet the idea that one argument may support another is very intuitive and seems particularly relevant in the area of decision-making where decision options may have multiple arguments for and against them. In the last decade, the study of support in argumentation has regained attention among researchers, but most approaches address support in the context of abstract argumentation where the elements from which arguments are composed are ignored. In contrast, this paper studies the notion of support between arguments in the context of structured argumentation systems where the elements from which arguments are composed play a crucial role. Different forms of support are presented, each of which takes into account the structure of arguments; and the relationships between these forms of support are studied. Then, the paper investigates whether there is a correspondence between the structured and abstract forms of support, and determines whether the abstract formalisms may be instantiated using concrete forms of support in terms of structured arguments. The conclusion is that support in structured argumentation does not mesh well with support in abstract argumentation, and this suggests that more work is required to develop forms of support in abstract argumentation that model what happens in structured argumentation.}
}

@article{lincoln34519,
          volume = {101},
           month = {March},
          author = {Amir Ghalamzan Esfahani and Matteo Ragaglia and  },
           title = {Robot learning from demonstrations: Emulation learning in environments with moving obstacles},
       publisher = {Elsevier},
            year = {2018},
         journal = {Robotics and autonomous systems},
             doi = {10.1016/j.robot.2017.12.001},
           pages = {45--56},
        keywords = {ARRAY(0x5632134337c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34519/},
        abstract = {In this paper, we present an approach to the problem of Robot Learning from Demonstration (RLfD) in a dynamic environment, i.e. an environment whose state changes throughout the course of performing a task. RLfD mostly has been successfully exploited only in non-varying environments to reduce the programming time and cost, e.g. fixed manufacturing workspaces. Non-conventional production lines necessitate Human?Robot Collaboration (HRC) implying robots and humans must work in shared workspaces. In such conditions, the robot needs to avoid colliding with the objects that are moved by humans in the workspace. Therefore, not only is the robot: (i) required to learn a task model from demonstrations; but also, (ii) must learn a control policy to avoid a stationary obstacle. Furthermore, (iii) it needs to build a control policy from demonstration to avoid moving obstacles. Here, we present an incremental approach to RLfD addressing all these three problems. We demonstrate the effectiveness of the proposed RLfD approach, by a series of pick-and-place experiments by an ABB YuMi robot. The experimental results show that a person can work in a workspace shared with a robot where the robot successfully avoids colliding with him.}
}

@article{lincoln34759,
          volume = {10},
          number = {1},
           month = {March},
          author = {Ronghua Shang and Bingqi Du and Kaiyun Dai and Licheng Jiao and Amir Ghalamzan Esfahani and Rustam Stolkin and   and  },
           title = {Quantum-Inspired Immune Clonal Algorithm for solving large-scale capacitated arc routing problems},
       publisher = {Springer},
            year = {2018},
         journal = {Memetic Computing},
             doi = {10.1007/s12293-017-0224-7},
           pages = {81--102},
        keywords = {ARRAY(0x5632134337f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34759/},
        abstract = {In this paper, we present an approach to Large-Scale CARP called Quantum-Inspired Immune Clonal Algorithm (QICA-CARP). This algorithm combines the feature of an artificial immune system and quantum computation ground on the qubit and the quantum superposition. We call an antibody of population quantum bit encoding, in QICA-CARP. For this encoding, to control the population with a high probability evolution towards a good schema we use the information on the current optimal antibody. The mutation strategy of quantum rotation gate accelerates the convergence of the original clone operator. Moreover, quantum crossover operator enhances the exchange of information and increases the diversity of the population. Furthermore, it avoids falling into local optimum. We also use the repair operator to amend the infeasible solutions to ensure the diversity of solutions. This makes QICA-CARP approximating the optimal solution. We demonstrate the effectiveness of our approach by a set of experiments and by Comparing the results of our approach with ones obtained with the RDG-MAENS and RAM using different test sets. Experimental results show that QICA-CARP outperforms other algorithms in terms of convergence rate and the quality of the obtained solutions. Especially, QICA-CARP converges to a better lower bound at a faster rate illustrating that it is suitable for solving large-scale CARP.}
}

@article{lincoln27883,
          volume = {42},
          number = {3},
           month = {March},
          author = {Alexandros Paraschos and Christian Daniel and Jan Peters and Gerhard Neumann},
           title = {Using probabilistic movement primitives in robotics},
       publisher = {Springer Verlag},
            year = {2018},
         journal = {Autonomous Robots},
             doi = {10.1007/s10514-017-9648-7},
           pages = {529--551},
        keywords = {ARRAY(0x563213433820)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27883/},
        abstract = {Movement Primitives are a well-established paradigm for modular movement representation and generation. They provide a data-driven representation of movements and support generalization to novel situations, temporal modulation, sequencing of primitives and controllers for executing the primitive on physical systems. However, while many MP frameworks exhibit some of these properties, there is a need for a unified framework that implements all of them in a principled way. In this paper, we show that this goal can be achieved by using a probabilistic representation. Our approach models trajectory distributions learned from stochastic movements. Probabilistic operations, such as conditioning can be used to achieve generalization to novel situations or to combine and blend movements in a principled way. We derive a stochastic feedback controller that reproduces the encoded variability of the
movement and the coupling of the degrees of freedom of the robot. We evaluate and compare our approach on several simulated and real robot scenarios.}
}

@article{lincoln32297,
          volume = {27},
          number = {5},
           month = {March},
          author = {Jianglong Guo and Khaled Elgeneidy and C Xiang and Niels Lohse and Laura Justham and Jonathan Rossiter},
           title = {Soft pneumatic grippers embedded with stretchable electroadhesion},
       publisher = {IOP Publishing},
            year = {2018},
         journal = {Smart Materials and Structures},
             doi = {10.1088/1361-665X/aab579},
           pages = {055006},
        keywords = {ARRAY(0x563213433850)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32297/},
        abstract = {Current soft pneumatic grippers cannot robustly grasp flat materials and flexible objects on curved surfaces without distorting them. Current electroadhesive grippers, on the other hand, are difficult to actively deform to complex shapes to pick up free-form surfaces or objects. An easy-to-implement PneuEA gripper is proposed by the integration of an electroadhesive gripper and a two-fingered soft pneumatic gripper. The electroadhesive gripper was fabricated by segmenting a soft conductive silicon sheet into a two-part electrode design and embedding it in a soft dielectric elastomer. The two-fingered soft pneumatic gripper was manufactured using a standard soft lithography approach. This novel integration has combined the benefits of both the electroadhesive and soft pneumatic grippers. As a result, the proposed PneuEA gripper was not only able to pick-and-place flat and flexible materials such as a porous cloth but also delicate objects such as a light bulb. By combining two soft touch sensors with the electroadhesive, an intelligent and shape-adaptive PneuEA material handling system has been developed. This work is expected to widen the applications of both soft gripper and electroadhesion technologies.}
}

@article{lincoln31687,
          volume = {7},
          number = {1-2},
           month = {March},
          author = {Takayuki Osa and Joni Pajarinen and Gerhard Neumann and J. Andrew Bagnell and Pieter Abbeel and Jan Peters},
           title = {An algorithmic perspective on imitation learning},
       publisher = {Now publishers},
            year = {2018},
         journal = {Foundations and Trends in Robotics},
             doi = {10.1561/2300000053},
           pages = {1--179},
        keywords = {ARRAY(0x563213433880)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31687/},
        abstract = {As robots and other intelligent agents move from simple environments and problems to more complex, unstructured settings, manually programming their behavior has become increasingly challenging and expensive. Often, it is easier for a teacher to demonstrate a desired behavior rather than attempt to manually engineer it. This process of learning from demonstrations, and the study of algorithms to do so, is called imitation learning. This work provides an introduction to imitation learning. It covers the underlying assumptions, approaches, and how they relate; the rich set of algorithms developed to tackle the problem; and advice on effective tools and implementation. We intend this paper to serve two audiences. First, we want to familiarize machine learning experts with the challenges of imitation learning, particularly those arising in robotics, and the interesting theoretical and practical distinctions between it and more familiar frameworks like statistical supervised learning theory and reinforcement learning. Second, we want to give roboticists and experts in applied artificial intelligence a broader appreciation for the frameworks and tools available for imitation learning. We pay particular attention to the intimate connection between imitation learning approaches and those of structured prediction Daum{\'e} III et al. [2009]. To structure this discussion, we categorize imitation learning techniques based on the following key criteria which drive algorithmic decisions:

1) The structure of the policy space. Is the learned policy a time-index trajectory (trajectory learning), a mapping from observations to actions (so called behavioral cloning [Bain and Sammut, 1996]), or the result of a complex optimization or planning problem at each execution as is common in inverse optimal control methods [Kalman, 1964, Moylan and Anderson, 1973].

2) The information available during training and testing. In particular, is the learning algorithm privy to the full state that the teacher possess? Is the learner able to interact with the teacher and gather corrections or more data? Does the learner have a (typically a priori) model of the system with which it interacts? Does the learner have access to the reward (cost) function that the teacher is attempting to optimize?

3) The notion of success. Different algorithmic approaches provide varying guarantees on the resulting learned behavior. These guarantees range from weaker (e.g., measuring disagreement with the agent?s decision) to stronger (e.g., providing guarantees on the performance of the learner with respect to a true cost function, either known or unknown). We organize our work by paying particular attention to distinction (1): dividing imitation learning into directly replicating desired behavior (sometimes called behavioral cloning) and learning the hidden objectives of the desired behavior from demonstrations (called inverse optimal control or inverse reinforcement learning [Russell, 1998]). In the latter case, behavior arises as the result of an optimization problem solved for each new instance that the learner faces. In addition to method analysis, we discuss the design decisions a practitioner must make when selecting an imitation learning approach. Moreover, application examples{--}such as robots that play table tennis [Kober and Peters, 2009], programs that play the game of Go [Silver et al., 2016], and systems that understand natural language [Wen et al., 2015]{--} illustrate the properties and motivations behind different forms of imitation learning. We conclude by presenting a set of open questions and point towards possible future research directions for machine learning.}
}

@inproceedings{lincoln31959,
       booktitle = {R4L @ HRI2018},
           month = {March},
           title = {Robots in the classroom: Learning to be a Good Tutor},
          author = {Emmanuel Senft and Severin Lemaignan and Madeleine Bartlett and Paul Baxter and Tony Belpaeme},
            year = {2018},
        keywords = {ARRAY(0x5632134338b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31959/},
        abstract = {To broaden the adoption and be more inclusive, robotic tutors need to tailor their
behaviours to their audience. Traditional approaches, such as Bayesian Knowledge
Tracing, try to adapt the content of lessons or the difficulty of tasks to the current
estimated knowledge of the student. However, these variations only happen in a limited
domain, predefined in advance, and are not able to tackle unexpected variation in a
student's behaviours. We argue that robot adaptation needs to go beyond variations in
preprogrammed behaviours and that robots should in effect learn online how to become
better tutors. A study is currently being carried out to evaluate how human supervision
can teach a robot to support child learning during an educational game using one
implementation of this approach.}
}

@inproceedings{lincoln31204,
       booktitle = {The 13th Annual ACM/IEEE International Conference on Human Robot Interaction},
           month = {March},
           title = {Studying table-top manipulation tasks: a robust framework for object tracking in collaboration},
          author = {Peter Lightbody and Paul Baxter and Marc Hanheide},
       publisher = {ACM/IEEE},
            year = {2018},
             doi = {10.1145/3173386.3177045},
        keywords = {ARRAY(0x5632134338e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31204/},
        abstract = {Table-top object manipulation is a well-established test bed on which to study both basic foundations of general human-robot interaction and more specific collaborative tasks. A prerequisite, both for studies and for actual collaborative or assistive tasks, is the robust perception of any objects involved. This paper presents a real-time capable and ROS-integrated approach, bringing together state-of-the-art detection and tracking algorithms, integrating perceptual cues from multiple cameras and solving detection, sensor fusion and tracking in one framework. The highly scalable framework was tested in a HRI use-case scenario with 25 objects being reliably tracked under significant temporary occlusions. The use-case demonstrates the suitability of the approach when working with multiple objects in small table-top environments and highlights the versatility and range of analysis available with this framework.}
}

@article{lincoln31137,
          volume = {11},
          number = {2},
           month = {February},
          author = {Ibrahim Saleh and Andrey Postnikov and Corneliu Arsene and Argyrios Zolotas and Chris Bingham and Ronald Bickerton and Simon Pearson},
           title = {Impact of demand side response on a commercial retail refrigeration system},
       publisher = {MDPI},
            year = {2018},
         journal = {Energies},
             doi = {10.3390/en11020371},
           pages = {371},
        keywords = {ARRAY(0x563213433910)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31137/},
        abstract = {The UK National Grid has placed increased emphasis on the development of Demand Side Response (DSR) tariff mechanisms to manage load at peak times. Refrigeration systems, along with HVAC, are estimated to consume 14\% of the UK?s electricity and could have a significant role for DSR application. However, characterized by relatively low individual electrical loads and massive asset numbers, multiple low power refrigerators need aggregation for inclusion in these tariffs. In this paper, the impact of the Demand Side Response (DSR) control mechanisms on food retailing refrigeration systems is investigated. The experiments are conducted in a test-rig built to resemble a typical small supermarket store. The paper demonstrates how the temperature and pressure profiles of the system, the active power and the drawn current of the compressors are affected following a rapid shut down and subsequent return to normal operation as a response to a DSR event. Moreover, risks and challenges associated with primary and secondary Firm Frequency Response (FFR) mechanisms, where the load is rapidly shed at high speed in response to changes in grid frequency, is considered. For instance, measurements are included that show a significant increase in peak inrush currents of approx. 30\% when the system returns to normal operation at the end of a DSR event. Consideration of how high inrush currents after a DSR event can produce voltage fluctuations of the supply and we assess risks to the local power supply system.}
}

@article{lincoln34757,
          volume = {142},
           month = {January},
          author = {Ronghua Shang and Yijing Yuan and Licheng Jiao and Yang Meng and Amir Ghalamzan Esfahani},
           title = {A self-paced learning algorithm for change detection in synthetic aperture radar images},
       publisher = {Elsevier},
            year = {2018},
         journal = {Signal Processing},
             doi = {10.1016/j.sigpro.2017.07.023},
           pages = {375--387},
        keywords = {ARRAY(0x563213433940)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34757/},
        abstract = {Detecting changed regions between two given synthetic aperture radar images is very important to monitor the change of landscapes, change of ecosystem and so on. This can be formulated as a classification problem and addressed by learning a classifier, traditional machine learning classification methods very easily stick to local optima which can be caused by noises of data. Hence, we propose an unsupervised algorithm aiming at constructing a classifier based on self-paced learning. Self-paced learning is a recently developed supervised learning approach and
has been proven to be capable to overcome effectively this shortcoming. After applying a pre-classification to the difference image, we uniformly select samples using the initial result. Then, self-paced learning is utilized to train a classifier. Finally, a filter is used based on spatial contextual information to further smooth the classification result. In order to demonstrate the efficiency of the proposed algorithm, we apply our proposed algorithm on five real synthetic aperture radar images datasets. The results obtained by our algorithm are compared with five other state-of-the-art algorithms, which demonstrates that our algorithm outperforms those state-of-the-art algorithms in terms of accuracy and robustness.}
}

@article{lincoln30806,
          volume = {10},
          number = {1},
           month = {January},
          author = {George Petropoulos and Prashant Srivastava and Maria Piles and Simon Pearson},
            note = {This article belongs to the Special Issue Precision Agriculture Technologies for a Sustainable Future: Current Trends and Perspectives},
           title = {Earth observation-based operational estimation of soil moisture and evapotranspiration for agricultural crops in support of sustainable water management},
       publisher = {MDPI},
            year = {2018},
         journal = {Sustainability},
             doi = {10.3390/su10010181},
           pages = {181},
        keywords = {ARRAY(0x563213433970)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30806/},
        abstract = {Global information on the spatio-temporal variation of parameters driving the Earth?s terrestrial water and energy cycles, such as evapotranspiration (ET) rates and surface soil moisture (SSM), is of key significance. The water and energy cycles underpin global food and water security and need to be fully understood as the climate changes. In the last few decades, Earth Observation (EO) technology has played an increasingly important role in determining both ET and SSM. This paper reviews the state of the art in the use specifically of operational EO of both ET and SSM estimates. We discuss the key technical and operational considerations to derive accurate estimates of those parameters from space. The review suggests significant progress has been made in the recent years in retrieving ET and SSM operationally; yet, further work is required to optimize parameter accuracy and to improve the operational capability of services developed using EO data. Emerging applications on which ET/SSM operational products may be included in the context specifically in relation to agriculture are also highlighted; the operational use of those operational products in such applications remains to be seen.}
}

@inproceedings{lincoln44713,
           month = {January},
          author = {Helen Harman and Keshav Chintamani and Pieter Simoens},
       booktitle = {2017 IEEE International Symposium on Robotics and Intelligent Sensors (IRIS)},
           title = {Architecture for incorporating Internet-of-Things sensors and actuators into robot task planning in dynamic environments},
       publisher = {IEEE},
             doi = {10.1109/IRIS.2017.8250091},
           pages = {13--18},
            year = {2018},
        keywords = {ARRAY(0x5632134339a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44713/},
        abstract = {Robots are being deployed in a wide range of smart environments that are equipped with sensors and actuators. These devices can provide valuable information beyond the perception range of a robot's on-board sensors, or provide additional actuators that can complement the robot's actuation abilities. Traditional robot task planners do not take these additional sensor and actuators abilities into account. This paper introduces an enhanced robotic planning framework which improves robots' ability to operate in dynamically changing environments. To keep planning time short, the amount of knowledge in the planner's world model is minimized.}
}

@inproceedings{lincoln31168,
       booktitle = {Global Power and Propulsion Forum},
           month = {January},
           title = {Performance analysis and prediction of compressor fouling condition for a twin-shaft engine},
          author = {Sepehr Maleki and Samuel Cruz-Manzo and Chris Bingham and Vili Panov},
       publisher = {Global Power and Propulsion Society},
            year = {2018},
        keywords = {ARRAY(0x5632134339d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31168/},
        abstract = {Performance of a twin-shaft Industrial Gas Turbine (IGT) at fouling condition is simulated via a gas turbine model based
on fundamental thermodynamics. Measurements across the engine during compressor fouling conditions were considered to validate the outcomes. By implementing correlation coefficients in the compressor model, the performance of the IGT during compressor fouling conditions is predicted. The change in the compressor air flow and the compressor efficiency during fouling conditions is estimated. The results show that the reduction of air flow rate is the dominating parameter in loss of generated power under fouled conditions. The model can provide an insight into the effect of compressor fouling conditions on IGT performance.}
}

@inproceedings{lincoln33098,
       booktitle = {Transportation Research Board},
           month = {January},
           title = {Models of human decision-making as tools for estimating and optimising impacts of vehicle automation},
          author = {G Markkula and R Romano and R Madigan and Charles Fox and O Giles and N Merat},
       publisher = {Transportatio n Research Record},
            year = {2018},
        keywords = {ARRAY(0x563213433a00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33098/},
        abstract = {With the development of increasingly automated vehicles (AVs) comes the increasingly difficult challenge of comprehensively validating these for acceptable, and ideally beneficial, impacts on the transport system. There is a growing consensus that virtual testing, where simulated AVs are deployed in simulated traffic, will be key for cost-effective testing and optimisation. The least mature model components in such simulations are those generating the behaviour of human agents in or around the AVs. In this paper, human models and virtual testing applications are presented for two example scenarios: (i) a human pedestrian deciding whether to cross a street in front of an approaching automated vehicle, with or without external human-machine interface elements, and (ii) an AV handing over control to a human driver in a critical rear-end situation. These scenarios have received much recent research attention, yet simulation-ready human behaviour models are lacking. They are discussed here in the context of existing models of perceptual decision-making, situational awareness, and traffic interactions. It is argued that the human behaviour in question might be usefully conceptualised as a number of interrelated decision processes, not all of which are necessarily directly associated with externally observable behaviour. The results show that models based on this type of framework can reproduce qualitative patterns of behaviour reported in the literature for the two addressed scenarios, and it is demonstrated how computer simulations based on the models, once these have been properly validated, could allow prediction and optimisation of  the AV.}
}

@article{lincoln32457,
          volume = {19},
          number = {14},
          author = {R. Akrour and A. Abdolmaleki and H. Abdulsamad and J. Peters and Gerhard Neumann},
           title = {Model-Free Trajectory-based Policy Optimization with Monotonic Improvement},
       publisher = {Journal of Machine Learning Research},
         journal = {Journal of Machine Learning Research (JMLR)},
           pages = {1--25},
            year = {2018},
        keywords = {ARRAY(0x563213433a30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32457/},
        abstract = {Many of the recent trajectory optimization algorithms alternate between linear approximation
of the system dynamics around the mean trajectory and conservative policy update.
One way of constraining the policy change is by bounding the Kullback-Leibler (KL)
divergence between successive policies. These approaches already demonstrated great experimental
success in challenging problems such as end-to-end control of physical systems.
However, these approaches lack any improvement guarantee as the linear approximation of
the system dynamics can introduce a bias in the policy update and prevent convergence
to the optimal policy. In this article, we propose a new model-free trajectory-based policy
optimization algorithm with guaranteed monotonic improvement. The algorithm backpropagates
a local, quadratic and time-dependent Q-Function learned from trajectory data
instead of a model of the system dynamics. Our policy update ensures exact KL-constraint
satisfaction without simplifying assumptions on the system dynamics. We experimentally
demonstrate on highly non-linear control tasks the improvement in performance of our algorithm
in comparison to approaches linearizing the system dynamics. In order to show the
monotonic improvement of our algorithm, we additionally conduct a theoretical analysis of
our policy update scheme to derive a lower bound of the change in policy return between
successive iterations.}
}

@inproceedings{lincoln32456,
       booktitle = {Proceedings of the International Conference on Machine Learning},
           title = {Efficient Gradient-Free Variational Inference using Policy Search},
          author = {O. Arenz and M. Zhong and Gerhard Neumann},
            year = {2018},
        keywords = {ARRAY(0x563213433a60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32456/},
        abstract = {Inference from complex distributions is a common problem in machine learning needed for many Bayesian methods. We propose an efficient, gradient-free method for learning general GMM approximations of multimodal distributions based on recent insights from stochastic search methods. Our method establishes information-geometric trust regions to ensure efficient exploration of the sampling space and stability of the GMM updates, allowing for efficient estimation of multi-variate Gaussian variational distributions. For GMMs, we apply a variational lower bound to decompose the learning objective into sub-problems given by learning the individual mixture components and the coefficients. The number of mixture components is adapted online in order to allow for arbitrary exact approximations. We demonstrate on several domains that we can learn significantly better approximations than competing variational inference methods and that the quality of samples drawn from our approximations is on par with samples created by state-of-the-art MCMC samplers that require significantly more computational resources.}
}

@article{lincoln33871,
          volume = {80},
           title = {Efficient Gradient-Free Variational Inference using Policy Search},
          author = {Oleg Arenz and Gerhard Neumann and Mingjun Zhong},
       publisher = {Proceedings of Machine Learning Research},
            year = {2018},
           pages = {234--243},
         journal = {Proceedings of the 35th International Conference on Machine Learning},
        keywords = {ARRAY(0x563213433a90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33871/},
        abstract = {Inference from complex distributions is a common problem in machine learning needed for many Bayesian methods. We propose an efficient, gradient-free method for learning general GMM approximations of multimodal distributions based on recent insights from stochastic search methods. Our method establishes information-geometric trust regions to ensure efficient exploration of the sampling space and stability of the GMM updates, allowing for efficient estimation of multi-variate Gaussian variational distributions. For GMMs, we apply a variational lower bound to decompose the learning objective into sub-problems given by learning the individual mixture components and the coefficients. The number of mixture components is adapted online in order to allow for arbitrary exact approximations. We demonstrate on several domains that we can learn significantly better approximations than competing variational inference methods and that the quality of samples drawn from our approximations is on par with samples created by state-of-the-art MCMC samplers that require significantly more computational resources.}
}

@inproceedings{lincoln33320,
       booktitle = {Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction - HRI '18},
           title = {Safe Human-Robot Interaction in Agriculture},
          author = {Paul Baxter and Grzegorz Cielniak and Marc Hanheide and Pal From},
       publisher = {ACM},
            year = {2018},
           pages = {59--60},
             doi = {doi:10.1145/3173386.3177072},
        keywords = {ARRAY(0x563213433ac0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33320/},
        abstract = {Robots in agricultural contexts are finding increased numbers of applications with respect to (partial) automation for increased productivity. However, this presents complex technical problems to be overcome, which are magnified when these robots are intended to work side-by-side with human workers. In this contribution we present an exploratory pilot study to characterise interactions between a robot performing an in-field transportation task and human fruit pickers. Partly an effort to inform the development of a fully autonomous system, the emphasis is on involving the key stakeholders (i.e. the pickers themselves) in the process so as to maximise the potential impact of such an application.}
}

@inproceedings{lincoln33321,
       booktitle = {Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction - HRI '18},
           title = {Robots Providing Cognitive Assistance in Shared Workspaces},
          author = {Paul Baxter and Peter Lightbody and Marc Hanheide},
       publisher = {ACM},
            year = {2018},
           pages = {57--58},
             doi = {doi:10.1145/3173386.3177070},
        keywords = {ARRAY(0x563213433af0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33321/},
        abstract = {Human-Robot Collaboration is an area of particular current interest, with the attempt to make robots more generally useful in contexts where they work side-by-side with humans. Currently, efforts typically focus on the sensory and motor aspects of the task on the part of the robot to enable them to function safely and effectively given an assigned task. In the present contribution, we rather focus on the cognitive faculties of the human worker by attempting to incorporate known (from psychology) properties of human cognition. In a proof-of-concept study, we demonstrate how applying characteristics of human categorical perception to the type of robot assistance impacts on task performance and experience of the participants. This lays the foundation for further developments in cognitive assistance and collaboration in side-by-side working for humans and robots.}
}

@book{lincoln39216,
       booktitle = {Operations Management in Agriculture},
           title = {Operations Management in Agriculture},
          author = {Dionysis Bochtis and Claus Aage Gr{\o}n S{\o}rensen and Dimitrios Kateris},
       publisher = {Elsevier},
            year = {2018},
             doi = {doi:10.1016/C2015-0-06290-6},
        keywords = {ARRAY(0x563213433b20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39216/},
        abstract = {Operations Management in Agriculture bridges the knowledge gap on operations management for agricultural machinery. It complements traditional topics (cost of using and choosing machinery) with advanced engineering approaches recently applied in agricultural machinery management (area coverage planning and sequential scheduling). The book covers new technologies in bio-production systems (robotics, IoT) and environmental compliance by employing a systems engineering perspective with focuses on sub-systems, including advanced optimization, supply chain systems, sustainability, autonomous vehicles and IT-driven decision-making. It will be a valuable resource for students studying decision-making and those working to improve the efficiency, effectiveness and sustainability of production through machinery choice.}
}

@inproceedings{lincoln33565,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2018) Workshops},
           title = {Towards pedestrian-AV interaction: method for elucidating pedestrian preferences},
          author = {Fanta Camara and Serhan Cosar and Nicola Bellotto and Natasha Merat and Charles Fox},
            year = {2018},
        keywords = {ARRAY(0x563213433b50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33565/},
        abstract = {Autonomous vehicle navigation around human pedestrians remains a challenge due to the potential for complex interactions and feedback loops between the agents. As a small step towards better understanding of these interactions, this Methods Paper presents a new empirical protocol based on tracking real humans in a controlled lab environment, which is able to make inferences about the human?s preferences for interaction (how they trade off the cost of their time against the cost of a collision). Knowledge of such preferences if collected in more realistic environments could then be used by future AVs to predict and control for pedestrian behaviour. This study is intended as a work-in-progress report on methods working towards real-time and less controlled experiments, demonstrating successful use of several key components required by such systems, but in its more controlled setting. This suggests that these components could be extended to more realistic situations and results in an ongoing research programme.}
}

@inproceedings{lincoln33126,
       booktitle = {The 21st IEEE International Conference on Intelligent Transportation Systems},
           title = {Predicting pedestrian road-crossing assertiveness for autonomous vehicle control},
          author = {Fanta Camara and O Giles and R Madigan and M Rothmueller and P Holm Rasmussen and SA Vendelbo-Larsen and G Markkula and YM Lee and L Garach and N Merat and CW Fox},
       publisher = {IEEE Xplore},
            year = {2018},
        keywords = {ARRAY(0x563213433b80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33126/},
        abstract = {Autonomous vehicles (AVs) must interact with other road users including pedestrians. Unlike passive environments, pedestrians are active agents having their own utilities and decisions, which must be inferred and predicted by AVs in order to control interactions with them and navigation around them. In particular, when a pedestrian wishes to cross the road in front of the vehicle at an unmarked crossing, the pedestrian and AV must compete for the space, which may be considered as a game-theoretic interaction in which one agent must yield to the other. To inform AV controllers in this setting, this study collects and analyses data from real-world human road crossings to determine what features of crossing behaviours are predictive about the level of assertiveness of pedestrians and of the eventual winner of the interactions. It presents the largest and most detailed data set of its kind known to us, and new methods to analyze and predict pedestrian-vehicle interactions based upon it. Pedestrian-vehicle interactions are decomposed into sequences of independent discrete events. We use probabilistic methods ?logistic regression and decision tree regression ? and sequence analysis to analyze sets and sub-sequences of actions used by both pedestrians and human drivers while crossing at an intersection, to find common patterns of behaviour and to predict the winner of each interaction. We report on the particular features found to be predictive and which can thus be integrated into game-theoretic AV controllers to inform real-time interactions.}
}

@inproceedings{lincoln33564,
       booktitle = {15th International Conference on Intelligent Autonomous Systems (IAS-15) workshops},
           title = {Filtration analysis of pedestrian-vehicle interactions for autonomous vehicles control},
          author = {Fanta Camara and Oscar Giles and Ruth Madigan and Markus Rothm{\"u}ller and Pernille Holm Rasmussen and Signe Alexandra Vendelbo-Larsen and Gustav Markkula and Yee Mun Lee and Laura Garach and Natasha Merat and Charles Fox},
            year = {2018},
        keywords = {ARRAY(0x563213433bb0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33564/},
        abstract = {Interacting with humans remains a challenge for autonomous
vehicles (AVs). When a pedestrian wishes to cross the road in front of the
vehicle at an unmarked crossing, the pedestrian and AV must compete
for the space, which may be considered as a game-theoretic interaction in
which one agent must yield to the other. To inform development of new
real-time AV controllers in this setting, this study collects and analy-
ses detailed, manually-annotated, temporal data from real-world human
road crossings as they interact with manual drive vehicles. It studies the
temporal orderings (filtrations) in which features are revealed to the ve-
hicle and their informativeness over time. It presents a new framework
suggesting how optimal stopping controllers may then use such data to
enable an AV to decide when to act (by speeding up, slowing down, or
otherwise signalling intent to the pedestrian) or alternatively, to continue
at its current speed in order to gather additional information from new
features, including signals from that pedestrian, before acting itself.}
}

@inproceedings{lincoln32028,
       booktitle = {Proc. Measuring Behaviour 2018: International Conference on Methods and Techniques in Behavioral Research},
           title = {Empirical game theory of pedestrian interaction for autonomous vehicles},
          author = {Fanta Camara and Richard A. Romano and Gustav Markkula and Ruth Madigan and Natasha Merat and Charles W. Fox},
            year = {2018},
         journal = {Proceedings of Measuring Behavior 2018.},
        keywords = {ARRAY(0x563213433be0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32028/},
        abstract = {Autonomous vehicles (AV?s) are appearing on roads, based on standard robotic mapping and
navigation algorithms. However their ability to interact with other road-users is much less well understood. If
AVs are programmed to stop every time another road user obstructs them, then other road users simply learn that
they can take priority at every interaction, and the AV will make little or no progress. This issue is especially
important in the case of a pedestrian crossing the road in front of the AV. The present methods paper expands the
sequential chicken model introduced in (Fox et al., 2018), using empirical data to measure behavior of humans in
a controlled plus-maze experiment, and showing how such data can be used to infer parameters of the model via
a Gaussian Process. This providing a more realistic, empirical understanding of the human factors intelligence
required by future autonomous vehicles.}
}

@inproceedings{lincoln33029,
       booktitle = {Turbomachinery Technical Conference and Exposition},
           title = {ANALYSIS OF PERFORMANCE OF A TWIN-SHAFT GAS TURBINE DURING HOT-END DAMAGE IN THE GAS GENERATOR TURBINE},
          author = {Samuel Cruz-Manzo and Sepehr Maleki and Vili Panov and Festus Agbonzikilo and Yu Zhang},
       publisher = {ASME},
            year = {2018},
        keywords = {ARRAY(0x56321345b3f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33029/},
        abstract = {In this study, an analysis of the performance of a twin-shaft industrial gas turbine (IGT) during hot-end damage in the gas generator turbine (GGT) at high-power operation has been carried out using a validated Simulink IGT model. The Simulink model is based on fundamental thermodynamics and allows the implementation of correlation coefficients in the GGT module to predict the performance of the IGT system during a hot-end GGT damage incident. Measured field data from a twin-shaft IGT operated as a power generation unit denoting a reduction in performance due to hot-end GGT damage are considered for the analysis. Four hot-end GGT damage incidents across a range of measured field data have been identified and considered for the analysis. The results show that the Simulink model can predict the change of physical parameters (pressure, temperature) across the IGT system for each GGT damage incident. Hot-end damage increases the flow capacity and reduces the efficiency of the GGT.  Future work will validate the dynamic change of flow capacity and efficiency during different GGT damage incidents.}
}

@article{lincoln33938,
           title = {Towards an automated masking process: A model-based approach},
          author = {Khaled Elgeneidy and Ali Al-Yacoub and Zahid Usman and Niels Lohsa and Michael jackson and Iain Wright},
       publisher = {Sage},
            year = {2018},
             doi = {10.1177/0954405418810058},
            note = {The final published version of this article can be found online at http://www.uk.sagepub.com/journals/Journal202016/},
         journal = {Journal of Engineering Manufacture},
        keywords = {ARRAY(0x5632132c9b58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33938/},
        abstract = {The masking of aircraft engine parts, such as turbine blades, is a major bottleneck for the aerospace industry. The process is often carried out manually in multiple stages of coating and curing, which requires extensive time and introduces variations in the masking quality. This article investigates the automation of the masking process utilising the well-established time?pressure dispensing process for controlled maskant dispensing and a robotic manipulator for accurate part handling. A mathematical model for the time?pressure dispensing process was derived, extending previous models from the literature by incorporating the robot velocity for controlled masking line width. An experiment was designed, based on the theoretical analysis of the dispensing process, to derive an empirical model from the generated data that incorporate the losses that are otherwise difficult to model mathematically. The model was validated under new input conditions to demonstrate the feasibility of the proposed approach and the masking accuracy using the derived model.}
}

@article{lincoln32562,
           title = {Directly Printable Flexible Strain Sensors for Bending and Contact Feedback of Soft Actuators},
          author = {Khaled Elgeneidy and Gerhard Neumann and Michael Jackson and Niels Lohse},
       publisher = {Frontiers Media},
            year = {2018},
             doi = {10.3389/frobt.2018.00002},
         journal = {Front. Robot. AI},
        keywords = {ARRAY(0x5632132c9b88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32562/},
        abstract = {This paper presents a fully printable sensorized bending actuator that can be calibrated to provide reliable bending feedback and simple contact detection. A soft bending actuator following a pleated morphology, as well as a flexible resistive strain sensor, were directly 3D printed using easily accessible FDM printer hardware with a dual-extrusion tool head. The flexible sensor was directly welded to the bending actuator?s body and systematically tested to characterize and evaluate its response under variable input pressure. A signal conditioning circuit was developed to enhance the quality of the sensory feedback, and flexible conductive threads were used for wiring. The sensorized actuator?s response was then calibrated using a vision system to convert the sensory readings to real bending angle values. The empirical relationship was derived using linear regression and validated at untrained input conditions to evaluate its accuracy. Furthermore, the sensorized actuator was tested in a constrained setup that prevents bending, to evaluate the potential of using the same sensor for simple contact detection by comparing the constrained and free-bending responses at the same input pressures. The results of this work demonstrated how a dual-extrusion FDM printing process can be tuned to directly print highly customizable flexible strain sensors that were able to provide reliable bending feedback and basic contact detection. The addition of such sensing capability to bending actuators enhances their functionality and reliability for applications such as controlled soft grasping, flexible wearables, and haptic devices.}
}

@inproceedings{lincoln32544,
       booktitle = {IROS 2018},
           title = {Contact Detection and Object Size Estimation using a Modular Soft Gripper with Embedded Flex Sensors},
          author = {Khaled Elgeneidy and Gerhard Neumann and Simon Pearson and Michael Jackson and Niels Lohse},
            year = {2018},
         journal = {IROS 2018},
        keywords = {ARRAY(0x5632133367d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32544/},
        abstract = {Soft-grippers can grasp delicate and deformable objects without bruise or damage as the gripper can adapt to the object?s shape. However, the contact forces are still hard to regulate due to missing contact feedback of such grippers. In this paper, a modular soft gripper design is presented utilizing interchangeable soft pneumatic actuators with embedded flex sensors as fingers of the gripper. The fingers can be assembled in different configurations using 3D printed connectors. The paper investigates the potential of utilizing the simple sensory feedback from the flex sensors to make additional meaningful inferences regarding the contact state and grasped object size. We study the effect of the grasped object size and contact type on the combined feedback from the embedded flex sensors of all fingers. Our results show that a simple linear relationship exists between the grasped object size and the final flex sensor reading at fixed input conditions, despite the variation in object weight and contact type. Additionally, by simply monitoring the time series response from the flex sensor, contact can be detected by comparing the response to the known free-bending response at the same input conditions. Furthermore, by utilizing the measured internal pressure supplied to the soft fingers, it is possible to distinguish between power and pinch grasps, as the nature of the contact affects the rate of change in the flex sensor readings against the internal pressure.}
}

@inproceedings{lincoln38402,
           title = {The CONSULT system: Demonstration},
          author = {K. Essers and M. Chapman and N. Kokciyan and I. Sassoon and T. Porat and P. Balatsoukas and P. Young and M. Ashworth and V. Curcin and S. Modgil and Simon Parsons and Elizabeth Sklar},
            year = {2018},
           pages = {385--386},
             doi = {10.1145/3284432.3287170},
            note = {cited By 0},
         journal = {HAI 2018 - Proceedings of the 6th International Conference on Human-Agent Interaction},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38402/}
}

@inproceedings{lincoln38543,
           title = {The CONSULT system: Demonstration},
          author = {K. Essers and M. Chapman and N. Kokciyan and I. Sassoon and T. Porat and P. Balatsoukas and P. Young and M. Ashworth and V. Curcin and S. Modgil and Simon Parsons and Elizabeth Sklar},
            year = {2018},
           pages = {385--386},
             doi = {10.1145/3284432.3287170},
            note = {cited By 0},
         journal = {HAI 2018 - Proceedings of the 6th International Conference on Human-Agent Interaction},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38543/}
}

@inproceedings{lincoln38542,
           title = {Assessing the POSTURE prototype: A late-breaking report on patient views},
          author = {K. Essers and R. Rogers and J. Sturt and Elizabeth Sklar and E. Black},
            year = {2018},
           pages = {344--346},
             doi = {10.1145/3284432.3287181},
            note = {cited By 0},
         journal = {HAI 2018 - Proceedings of the 6th International Conference on Human-Agent Interaction},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38542/}
}

@inproceedings{lincoln32029,
       booktitle = {Proc. 4th International Conference on Vehicle Technology and Intelligent Transport Systems (VEHITS)},
           title = {When should the chicken cross the road?: Game theory for autonomous vehicle-human interactions},
          author = {Charles Fox and F. Camara and G. Markkula and R. Romano and R. Madigan and N. Merat},
            year = {2018},
        keywords = {ARRAY(0x56321345b440)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32029/},
        abstract = {Autonomous vehicle control is well understood for local- [15], good approximations exist such as particle ?ltering,
ization, mapping and planning in un-reactive environ- which make use of large compute power to draw samples
ments, but the human factors of complex interactions near solutions.
stood [16], and despite its exact solution being NP-hard
with other road users are not yet developed.
Route planning in non-interactive envi-
ronments also has well known tractable solutions such as
This po-
the A-star algorithm. Given a route, localizing and con-
sition paper presents an initial model for negotiation be-
trol to follow that route then becomes a similar task to
tween an autonomous vehicle and another vehicle at an
that performed by the 1959 General Motors Firebird-III
unsigned intersections or (equivalently) with a pedestrian
self-driving car [1], which used electromagnetic sensing
at an unsigned road-crossing (jaywalking), using discrete
to follow a wire built into the road.
Such path follow-
sequential game theory. The model is intended as a ba- ing, using wires or SLAM, can then be augmented with
sic framework for more realistic and data-driven future simple safety logic to stop the vehicle if any obstacle is
extensions. The model shows that when only vehicle po- in its way, as detected by any range sensor.
sition is used to signal intent, the optimal behaviors for open source systems for this level of `self-driving' are now
both agents must include a non-zero probability of al- widely available [6].
lowing a collision to occur.
In contrast,
This suggests extensions to
problems that these vehicles will face
around interacting with other road users are much harder
reduce this probability in future, such as other forms of
both to formulate and solve. Autonomous vehicles do not
signaling and control. Unlike most Game Theory appli-
just have to deal with inanimate objects, sensors, and
cations in Economics, active vehicle control requires real-
maps.
time selection from multiple equilibria with no history,
They have to deal with other agents, currently
human drivers and pedestrians and eventually other au-
and we present and argue for a novel solution concept,
meta-strategy convergence , suited to this task.}
}

@article{lincoln33158,
          volume = {3},
          number = {4},
          author = {Roberto Pinillos Herrero and Jaime Pulido Fentanes and Marc Hanheide},
            note = {The final published version of this article can be accessed online at https://ieeexplore.ieee.org/document/8411093/},
           title = {Getting to Know Your Robot Customers: Automated Analysis of User Identity and Demographics for Robots in the Wild},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {doi:10.1109/LRA.2018.2856264},
           pages = {3733--3740},
        keywords = {ARRAY(0x563213330528)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33158/},
        abstract = {Long-term studies with autonomous robots ?in the wild? (deployed in real-world human-inhabited environments) are among the most laborious and resource-intensive endeavours in human-robot interaction. Even if a robot system itself is robust and well-working, the analysis of the vast amounts of user data one aims to collect and analyze poses a significant challenge. This letter proposes an automated processing pipeline, using state-of-the-art computer vision technology to estimate demographic factors from users? faces and reidentify them to establish usage patterns. It overcomes the problem of explicitly recruiting participants and having them fill questionnaires about their demographic background and allows one to study completely unsolicited and nonprimed interactions over long periods of time. This letter offers a comprehensive assessment of the performance of the automated analysis with data from 68 days of continuous deployment of a robot in a care home and also presents a set of findings obtained through the analysis, underpinning the viability of the approach.
Index}
}

@inproceedings{lincoln32460,
       booktitle = {International Conference for Swarm Intelligence (ANTS)},
           title = {Exploiting Local Communication Protocols for Learning Complex Swarm Behaviors with Deep Reinforcement Learning},
          author = {Max Huttenrauch and Adrian Sosic and Gerhard Neumann},
       publisher = {Springer International Publishing},
            year = {2018},
        keywords = {ARRAY(0x5632134609f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32460/},
        abstract = {Swarm systems constitute a challenging problem for reinforcement learning (RL) as the algorithm needs to learn decentralized control policies that can cope with limited local sensing and communication abilities of the agents. While it is often difficult to directly define the behavior of the agents, simple communication protocols can be defined more easily using prior knowledge about the given task. In this paper, we propose a number of simple communication protocols that can be exploited by deep reinforcement learning to find decentralized control policies in a multi-robot swarm environment. The protocols are based on histograms that encode the local neighborhood relations of the gents
and can also transmit task-specific information, such as the shortest distance and direction to a desired target. In our framework, we use an adaptation of Trust Region Policy Optimization to learn complex collaborative tasks, such as formation building and building a communication link. We evaluate our findings in a simulated 2D-physics environment, and compare the implications of different communication protocols.}
}

@inproceedings{lincoln38541,
           title = {HAI 2018 Chairs? Welcome},
          author = {M. Imai and Elizabeth Sklar and T.J. Norman and T. Komatsu},
            year = {2018},
           pages = {III},
            note = {cited By 0},
         journal = {HAI 2018 - Proceedings of the 6th International Conference on Human-Agent Interaction},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38541/}
}

@incollection{lincoln38408,
          volume = {305},
          author = {N. Kokciyan and I. Sassoon and A.P. Young and S. Modgil and S. Parsons},
          series = {Frontiers in Artificial Intelligence and Applications},
            note = {cited By 0},
       booktitle = {Computational Models of Argument},
           title = {Reasoning with metalevel argumentation frameworks in aspartix},
       publisher = {IOS Press},
            year = {2018},
         journal = {Frontiers in Artificial Intelligence and Applications},
             doi = {10.3233/978-1-61499-906-5-463},
           pages = {463--464},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38408/},
        abstract = {In this demo paper, we propose an encoding for Metalevel Argumentation Frameworks
(MAFs) to be used in Aspartix, an Answer Set Programming (ASP) approach to find
the justified arguments of an AF [2]. MAFs provide a uniform encoding of object level
Dung Frameworks and extensions thereof that include values, preferences and attacks
on attacks (EAFs). The justification status of arguments in the object level AF can then
be evaluated and explained through evaluation of the arguments in the MAF. The demo
includes multiple examples from the literature to show the applicability of our proposed
encoding for translating various object level AFs to the uniform language of MAFs.}
}

@article{lincoln34133,
          volume = {3},
          number = {4},
          author = {Lars Kunze and Nick Hawes and Tom Duckett and Marc Hanheide},
           title = {Introduction to the Special Issue on AI for Long-Term Autonomy},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2870466},
           pages = {4431--4434},
        keywords = {ARRAY(0x563213336f88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34133/},
        abstract = {The papers in this special section focus on the use of artificial intelligence (AI) for long term autonomy. Autonomous systems have a long history in the fields of AI and robotics. However, only through recent advances in technology has it been possible to create autonomous systems capable of operating in long-term, real-world scenarios. Examples include autonomous robots that operate outdoors on land, in air, water, and space; and indoors in offices, care homes, and factories. Designing, developing, and maintaining intelligent autonomous systems that operate in real-world environments over long periods of time, i.e. weeks, months, or years, poses many challenges. This special issue focuses on such challenges and on ways to overcome them using methods from AI. Long-term autonomy can be viewed as both a challenge and an opportunity. The challenge of long-term autonomy requires system designers to ensure that an autonomous system can continue operating successfully according to its real-world application demands in unstructured and semi-structured environments. This means addressing issues related to hardware and software robustness (e.g., gluing in screws and profiling for memory leaks), as well as ensuring that all modules and functions of the system can deal with the variation in the environment and tasks that is expected to occur over its operating time.}
}

@article{lincoln32829,
          volume = {3},
          number = {4},
          author = {Lars Kunze and Nick Hawes and Tom Duckett and Marc Hanheide and Tomas Krajnik},
           title = {Artificial Intelligence for Long-Term Robot Autonomy: A Survey},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2860628},
           pages = {4023--4030},
        keywords = {ARRAY(0x5632132922c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32829/},
        abstract = {Autonomous systems will play an essential role in many applications across diverse domains including space, marine, air, field, road, and service robotics. They will assist us in our daily routines and perform dangerous, dirty and dull tasks. However, enabling robotic systems to perform autonomously in complex, real-world scenarios over extended time periods (i.e. weeks, months, or years) poses many challenges. Some of these have been investigated by sub-disciplines of Artificial Intelligence (AI) including navigation \& mapping, perception, knowledge representation \& reasoning, planning, interaction, and learning. The different sub-disciplines have developed techniques that, when re-integrated within an autonomous system, can enable robots to operate effectively in complex, long-term scenarios. In this paper, we survey and discuss AI techniques as ?enablers? for long-term robot autonomy, current progress in integrating these techniques within long-running robotic systems, and the future challenges and opportunities for AI in long-term autonomy.}
}

@inproceedings{lincoln39622,
          volume = {152},
          author = {William Lewinger and Francisco Comin and Marcus Matthews and Chakravarthini Saaj},
       booktitle = {14th Symposium on Advanced Space Technologies in Robotics and Automation},
           title = {Earth analogue testing and analysis of Martian duricrust properties},
       publisher = {Elsevier},
            year = {2018},
         journal = {Acta Astronautica},
             doi = {10.1016/j.actaastro.2018.05.025},
           pages = {567--579},
        keywords = {ARRAY(0x5632134a1d90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39622/},
        abstract = {Previous and current Mars rover missions have noted a nearly ubiquitous presence of duricrusts on the planet surface. Duricrusts are thin, brittle layers of cemented regolith that cover the underlying terrain. In some cases, the duricrust hides safe or relatively safe underneath the top soil. However, as was observed by both Mars exploration rovers, Spirit and Opportunity, such crusts can also hide loose, untrafficable terrain, leading to Spirit becoming permanently incapacitated in 2009. Whilst several reports of the Martian surface have indicated the presence of duricrusts, none have been able to provide details on the physical properties of the material, which may indicate the level of safe traversability of duricrust terrains. This paper presents the findings of testing terrestrially-created duricrusts with simulated Martian soil properties, in order to determine the properties of such duricrusts and to discover what level of hazard that they may represent (e.g. can vehicles traverse the duricrust surface without penetration to lower sub-surface soils?). Combinations of elements that have been observed in the Martian soil were used as the basis for forming the laboratory-created duricrusts. Variations in duricrust thickness, water content, and the iron oxide compound were investigated. As was observed throughout the testing process, duricrusts behave in a rather brittle fashion and are easily destroyed by low surface pressures. This indicates that duricrusts are not safe for traversing and they present a definite hazard for travelling on the Martian landscape when utilising only visual terrain classification, as the surface appearance is not necessarily representative of what may be lying beneath.}
}

@article{lincoln38404,
          volume = {10767},
          author = {Z. Li and A. Cohen and Simon Parsons},
            note = {cited By 0},
           title = {Two forms of minimality in ASPIC+},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-01713-2{$_1$}{$_5$}},
           pages = {203--218},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38404/}
}

@article{lincoln38405,
          volume = {10757},
          author = {Z. Li and N. Oren and S. Parsons},
            note = {cited By 0},
           title = {On the links between argumentation-based reasoning and nonmonotonic reasoning},
       publisher = {Springer},
            year = {2018},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-75553-3\_5},
           pages = {67--85},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38405/},
        abstract = {In this paper we investigate the links between instantiated argumentation systems and the axioms for non-monotonic reasoning described in [15] with the aim of characterising the nature of argument based reasoning. In doing so, we consider two possible interpretations of the consequence relation, and describe which axioms are met by   ASPIC+  under each of these interpretations. We then consider the links between these axioms and the rationality postulates. Our results indicate that argument based reasoning as characterised by   ASPIC+  is{--}according to the axioms of [15]{--}non-cumulative and non-monotonic, and therefore weaker than the weakest non-monotonic reasoning systems considered in [15]. This weakness underpins   ASPIC+ ?s success in modelling other reasoning systems. We conclude by considering the relationship between   ASPIC+  and other weak logical systems.}
}

@article{lincoln33015,
          volume = {18},
          number = {8},
          author = {Konstantinos Liakos and Patrizia Busato and Dimitrios Moshou and Simon Pearson and Dionysis Bochtis},
            note = {This is an open access article distributed under the Creative Commons Attribution License which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. (CC BY 4.0).},
           title = {Machine Learning in Agriculture: A Review},
       publisher = {MDPI},
            year = {2018},
         journal = {Sensors},
             doi = {10.3390/s18082674},
           pages = {2674},
        keywords = {ARRAY(0x563213336760)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33015/},
        abstract = {Machine learning has emerged with big data technologies and high-performance computing to create new opportunities for data intensive science in the multi-disciplinary agri-technologies domain. In this paper, we present a comprehensive review of research dedicated to applications of machine learning in agricultural production systems. The works analyzed were categorized in (a) crop management, including applications on yield prediction, disease detection, weed detection crop quality, and species recognition; (b) livestock management, including applications on animal welfare and livestock production; (c) water management; and (d) soil management. The filtering and classification of the presented articles demonstrate how agriculture will benefit from machine learning technologies. By applying machine learning to sensor data, farm management systems are evolving into real time artificial intelligence enabled programs that provide rich recommendations and insights for farmer decision support and action}
}

@inproceedings{lincoln32540,
       booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           title = {Energy-efficient design and control of a vibro-driven robot},
          author = {Pengcheng Liu and Gerhard Neumann and Qinbing Fu and Simon Pearson and Hongnian Yu},
       publisher = {IEEE},
            year = {2018},
        keywords = {ARRAY(0x563213471178)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32540/},
        abstract = {Vibro-driven robotic (VDR) systems use stick-slip motions for locomotion. Due to the underactuated nature of the system, efficient design and control are still open problems. We present a new energy preserving design based on a spring-augmented pendulum. We indirectly control the friction-induced stick-slip motions by exploiting the passive dynamics in order to achieve an improvement in overall travelling distance and energy efficacy. Both collocated and non-collocated constraint conditions are elaborately analysed and considered to obtain a desired trajectory generation profile. For tracking control, we develop a partial feedback controller which for the pendulum which counteracts the dynamic contributions from the platform. Comparative simulation studies show the effectiveness and intriguing performance of the proposed approach, while its feasibility is experimentally verified through a physical robot. Our robot is to the best of our knowledge the first nonlinear-motion prototype in literature towards the VDR systems.}
}

@inproceedings{lincoln33448,
       booktitle = {TAROS},
           title = {Modelling and Predicting Rhythmic Flow Patterns in Dynamic Environments},
          author = {Sergi Molina Mellado and Grzegorz Cielniak and Tom{\'a}{\v s} Krajn{\'i}k and Tom Duckett},
            year = {2018},
           pages = {135--146},
        keywords = {ARRAY(0x563213336be0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33448/},
        abstract = {We present a time-dependent probabilistic map able to model and predict flow patterns of people in indoor environments. The proposed representation models the likelihood of motion direction on a grid-based map by a set of harmonic functions, which efficiently capture long-term (minutes to weeks) variations of crowd movements over time. The evaluation, performed on data from two real environments, shows that the proposed model enables prediction of human movement patterns in the future. Potential applications include human-aware motion planning, improving the efficiency and safety of robot navigation.}
}

@misc{lincoln32454,
          volume = {7},
          number = {1-2},
          author = {Takayuki Osa and Joni Pajarinen and Gerhard Neumann and J. Andrew Bagnell and Pieter Abbeel and Jan Peters},
           title = {An Algorithmic Perspective on Imitation Learning},
       publisher = {Now Publishers},
            year = {2018},
         journal = {Foundations and Trends in Robotics},
             doi = {10.1561/2300000053},
           pages = {1--179},
        keywords = {ARRAY(0x5632133367a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32454/},
        abstract = {As robots and other intelligent agents move from simple environments and problems to more complex, unstructured settings, manually programming their behavior has become increasingly challenging and expensive. Often, it is easier for a teacher to demonstrate a desired behavior rather than attempt to manually engineer it. This process of learning from demonstrations, and the study of algorithms to do so, is called imitation learning. This work provides an introduction to imitation learning. It covers the underlying assumptions, approaches, and how they relate; the rich set of algorithms developed to tackle the problem; and advice on effective tools and implementation. We intend this paper to serve two audiences. First, we want to familiarize machine learning experts with the challenges of imitation learning, particularly those arising in robotics, and the interesting theoretical and practical distinctions between it and more familiar frameworks like statistical supervised learning theory and reinforcement learning. Second, we want to give roboticists and experts in applied artificial intelligence a broader appreciation for the frameworks and tools available for imitation learning. We pay particular attention to the intimate connection between imitation learning approaches and those of structured prediction Daum{\'e} III et al. [2009]. To structure this discussion, we categorize imitation learning techniques based on the following key criteria which drive algorithmic decisions:

1) The structure of the policy space. Is the learned policy a time-index trajectory (trajectory learning), a mapping from observations to actions (so called behavioral cloning [Bain and Sammut, 1996]), or the result of a complex optimization or planning problem at each execution as is common in inverse optimal control methods [Kalman, 1964, Moylan and Anderson, 1973].

2) The information available during training and testing. In particular, is the learning algorithm privy to the full state that the teacher possess? Is the learner able to interact with the teacher and gather corrections or more data? Does the learner have a (typically a priori) model of the system with which it interacts? Does the learner have access to the reward (cost) function that the teacher is attempting to optimize?

3) The notion of success. Different algorithmic approaches provide varying guarantees on the resulting learned behavior. These guarantees range from weaker (e.g., measuring disagreement with the agent?s decision) to stronger (e.g., providing guarantees on the performance of the learner with respect to a true cost function, either known or unknown). We organize our work by paying particular attention to distinction (1): dividing imitation learning into directly replicating desired behavior (sometimes called behavioral cloning) and learning the hidden objectives of the desired behavior from demonstrations (called inverse optimal control or inverse reinforcement learning [Russell, 1998]). In the latter case, behavior arises as the result of an optimization problem solved for each new instance that the learner faces. In addition to method analysis, we discuss the design decisions a practitioner must make when selecting an imitation learning approach. Moreover, application examples{--}such as robots that play table tennis [Kober and Peters, 2009], programs that play the game of Go [Silver et al., 2016], and systems that understand natural language [Wen et al., 2015]{--} illustrate the properties and motivations behind different forms of imitation learning. We conclude by presenting a set of open questions and point towards possible future research directions for machine learning.}
}

@article{lincoln38406,
          volume = {305},
          author = {A.R. Panisson and Simon Parsons and P. McBurney and R.H. Bordini},
            note = {cited By 0},
           title = {Choosing appropriate arguments from trustworthy sources},
         journal = {Frontiers in Artificial Intelligence and Applications},
             doi = {10.3233/978-1-61499-906-5-345},
           pages = {345--352},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38406/}
}

@inproceedings{lincoln38409,
          volume = {2154},
           title = {Lies, bullshit, and deception in agent-oriented programming languages},
          author = {A.R. Panisson and S. Sarkadi and P. McBurney and Simon Parsons and R.H. Bordini},
            year = {2018},
           pages = {50--61},
            note = {cited By 2},
         journal = {CEUR Workshop Proceedings},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38409/}
}

@unpublished{lincoln34265,
            type = {Project Report},
           title = {Internet of Food Things Network Plus: IoFT Launch Event},
          author = {Simon Pearson and Steve Brewer and Jill Duarte},
         address = {Lincoln, UK},
       publisher = {University of Lincoln},
            year = {2018},
     institution = {University of Lincoln},
        keywords = {ARRAY(0x563213447ea8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34265/},
        abstract = {The Internet of Food Things Network Plus (IoFT+) launched at the IET Global Engineering Hub in London on 21 September 2018 with a gathering of experts from industry, government and academia. 

In a series of keynote talks and discussions they opened a three-year investigation into how artificial intelligence, data analytics and emerging digital technologies can improve the safety, security and efficiency of the UK food supply chain.}
}

@article{lincoln38545,
          volume = {10767},
          author = {J. Raphael and Elizabeth Sklar},
            note = {cited By 0},
           title = {Towards dynamic coalition formation for intelligent traffic management},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-01713-2},
           pages = {400--414},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38545/}
}

@inproceedings{lincoln32931,
       booktitle = {International Conference on Energy Engineering and Smart Grids},
           title = {Aggregated power profile of a large network of refrigeration compressors following FFR DSR events},
          author = {Ibrahim Saleh and Andrey Postnikov and Chris Bingham and Ronald Bickerton and Argyrios Zolotas and Simon Pearson},
       publisher = {ESG2018},
            year = {2018},
        keywords = {ARRAY(0x563213336730)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32931/},
        abstract = {Refrigeration systems and HVAC are estimated to consume approximately 14\% of the UK?s electricity and could make a significant contribution towards the application of DSR. In this paper, active power profiles of single and multi-pack refrigeration systems responding DSR events are experimentally investigated. Further, a large population of 300 packs (approx. 1.5 MW capacity) is simulated to investigate the potential of delivering DSR using a network of refrigeration compressors, in common with commercial retail refrigeration systems. Two scenarios of responding to DSR are adopted for the studies viz. with and without applying a suction pressure offset after an initial 30 second shut-down of the compressors. The experiments are conducted at the Refrigeration Research Centre at University of Lincoln. Simulations of the active power profile for the compressors following triggered DSR events are realized based on a previously reported model of the thermodynamic properties of the refrigeration system. A Simulink model of a three phase power supply system is used to determine the impact of compressor operation on the power system performance, and in particular, on the line voltage of the local power supply system. The authors demonstrate how the active power and the drawn current of the multi-pack refrigeration system are affected following a rapid shut down and subsequent return to operation. Specifically, it is shown that there is a significant increase in power consumption post DSR, approximately two times higher than during normal operation, particularly when many packs of compressors are synchronized post DSR event, which can have a significant effect on the line voltage of the power supply.}
}

@inproceedings{lincoln38540,
           title = {Explanation through argumentation},
          author = {Elizabeth Sklar and M.Q. Azhar},
            year = {2018},
           pages = {277--285},
             doi = {10.1145/3284432.3284473},
            note = {cited By 0},
         journal = {HAI 2018 - Proceedings of the 6th International Conference on Human-Agent Interaction},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38540/}
}

@incollection{lincoln38407,
          volume = {305},
          author = {A.P. Young and N. Kokciyan and I. Sassoon and S. Modgil and S. Parsons},
          series = {Frontiers in Artificial Intelligence and Applications},
            note = {cited By 1},
       booktitle = {Computational Models of Argument},
           title = {Instantiating metalevel argumentation frameworks},
       publisher = {IOS Press},
            year = {2018},
         journal = {Frontiers in Artificial Intelligence and Applications},
             doi = {10.3233/978-1-61499-906-5-97},
           pages = {97--108},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38407/},
        abstract = {We directly instantiate metalevel argumentation frameworks (MAFs) to enable argumentation-based reasoning about information relevant to various applications. The advantage of this is that information that typically cannot be incorporated via the instantiation of object-level argumentation frameworks can now be incorporated, in particular information referencing (1) preferences over arguments, (2) the rationale for attacks, and (3) the dialectical effect of critical questions that shifts the burden of proof when posed. We achieve this by using a variant of ASPIC+ and a higher-order typed language that can reference object-level formulae and arguments. We illustrate these representational advantages with a running example from clinical decision support.}
}

