@article{lincoln52115,
          volume = {13},
          number = {100051},
           month = {April},
          author = {P. Craigon and J. Sacks and S. Brewer and J. Frey and A. Gutierrez Mendoza and S. Kanza and L. Manning and S. Munday and A. Wintour and S. Pearson},
           title = {Ethics by Design: Responsible Research \& Innovation for AI in the Food Sector},
       publisher = {Elsevier},
            year = {2023},
         journal = {Journal of Responsible Technology},
             doi = {10.1016/j.jrt.2022.100051},
        keywords = {ARRAY(0x5568fbb47420)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52115/},
        abstract = {Here we reflect on how a multi-disciplinary working group explored the ethical complexities of the use of new technologies for data sharing in the food supply chain. We used a three-part process of varied design methods, which included collaborative ideation and speculative scenario development, the creation of design fiction objects, and assessment using the Moral-IT deck, a card-based tool. We present, through the lens of the EPSRC's Framework for Responsible Innovation how processes of anticipation, reflection, engagement and action built a plausible, fictional world in which a data trust uses artificial intelligence (AI) to support data sharing and decision-making across the food supply chain. This approach provides rich opportunities for considering ethical challenges to data sharing as part of a reflexive and engaged responsible innovation approach. We reflect on the value and potential of this approach as a method for engaged (co-)design and responsible innovation.}
}

@inproceedings{lincoln53780,
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           month = {April},
           title = {Domain Generalised Fully Convolutional One Stage Detection},
          author = {Karthik Seemakurthy and Petra Bosilj and Erchan Aptoula and Charles Fox},
       publisher = {IEEE},
            year = {2023},
        keywords = {ARRAY(0x5568fbb44ef8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53780/},
        abstract = {Abstract{--}Real-time vision in robotics plays an important role in localising and recognising objects. Recently, deep learning approaches have been widely used in robotic vision. However, most of these approaches have assumed that training and test sets come from similar data distributions, which is not valid in many real world applications. This study proposes an approach to address domain generalisation (i.e. out-of distribution generalisation, OODG) where the goal is to train a model via one or more source domains, that will generalise well to unknown target domains using single stage detectors. All existing approaches which deal with OODG either use slow two stage detectors or operate under the covariate shift assumption which may not be useful for real-time robotics. This is the first paper to address domain generalisation in the context of single stage anchor free object detector FCOS without the covariate shift assumption. We focus on improving the generalisation ability of object detection by proposing new regularisation terms to address the domain shift that arises due to both classification and bounding box regression. Also, we include an additional consistency regularisation term to align the local and global level predictions. The proposed approach is implemented as a Domain Generalised Fully Convolutional One Stage (DGFCOS) detection and evaluated using four object detection datasets which provide domain metadata (GWHD, Cityscapes, BDD100K, Sim10K) where it exhibits a consistent performance improvement over the baselines and is able to run in real-time for robotics.}
}

@inproceedings{lincoln53113,
       booktitle = {Conference on Causal Learning and Reasoning (CLeaR)},
           month = {April},
           title = {Enhancing Causal Discovery from Robot Sensor Data in Dynamic Scenarios},
          author = {Luca Castri and Sariah Mghames and Marc Hanheide and Nicola Bellotto},
            year = {2023},
        keywords = {ARRAY(0x5568fbb44ee0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53113/},
        abstract = {Identifying the main features and learning the causal relationships of a dynamic system from time-series of sensor data are key problems in many real-world robot applications. In this paper, we propose an extension of a state-of-the-art causal discovery method, PCMCI, embedding an additional feature-selection module based on transfer entropy. Starting from a prefixed set of variables, the new algorithm reconstructs the causal model of the observed system by considering only the its main features and neglecting those deemed unnecessary for understanding the evolution of the system. We first validate the method on a toy problem, for which the ground-truth model is available, and then on a real-world robotics scenario using a large-scale time-series dataset of human trajectories. The experiments demonstrate that our solution outperforms the previous state-of-the-art technique in terms of accuracy and computational efficiency, allowing better and faster causal discovery of meaningful models from robot sensor data.}
}

@inproceedings{lincoln54118,
           month = {March},
          author = {Marina Constantinou and Riccardo Polvara and Evagoras Makridis},
       booktitle = {17th International Technology, Education and Development Conference},
           title = {The technologisation of thematic analysis: a case study into automatising qualitative research},
       publisher = {IATED},
            year = {2023},
         journal = {17th International Technology, Education and Development Conference},
             doi = {10.21125/inted.2023.0323},
           pages = {1092--1098},
        keywords = {ARRAY(0x5568fbb474b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54118/},
        abstract = {Thematic analysis is the most commonly used form of qualitative analysis used extensively in educational sciences. While the process is straightforward in the sense that a hermeneutic analysis is conducted so as to detect patterns and assign themes emerging from the data acquired, replicability can be challenging. As a result, there is significant debate about what constitutes reliability and rigour in relation to qualitative coding. Traditional thematic analysis in educational sciences requires the development of a codebook and the recruitment of a research team for intercoder reviewing and code testing. Such a process is often lengthy and infeasible when the number of texts to be analysed increases exponentially. To overcome these limitations, in this work, we use an unsupervised text analysis technique called the Latent Dirichlet Allocation (LDA) to identify distinct abstract topics which are then clustered into potential themes. Our results show that thematic analysis in the field of educational sciences using the LDA text analysis technique has prospects of demonstrating rigour and higher thematic coding reliability and validity while offering a valid intra-coder complementary support to the researcher.}
}

@article{lincoln53439,
          volume = {133},
           month = {March},
          author = {L. Manning and S. Brewer and P. Craigon and J. Frey and A. Gutierrez and N. Jacobs and S. Kanza and S. Munday and J. Sacks and S. Pearson},
           title = {Reflexive governance architectures: considering the ethical implications of autonomous technology adoption in food supply chains},
       publisher = {Elsevier},
            year = {2023},
         journal = {Trends in Food Science \& Technology},
             doi = {10.1016/j.tifs.2023.01.015},
           pages = {114--126},
        keywords = {ARRAY(0x5568fbb47498)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53439/},
        abstract = {Background: The application of autonomous technology in food supply chains gives rise to a number of ethical considerations associated with the interaction between human and technology, human-technology-plant and human-technology-animal. These considerations and their implications influence technology design, the ways in which technology is applied, how the technology changes food supply chain practices, decision-making and the associated ethical aspects and outcomes.
Scope and approach: Using the concept of reflexive governance, this paper has critiqued existing reflective food-related ethical assessment tools and proposed the structural elements required for reflexive governance architectures which address both the sharing of data, and the use of artificial intelligence (AI) and machine learning in food supply chains. 
Key findings and conclusions: Considering the ethical implications of using autonomous technology in real life contexts is challenging. The current approach, focusing on discrete ethical elements in isolation e.g., ethical aspects or outcomes, normative standards or ethically orientated compliance-based business strategies is not sufficient in itself. Alternatively, the application of more holistic, reflexive governance architectures can inform consideration of ethical aspects, potential ethical outcomes, in particular how they are interlinked and/or interdependent, and the need for mitigation at all lifecycle stages of technology and food product conceptualisation, design, realisation and adoption in the food supply chain. This research is of interest to those who are undertaking ethical deliberation on data sharing, and  the use of AI and machine learning in food supply chains.}
}

@inproceedings{lincoln53114,
       booktitle = {18th International Conference on Computer Vision Theory and Applications (VISAPP)},
           month = {February},
           title = {Evaluation of Computer Vision-Based Person Detection on Low-Cost Embedded Systems},
          author = {Francesco Pasti and Nicola Bellotto},
            year = {2023},
        keywords = {ARRAY(0x5568fbb474f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53114/},
        abstract = {Person detection applications based on computer vision techniques often rely on complex Convolutional Neural Networks that require powerful hardware in order achieve good runtime performance. The work of this paper has been developed with the aim of implementing a safety system, based on computer vision algorithms, able to detect people in working environments using an embedded device. Possible applications for such safety systems include remote site monitoring and autonomous mobile robots in warehouses and industrial premises. Similar studies already exist in the literature, but they mostly rely on systems like NVidia Jetson that, with a Cuda enabled GPU, are able to provide satisfactory results. This, however, comes with a significant downside as such devices are usually expensive and require significant power consumption. The current paper instead is going to consider various implementations of computer vision-based person detection on two power-efficient and inexpensive devices, namely Raspberry Pi 3 and 4. In order to do so, some solutions based on off-the-shelf algorithms are first explored by reporting experimental results based on relevant performance metrics. Then, the paper presents a newly-created custom architecture, called eYOLO, that tries to solve some limitations of the previous systems. The experimental evaluation demonstrates the good performance of the proposed approach and suggests ways for further improvement.}
}

@inproceedings{lincoln53115,
       booktitle = {AAAI Bridge Program ?AI and Robotics?},
           month = {February},
           title = {Towards Long-term Autonomy: A Perspective from Robot Learning},
          author = {Zhi Yan and Li Sun and Tomas Krajnik and Tom Duckett and Nicola Bellotto},
            year = {2023},
        keywords = {ARRAY(0x5568fbb4fcc0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53115/},
        abstract = {In the future, service robots are expected to be able to operate autonomously for long periods of time without human intervention. Many work striving for this goal have been emerging with the development of robotics, both hardware and software. Today we believe that an important underpinning of long-term robot autonomy is the ability of robots to learn on site and on-the-fly, especially when they are deployed in changing environments or need to traverse different environments. In this paper, we examine the problem of long-term autonomy from the perspective of robot learning, especially in an online way, and discuss in tandem its premise "data" and the subsequent "deployment".}
}

@inproceedings{lincoln50521,
           month = {January},
          author = {Fetullah Atas and Grzegorz Cielniak and Lars Grimstad},
            note = {ISBN: 978-3-031-22216-0},
       booktitle = {17th International Conference on Intelligent Autonomous Systems},
           title = {Benchmark of Sampling-Based Optimizing Planners for Outdoor Robot Navigation},
       publisher = {Springer},
            year = {2023},
             doi = {10.1007/978-3-031-22216-0\_16},
           pages = {231--243},
        keywords = {ARRAY(0x5568fbb47438)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50521/},
        abstract = {This paper evaluates Sampling-Based Optimizing (SBO) planners from the Open Motion Planning Library (OMPL) in the context of mobile robot navigation in outdoor environments. Many SBO planners have been proposed, and determining performance differences among these planners for path planning problems can be time-consuming and ambiguous. The probabilistic nature of SBO planners can also complicate this procedure, as different results for the same planning problem can be obtained even in consecutive queries from the same planner. We compare all available SBO planners in OMPL with an automated planning problem generation method designed specifically for outdoor robot navigation scenarios. Several evaluation metrics are chosen, such as the length, smoothness, and success rate of the resulting path, and probability distributions for metrics are presented. With the experimental results obtained, clear recommendations on high-performing planners for mobile robot path planning problems are made, which will be useful to researchers and practitioners in mobile robot planning and navigation.}
}

@article{lincoln52872,
          volume = {7},
          number = {1},
           month = {January},
          author = {Vijja Wichitwechkarn and Charles Fox},
           title = {MACARONS: A Modular and Open-Sourced Automation System for Vertical Farming},
       publisher = {Ubiquity Press},
            year = {2023},
         journal = {Jounral of Open Hardware},
             doi = {10.5334/joh.53},
        keywords = {ARRAY(0x5568fbb47450)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52872/},
        abstract = {The Modular Automated Crop Array Online System (MACARONS) is an extensible, scalable, open hardware system for plant transport in automated horticulture systems such as vertical farms.  It is specified to move trays of plants up to 1060mm \${$\backslash$}times\$ 630mm and 12.5kg at a rate of 100mm/s along the guide rails and 41.7mm/s up the lifts, such as between stations for monitoring and actuating plants. The cost for the construction of one grow unit of MACARONS is 144.96USD which equates to 128.85USD/m\${\^{ }}2\$ of grow area. The designs are released and meets the requirements of CERN-OSH-W, which includes step-by-step graphical build instructions and can be built by a typical technical person in one day at a cost of 1535.50 USD.  Integrated tests are included in the build instructions are used to validate against the specifications, and we report on a successful build.  Through a simple analysis, we demonstrate that MACARONS can operate at a rate sufficient to automate tray loading/unloading, to reduce labour costs in a vertical farm.}
}

@article{lincoln54285,
           title = {DeepVerge: Classification of Roadside Verge Biodiversity and Conservation Potential},
          author = {Andrew Perrett and Harry Pollard and Charlie Barnes and Mark Schofield and Lan Qie and Petra Bosilj and James Brown},
       publisher = {Elsevier},
            year = {2023},
         journal = {Computers, Environment and Urban Systems},
        keywords = {ARRAY(0x5568fbb4fcf0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54285/},
        abstract = {Grasslands are increasingly modified by anthropogenic activities and species rich grasslands have become rare habitats in the UK. However, grassy roadside verges often contain conservation priority plant species and should be targeted for protection. Identification of verges with high conservation potential represents a considerable challenge for ecologists, driving the development of automated methods to make up for the shortfall of relevant expertise nationally. Using survey data from 3,900 km of roadside verges alongside publicly available street-view imagery, we present DeepVerge: a deep learning-based method that can automatically survey sections of roadside verge by detecting the presence of positive indicator species. Using images and ground truth survey data from the rural UK county of Lincolnshire, DeepVerge achieved a mean accuracy of 88\% and a mean F1 score of 0.82. Such a method may be used by local authorities to identify new local wildlife sites, and aid management and environmental planning in line with legal and government policy obligations, saving thousands of hours of skilled labour}
}

@article{lincoln52940,
          volume = {205},
           month = {December},
          author = {Chao Qi and Murilo Sandroni and Jesper Cairo Westergaard and Ea H{\o}egh Riis Sundmark and Merethe Bagge and Erik Alexandersson and Junfeng Gao},
           title = {In-field classification of the asymptomatic biotrophic phase of potato late blight based on deep learning and proximal hyperspectral imaging},
       publisher = {Elsevier},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2022.107585},
            year = {2022},
        keywords = {ARRAY(0x5568fbb4fd08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52940/},
        abstract = {Effective detection of potato late blight (PLB) is an essential aspect of potato cultivation. However, it is a challenge to detect late blight in asymptomatic biotrophic phase in fields with conventional imaging approaches because of the lack of visual symptoms in the canopy. Hyperspectral imaging can capture spectral signals from a wide range of wavelengths also outside the visual wavelengths. Here, we propose a deep learning classification architecture for hyperspectral images by combining 2D convolutional neural network (2D-CNN) and 3D-CNN with deep cooperative attention networks (PLB-2D-3D-A). First, 2D-CNN and 3D-CNN are used to extract rich spectral space features, and then the attention mechanism AttentionBlock and SE-ResNet are used to emphasize the salient features in the feature maps and increase the generalization ability of the model. The dataset is built with 15,360 images (64x64x204), cropped from 240 raw images captured in an experimental field with over 20 potato genotypes. The accuracy in the test dataset of 2000 images reached 0.739 in the full band and 0.790 in the specific bands (492 nm, 519 nm, 560 nm, 592 nm, 717 nm and 765 nm). This study shows an encouraging result for classification of the asymptomatic biotrophic phase of PLB disease with deep learning and proximal hyperspectral imaging.}
}

@inproceedings{lincoln51680,
           month = {December},
          author = {Adrian Salazar-Gomez and Madeleine Darbyshire and Junfeng Gao and Elizabeth Sklar and Simon Parsons},
       booktitle = {2022 IEEE/RSJ International Conference on Intelligent Robots and Systems},
           title = {Beyond mAP: Towards practical object detection for weed spraying in precision agriculture},
       publisher = {IEEE Press},
             doi = {10.1109/IROS47612.2022.9982139},
           pages = {9232--9238},
            year = {2022},
        keywords = {ARRAY(0x5568fbb4fd38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/51680/},
        abstract = {The evolution of smaller and more powerful GPUs over the last 2 decades has vastly increased the opportunity to apply robust deep learning-based machine vision approaches to real-time use cases in practical environments. One exciting application domain for such technologies is precision agriculture, where the ability to integrate on-board machine vision with data-driven actuation means that farmers can make decisions about crop care and harvesting at the level of the individual plant rather than the whole field. This makes sense both economically and environmentally. This paper assesses the feasibility of precision spraying weeds via a comprehensive evaluation of weed detection accuracy and speed using two separate datasets, two types of GPU, and several state-of-the-art object detection algorithms. A simplified model of precision spraying is used to determine whether the weed detection accuracy achieved could result in a sufficiently high weed hit rate combined with a significant reduction in herbicide usage. The paper introduces two metrics to capture these aspects of the real-world deployment of precision weeding and demonstrates their utility through experimental results.}
}

@article{lincoln52689,
          volume = {31},
           month = {November},
          author = {Asier Lopez Zorrilla and M. Ines Torres and Heriberto Cuayahuitl},
           title = {Audio Embedding-Aware Dialogue Policy Learning},
       publisher = {IEEE},
            year = {2022},
         journal = {IEEE TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING},
             doi = {10.1109/TASLP.2022.3225658},
           pages = {525--538},
        keywords = {ARRAY(0x5568fbb4fd50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52689/},
        abstract = {Following the success of Natural Language Processing (NLP) transformers pretrained via self-supervised learning, similar models have been proposed recently for speech processing such as Wav2Vec2, HuBERT and UniSpeech-SAT. An interesting yet unexplored area of application of these models is Spoken Dialogue Systems, where the users? audio signals are typically just mapped to word-level features derived from an Automatic Speech Recogniser (ASR), and then processed using NLP techniques to generate system responses. This paper reports a comprehensive comparison of dialogue policies trained using ASR-based transcriptions and extended with the aforementioned audio processing transformers in the DSTC2 task. Whilst our dialogue policies are trained with supervised and policy-based deep reinforcement learning, they are assessed using both automatic task completion metrics and a human evaluation. Our results reveal that using audio embeddings is more beneficial than detrimental in most of our trained dialogue policies, and that the benefits are stronger for supervised learning than reinforcement learning.}
}

@article{lincoln53298,
          volume = {14},
          number = {22},
           month = {November},
          author = {Mohamad Al Al Mdfaa and Geesara Kulathunga and Alexandr Klimchik},
           title = {3D-SiamMask: Vision-Based Multi-Rotor Aerial-Vehicle Tracking for a Moving Object},
       publisher = {MDPI},
            year = {2022},
         journal = {Remote Sensing},
             doi = {10.3390/rs14225756},
           pages = {5756},
        keywords = {ARRAY(0x5568fbb4fd80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53298/},
        abstract = {This paper aims to develop a multi-rotor-based visual tracker for a specified moving object. Visual object-tracking algorithms for multi-rotors are challenging due to multiple issues such as occlusion, quick camera motion, and out-of-view scenarios. Hence, algorithmic changes are required for dealing with images or video sequences obtained by multi-rotors. Therefore, we propose two approaches: a generic object tracker and a class-specific tracker. Both tracking settings require the object bounding box to be selected in the first frame. As part of the later steps, the object tracker uses the updated template set and the calibrated RGBD sensor data as inputs to track the target object using a Siamese network and a machine-learning model for depth estimation. The class-specific tracker is quite similar to the generic object tracker but has an additional auxiliary object classifier. The experimental study and validation were carried out in a robot simulation environment. The simulation environment was designed to serve multiple case scenarios using Gazebo. According to the experiment results, the class-specific object tracker performed better than the generic object tracker in terms of stability and accuracy. Experiments show that the proposed generic tracker achieves promising results on three challenging datasets. Our tracker runs at approximately 36 fps on GPU. {\copyright} 2022 by the authors.}
}

@inproceedings{lincoln52220,
       booktitle = {6th Conference on Robot Learning},
           month = {November},
           title = {Proactive slip control by learned slip model and trajectory adaptation},
          author = {Kiyanoush Nazari and Willow Mandil and Amir Ghalamzan Esfahani},
            year = {2022},
         journal = {Conference of Robot Learning},
        keywords = {ARRAY(0x5568fbb4fdb0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52220/},
        abstract = {This paper presents a novel control approach to dealing with object slip during robotic manipulative movements. Slip is a major cause of failure in many robotic grasping and manipulation tasks. Existing works increase grip force to avoid/control slip. However, this may not be feasible when (i) the robot cannot increase the gripping force? the max gripping force is already applied or (ii) in- creased force damages the grasped object, such as soft fruit. Moreover, the robot fixes the gripping force when it forms a stable grasp on the surface of an object, and changing the gripping force during real-time manipulation may not be an effective control policy. We propose a novel control approach to slip avoidance including a learned action-conditioned slip predictor and a constrained optimiser avoiding a predicted slip given a desired robot action. We show the effectiveness of the proposed trajectory adaptation method with the receding horizon controller with a series of real-robot test cases. Our experimental results show our proposed data-driven predictive controller can control slip for objects unseen in training.}
}

@inproceedings{lincoln52266,
       booktitle = {International Conference on Social Robotics (ICSR)},
           month = {October},
           title = {Causal Discovery of Dynamic Models for Predicting Human Spatial Interactions},
          author = {Luca Castri and Sariah Mghames and Marc Hanheide and Nicola Bellotto},
       publisher = {Springer},
            year = {2022},
        keywords = {ARRAY(0x5568fbb4fde0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52266/},
        abstract = {Exploiting robots for activities in human-shared environments, whether warehouses, shopping centres or hospitals, calls for such robots to understand the underlying physical interactions between nearby agents and objects. In particular, modelling cause-and-effect relations between the latter can help to predict unobserved human behaviours and anticipate the outcome of specific robot interventions. In this paper, we propose an application of causal discovery methods to model human-robot spatial interactions, trying to understand human behaviours from real-world sensor data in two possible scenarios: humans interacting with the environment, and humans interacting with obstacles. New methods and practical solutions are discussed to exploit, for the first time, a state-of-the-art causal discovery algorithm in some challenging human environments, with potential application in many service robotics scenarios. To demonstrate the utility of the causal models obtained from real-world datasets, we present a comparison between causal and non-causal prediction approaches. Our results show that the causal model correctly captures the underlying interactions of the considered scenarios and improves its prediction accuracy.}
}

@inproceedings{lincoln52350,
       booktitle = {Perception and Navigation for Autonomous Robotics in Unstructured and Dynamic Environments},
           month = {October},
           title = {Collection and Evaluation of a Long-Term 4D Agri-Robotic Dataset},
          author = {Riccardo Polvara and Sergio Molina Mellado and Ibrahim Hroob and Grzegorz Cielniak and Marc Hanheide},
            year = {2022},
             doi = {10.5281/zenodo.7135175},
        keywords = {ARRAY(0x5568fbb4fe10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52350/},
        abstract = {Long-term autonomy is one of the most demanded capabilities looked into a robot. The possibility to perform the same task over and over on a long temporal horizon, offering a high standard of reproducibility and robustness, is appealing. Long-term autonomy can play a crucial role in the adoption of robotics systems for precision agriculture, for example in assisting humans in monitoring and harvesting crops in a large orchard. With this scope in mind, we report an ongoing effort in the long-term deployment of an autonomous mobile robot in a vineyard for data collection across multiple months. The main aim is to collect data from the same area at different points in time so to be able to analyse the impact of the environmental changes in the mapping and localisation tasks.
In this work, we present a map-based localisation study taking 4 data sessions. We identify expected failures when the pre-built map visually differs from the environment's current appearance and we anticipate LTS-Net, a solution pointed at extracting stable temporal features for improving long-term 4D localisation results.}
}

@article{lincoln52212,
           month = {October},
           title = {Multi-agent task allocation for harvest management},
          author = {Helen Harman and Elizabeth Sklar},
       publisher = {Frontiers},
            year = {2022},
             doi = {10.3389/frobt.2022.864745},
         journal = {Frontiers in Robotics and AI},
        keywords = {ARRAY(0x5568fbb4fe40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52212/},
        abstract = {Multi-agent task allocation methods seek to distribute a set of tasks fairly amongst a set of agents. In real-world settings, such as soft fruit farms, human labourers undertake harvesting tasks. The harvesting workforce is typically organised by farm manager(s) who assign workers to the fields that are ready to be harvested and team leaders who manage the workers in the fields. Creating these assignments is a dynamic and complex problem, as the skill of the workforce and the yield (quantity of ripe fruit picked) are variable and not entirely predictable. The work presented here posits that multi-agent task allocation methods can assist farm managers and team leaders to manage the harvesting workforce effectively and efficiently. There are three key challenges faced when adapting multi-agent approaches to this problem: (i) staff time (and thus cost) should be minimised; (ii) tasks must be distributed fairly to keep staff motivated; and (iii) the approach must be able to handle incremental (incomplete) data as the season progresses. An adapted variation of Round Robin (RR) is proposed for the problem of assigning workers to fields, and market-based task allocation mechanisms are applied to the challenge of assigning tasks to workers within the fields. To evaluate the approach introduced here, experiments are performed based on data that was supplied by a large commercial soft fruit farm for the past two harvesting seasons. The results demonstrate that our approach produces appropriate worker-to-field allocations. Moreover, simulated experiments demonstrate that there is a ?sweet spot? with respect to the ratio between two types of in-field workers.}
}

@inproceedings{lincoln52845,
       booktitle = {2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {October},
           title = {Elevation State-Space: Surfel-Based Navigation in Uneven Environments for Mobile Robots},
          author = {Fetullah Atas and Grzegorz Cielniak and Grimstad Lars},
       publisher = {IEEE},
            year = {2022},
        keywords = {ARRAY(0x5568fbb4fe70)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52845/},
        abstract = {This paper introduces a new method for robot motion planning and navigation in uneven environments through a surfel representation of underlying point clouds. The proposed method addresses the shortcomings of state-of-the-art navigation methods by incorporating both kinematic and physical constraints of a robot with standard motion planning algorithms (e.g., those from the Open Motion Planning Library), thus enabling efficient sampling-based planners for challenging uneven terrain navigation on raw point cloud maps. Unlike techniques based on Digital Elevation Maps (DEMs), our novel surfel-based state-space formulation and implementation are based on raw point cloud maps, allowing for the modeling of overlapping surfaces such as bridges, piers, and tunnels. Experimental results demonstrate the robustness of the proposed method for robot navigation in real and simulated unstructured environments. The proposed approach also optimizes planners' performances by boosting their success rates up to 5x for challenging unstructured terrain planning and navigation, thanks to our surfel-based approach's robot constraint-aware sampling strategy. Finally, we provide an open-source implementation of the proposed method to benefit the robotics community.}
}

@inproceedings{lincoln50442,
           month = {October},
          author = {Abdalkarim Mohtasib and Gerhard Neumann and Heriberto Cuayahuitl},
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           title = {Robot Policy Learning from Demonstration Using Advantage Weighting and Early Termination},
       publisher = {IEEE},
             doi = {10.1109/IROS47612.2022.9981056},
           pages = {7414--7420},
            year = {2022},
        keywords = {ARRAY(0x5568fbb4fea0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50442/},
        abstract = {Learning robotic tasks in the real world is still highly challenging and effective practical solutions remain to be found. Traditional methods used in this area are imitation learning and reinforcement learning, but they both have limitations when applied to real robots. Combining reinforcement learning with pre-collected demonstrations is a promising approach that can help in learning control policies to solve robotic tasks. In this paper, we propose an algorithm that uses novel techniques to leverage offline expert data using offline and online training to obtain faster convergence and improved performance. The proposed algorithm (AWET) weights the critic losses with a novel agent advantage weight to improve over the expert data. In addition, AWET makes use of an automatic early termination technique to stop and discard policy rollouts that are not similar to expert trajectories---to prevent drifting far from the expert data. In an ablation study, AWET showed improved and promising performance when compared to state-of-the-art baselines on four standard robotic tasks.}
}

@article{lincoln52098,
          volume = {9},
           month = {October},
          author = {Manu Harikrishnan Nair and Mini Chrakravarthini Rai and Mithun Poozhiyil},
           title = {Design Engineering a Walking Robotic Manipulator for In-Space Assembly Missions},
       publisher = {Frontiers Media},
            year = {2022},
         journal = {Frontiers in Robotics and AI},
             doi = {10.3389/frobt.2022.995813},
           pages = {995813},
        keywords = {ARRAY(0x5568fbb4fed0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52098/},
        abstract = {In-Space Services aim to introduce sustainable futuristic technology to support the current and growing orbital ecosystem. As the scale of space missions grows, there is a need for more extensive infrastructures in orbit. In-Space Assembly missions would hold one of the key responsibilities in meeting the increasing demand. In the forthcoming decades, newer infrastructures in the Earth?s orbits, which are much more advanced than the International Space Station are needed for in-situ manufacturing, servicing, and astronomical and observational stations. The prospect of in-orbit commissioning a Large Aperture Space Telescope (LAST) has fuelled scientific and commercial interests in deep-space astronomy and Earth Observation. However, the in-situ assembly of such large-scale, high-value assets in extreme environments, like space, is highly challenging and requires advanced robotic solutions. This paper introduces an innovative dexterous walking robotic system for in-orbit assembly missions and considers the Large Aperture Space
Telescope system with an aperture of 25m as the use case. The top-level assembly requirements are identified with a deep insight into the critical functionalities and challenges to overcome while assembling the modular LAST. The design and sizing of an End-over-end Walking Robot (E-Walker) are discussed based on the design of the LAST and the specifications of the spacecraft platform. The E-Walker?s detailed design engineering includes the structural finite element analysis results for space and earth-analogue design and the corresponding actuator selection methods. Results of the modal analysis demonstrate the deflections in the E-Walker links and end-effector in the open-loop due to the extremities present in the space environment. The design and structural analysis of E-Walker?s scaled-down prototype is also presented to showcase its feasibility in supporting both in-orbit and terrestrial activities requiring robotic capabilities over an enhanced workspace. Further, the mission concept of operations is presented based on two E-Walkers that carry out the assembly of the mirror modules. The mission discussed was shortlisted after conducting an extensive trade-off study in the literature. Simulated results prove the dual E-Walker robotic system?s efficacy for accomplishing complex in-situ assembly operations through task-sharing.}
}

@article{lincoln52159,
           month = {October},
           title = {Unfreezing autonomous vehicles with game theory, proxemics, and trust},
          author = {Fanta Camara and Charles Fox},
       publisher = {Frontiers Media},
            year = {2022},
             doi = {10.3389/fcomp.2022.969194},
         journal = {Frontiers in Computer Science},
        keywords = {ARRAY(0x5568fbb4ff00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52159/},
        abstract = {Recent years have witnessed the rapid deployment of robotic systems in
public places such as roads, pavements, workplaces and care homes. Robot
navigation in environments with static objects is largely solved, but navigating
around humans in dynamic environments remains an active research question
for autonomous vehicles (AVs). To navigate in human social spaces, self-driving
cars and other robots must also show social intelligence. This involves
predicting and planning around pedestrians, understanding their personal
space, and establishing trust with them. Most current AVs, for legal and
safety reasons, consider pedestrians to be obstacles, so these AVs always
stop for or replan to drive around them. But this highly safe nature may lead
pedestrians to take advantage over them and slow their progress, even to a
complete halt. We provide a review of our recent research on predicting and
controlling human?AV interactions, which combines game theory, proxemics
and trust, and uni?es these ?elds via quantitative, probabilistic models and
robot controllers, to solve this ?freezing robot? problem.}
}

@inproceedings{lincoln50057,
           month = {October},
          author = {Helen Harman and Elizabeth Sklar},
       booktitle = {Advances in Practical Applications of Agents, Multi-Agent Systems, and Complex Systems Simulation. The PAAMS Collection},
           title = {Multi-Agent Task Allocation Techniques for Harvest Team Formation},
       publisher = {Springer},
             doi = {10.1007/978-3-031-18192-4\_18},
           pages = {217--228},
            year = {2022},
        keywords = {ARRAY(0x5568fbb4ff30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50057/},
        abstract = {With increasing demands for soft fruit and shortages of seasonal workers, farms are seeking innovative solutions for efficiently managing their workforce. The harvesting workforce is typically organised by farm managers who assign workers to the fields that are ready to be harvested. They aim to minimise staff time (and costs) and distribute work fairly, whilst still picking all ripe fruit within the fields that need to be harvested. This paper posits that this problem can be addressed using multi-criteria, multi-agent task allocation techniques. The work presented compares the application of Genetic Algorithms (GAs) vs auction-based approaches to the challenge of assigning workers with various skill sets to fields with various estimated yields. These approaches are evaluated alongside a previously suggested method and the teams that were manually created by a farm manager during the 2021 harvesting season. Results indicate that the GA approach produces more efficient team allocations than the alternatives assessed.}
}

@unpublished{lincoln50259,
       booktitle = {4th International Conference on�Control and Robotics (ICCR 2022)},
           month = {October},
           title = {Peduncle Gripping and Cutting Force for Strawberry Harvesting Robotic end-effector Design},
          author = {Rajendran Sugathakumary Vishnu and Soran Parsa and Simon Parsons and Amir Ghalamzan Esfahani},
            year = {2022},
         journal = {4th International Conference on Control and Robotics (ICCR 2022)},
        keywords = {ARRAY(0x5568fbb4ff60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50259/},
        abstract = {Robotic harvesting of strawberries has gained much interest in the recent past. Although there are many innovations, they haven?t yet reached a level that is comparable to an expert human picker. The end effector unit plays a major role in defining the efficiency of such a robotic harvesting system. Even though there are reports on various end effectors for strawberry harvesting, but there they lack a picture of certain parameters that the researchers can rely upon to develop new end effectors. These parameters include the limit of gripping force that can be applied on the peduncle for effective gripping, the force required to cut the strawberry peduncle, etc. These estimations would be helpful in the design cycle of the end effectors that target to grip and cut the strawberry peduncle during the harvesting action. This paper studies the estimation and analysis of these parameters experimentally. It has been estimated that the peduncle gripping force can be limited to 10 N. This enables an end effector to grip a strawberry of mass up to 50 grams with a manipulation acceleration of 50 m/s2 without squeezing the peduncle. The study on peduncle cutting force reveals that a force of 15 N is sufficient to cut strawberry peduncle using a blade with a wedge angle of 16.60 at 300 orientation.}
}

@inproceedings{lincoln52805,
           month = {September},
          author = {Hao Luan and Mu Hua and Jigen Peng and Shigang Yue and Shengyong Chen and Qinbing Fu},
       booktitle = {2022 International Joint Conference on Neural Networks (IJCNN)},
           title = {Accelerating Motion Perception Model Mimics the Visual Neuronal Ensemble of Crab},
       publisher = {IEEE},
             doi = {10.1109/IJCNN55064.2022.9892540},
           pages = {1--8},
            year = {2022},
        keywords = {ARRAY(0x5568fbb4ff90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52805/},
        abstract = {In nature, crabs have a panoramic vision for the localization and perception of accelerating motion from local segments to global view in order to guide reactive behaviours including escape. The visual neuronal ensemble in crab plays crucial roles in such capability, however, has never been investigated and modelled as an artificial vision system. To bridge this gap, we propose an accelerating motion perception model (AMPM) mimicking the visual neuronal ensemble in crab. The AMPM includes two main parts, wherein the pre-synaptic network from the previous modelling work simulates 16 MLG1 neurons covering the entire view to localize moving objects. The emphasis herein is laid on the original modelling of MLG1s? post-synaptic network to perceive accelerating motions from a global view, which employs a novel spatial-temporal difference encoder (STDE), and an adaptive spiking threshold temporal difference encoder (AT-TDE). Specifically, the STDE transforms ?time-to-travel? between activations of two successive segments of MLG1 into excitatory post-synaptic current (EPSC), which decays with the elapse of time. The AT-TDE in two directional, i.e., counter-clockwise and clockwise accelerating detectors guarantees ?non-firing? to con-stant movements. Accordingly, the accelerating motion can be effectively localized and perceived by the whole network. The systematic experiments verified the feasibility and robustness of the proposed method. The model responses to translational accelerating motion also fit many of the explored physiological features of direction selective neurons in the lobula complex of crab (i.e. lobula complex direction cells, LCDCs). This modelling study not only provides a reasonable hypothesis for such biological neural pathways, but is also critical for developing a new neuromorphic sensor strategy.}
}

@inproceedings{lincoln49463,
       booktitle = {Model Based Space Systems and Software Engineering MBSE2021},
           month = {September},
           title = {Using Semantic Systems Engineering Techniques to Verity the Large Aperture Space Telescope Mission ? Current Status},
          author = {Joe Gregory and Manu H. Nair and Gianmaria Bullegas and Mini Rai Saaj},
       publisher = {European Space Agency},
            year = {2022},
        keywords = {ARRAY(0x5568fbb4ffc0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49463/},
        abstract = {MBSE aims to integrate engineering models across tools and domain boundaries to support traditional systems engineering activities (e.g., requirements elicitation and traceability, design, analysis, verification and validation). However, MBSE does not inherently solve interoperability with the multiple model-based infrastructures involved in a complex systems engineering project. The challenge is to implement digital continuity in the three dimensions of systems engineering: across disciplines, throughout the lifecycle, and along the supply chain. Space systems are ideal candidates for the application of MBSE and semantic modelling as these complex and expensive systems are mission-critical and often co-developed by multiple stakeholders. In this paper, the authors introduce the concept of Semantic Systems Engineering (SES) as an expansion of MBSE practices to include semantic modelling through SWTs. The paper also presents the progress and status of a novel Semantic Systems Engineering Ontology (SESO) in the context of a specific design case study ? the Large Aperture Space Telescope mission.}
}

@inproceedings{lincoln50390,
       booktitle = {23rd Towards Autonomous Robotic Systems (TAROS) Conference},
           month = {September},
           title = {EMap: Real-time Terrain Estimation},
          author = {Jacobus Lock and Fanta Camara and Charles Fox},
       publisher = {Springer},
            year = {2022},
        keywords = {ARRAY(0x5568fbb4fff0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50390/},
        abstract = {Terrain mapping has a many use cases in both land surveyance and autonomous vehicles.
Popular methods generate occupancy maps over 3D space, which are sub-optimal in outdoor scenarios with large, clear spaces where gaps in LiDAR readings are common.
A terrain can instead be modelled as a height map over 2D space which can iteratively be updated with incoming LiDAR data, which simplifies computation and allows missing points to be estimated based on the current terrain estimate.
The latter point is of particular interest, since it can reduce the data collection effort required (and its associated costs) and current options are not suitable to real-time operation. 
In this work, we introduce a new method that is capable of performing such terrain mapping and inferencing tasks in real-time.
We evaluate it with a set of mapping scenarios and show it is capable of generating maps with higher accuracy than an OctoMap-based method.}
}

@article{lincoln52104,
          number = {4},
           month = {September},
          author = {Gianmarco Mengaldo and Federico Renda and Steven Brunton and Moritz Bacher and Marcello Calisti and Christian Duriez and Gregory Chirikjian and Cecilia Laschi},
           title = {A concise guide to modelling the physics of embodied intelligence in soft robotics.},
       publisher = {Nature Research},
            year = {2022},
         journal = {Nature Reviews Physics},
             doi = {10.1038/s42254-022-00481-z},
           pages = {595--610},
        keywords = {ARRAY(0x5568fbb50020)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52104/},
        abstract = {Embodied intelligence (intelligence that requires and leverages a physical body) is a well-known paradigm in soft robotics, but its mathematical description and consequent computational modelling remain elusive, with a need for models that can be used for design and control purposes. We argue that filling this gap will enable full uptake of embodied intelligence in soft robots. We provide a concise guide to the main mathematical modelling approaches, and consequent computational modelling strategies, that can be used to describe soft robots and their physical interactions with the surrounding environment, including fluid and solid media. We aim to convey the challenges and opportunities within the context of modelling the physical interactions underpinning embodied intelligence. We emphasize that interdisciplinary work is required, especially in the context of fully coupled robot?environment interaction modelling. Promoting this dialogue across disciplines is a necessary step to further advance the field of soft robotics.}
}

@inproceedings{lincoln49154,
       booktitle = {International Computer Music Conference},
           month = {September},
           title = {Towards Open Source Hardware Robotic Woodwind: an Internal Duct Flute Player},
          author = {James Bennett and Bethan Moncur and Kyle Fogarty and Garry Clawson and Charles Fox},
       publisher = {ICMA},
            year = {2022},
        keywords = {ARRAY(0x5568fbb50050)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49154/},
        abstract = {We present the first open source hardware (OSH) design and build of an automated robotic internal duct flute player, including an artificial lung and pitch calibration system. Using a recorder as an introductory instrument, the system is designed to be as modular as possible, enabling  modification to fit further instruments across the woodwind family. Design considerations include the need to be as open to modification and accessible to as many people and instruments as possible.  The system is split into two physical modules: a blowing module and a fingering module, and three software modules: actuator control, pitch calibration and musical note processing via MIDI.
The system is able to perform beginner level recorder player melodies.}
}

@inproceedings{lincoln49153,
       booktitle = {International Computer Music Conference},
           month = {September},
           title = {RhythmTrain: making rhythmic sight reading training fun},
          author = {Reece Godfrey and Matthew Rimmer and Chris Headleand and Charles Fox},
       publisher = {ICMA},
            year = {2022},
        keywords = {ARRAY(0x5568fbb50080)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49153/},
        abstract = {Rhythmic sight-reading forms a barrier to many musicians' progress. It is difficult to practice in isolation, as it is hard to get feedback on accuracy.  Different performers have different starting skills in different styles so it is hard to create a general curriculum for study.  It can be boring to rehearse the same rhythms many times.   We examine theories of motivation, engagement, and fun, and draw them together to design a novel training system, RhythmTrain.   This includes consideration of dynamic difficultly, gamification and juicy design.  The system uses machine learning to learn individual performers' strengths, weaknesses, and interests, and optimises the selection of rhythms presented to maximise their engagement.  An open source implementation is released as part of this publication.}
}

@article{lincoln50417,
          volume = {197},
           month = {September},
          author = {Hamid Reza Karbasian and Javad Abolfazli Esfahani and Aliyu Musa Aliyu and Kyung Chun Kim},
           title = {Numerical analysis of wind turbines blade in deep dynamic stall},
       publisher = {Elsevier},
            year = {2022},
         journal = {Renewable Energy},
             doi = {10.1016/j.renene.2022.07.115},
           pages = {1094--1105},
        keywords = {ARRAY(0x5568fbb500b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50417/},
        abstract = {This study numerically investigates kinematics of dynamic stall, which is a crucial matter in wind turbines. Distinct movements of the blade with the same angle of attack (AOA) profile may provoke the flow field due to their kinematic characteristics. This induction can significantly change aerodynamic loads and dynamic stall process in wind turbines. The simulation involves a 3D NACA 0012 airfoil with two distinct pure-heaving and pure-pitching motions. The flow field over this 3D airfoil was simulated using Delayed Detached Eddy Simulations (DDES). The airfoil begins to oscillate at a Reynolds number of Re = 1.35 {$\times$} 105. The given attack angle profile remains unchanged for all cases. It is shown that the flow structures differ notably between pure-heaving and pure-pitching motions, such that the pure-pitching motions induce higher drag force on the airfoil than the pure-heaving motion. Remarkably, heaving motion causes excessive turbulence in the boundary layer, and then the coherent structures seem to be more stable. Hence, pure-heaving motion contains more energetic core vortices, yielding higher lift at post-stall. In contrast to conventional studies on the dynamic stall of wind turbines, current results show that airfoils? kinematics significantly affect the load predictions during the dynamic stall phenomenon.}
}

@inproceedings{lincoln52228,
           month = {September},
          author = {Laurence Roberts-Elliott and Gautham Das and Alan Millard},
       booktitle = {Towards Autonomous Robotic Systems},
         address = {Cham},
           title = {Agent-Based Simulation of Multi-robot Soil Compaction Mapping},
       publisher = {Springer International Publishing},
            year = {2022},
             doi = {10.1007/978-3-031-15908-4\_20},
           pages = {251--265},
        keywords = {ARRAY(0x5568fbb500e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52228/},
        abstract = {Soil compaction, an increase in soil density and decrease in porosity, has a negative effect on crop yields, and damaging environmental impacts. Mapping soil compaction at a high resolution is an important step in enabling precision agriculture practices to address these issues. Autonomous ground-based robotic approaches using proximal sensing have been proposed as alternatives to time-consuming and costly manual soil sampling. Soil compaction has high spatial variance, which can be challenging to capture in a limited time window. A multi-robot system can parallelise the sampling process and reduce the overall sampling time. Multi-robot soil sampling is critically underexplored in literature, and requires selection of methods to efficiently coordinate the sampling. This paper presents a simulation of multi-agent spatial sampling, extending the Mesa agent-based simulation framework, with general applicability, but demonstrated here as a testbed for different methodologies of multi-robot soil compaction mapping. To reduce the necessary number of samples for accurate mapping, while maximising information gained per sample, a dynamic sampling strategy, informed by kriging variance from kriging interpolation of sampled soil compaction values, has been implemented. This is enhanced by task clustering and insertion heuristics for task queuing. Results from the evaluation trials show the suitability of sequential single item auctions in this highly dynamic environment, and high interpolation accuracy resulting from our dynamic sampling, with avenues for improvements in this bespoke sampling methodology in future work.}
}

@article{lincoln51719,
          volume = {36},
          number = {3},
           month = {September},
          author = {Kate Smith and Marc Hanheide},
           title = {Future leaders in agri?food robotics},
       publisher = {Wiley},
            year = {2022},
         journal = {Food Science and Technology},
             doi = {10.1002/fsat.3603\_15.x},
           pages = {62--65},
        keywords = {ARRAY(0x5568fbb50110)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/51719/},
        abstract = {The AgriFoRwArdS EPSRC Centre for Doctoral Training1 (CDT) is at the fore of nurturing and developing the next cohort of experts in the agri-food robotics sector.

The Centre, established by the University of Lincoln in collaboration with the University of Cambridge and the University of East Anglia and funded by UKRI's Engineering and Physical Sciences Research Council, is providing fully funded opportunities for 50 students to undertake their PhD studies and become the next leaders in the agri-food robotics community.

Through collaboration with industry partners and utilising the expertise of the three partner organisations, the AgriFoRwArdS CDT aims to ensure that its work, and that of its students, helps transform agri-food robotics and the wider food production industry.}
}

@inproceedings{lincoln52230,
           month = {September},
          author = {Ni Wang and Gautham Das and Alan Millard},
       booktitle = {Towards Autonomous Robotic Systems},
         address = {Cham},
           title = {Learning Cooperative Behaviours in Adversarial Multi-agent Systems},
       publisher = {Springer International Publishing},
            year = {2022},
             doi = {10.1007/978-3-031-15908-4\_15},
           pages = {179--189},
        keywords = {ARRAY(0x5568fbb50140)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52230/},
        abstract = {This work extends an existing virtual multi-agent platform called RoboSumo to create TripleSumo---a platform for investigating multi-agent cooperative behaviors in continuous action spaces, with physical contact in an adversarial environment. In this paper we investigate a scenario in which two agents, namely `Bug' and `Ant', must team up and push another agent `Spider' out of the arena. To tackle this goal, the newly added agent `Bug' is trained during an ongoing match between `Ant' and `Spider'. `Bug' must develop awareness of the other agents' actions, infer the strategy of both sides, and eventually learn an action policy to cooperate. The reinforcement learning algorithm Deep Deterministic Policy Gradient (DDPG) is implemented with a hybrid reward structure combining dense and sparse rewards. The cooperative behavior is quantitatively evaluated by the mean probability of winning the match and mean number of steps needed to win.}
}

@article{lincoln52277,
          volume = {33},
           month = {September},
          author = {Nabeel Ali Khan and Mokhtar Mohammadi and Mubeen Ghafoor and Syed Ali Tariq},
           title = {Convolutional Neural Networks Based Time-Frequency Image Enhancement For the Analysis of EEG Signals},
       publisher = {Springer},
            year = {2022},
         journal = {Multidimensional Systems and Signal Processing},
             doi = {10.1007/s11045-022-00822-2},
           pages = {863--877},
        keywords = {ARRAY(0x5568fbb50170)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52277/},
        abstract = {Quadratic time-frequency (TF) methods are commonly used for the analysis, modeling, and classification of time-varying non-stationary electroencephalogram (EEG) signals. Commonly employed TF methods suffer from an inherent tradeoff between cross-term suppression and preservation of auto-terms. In this paper, we propose a new convolutional neural network (CNN) based approach to enhancing TF images. The proposed method trains a CNN using the Wigner-Ville distribution as the input image and the ideal time-frequency distribution with the total concentration of signal energy along the IF curves as the output image. The results show significant improvement compared to the other state-of-the-art TF enhancement methods. The codes for reproducing the results can be accessed on the GitHub via https://github.com/nabeelalikhan1/CNN-based-TF-image-enhancement.}
}

@article{lincoln49681,
          volume = {4},
          number = {5},
           month = {August},
          author = {Katherine Margaret Frances James and Daniel James Sargent and Adam Whitehouse and Grzegorz Cielniak},
           title = {High-throughput phenotyping for breeding targets - Current status and future directions of strawberry trait automation},
       publisher = {Wiley},
            year = {2022},
         journal = {Plants, People, Planet},
             doi = {10.1002/ppp3.10275},
           pages = {432--443},
        keywords = {ARRAY(0x5568fbb501a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49681/},
        abstract = {Automated image-based phenotyping has become widely accepted in crop phenotyping, particularly in cereal crops, yet few traits used by breeders in the strawberry industry have been automated. Early phenotypic assessment remains largely qualitative in this area since the manual phenotyping process is laborious and domain experts are constrained by time. Precision agriculture, facilitated by robotic technologies, is increasing in the strawberry industry, and the development of quantitative automated phenotyping methods is essential to ensure that breeding programs remain economically competitive. In this review, we investigate the external morphological traits relevant to the breeding of strawberries that have been automated and assess the potential for automation of traits that are still evaluated manually, highlighting challenges and limitations of the approaches used, particularly when applying high-throughput strawberry phenotyping in real-world environmental conditions.}
}

@inproceedings{lincoln52846,
       booktitle = {2022 15th International Conference on Human System Interaction (HSI)},
           month = {August},
           title = {Towards Safety in Open-field Agricultural Robotic Applications: A Method for Human Risk Assessment using Classifiers},
          author = {C. Mayoral Mayoral and Lars Grimstad and P{\r a}l J. From and Grzegorz Cielniak},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/HSI55341.2022.9869472},
        keywords = {ARRAY(0x5568fbb501d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52846/},
        abstract = {Tractors and heavy machinery have been used for decades to improve the quality and overall agriculture production. Moreover, agriculture is becoming a trend domain for robotics, and as a consequence, the efforts towards automatizing agricultural task increases year by year. However, for autonomous applications, accident prevention is of prior importance for warrantying human safety during operation in any scenario. This paper rephrases human safety as a classification problem using a custom distance criterion where each detected human gets a risk level classification. We propose the use of a neural network trained to detect and classify humans in the scene according to these criteria. The proposed approach learns from real-world data corresponding to an open-field scenario and is assessed with a custom risk assessment method.}
}

@inproceedings{lincoln49872,
       booktitle = {31st IEEE International Conference on Robot \& Human Interactive Communication},
           month = {August},
           title = {Extending Quantitative Proxemics and Trust to HRI},
          author = {Fanta Camara and Charles Fox},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/RO-MAN53752.2022.9900821},
        keywords = {ARRAY(0x5568fbb50200)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49872/},
        abstract = {Human-robot interaction (HRI) requires quantitative models of proxemics and trust for robots to use in negotiating with people for space. Hall?s theory of proxemics has been used for decades to describe social interaction distances but has lacked detailed quantitative models and generative explanations to apply to these cases. In the limited case of 
 autonomous vehicle interactions with pedestrians crossing a road, a recent model has explained the quantitative sizes of Hall?s distances to 4\% error and their links to the concept of trust in human interactions. The present study extends this model by generalising several of its assumptions to cover further cases including human-human and human-robot interactions. It tightens the explanations of Hall zones from 4\% to 1\% error and fits several more recent empirical HRI results. This may help to further unify these disparate fields and quantify them to a level which enables real-world operational HRI applications.}
}

@inproceedings{lincoln50385,
       booktitle = {The 5th UK Robotics and Autonomous Systems Conference},
           month = {August},
           title = {Blockchain Crop Assurance and Localisation},
          author = {Garry Clawson and Charles Fox},
       publisher = {UKRAS},
            year = {2022},
        keywords = {ARRAY(0x5568fbb50230)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50385/},
        abstract = {Food supply chain assurance should begin in the field with regular per-plant re-identification and logging.  This is challenging due to localisation and storage requirements. A proof-of-concept solution is provided, using an image-based, super-GNSS precision, robotic localisation per-plant re-identification technique with decentralised storage and blockchain technology. ORB descriptors and RANSAC are used to align in-field stones to previously captured stone images for localisation. Blockchain smart contracts act as a data broker for repeated update and retrieval of an image from a distributed file share system. Results suggest that localisation can be achieved to sub 100mm within a time window of 18 seconds. The implementation is open source and available at: {$\backslash$}url\{https://github.com/garry-clawson/Blockchain-Crop-Assurance-and-Localisation\}}
}

@inproceedings{lincoln53105,
           month = {August},
          author = {Madeleine Darbyshire and Adrian Salazar-Gomez and Callum Lennox and Junfeng Gao and Elizabeth Sklar and Simon Parsons},
       booktitle = {UKRAS22 Conference ?Robotics for Unconstrained Environments?},
           title = {Localising Weeds Using a Prototype Weed Sprayer},
       publisher = {UK-RAS Network},
             doi = {10.31256/Ua7Pr2W},
           pages = {12--13},
            year = {2022},
        keywords = {ARRAY(0x5568fbb50260)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53105/},
        abstract = {The application of convolutional neural networks (CNNs) to challenging visual recognition tasks has been shown to be highly effective and robust compared to traditional machine vision techniques. The recent development of small, powerful GPUs has enabled embedded systems to incorporate real-time, CNN-based, visual inference. Agriculture is a domain where this technology could be hugely advantageous. One such application within agriculture is precision spraying where only weeds are targeted with herbicide. This approach promises weed control with significant economic and environmental benefits from re- duced herbicide usage. While existing research has validated that CNN-based vision methods can accurately discern between weeds and crops, this paper explores how such detections can be used to actuate a prototype precision sprayer that incorporates a CNN- based weed detection system and validates spraying performance in a simplified scenario.}
}

@article{lincoln50550,
           month = {August},
           title = {Trustworthy UAV relationships: Applying the Schema Action World taxonomy to UAVs and UAV swarm operations},
          author = {Katie J. Parnell and Joel Fischer and Jed Clark and Adrian Bodenman and Maria J. Galvez Trigo and Mario P. Brito and Mohammad Divband Soorati and Katherine Plant and Sarvapali Ramchurn},
       publisher = {Taylor and Francis},
            year = {2022},
             doi = {10.1080/10447318.2022.2108961},
         journal = {International Journal of Human?Computer Interaction},
        keywords = {ARRAY(0x5568fbb50290)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50550/},
        abstract = {Human Factors play a significant role in the development and integration of avionic systems to ensure that they are trusted and can be used effectively. As Unoccupied Aerial Vehicle (UAV) technology becomes increasingly important to the aviation domain this holds true. The study presented in this paper aims to gain an understanding of UAV operators? trust requirements when piloting UAVs by utilising a popular aviation interview methodology (Schema World Action Research Method), in combination with key questions on trust identified from the literature. Interviews were conducted with six UAV operators, with a range of experience, to identify the trust requirements that UAV operators hold and their views on how UAV swarms may alter the trust relationship between the operator and the UAV technology. Both methodological and practical contributions of the research interviews are discussed.}
}

@article{lincoln52106,
          volume = {5},
           month = {August},
          author = {Barbara Mazzolai and Alessio Mondini and Emanuela Del Dottore and Laura Margheri and Koichi Suzumori and Matteo Cianchetti and Thomas Speck and Stoyan Smoukov and Ingo Burget and Tobias Keplinger and Gilberto De Freitas Siqueira and Felix Vanneste and Olivier Goury and Christian Duriez and Thrishantha Nanayakkara and Bram Vanderborght and Joost Brancart and Seppe Terryn and Steven Rich and Ruiyuan Liu and Kenjiro Fukuda and Takao Someya and Marcello Calisti and Cecilia Laschi and Wenguang Sun and Gang Wang and Li Wen and Robert Baines and Patiballa Kalyan Sree and Rebecca Kramer-Bottiglio and Daniela Rus and Peer Fischer and Friedrich Simmel and Andreas Lendlein},
           title = {Roadmap on soft robotics: multifunctionality, adaptability and growth without borders},
       publisher = {IOP Publishing},
            year = {2022},
         journal = {Multifunctional Materials},
             doi = {10.1088/2399-7532/ac4c95},
           pages = {032001},
        keywords = {ARRAY(0x5568fbb502c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52106/},
        abstract = {Soft robotics aims at creating systems with improved performance of movement and adaptability in unknown, challenging, environments and with higher level of safety during interactions with humans. This Roadmap on Soft Robotics covers selected aspects for the design of soft robots significantly linked to the area of multifunctional materials, as these are considered a fundamental component in the design of soft robots for an improvement of their peculiar abilities, such as morphing, adaptivity and growth. The roadmap includes different approaches for components and systems design, bioinspired materials, methodologies for building soft robots, strategies for the implementation and control of their functionalities and behavior, and examples of soft-bodied systems showing abilities across different environments. For each covered topic, the author(s) describe the current status and research directions, current and future challenges, and perspective advances in science and technology to meet the challenges.}
}

@inproceedings{lincoln50291,
           month = {July},
          author = {Iris Jestin and Joel E. Fischer and Maria J. Galvez Trigo and David R. Large and Gary E. Burnett},
       booktitle = {CUI ?22: Conversational User Interfaces Conference},
           title = {Effects of Wording and Gendered Voices on Acceptability of Voice Assistants in Future Autonomous Vehicles},
       publisher = {ACM},
             doi = {10.1145/3543829.3543836},
           pages = {1--11},
            year = {2022},
        keywords = {ARRAY(0x5568fbb502f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50291/},
        abstract = {Voice assistants in future autonomous vehicles may play a major role in supporting the driver during periods of a transfer of control with the vehicle (handover and handback). However, little is known about the effects of different qualities of the voice assistant on its perceived acceptability, and thus its potential to support the driver?s trust in the vehicle. A desktop study was carried out with 18 participants, investigating the effects of three gendered voices and different wording of prompts during handover and handback driving scenarios on measures of acceptability. Participants rated prompts by the voice assistant in nine different driving scenarios, using 5-point Likert style items in a during and post-study questionnaire as well as a short interview at the end. A commanding/formally worded prompt was rated higher on most of the desirable measures of acceptability as compared to an informally worded prompt. The ?Matthew? voice used was perceived to be less artificial and more desirable than the ?Joanna? voice and the gender-ambiguous ?Jordan? voice; however, we caution against interpreting these results as indicative of a general preference of gender, and instead discuss our results to throw light on the complex socio-phonetic nature of voices (including gender) and wording of voice assistants, and the need for careful consideration while designing the same. Results gained facilitate the drawing of insights needed to take better care when designing the voice and wording for voice assistants in future autonomous vehicles.}
}

@inproceedings{lincoln49936,
       booktitle = {11th International Conference on Biomimetic and Biohybrid Systems (Living Machines)},
           month = {July},
           title = {Scaling a hippocampus model with GPU parallelisation and test-driven refactoring},
          author = {Jack Stevenson and Charles Fox},
       publisher = {Springer LNCS},
            year = {2022},
        keywords = {ARRAY(0x5568fbb50320)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49936/},
        abstract = {The hippocampus is the brain area used for localisation,  mapping and episodic memory.  Humans and animals can outperform robotic systems in these tasks, so functional models of hippocampus may be useful to improve robotic navigation, such as for self-driving cars. 
Previous work developed a biologically plausible model of hippocampus based on Unitary Coherent Particle Filter (UCPF) and Temporal Restricted Boltzmann Machine, which was able to learn to navigate around small test environments.  However it was implemented in serial software, which becomes very slow as the environments and numbers of neurons scale up.  Modern GPUs can parallelize execution of neural networks. 
 The present Neural Software Engineering study develops a GPU accelerated version of the UCPF hippocampus software, using the formal Software Engineering techniques of profiling, optimisation and test-driven refactoring.  Results show that the model can greatly benefit from parallel execution, which may enable it to scale from toy environments and applications to real-world ones such as self-driving car navigation.   The refactored parallel code is released to the community as open source software as part of this publication.}
}

@inproceedings{lincoln52095,
       booktitle = {International Conference on Space Robotics and Automation},
           month = {July},
           title = {Ta-DAH: Task Driven Automated Hardware Design of Free-Flying Space Robots},
          author = {Lucy Elaine Jackson and Celyn Walters and Steve Eckersley and Mini Rai and Simon Hadfield},
       publisher = {World Academy of Science Engineering and Technology},
            year = {2022},
        keywords = {ARRAY(0x5568fbb50350)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52095/},
        abstract = {Space robots will play an integral part in exploring the universe and beyond. A correctly designed space robot will
facilitate OOA, satellite servicing and ADR. However, problems arise when trying to design such a system as it is a highly complex multidimensional problem into which there is little research. Current design techniques are slow and specific to terrestrial manipulators. This paper presents a solution to the slow speed of robotic hardware design, and generalizes the technique to free-flying space robots. It presents Ta-DAH Design, an automated design approach that utilises a multi-objective cost function in an iterative and automated pipeline. The design approach leverages prior knowledge and facilitates the faster output of optimal designs. The result is a system that can optimise the size of the base spacecraft, manipulator and some key subsystems for any given task. Presented in this work is the methodology behind Ta-DAH Design and a number optimal space robot designs.}
}

@inproceedings{lincoln48682,
       booktitle = {2022 IEEE International Conference on Robotics and Automation (ICRA)},
           month = {July},
           title = {Self-supervised Representation Learning for Reliable Robotic Monitoring of Fruit Anomalies},
          author = {Taeyeong Choi and Owen Would and Adrian Salazar-Gomez and Grzegorz Cielniak},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/ICRA46639.2022.9811954},
        keywords = {ARRAY(0x5568fbb50380)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48682/},
        abstract = {Data augmentation can be a simple yet powerful tool for autonomous robots to fully utilise available data for self-supervised
identification of atypical scenes or objects. State-of-the-art augmentation methods arbitrarily embed "structural" peculiarity on typical images so that classifying these artefacts can provide guidance for learning representations for the detection of anomalous visual signals. In this paper, however, we argue that learning such structure-sensitive representations can be a suboptimal approach to some classes of anomaly (e.g., unhealthy fruits) which could be better recognised by a different type of visual element such as "colour". We thus propose Channel Randomisation as a novel data augmentation method for restricting neural networks to learn encoding of "colour irregularity" whilst predicting channel-randomised images to ultimately build reliable fruit-monitoring robots identifying atypical fruit qualities. Our experiments show that (1) this colour-based alternative can better learn representations for consistently accurate identification of fruit anomalies in various fruit species, and also, (2) unlike other methods, the validation accuracy can be utilised as a criterion for early stopping of training in practice due to positive correlation between the performance in the self-supervised colour-differentiation task and the subsequent detection rate of actual anomalous fruits. Also, the proposed approach is evaluated on a new agricultural dataset, Riseholme-2021, consisting of 3.5K strawberry images gathered by a mobile robot, which we share online to encourage active agri-robotics research.}
}

@article{lincoln50054,
           month = {July},
           title = {A survey on deep reinforcement learning for audio?based applications},
          author = {Siddique Latif and Heriberto Cuayahuitl and Farrukh Pervez and Fahad Shamshad and Hafiz Shehbaz Ali and Erik Cambria},
       publisher = {Springer Nature B.V.},
            year = {2022},
             doi = {10.1007/s10462-022-10224-2},
         journal = {Artifcial Intelligence Review},
        keywords = {ARRAY(0x5568fbb503b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50054/},
        abstract = {Deep reinforcement learning (DRL) is poised to revolutionise the field of artificial intelligence (AI) by endowing autonomous systems with high levels of understanding of the real world. Currently, deep learning (DL) is enabling DRL to effectively solve various intractable problems in various fields including computer vision, natural language processing, healthcare, robotics, to name a few. Most importantly, DRL algorithms are also being employed in audio signal processing to learn directly from speech, music and other sound signals in order to create audio-based autonomous systems that have many promising applications in the real world. In this article, we conduct a comprehensive survey on the progress of DRL in the audio domain by bringing together research studies across different but related areas in speech and music. We begin with an introduction to the general field of DL and reinforcement learning (RL), then progress to the main DRL methods and their applications in the audio domain. We conclude by presenting important challenges faced by audio-based DRL agents and by highlighting open areas for future research and investigation. The findings of this paper will guide researchers interested in DRL for the audio domain.}
}

@inproceedings{lincoln50876,
       booktitle = {RSS Pioneers Workshop},
           month = {June},
           title = {Learning Pedestrian Social Behaviour for Game-Theoretic Self-Driving Cars},
          author = {Fanta Camara and Charles Fox},
       publisher = {RSS},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49718)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50876/},
        abstract = {Robot navigation in environments with static objects appears to be a solved problem, but navigating around humans in dynamic and unstructured environments remains an active research question. This requires not only advanced path planning methods but also a good perception system, models of multi-agent interactions and realistic hardware for testing. To evolve in human social spaces, robots must also show social intelligence, i.e. the ability to understand human behaviour via explicit and implicit communication cues (e.g. proxemics) for better human-robot interactions (HRI) [28]. Similarly, autonomous vehicles (AVs), also called ?self-driving cars? that are appearing on the roads need a better understanding of pedestrians? social behaviour, especially in urban areas [26]. In particular, previous work showed that pedestrians may take advantage over autonomous vehicles [13] by intentionally and constantly stepping in front of AVs, hence preventing them from making progress on the roads. This inability of current AVs to read the intention of other road users, predict their future behaviour and interact with them is known as ?the big problem with self-driving cars? [1]. Thus, AVs need better decision-making models and must find a good balance between stopping for pedestrians when required and driving to reach their final destination as quickly as possible for their on-board passengers. A comprehensive review of existing pedestrian models for AVs, ranging from low-level sensing, detection and tracking models [9] to high-level interaction and game theoretic models of pedestrian behaviour [10], found that the lower-level models are accurate and mature enough to be deployed on AVs but more research is needed in the higher-level models. Hence, in this work, we focus on modelling, learning and operating pedestrian high-level social behaviour on self-driving cars using game theory and proxemics.}
}

@article{lincoln49926,
          volume = {28},
          number = {2},
           month = {June},
          author = {Archie Drake and Isabel Sassoon and Panos Balatsoukas and Talya Porat and Mark Ashworth and Ellen Wright and Vasa Curcin and Martin Chapman and Nadin Kokciyan and Modgil Sanjay and Elizabeth Sklar and Simon Parsons},
           title = {The relationship of socio-demographic factors and patient attitudes to connected health technologies: a survey of stroke survivors.},
       publisher = {SAGE Publications},
            year = {2022},
         journal = {Health Informatics Journal},
             doi = {10.1177\%2F14604582221102373},
        keywords = {ARRAY(0x5568fbb49748)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49926/},
        abstract = {More evidence is needed on technology implementation for remote monitoring and self-management across the various settings relevant to chronic conditions. This paper describes the findings of a survey designed to explore the relevance of socio-demographic factors to attitudes towards connected health technologies in a community of patients. Stroke survivors living in the UK were invited to answer questions about themselves and about their attitudes to a prototype remote monitoring and self-management app developed around their preferences. Eighty (80) responses were received and analysed, with limitations and results presented in full. Socio-demographic factors were not found to be associated with variations in participants? willingness to use the system and attitudes to data sharing. Individuals? levels of interest in relevant technology was suggested as a more important determinant of attitudes. These observations run against the grain of most relevant literature to date, and tend to underline the importance of prioritising patient-centred participatory research in efforts to advance connected health technologies.}
}

@incollection{lincoln49943,
           month = {June},
          author = {Amir Ghalamzan Esfahani and Gautham Das and Iain Gould and Payam Zarafshan and Vishnu Rajendran Sugathakumary and James Heselden and Amir Badiee and Isobel Wright and Simon Pearson},
       booktitle = {Solar Energy Advancements in Agriculture and Food Production Systems},
          editor = {Shiva Gorjian and Pietro Elia Campana},
           title = {Applications of robotic and solar energy in precision agriculture and smart farming},
       publisher = {Elsevier},
             doi = {10.1016/C2020-0-03304-9},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49778)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49943/},
        abstract = {Population growth, healthy diet requirements, and changes in food demand towards a more plant-based protein diet increase existing pressures for food production and land-use change. The increasing demand and current agriculture approaches jeopardise the health of soil and biodiversity which will affect the future ecosystem and food production. One of the solutions to the increasing pressure on agriculture is PA which offers to minimize the use of resources, including land, water, energy, herbicides, and pesticides, and maximise the yield. The development of PA requires a multidisciplinary approach including engineering, AI, and robotics. Robots will play a crucial role in delivering PA and will pave the way toward sustainable healthy food production.
While PA is the way forward in the agriculture industry the related devices to collect various supporting data and also the agriculture machinery need to be run by clean energy to ensure sustainable growth in the sector. Among renewable energy sources, solar energy and solar PV have shown a great potential to dominate the future of sustainable energy and agriculture developments. For developing PV in rural and off-grid agriculture farms and lands the use of solar-powered devices is unavoidable. Such a transition to photovoltaic agriculture requires significant changes to agricultural practices and the adoption of smart technologies like IoT, robotics, and WSN.
Future food production needs to adapt to changing consumer behaviour along with the rapidly deteriorating environmental factors. PA is also a response to future food production challenges where one of its key aims is to improve sustainability to minimize the use of diminishing resources and minimize GHG emissions by use of renewable energy sources. Along with these adaptations, the new technologies should be using green energy sources (i.e., solar energy) for meeting the power requirements for sustainable developments of these smart technologies. Since there is a rapid inflow of robotic technologies into the agriculture sector, increasing power demand is inevitable, especially in remote areas where PV-based systems can play a game-changing role. It is expected for the agriculture sector to witness a technological revolution toward sustainable food production which cannot be achieved without solar PV development and support.}
}

@inproceedings{lincoln48058,
           month = {June},
          author = {Maria Galvez Trigo and Penelope Standen and Sue Cobb},
       booktitle = {HCI International Conference 2022},
           title = {Educational robots and their control interfaces: how can we make them more accessible for Special Education?},
       publisher = {Springer},
             doi = {10.1007/978-3-031-05039-8\_2},
           pages = {15--34},
            year = {2022},
        keywords = {ARRAY(0x5568fbb497a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48058/},
        abstract = {Existing design standards and guidelines provide guidance on what factors to consider to produce interactive systems that are not only usable, but also accessible. However, these standards are usually general, and when it comes to designing an interactive system for children with Learning Difficulties or Disabilities (LD) and/or Autism Spectrum Conditions (ASC) they are often not specific enough, leading to systems that are not fit for that purpose. If we dive into the area of educational robotics, we face even more issues, in part due to the relative novelty of these technologies. In this paper, we present an analysis of 26 existing educational robots and the interfaces used to control them. Furthermore, we present the results of running focus groups and a questionnaire with 32 educators with expertise in Special Education and parents at four different institutions, to explore potential accessibility issues of existing systems and to identify desirable characteristics. We conclude introduc- ing an initial set of design recommendations, to complement existing design standards and guidelines, that would help with producing future more accessible control interfaces for educational robots, with an especial focus on helping pupils with LDs and/or ASC.}
}

@article{lincoln49874,
          volume = {136},
           month = {June},
          author = {Hamdi Yahyaoui and Zakaria Maamar and Mohammed Al-Khafajiy and Hamid Al-Hamadi},
           title = {Trust-based management in IoT federations},
       publisher = {Elsevier},
            year = {2022},
         journal = {Future Generation Computer Systems},
             doi = {10.1016/j.future.2022.06.003},
           pages = {182--192},
        keywords = {ARRAY(0x5568fbb497d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49874/},
        abstract = {This paper presents a trust-based evolutionary game model for managing Internet-of-Things (IoT) federations. The model adopts trust-based payoff to either reward or penalize things based on the behaviors they expose. The model also resorts to monitoring these behaviors to ensure that the share of untrustworthy things in a federation does not hinder the good functioning of trustworthy things in this federation. The trust scores are obtained using direct experience with things and feedback from other things and are integrated into game strategies. These strategies capture the dynamic nature of federations since the population of trustworthy versus untrustworthy things changes over time with the aim of retaining the trustworthy ones. To demonstrate the technical doability of the game strategies along with rewarding/penalizing things, a set of experiments were carried out and results were benchmarked as per the existing literature. The results show a better mitigation of attacks such as bad-mouthing and ballot-stuffing on trustworthy things.}
}

@article{lincoln49961,
          volume = {7},
          number = {3},
           month = {June},
          author = {Francesco Del Duchetto and Marc Hanheide},
           title = {Learning on the Job: Long-Term Behavioural Adaptation in Human-Robot Interactions},
       publisher = {IEEE},
            year = {2022},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2022.3178807},
           pages = {6934--6941},
        keywords = {ARRAY(0x5568fbb49808)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49961/},
        abstract = {In this work, we propose a framework for allowing autonomous robots deployed for extended periods of time in public spaces to adapt their own behaviour online from user interactions. The robot behaviour planning is embedded in a Reinforcement Learning (RL) framework, where the objective is maximising the level of overall user engagement during the interactions. We use the Upper-Confidence-Bound Value-Iteration (UCBVI) algorithm, which gives a helpful way of managing the exploration-exploitation trade-off for real-time interactions. An engagement model trained end-to-end generates the reward function in real-time during policy execution. We test this approach in a public museum in Lincoln (U.K.), where the robot is deployed as a tour guide for the visitors. Results show that after a couple of months of exploration, the robot policy learned to maintain the engagement of users for longer, with an increase of 22.8\% over the initial static policy in the number of items visited during the tour and a 30\% increase in the probability of completing the tour. This work is a promising step toward behavioural adaptation in long-term scenarios for robotics applications in social settings.}
}

@article{lincoln49800,
           month = {June},
           title = {A comparison of neural?based visual recognisers for speech activity detection},
          author = {Sajjadali Raza and Heriberto Cuayahuitl},
       publisher = {Springer},
            year = {2022},
             doi = {10.1007/s10772-021-09956-3},
         journal = {International Journal of Speech Technology},
        keywords = {ARRAY(0x5568fbb49838)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49800/},
        abstract = {Existing literature on speech activity detection (SAD) highlights different approaches within neural networks but does not provide a comprehensive comparison to these methods. This is important because such neural approaches often require hardware-intensive resources. In this article, we provide a comparative analysis of three different approaches: classification with still images (CNN model), classification based on previous images (CRNN model), and classification of sequences of images (Seq2Seq model). Our experimental results using the Vid-TIMIT dataset show that the CNN model can achieve an accuracy of 97\% whereas the CRNN and Seq2Seq models increase the classification to 99\%. Further experiments show that the CRNN model is almost as accurate as the Seq2Seq model (99.1\% vs. 99.6\% of classification accuracy, respectively) but 57\% faster to train (326 vs. 761 secs. per epoch).}
}

@article{lincoln49340,
          volume = {197},
           month = {June},
          author = {Xiaodong Li and Rob Lloyd and Sarah Ward and Jonathan Cox and Shaun Coutts and Charles Fox},
           title = {Robotic crop row tracking around weeds using cereal-specific features},
       publisher = {Elsevier},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2022.106941},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49868)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49340/},
        abstract = {Crop row following is especially challenging in narrow row cereal crops, such as wheat. Separation between plants within a row disappears at an early growth stage, and canopy closure between rows, when leaves from different rows start to occlude each other, occurs three to four months after the crop emerges. Canopy closure makes it challenging to identify separate rows through computer vision as clear lanes become obscured. Cereal crops are grass species and so their leaves have a predictable shape and orientation. We introduce an image processing pipeline which exploits grass shape to identify and track rows. The key observation exploited is that leaf orientations tend to be vertical along rows and horizontal between rows due to the location of the stems within the rows. Adaptive mean-shift clustering on Hough line segments is then used to obtain lane centroids, and followed by a nearest neighbor data association creating lane line candidates in 2D space. Lane parameters are fit with linear regression and a Kalman filter is used for tracking lanes between frames. The method is achieves sub-50 mm accuracy which is sufficient for placing a typical agri-robot?s wheels between real-world, early-growth wheat crop rows to drive between them, as long as the crop is seeded in a wider spacing such as 180 mm row spacing for an 80 mm wheel width robot.}
}

@article{lincoln50887,
          volume = {3},
           month = {June},
          author = {Simon Pearson and Tania Carolina Camacho-Villa and Ravi Valluru and Oorbessy Gaju and Mini Rai and Iain Gould and Steve Brewer and Elizabeth Sklar},
           title = {Robotics and autonomous systems for net-zero agriculture},
       publisher = {Springer},
            year = {2022},
         journal = {Current Robotics Reports},
             doi = {10.1007/s43154-022-00077-6},
           pages = {57--64},
        keywords = {ARRAY(0x5568fbb49898)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50887/},
        abstract = {Purpose of ReviewThe paper discusses how robotics and autonomous systems (RAS) are being deployed to decarbonise agricultural production. The climate emergency cannot be ameliorated without dramatic reductions in greenhouse gas emis-sions across the agri-food sector. This review outlines the transformational role for robotics in the agri-food system and considers where research and focus might be prioritised.Recent FindingsAgri-robotic systems provide multiple emerging opportunities that facilitate the transition towards net zero agriculture. Five focus themes were identified where robotics could impact sustainable food production systems to (1) increase nitrogen use efficiency, (2) accelerate plant breeding, (3) deliver regenerative agriculture, (4) electrify robotic vehicles, (5) reduce food waste.SummaryRAS technologies create opportunities to (i) optimise the use of inputs such as fertiliser, seeds, and fuel/energy; (ii) reduce the environmental impact on soil and other natural resources; (iii) improve the efficiency and precision of agri-cultural processes and equipment; (iv) enhance farmers? decisions to improve crop care and reduce farm waste. Further and scaled research and technology development are needed to exploit these opportunities.}
}

@article{lincoln49460,
          volume = {3},
           month = {June},
          author = {Simon Pearson and Carolina Camacho?Villa and Ravi Valluru and Gaju Oorbessy and Mini Rai and Iain Gould and Steve Brewer and Elizabeth Sklar},
           title = {Robotics and Autonomous Systems for Net Zero Agriculture},
       publisher = {Springer},
            year = {2022},
         journal = {Current Robotics Reports},
             doi = {10.1007/s43154-022-00077-6},
           pages = {57--64},
        keywords = {ARRAY(0x5568fbb498c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49460/},
        abstract = {The paper discusses how robotics and autonomous systems (RAS) are being deployed to decarbonise
agricultural production. The climate emergency cannot be ameliorated without dramatic reductions in greenhouse gas emissions across the agri-food sector. This review outlines the transformational role for robotics in the agri-food system and considers where research and focus might be prioritised.}
}

@inproceedings{lincoln49183,
       booktitle = {Social Robot Navigation: Advances and Evaluation (SEANavBench 2022)},
           month = {May},
           title = {Game Theory, Proxemics and Trust for Self-Driving Car Social Navigation},
          author = {Fanta Camara and Charles Fox},
       publisher = {Social Robot Navigation: Advances and Evaluation},
            year = {2022},
        keywords = {ARRAY(0x5568fbb498f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49183/},
        abstract = {To navigate in human social spaces, self-driving cars and other robots must show social intelligence. This involves predicting and planning around pedestrians, understanding their personal space, and establishing trust with them. The present paper gives an overview of our ongoing work on modelling and controlling human?self-driving car interactions using game theory, proxemics and trust, and unifying these fields via quantitative models and robot controllers.}
}

@article{lincoln47700,
          volume = {193},
           month = {May},
          author = {Chao Qi and Junfeng Gao and Simon Pearson and Helen Harman and Kunjie Chen and Lei Shu},
           title = {Tea chrysanthemum detection under unstructured environments using the TC-YOLO model},
       publisher = {Elsevier},
         journal = {Expert Systems with Applications},
             doi = {10.1016/j.eswa.2021.116473},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49928)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47700/},
        abstract = {Tea chrysanthemum detection at its flowering stage is one of the key components for selective chrysanthemum harvesting robot development. However, it is a challenge to detect flowering chrysanthemums under unstructured field environments given variations on illumination, occlusion and object scale. In this context, we propose a highly fused and lightweight deep learning architecture based on YOLO for tea chrysanthemum detection (TC-YOLO). First, in the backbone component and neck component, the method uses the Cross-Stage Partially Dense network (CSPDenseNet) and the Cross-Stage Partial ResNeXt network (CSPResNeXt) as the main networks, respectively, and embeds custom feature fusion modules to guide the gradient flow. In the final head component, the method combines the recursive feature pyramid (RFP) multiscale fusion reflow structure and the Atrous Spatial Pyramid Pool (ASPP) module with cavity convolution to achieve the detection task. The resulting model was tested on 300 field images using a data enhancement strategy combining flipping and rotation, showing that under the NVIDIA Tesla P100 GPU environment, if the inference speed is 47.23 FPS for each image (416 {$\times$} 416), TC-YOLO can achieve the average precision (AP) of 92.49\% on our own tea chrysanthemum dataset. Through further validation, it was found that overlap had the least effect on tea chrysanthemum detection, and illumination had the greatest effect on tea chrysanthemum detection. In addition, this method (13.6 M) can be deployed on a single mobile GPU, and it could be further developed as a perception system for a selective chrysanthemum harvesting robot in the future.}
}

@inproceedings{lincoln49037,
       booktitle = {The 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2022)},
           month = {May},
           title = {Multi-agent Task Allocation for Fruit Picker Team Formation (Extended Abstract)},
          author = {Helen Harman and Elizabeth Sklar},
       publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
            year = {2022},
           pages = {1618--1620},
        keywords = {ARRAY(0x5568fbb49958)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49037/},
        abstract = {Multi-agent task allocation methods seek to distribute a set of tasks fairly amongst a set of agents. In real-world settings, such as fruit farms, human labourers undertake harvesting tasks, organised each day by farm manager(s) who assign workers to the fields that are ready to be harvested. The work presented here considers three challenges identified in the adaptation of a multi-agent task allocation methodology applied to the problem of distributing workers to fields. First, the methodology must be fast to compute so that it can be applied on a daily basis. Second, the incremental acquisition of harvesting data used to make decisions about worker-task assignments means that a data-backed approach must be derived from incomplete information as the growing season unfolds. Third, the allocation must take ?fairness? into account and consider worker motivation. Solutions to these challenges are demonstrated, showing statistically significant results based on the operations at a soft fruit farm during their 2020 and 2021 harvesting seasons.}
}

@article{lincoln49062,
          volume = {18},
          number = {4},
           month = {April},
          author = {Magd Badaoui and Pedro Buigues and Denes Berta and Guarav Mandana and Hankang Gu and Tam{\'a}s F{\"o}ldes and Callum Dickson and Viktor Hornak and Mitsunori Kato and Carla Molteni and Simon Parsons and Edina Rosta},
           title = {Combined Free-Energy Calculation and Machine Learning Methods for Understanding Ligand Unbinding Kinetics},
       publisher = {American Chemical Society},
            year = {2022},
         journal = {Journal of Chemical Theory and Computation},
             doi = {10.1021/acs.jctc.1c00924},
           pages = {2543--2555},
        keywords = {ARRAY(0x5568fbb49988)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49062/},
        abstract = {The determination of drug residence times, which define the time an inhibitor is in complex with its
target, is a fundamental part of the drug discovery process. Synthesis and experimental
measurements of kinetic rate constants are, however, expensive, and time-consuming. In this work,
we aimed to obtain drug residence times computationally. Furthermore, we propose a novel
algorithm to identify molecular design objectives based on ligand unbinding kinetics. We designed
an enhanced sampling technique to accurately predict the free energy profiles of the ligand
unbinding process, focusing on the free energy barrier for unbinding. Our method first identifies
unbinding paths determining a corresponding set of internal coordinates (IC) that form contacts
between the protein and the ligand, it then iteratively updates these interactions during a series of
biased molecular-dynamics (MD) simulations to reveal the ICs that are important for the whole of
the unbinding process. Subsequently, we performed finite temperature string simulations to obtain
the free energy barrier for unbinding using the set of ICs as a complex reaction coordinate.
Importantly, we also aimed to enable further design of drugs focusing on improved residence 
times. To this end, we developed a supervised machine learning (ML) approach with inputs from
unbiased ?downhill? trajectories initiated near the transition state (TS) ensemble of the string
unbinding path. We demonstrate that our ML method can identify key ligand-protein interactions
driving the system through the TS. Some of the most important drugs for cancer treatment are
kinase inhibitors. One of these kinase targets is Cyclin Dependent Kinase 2 (CDK2), an appealing
target for anticancer drug development. Here, we tested our method using two different CDK2
inhibitors for potential further development of these compounds. We compared the free energy
barriers obtained from our calculations with those observed in available experimental data. We
highlighted important interactions at the distal ends of the ligands that can be targeted for
improved residence times. Our method provides a new tool to determine unbinding rates, and to
identify key structural features of the inhibitors that can be used as starting points for novel design
strategies in drug discovery.}
}

@inproceedings{lincoln53890,
           month = {April},
          author = {Zhuoling Huang and Elizabeth Sklar and Simon Parsons},
       booktitle = {HRI '20: Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction},
           title = {Design of Automatic Strawberry Harvest Robot Suitable in Complex Environments},
       publisher = {Association for Computing Machinery},
             doi = {10.1145/3371382.3377443},
           pages = {567--569},
            year = {2022},
        keywords = {ARRAY(0x5568fbb499b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53890/},
        abstract = {Strawberries are an important cash crop that are grown worldwide. They are also a labour-intensive crop, with harvesting a particularly labour-intensive task because the fruit needs careful handling. This project investigates collaborative human-robot strawberry harvesting, where interacting with a human potentially increases the adaptability of a robot to work in more complex environments. The project mainly concentrates on two aspects of the problem: the identification of the fruit and the picking of the fruit.}
}

@inproceedings{lincoln49117,
       booktitle = {2021 2nd International Symposium on Automation, Information and Computing (ISAIC 2021)},
           month = {April},
           title = {Temperature-based Collision Detection in Extreme Low Light Condition with Bio-inspired LGMD Neural Network},
          author = {Yicheng Zhang and Cheng Hu and Mei Liu and Hao Luan and Fang Lei and Heriberto Cuayahuitl and Shigang Yue},
       publisher = {IOP Publishing Ltd},
            year = {2022},
             doi = {10.1088/1742-6596/2224/1/012004},
        keywords = {ARRAY(0x5568fbb499e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49117/},
        abstract = {It is an enormous challenge for intelligent vehicles to avoid collision accidents at night because of the extremely poor light conditions. Thermal cameras can capture temperature map at night, even with no light sources and are ideal for collision detection in darkness. However, how to extract collision cues efficiently and effectively from the captured temperature map with limited computing resources is still a key issue to be solved. Recently, a bio-inspired neural network LGMD has been proposed for collision detection successfully, but for daytime and visible light. Whether it can be used for temperature-based collision detection or not remains unknown. In this study, we proposed an improved LGMD-based visual neural network for temperature-based collision detection at extreme light conditions. We show in this study that the insect inspired visual neural network can pick up the expanding temperature differences of approaching objects as long as the temperature difference against its background can be captured by a thermal sensor. Our results demonstrated that the proposed LGMD neural network can detect collisions swiftly based on the thermal modality in darkness; therefore, it can be a critical collision detection algorithm for autonomous vehicles driving at night to avoid fatal collisions with humans, animals, or other vehicles.}
}

@article{lincoln46497,
           month = {April},
           title = {Robotic Exploration for Learning Human Motion Patterns},
          author = {Sergio Molina Mellado and Grzegorz Cielniak and Tom Duckett},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/TRO.2021.3101358},
         journal = {IEEE Transaction on Robotics},
        keywords = {ARRAY(0x5568fbb49a18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46497/},
        abstract = {Understanding how people are likely to move is key to efficient and safe robot navigation in human environments. However, mobile robots can only observe a fraction of the environment at a time, while the activity patterns of people may also change at different times. This paper introduces a new methodology for mobile robot exploration to maximise the knowledge of human activity patterns by deciding where and when to collect observations. We introduce an exploration policy driven by the entropy levels in a spatio-temporal map of pedestrian flows, and compare multiple spatio-temporal exploration strategies including both informed and uninformed approaches. The evaluation is performed by simulating mobile robot exploration using real sensory data from three long-term pedestrian datasets. The results show that for certain scenarios the models built with proposed exploration system can better predict the flow patterns than uninformed strategies, allowing the robot to move in a more socially compliant way, and that the exploration ratio is a key factor when it comes to the model prediction accuracy.}
}

@inproceedings{lincoln50609,
           month = {April},
          author = {Soran Parsa and Horia A. Maior and Alex Reeve Elliott Thumwood and Max L Wilson and Marc Hanheide and Amir Ghalamzan Esfahani},
       booktitle = {CHI Conference on Human Factors in Computing Systems Extended Abstracts},
           title = {The Impact of Motion Scaling and Haptic Guidance on Operators? Workload and Performance in Teleoperation},
       publisher = {ACM},
             doi = {10.1145/3491101.3519814},
           pages = {1--7},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49a48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50609/},
        abstract = {The use of human operator managed robotics, especially for safety critical work, includes a shift from physically demanding to mentally challenging work, and new techniques for Human-Robot Interaction are being developed to make teleoperation easier and more accurate. This study evaluates the impact of combining two teleoperation support features (i) scaling the velocity mapping of leader-follower arms (motion scaling), and (ii) haptic-feedback guided shared control (haptic guidance). We used purposely difficult peg-in-the-hole tasks requiring high precision insertion and manipulation, and obstacle avoidance, and evaluated the impact of using individual and combined support features on a) task performance and b) operator workload. As expected, long distance tasks led to higher mental workload and lower performance than short distance tasks. Our results showed that motion scaling and haptic guidance impact workload and improve performance during more difficult tasks, and we discussed this in contrast to participants preference for using different teleoperation features.}
}

@article{lincoln49488,
          volume = {9},
           month = {March},
          author = {Craig R. Carignan and Renaud Detry and Mini Rai Saaj and Giacomo Marani and Joshua D. Vander Hook},
           title = {Editorial: Robotic In-Situ Servicing, Assembly and Manufacturing},
       publisher = {Frontiers Media},
         journal = {Frontiers in Robotics and AI},
             doi = {10.3389/frobt.2022.887506},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49a78)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49488/},
        abstract = {This research topic is dedicated to articles focused on robotic manufacturing, assembly, and servicing utilizing in-situ resources, especially for space robotic applications. The purpose was to gather resource material for researchers from a variety of disciplines to identify common themes, formulate problems, and share promising technologies for autonomous large-scale construction, servicing, and assembly robots. The articles under this special topic provide a snapshot of several key technologies under development to support on-orbit robotic servicing, assembly, and manufacturing.}
}

@inproceedings{lincoln48675,
       booktitle = {AAAI - AI for Agriculture and Food Systems},
           month = {February},
           title = {Multiple broccoli head detection and tracking in 3D point clouds for autonomous harvesting},
          author = {Hector A. Montes and Grzegorz Cielniak},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49aa8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48675/},
        abstract = {This paper explores a tracking method of broccoli heads that combine a Particle Filter and 3D features detectors to track multiple crops in a sequence of 3D data frames. The tracking accuracy is verified based on a data association method that matches detections with tracks over each frame. The particle filter incorporates a simple motion model to produce the posterior particle distribution, and a similarity model as probability function to measure the tracking accuracy. The method is tested with datasets of two broccoli varieties collected in planted fields from two different countries. Our evaluation shows the tracking method reduces the number of false negatives produced by the detectors on their own. In addition, the method accurately detects and tracks the 3D locations of broccoli heads relative to the vehicle at high frame rates}
}

@article{lincoln48358,
           month = {February},
          author = {Fang Lei and Zhiping Peng and Mei Liu and Jigen Peng and Vassilis Cutsuridis and Shigang Yue},
           title = {A Robust Visual System for Looming Cue Detection Against Translating Motion},
       publisher = {IEEE},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
             doi = {10.1109/TNNLS.2022.3149832},
           pages = {1--15},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49ad8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48358/},
        abstract = {Collision detection is critical for autonomous vehicles or robots to serve human society safely. Detecting looming objects robustly and timely plays an important role in collision avoidance systems. The locust lobula giant movement detector (LGMD1) is specifically selective to looming objects which are on a direct collision course. However, the existing LGMD1 models can not distinguish a looming object from a near and fast translatory moving object, because the latter can evoke a large amount of excitation that can lead to false LGMD1 spikes. This paper presents a new visual neural system model (LGMD1) that applies a neural competition mechanism within a framework of separated ON and OFF pathways to shut off the translating response. The competition-based approach responds vigorously to monotonous ON/OFF responses resulting from a looming object. However, it does not respond to paired ON-OFF responses that result from a translating object, thereby enhancing collision selectivity. Moreover, a complementary denoising mechanism ensures reliable collision detection. To verify the effectiveness of the model, we have conducted systematic comparative experiments on synthetic and real datasets. The results show that our method exhibits more accurate discrimination between looming and translational events -- the looming motion can be correctly detected. It also demonstrates that the proposed model is more robust than comparative models.}
}

@article{lincoln49162,
           month = {February},
           title = {A Robust Visual System for Looming Cue Detection Against Translation Motion},
          author = {Fang Lei and Zhiping Peng and Mei Liu and Jigen Peng and Vassilis Cutsuridis and Shigang Yue},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/TNNLS.2022.3149832},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
        keywords = {ARRAY(0x5568fbb49b08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49162/},
        abstract = {Collision detection is critical for autonomous vehicles or robots to serve human society safely. Detecting looming objects robustly and timely plays an important role in collision avoidance systems. The locust lobula giant movement detector (LGMD1) is specifically selective to looming objects which are on a direct collision course. However, the existing LGMD1 models cannot distinguish a looming object from a near and fast translatory moving object, because the latter can evoke a large amount of excitation that can lead to false LGMD1 spikes. This article presents a new visual neural system model (LGMD1) that applies a neural competition mechanism within a framework of separated ON and OFF pathways to shut off the translating response. The competition-based approach responds vigorously to
monotonous ON/OFF responses resulting from a looming object. However, it does not respond to paired ON?OFF responses that result from a translating object, thereby enhancing collision selectivity. Moreover, a complementary denoising mechanism ensures reliable collision detection. To verify the effectiveness of the model, we have conducted systematic comparative experiments on synthetic and real datasets. The results show that our method exhibits more accurate discrimination between looming and translational events{--}the looming motion can be correctly detected. It also demonstrates that the proposed model is more robust than comparative models.}
}

@article{lincoln52103,
          volume = {22},
          number = {1471},
           month = {February},
          author = {Angela Mazzeo and Jacopo Aguzzi and Marcello Calisti and Simonpietro Canese and Michela Angiolillo and Louise Allcock and Fabrizio Vecchi and Sergio Stefanni and Marco Controzzi},
           title = {Marine Robotics for Deep-Sea Specimen Collection: A Taxonomy of Underwater Manipulative Actions},
       publisher = {MDPI},
            year = {2022},
         journal = {Sensors},
             doi = {10.3390/s22041471},
        keywords = {ARRAY(0x5568fbb49b38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52103/},
        abstract = {In order to develop a gripping system or control strategy that improves scientific sampling procedures, knowledge of the process and the consequent definition of requirements is fundamental. Nevertheless, factors influencing sampling procedures have not been extensively described, and selected strategies mostly depend on pilots? and researchers? experience. We interviewed 17 researchers and remotely operated vehicle (ROV) technical operators, through a formal questionnaire or in-person interviews, to collect evidence of sampling procedures based on their direct field experience. We methodologically analyzed sampling procedures to extract single basic actions (called atomic manipulations). Available equipment, environment and species-specific features strongly influenced the manipulative choices. We identified a list of functional and technical requirements for the development of novel end-effectors for marine sampling. Our results indicate that the unstructured and highly variable deep-sea environment requires a versatile system, capable of robust interactions with hard surfaces such as pushing or scraping, precise tuning of gripping force for tasks such as pulling delicate organisms away from hard and soft substrates, and rigid holding, as well as a mechanism for rapidly switching among external tools.}
}

@article{lincoln52102,
          volume = {10},
          number = {1},
           month = {February},
          author = {Jacopo Aguzzi and Sascha Flogel and Simone Marini and Laurenz Thomsen and Jan Albiez and Peter Weiss and Giacomo Picardi and Marcello Calisti and Sergio Stefanni and Luca Mirimin and Fabrizio Vecchi and Cecilia Laschi and Andrew Branch and Evan Clark and Bernard Foing and Armin Wedler and Damianos Chatzievangelou and Michael Tangherlini and Autun Purser and Lewis Dartnell and Roberto Danovaro},
           title = {Developing technological synergies between deep-sea and space research},
       publisher = {University of California},
            year = {2022},
         journal = {Elementa: Science of the Anthropocene},
             doi = {10.1525/elementa.2021.00064},
           pages = {00064},
        keywords = {ARRAY(0x5568fbb49b68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52102/},
        abstract = {Recent advances in robotic design, autonomy and sensor integration create solutions for the exploration of
deep-sea environments, transferable to the oceans of icy moons. Marine platforms do not yet have the mission
autonomy capacity of their space counterparts (e.g., the state of the art Mars Perseverance rover mission),
although different levels of autonomous navigation and mapping, as well as sampling, are an extant capability.
In this setting their increasingly biomimicked designs may allow access to complex environmental scenarios,
with novel, highly-integrated life-detecting, oceanographic and geochemical sensor packages. Here, we lay an
outlook for the upcoming advances in deep-sea robotics through synergies with space technologies within
three major research areas: biomimetic structure and propulsion (including power storage and generation),
artificial intelligence and cooperative networks, and life-detecting instrument design. New morphological and
material designs, with miniaturized and more diffuse sensor packages, will advance robotic sensing systems.
Artificial intelligence algorithms controlling navigation and communications will allow the further
development of the behavioral biomimicking by cooperating networks. Solutions will have to be tested
within infrastructural networks of cabled observatories, neutrino telescopes, and off-shore industry sites
with agendas and modalities that are beyond the scope of our work, but could draw inspiration on the
proposed examples for the operational combination of fixed and mobile platforms.}
}

@inproceedings{lincoln48676,
       booktitle = {AI for Agriculture and Food Systems},
           month = {January},
           title = {Channel Randomisation with Domain Control for Effective Representation Learning of Visual Anomalies in Strawberries},
          author = {Taeyeong Choi and Grzegorz Cielniak},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49b98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48676/},
        abstract = {Channel Randomisation (CH-Rand) has appeared as a key data augmentation technique for anomaly detection on fruit
images because neural networks can learn useful representations of colour irregularity whilst classifying the samples
from the augmented "domain". Our previous study has revealed its success with significantly more reliable performance than other state-of-the-art methods, largely specialised for identifying structural implausibility on non-agricultural objects (e.g., screws). In this paper, we further enhance CH-Rand with additional guidance to generate more informative data for representation learning of anomalies in fruits as most of its fundamental designs are still maintained. To be specific, we first control the "colour space" on which CH-Rand is executed to investigate whether a particular model{--}e.g., HSV , YCbCr, or L*a*b* {--}can better help synthesise realistic anomalies than the RGB, suggested in the original design. In addition, we develop a learning "curriculum" in which CH-Rand shifts its augmented domain to gradually increase the difficulty of the examples for neural networks to classify. To the best of our best knowledge, we are the first to connect the concept of curriculum to self-supervised representation learning for anomaly detection. Lastly, we perform evaluations with the Riseholme-2021 dataset, which contains {\ensuremath{>}} 3.5K real strawberry images at various growth levels along with anomalous examples. Our experimental results show that the trained models with the proposed strategies can achieve over 16\% higher scores of AUC-PR with more than three times less variability than the naive CH-Rand whilst using the same deep networks and data.}
}

@article{lincoln49094,
           month = {January},
           title = {A Looming Spatial Localization Neural Network Inspired by MLG1 Neurons in the Crab Neohelice},
          author = {Hao Luan and Qingbing Fu and Yicheng Zhang and Mu Hua and Shengyong Chen and Shigang Yue},
       publisher = {Frontiers Media},
            year = {2022},
             doi = {10.3389/fnins.2021.787256},
         journal = {Frontiers in Neuroscience},
        keywords = {ARRAY(0x5568fbb49bc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49094/},
        abstract = {Similar to most visual animals, the crab Neohelice granulata relies predominantly on visual information to escape from predators, to track prey and for selecting mates. It, therefore, needs specialized neurons to process visual information and determine the spatial location of looming objects. In the crab Neohelice granulata, the Monostratified Lobula Giant type1 (MLG1) neurons have been found to manifest looming sensitivity with finely tuned capabilities of encoding spatial location information. MLG1s neuronal ensemble can not only perceive the location of a looming stimulus, but are also thought to be able to influence the direction of movement continuously, for example, escaping from a threatening, looming target in relation to its position. Such specific characteristics make the MLG1s unique compared to normal looming detection neurons in invertebrates which can not localize spatial looming. Modeling the MLG1s ensemble is not only critical for elucidating the mechanisms underlying the functionality of such neural circuits, but also important for developing new autonomous, efficient, directionally reactive collision avoidance systems for robots and vehicles. However, little computational modeling has been done for implementing looming spatial localization analogous to the specific functionality of MLG1s ensemble. To bridge this gap, we propose a model of MLG1s and their pre-synaptic visual neural network to detect the spatial location of looming objects. The model consists of 16 homogeneous sectors arranged in a circular field inspired by the natural arrangement of 16 MLG1s? receptive fields to encode and convey spatial information concerning looming objects with dynamic expanding edges in different locations of the visual field. Responses of the proposed model to systematic real-world visual stimuli match many of the biological characteristics of MLG1 neurons.
The systematic experiments demonstrate that our proposed MLG1s model works effectively and robustly to perceive and localize looming information, which could be a promising candidate for intelligent machines interacting within dynamic environments free of collision. This study also sheds light upon a new type of neuromorphic visual sensor strategy that can extract looming objects with locational information in a quick and reliable manner.}
}

@article{lincoln52101,
          volume = {22},
          number = {2},
           month = {January},
          author = {Angelo Mazzeo and Jacopo Aguzzi and Marcello Calisti and Simonpietro Canese and Fabrizio Vecchi and Sergio Stefanni and Marco Controzzi},
           title = {Marine Robotics for Deep-Sea Specimen Collection: A Systematic Review of Underwater Grippers},
       publisher = {MDPI},
            year = {2022},
         journal = {Sensors},
             doi = {10.3390/s22020648},
           pages = {648},
        keywords = {ARRAY(0x5568fbb49bf8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52101/},
        abstract = {The collection of delicate deep-sea specimens of biological interest with remotely operated vehicle (ROV) industrial grippers and tools is a long and expensive procedure. Industrial grippers were originally designed for heavy manipulation tasks, while sampling specimens requires dexterity and precision. We describe the grippers and tools commonly used in underwater sampling for scientific purposes, systematically review the state of the art of research in underwater gripping technologies, and identify design trends. We discuss the possibility of executing typical manipulations of sampling procedures with commonly used grippers and research prototypes. Our results indicate that commonly used grippers ensure that the basic actions either of gripping or caging are possible, and their functionality is extended by holding proper tools. Moreover, the approach of the research status seems to have changed its focus in recent years: from the demonstration of the validity of a specific technology (actuation, transmission, sensing) for marine applications, to the solution of specific needs of underwater manipulation. Finally, we summarize the environmental and operational requirements that should be considered in the design of an underwater gripper.}
}

@inproceedings{lincoln49913,
       booktitle = {IEEE International Conference on Automation Science and Engineering (CASE)},
           title = {Towards Infield Navigation: leveraging simulated data for crop row detection},
          author = {Rajitha De Silva and Grzegorz Cielniak and Junfeng Gao},
       publisher = {IEEE},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49c28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49913/},
        abstract = {Agricultural datasets for crop row detection are often bound by their limited number of images. This restricts
the researchers from developing deep learning based models  for precision agricultural tasks involving crop row detection. We suggest the utilization of small real-world datasets alongwith additional data generated by simulations to yield similar crop row detection performance as that of a model trained with a large real world dataset. Our method could reach the performance of a deep learning based crop row detection model trained with real-world data by using 60\% less labelled realworld data. Our model performed well against field variations such as shadows, sunlight and growth stages. We introduce an automated pipeline to generate labelled images for crop row detection in simulation domain. An extensive comparison is done to analyze the contribution of simulated data towards reaching robust crop row detection in various real-world field scenarios.}
}

@inproceedings{lincoln48515,
       booktitle = {Ital-IA 2022},
           title = {From Human Perception and Action Recognition to Causal Understanding of Human-Robot Interaction in Industrial Environments},
          author = {Stefano Ghidoni and Matteo Terreran and Daniele Evangelista and Emanuele Menegatti and Christian Eitzinger and Enrico Villagrossi and Nicola Pedrocchi and Nicola Castaman and Marcin Malecha and Sariah Mghames and Luca Castri and Marc Hanheide and Nicola Bellotto},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49c58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48515/},
        abstract = {Human-robot collaboration is migrating from lightweight robots in laboratory environments to industrial applications, where heavy tasks and powerful robots are more common. In this scenario, a reliable perception of the humans involved in the process and related intentions and behaviors is fundamental. This paper presents two projects investigating the use of robots in relevant industrial scenarios, providing an overview of how industrial human-robot collaborative tasks can be successfully addressed.}
}

@inproceedings{lincoln49036,
       booktitle = {The 23rd International Workshop on Multi-Agent-Based Simulation (MABS))},
           title = {Challenges for Multi-Agent Based Agricultural Workforce Management},
          author = {Helen Harman and Elizabeth I. Sklar},
       publisher = {Springer},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49c88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49036/},
        abstract = {Multi-agent task allocation methods seek to distribute a set of tasks fairly amongst a set of agents. In real-world settings, such as soft fruit farms, human labourers undertake harvesting tasks, assigned by farm managers. The work here explores the application of artificial intelligence planning methodologies to optimise the existing workforce and applies multi-agent based simulation to evaluate the efficacy of the AI strategies. Key challenges threatening the acceptance of such an approach are highlighted and solutions are evaluated experimentally.}
}

@article{lincoln49072,
           title = {Artificial intelligence and ethics within the food sector: developing a common language for technology adoption across the supply chain},
          author = {Louise Manning and Steve Brewer and Peter Craigon and P.J Frey and Anabel Gutierrez and Naomi Jacobs and Samantha Kanza and Samuel Munday and Justin Sacks and Simon Pearson},
       publisher = {Elsevier},
            year = {2022},
         journal = {Trends in Food Science and Technology},
        keywords = {ARRAY(0x5568fbb49cb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49072/},
        abstract = {Background:  The use of artificial intelligence (AI) is growing in food supply chains. The ethical language associated with food supply and technology is contextualised and framed by the meaning given to it by stakeholders. Failure to differentiate between these nuanced meanings can create a barrier to technology adoption and reduce the benefit derived.
Scope and approach: The aim of this review paper is to consider the embedded ethical language used by stakeholders who collaborate in the adoption of AI in food supply chains.    Ethical perspectives frame this literature review and provide structure to consider how to shape a common discourse to build trust in, and frame more considered utilisation of, AI in food supply chains to the benefit of users, and wider society. 
Key findings and conclusions: Whilst the nature of data within the food system is much broader than the personal data covered by the European Union General Data Protection Regulation (GDPR), the ethical issues for computational and AI systems are similar and can be considered in terms of particular aspects: transparency, traceability, explainability, interpretability, accessibility, accountability and responsibility. The outputs of this research assist in giving a more rounded understanding of the language used, exploring the ethical interaction of aspects of AI used in food supply chains and also the management activities and actions that can be adopted to improve the applicability of AI technology, increase engagement and derive greater performance benefits. This work has implications for those developing AI governance protocols for the food supply chain as well as supply chain practitioners.}
}

@inproceedings{lincoln51674,
       booktitle = {UKRAS2022 Conference ?Robotics for Unconstrained Environments?},
           title = {Towards Autonomous Task Allocation Using a Robot Team in a Food Factory},
          author = {Amie Owen and Helen Harman and Elizabeth Sklar},
       publisher = {UK-RAS},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49ce8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/51674/},
        abstract = {Scheduling of hygiene tasks in a food production environment is a complex challenge which is typically performed manually. Many factors must be considered during scheduling; this includes what training a hygiene operative (i.e. cleaning staff member) has undergone, the availability of hygiene operatives (holiday commitments, sick leave etc.) and the production constraints (how long does the oven take to cool, when does production begin again etc.). This paper seeks to apply multiagent task allocation (MATA) to automate and optimise the process of allocating tasks to hygiene operatives. The intention is that this optimization module will form one part of a proposed larger system. that we propose to develop. A simulation has been created to function as a digital twin of a factory environment, allowing us to evaluate experimentally a variety of task allocation methodologies. Trialled methods include Round Robin (RR), Sequential Single Item (SSI) auctions, Lowest Bid and Least Contested Bid.}
}

@inproceedings{lincoln51673,
       booktitle = {20th International Conference on Practical Applications of Agents and Multi-Agent Systems, PAAMS 2022},
           title = {Towards the application of multi-agent task allocation to hygiene tasks in the food production industry.},
          author = {Amie Owen and Helen Harman and Elizabeth I. Sklar},
       publisher = {Springer Cham},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49d18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/51673/},
        abstract = {The food production industry faces the complex challenge of scheduling both production and hygiene tasks. These tasks are typically scheduled manually. However, due to the increasing costs of raw materials and the regulations factories must adhere to, inefficiencies can be costly. This paper presents the initial findings of a survey, conducted to learn more about the hygiene tasks within the industry and to inform research on how multi-agent task allocation (MATA) methodologies could automate and improve the scheduling of hygiene tasks. A simulation of a heterogeneous human workforce within a factory environment is presented. This work evaluates experimentally different strategies for applying market-based mechanisms, in particular Sequential Single Item (SSI) auctions, to the problem of allocation hygiene tasks to a heterogeneous workforce.}
}

@article{lincoln49668,
          volume = {12},
          number = {6},
          author = {Abhishesh Pal and Gautham Das and Marc Hanheide and Antonio Candea Leite and Pal From},
           title = {An Agricultural Event Prediction Framework towards Anticipatory Scheduling of Robot Fleets: General Concepts and Case Studies},
       publisher = {MDPI},
         journal = {Agronomy},
             doi = {10.3390/agronomy12061299},
            year = {2022},
        keywords = {ARRAY(0x5568fbb49d48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49668/},
        abstract = {Harvesting in soft-fruit farms is labor intensive, time consuming and is severely affected by scarcity of skilled labors. Among several activities during soft-fruit harvesting, human pickers take 20?30\% of overall operation time into the logistics activities. Such an unproductive time, for example, can be reduced by optimally deploying a fleet of agricultural robots and schedule them by anticipating the human activity behaviour (state) during harvesting. In this paper, we propose a framework for spatio-temporal prediction of human pickers? activities while they are picking fruits in agriculture fields. Here we exploit temporal patterns of picking operation and 2D discrete points, called topological nodes, as spatial constraints imposed by the agricultural environment. Both information are used in the prediction framework in combination with a variant of the Hidden Markov Model (HMM) algorithm to create two modules. The proposed methodology is validated with two test cases. In Test Case 1, the first module selects an optimal temporal model called as picking\_state\_progression model that uses temporal features of a picker state (event) to statistically evaluate an adequate number of intra-states also called sub-states. In Test Case 2, the second module uses the outcome from the optimal temporal model in the subsequent spatial model called node\_transition model and performs ?spatio-temporal predictions? of the picker?s movement while the picker is in a particular state. The Discrete Event Simulation (DES) framework, a proven agricultural multi-robot logistics model, is used to simulate the different picking operation scenarios with and without our proposed prediction framework and the results are then statistically compared to each other. Our prediction framework can reduce the so-called unproductive logistics time in a fully manual harvesting process by about 80 percent in the overall picking operation. This research also indicates that the different rates of picking operations involve different numbers of sub-states, and these sub-states are associated with different trends considered in spatio-temporal predictions.}
}

@article{lincoln48499,
           title = {Tea Chrysanthemum Detection by Leveraging Generative Adversarial Networks and Edge Computing},
          author = {Chao Qi and Junfeng Gao and Kunjie Chen and Lei Shu and Simon Pearson},
       publisher = {Frontiers Media},
            year = {2022},
         journal = {Frontiers in plant science},
        keywords = {ARRAY(0x5568fbb49d78)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48499/},
        abstract = {A high resolution dataset is one of the prerequisites for tea chrysanthemum detection with deep learning algorithms. This is crucial for further developing a selective chrysanthemum harvesting robot. However, generating high resolution datasets of the tea chrysanthemum with complex unstructured environments is a challenge. In this context, we propose a novel generative adversarial network (TC-GAN) that attempts to deal with this challenge. First, we designed a non-linear mapping network for untangling the features of the underlying code. Then, a customized regularisation method was used to provide fine-grained control over the image details. Finally, a gradient diversion design with multi-scale feature extraction capability was adopted to optimize the training process. The proposed TC-GAN was compared with 12 state-of-the-art generative adversarial networks, showing that an optimal average precision (AP) of 90.09\% was achieved with the generated images (512*512) on the developed TC-YOLO object detection model under the NVIDIA Tesla P100 GPU environment. Moreover, the detection model was deployed into the embedded NVIDIA Jetson TX2 platform with 0.1s inference time, and this edge computing device could be further developed into a perception system for selective chrysanthemum picking robots in the future.}
}

@article{lincoln44717,
          volume = {8},
           month = {December},
          author = {Nikolas Andreakos and Shigang Yue and Vassilis Cutsuridis},
           title = {Quantitative Investigation Of Memory Recall Performance Of A Computational Microcircuit Model Of The Hippocampus},
       publisher = {SpringerOpen},
            year = {2021},
         journal = {Brain Informatics},
             doi = {10.1186/s40708-021-00131-7},
           pages = {9},
        keywords = {ARRAY(0x5568fbb49da8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44717/},
        abstract = {Memory, the process of encoding, storing, and maintaining information over time in order to influence future actions, is very important in our lives. Losing it, it comes with a great cost. Deciphering the biophysical mechanisms leading to recall improvement should thus be of outmost importance. In this study we embarked on the quest to improve computationally the recall performance of a bio-inspired microcircuit model of the mammalian hippocampus, a brain region responsible for the storage and recall of short-term declarative memories. The model consisted of excitatory and inhibitory cells. The cell properties followed closely what is currently known from the experimental neurosciences. Cells? firing was timed to a theta oscillation paced by two distinct neuronal populations exhibiting highly regular bursting activity, one tightly coupled to the trough and the other to the peak of theta. An excitatory input provided to excitatory cells context and timing information for retrieval of previously stored memory patterns. Inhibition to excitatory cells acted as a non-specific global threshold machine that removed spurious activity during recall. To systematically evaluate the model?s recall performance against stored patterns, pattern overlap, network size and active cells per pattern, we selectively modulated feedforward and feedback excitatory and inhibitory pathways targeting specific excitatory and inhibitory cells. Of the different model variations (modulated pathways) tested, ?model 1? recall quality was excellent across all conditions. ?Model 2? recall was the worst. The number of ?active cells? representing a memory pattern was the determining factor in improving the model?s recall performance regardless of the number of stored patterns and overlap between them. As ?active cells per pattern? decreased, the model?s memory capacity increased, interference effects between stored patterns decreased, and recall quality improved.}
}

@article{lincoln46525,
          volume = {1},
           month = {December},
          author = {Liyun Gong and Miao Yu and Shouyong Jiang and Vassilis Cutsuridis and Stefanos Kollias and Simon Pearson},
           title = {Studies of evolutionary algorithms for the reduced Tomgro model calibration for modelling tomato yields},
       publisher = {Elsevier},
            year = {2021},
         journal = {Smart Agricultural Technology},
             doi = {10.1016/j.atech.2021.100011},
           pages = {100011},
        keywords = {ARRAY(0x5568fbb49dd8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46525/},
        abstract = {The reduced Tomgro model is one of the popular biophysical models, which can reflect the actual growth process and model the yields of tomato-based on environmental parameters in a greenhouse. It is commonly integrated with the greenhouse environmental control system for optimally controlling environmental parameters to maximize the tomato growth/yields under acceptable energy consumption. In this work, we compare three mainstream evolutionary algorithms (genetic algorithm (GA), particle swarm optimization (PSO), and differential evolutionary (DE)) for calibrating the reduced Tomgro model, to model the tomato mature fruit dry matter (DM) weights. Different evolutionary algorithms have been applied to calibrate 14 key parameters of the reduced Tomgro model. And the performance of the calibrated Tomgro models based on different evolutionary algorithms has been evaluated based on three datasets obtained from a real tomato grower, with each dataset containing greenhouse environmental parameters (e.g., carbon dioxide concentration, temperature, photosynthetically active radiation (PAR)) and tomato yield information at a particular greenhouse for one year. Multiple metrics (root mean square errors (RMSEs), relative root mean square errors (r-RSMEs), and mean average errors (MAEs)) between actual DM weights and model-simulated ones for all three datasets, are used to validate the performance of calibrated reduced Tomgro model.}
}

@article{lincoln47447,
          volume = {9},
           month = {December},
          author = {Tian Liu and Xuelong Sun and Cheng Hu and Qinbing Fu and Shigang Yue},
           title = {A Multiple Pheromone Communication System for Swarm Intelligence},
       publisher = {IEEE},
            year = {2021},
         journal = {IEEE Access},
             doi = {10.1109/ACCESS.2021.3124386},
           pages = {148721--148737},
        keywords = {ARRAY(0x5568fbb49e08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47447/},
        abstract = {Pheromones are chemical substances essential for communication among social insects.  In the application of swarm intelligence to real micro mobile robots, the deployment of a single virtual pheromone has emerged recently as a powerful real-time method for indirect communication.  However, these studies usually exploit only one kind of pheromones in their task, neglecting the crucial fact that in the world of real insects, multiple pheromones play important roles in shaping stigmergic behaviours such as foraging or nest building. To explore the multiple pheromones mechanism which enable robots to solve complex collective tasks efficiently, we introduce an artificial multiple pheromone system (ColCOS\${$\backslash$}Phi\$) to support swarm intelligence research by enabling multiple robots to deploy and react to multiple pheromones simultaneously. The proposed system ColCOS\${$\backslash$}Phi\$ uses optical signals to emulate different evaporating chemical substances i.e. pheromones. These emulated pheromones are represented by trails displayed on a wide LCD display screen positioned horizontally, on which multiple miniature robots can move freely. The colour sensors beneath the robots can detect and identify lingering "pheromones" on the screen. Meanwhile, the release of any pheromone from each robot is enabled by monitoring its positional information over time with an overhead camera. No other communication methods apart from virtual pheromones are employed in this system. Two case studies have been carried out which have verified the feasibility and effectiveness of the proposed system in achieving complex swarm tasks as empowered by multiple pheromones. This novel platform is a timely and powerful tool for research into swarm intelligence.}
}

@article{lincoln47573,
          volume = {16},
           month = {December},
          author = {Zakaria Maamar and Noura Faci and Mohammed Al-Khafajiy and Murtada Dohan},
           title = {Time-centric and resource-driven composition for the Internet of Things},
       publisher = {Elsevier},
            year = {2021},
         journal = {Internet of Things},
             doi = {10.1016/j.iot.2021.100460},
           pages = {100460},
        keywords = {ARRAY(0x5568fbb49e38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47573/},
        abstract = {Internet of Things (IoT), one of the fastest growing Information and Communication Technologies (ICT), is playing a major role in provisioning contextualized, smart services to end-users and organizations. To sustain this role, many challenges must be tackled with focus in this paper on the design and development of thing composition. The complex nature of today?s needs requires groups of things, and not separate things, to work together to satisfy these needs. By analogy with other ICTs like Web services, thing composition is specified with a model that uses dependencies to decide upon things that will do what, where, when, and why. Two types of dependencies are adopted, regular that schedule the execution chronology of things and special that coordinate the operations of things when they run into obstacles like unavailability of resources to use. Both resource use and resource availability are specified in compliance with Allen?s time intervals upon which reasoning takes place. This reasoning is technically demonstrated through a system extending EdgeCloudSim and backed with a set of experiments.}
}

@article{lincoln47914,
           month = {December},
           title = {Application of region-based video surveillance 
in smart cities using deep learning},
          author = {Asma Zahra and Mubeen Ghafoor and Kamran Munir and Ata Ullah and Zain Ul Abideen},
       publisher = {Springer},
            year = {2021},
             doi = {10.1007/s11042-021-11468-w},
         journal = {Multimedia Tools and Applications},
        keywords = {ARRAY(0x5568fbb49e68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47914/},
        abstract = {Smart video surveillance helps to build more robust smart city environment. The varied 
angle cameras act as smart sensors and collect visual data from smart city environment and 
transmit it for further visual analysis. The transmitted visual data is required to be in high 
quality for efcient analysis which is a challenging task while transmitting videos on low 
capacity bandwidth communication channels. In latest smart surveillance cameras, high 
quality of video transmission is maintained through various video encoding techniques 
such as high efciency video coding. However, these video coding techniques still provide 
limited capabilities and the demand of high-quality based encoding for salient regions such 
as pedestrians, vehicles, cyclist/motorcyclist and road in video surveillance systems is still 
not met. This work is a contribution towards building an efcient salient region-based sur?veillance framework for smart cities. The proposed framework integrates a deep learning?based video surveillance technique that extracts salient regions from a video frame without 
information loss, and then encodes it in reduced size. We have applied this approach in 
diverse case studies environments of smart city to test the applicability of the framework. 
The successful result in terms of bitrate 56.92\%, peak signal to noise ratio 5.35 bd and 
SR based segmentation accuracy of 92\% and 96\% for two diferent benchmark datasets is 
the outcome of proposed work. Consequently, the generation of less computational region?based video data makes it adaptable to improve surveillance solution in Smart Cities.}
}

@article{lincoln47708,
          volume = {18},
          number = {181},
           month = {December},
          author = {Despina Laparidou and Ffion Curtis and Joseph Akanuwe and Khaled Goher and Niro Siriwardena and Ayse Kucukyilmaz},
           title = {Patient, carer, and staff perceptions of robotics in motor rehabilitation: a systematic review and qualitative meta?synthesis.},
       publisher = {BMC},
            year = {2021},
         journal = {Journal of NeuroEngineering and Rehabilitation},
             doi = {10.1186/s12984-021-00976-3},
        keywords = {ARRAY(0x5568fbb49e98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47708/},
        abstract = {Background: In recent years, robotic rehabilitation devices have often been used for motor training. However, to date, no systematic reviews of qualitative studies exploring the end-user experiences of robotic devices in motor rehabilitation have been published. The aim of this study was to review end-users? (patients, carers and healthcare professionals) experiences with robotic devices in motor rehabilitation, by conducting a systematic review and thematic meta-synthesis of qualitative studies concerning the users? experiences with such robotic devices.
Methods: Qualitative studies and mixed-methods studies with a qualitative element were eligible for inclusion.  Nine electronic databases were searched from inception to August 2020, supplemented with internet searches and forward and backward citation tracking from the included studies and review articles. Data were synthesised thematically following the Thomas and Harden approach. The CASP Qualitative Checklist was used to assess the quality of the included studies of this review.
Results: The search strategy identified a total of 13,556 citations and after removing duplicates and excluding citations based on title and abstract, and full text screening, 30 studies were included. All studies were considered of acceptable quality. We developed six analytical themes: logistic barriers; technological challenges; appeal and engagement; supportive interactions and relationships; benefits for physical, psychological, and social function(ing); and expanding and sustaining therapeutic options.
Conclusions: Despite experiencing technological and logistic challenges, participants found robotic devices acceptable, useful and beneficial (physically, psychologically, and socially), as well as fun and interesting. Having supportive relationships with significant others and positive therapeutic relationships with healthcare staff were considered the foundation for successful rehabilitation and recovery.}
}

@article{lincoln48335,
          volume = {8},
           month = {December},
          author = {Asma Seddaoui and Chakravarthini Mini Saaj and Manu Harikrishnan Nair},
           title = {Modeling a Controlled-Floating Space Robot for In-Space Services: A Beginner?s Tutorial},
       publisher = {Frontiers Media},
         journal = {Frontiers in Robotics and AI},
             doi = {10.3389/frobt.2021.725333},
            year = {2021},
        keywords = {ARRAY(0x5568fbb49ec8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48335/},
        abstract = {Ground-based applications of robotics and autonomous systems (RASs) are fast
advancing, and there is a growing appetite for developing cost-effective RAS solutions
for in situ servicing, debris removal, manufacturing, and assembly missions. An orbital
space robot, that is, a spacecraft mounted with one or more robotic manipulators, is an
inevitable system for a range of future in-orbit services. However, various practical
challenges make controlling a space robot extremely difficult compared with its
terrestrial counterpart. The state of the art of modeling the kinematics and dynamics of
a space robot, operating in the free-flying and free-floating modes, has been well studied
by researchers. However, these two modes of operation have various shortcomings,
which can be overcome by operating the space robot in the controlled-floating mode. This
tutorial article aims to address the knowledge gap in modeling complex space robots
operating in the controlled-floating mode and under perturbed conditions. The novel
research contribution of this article is the refined dynamic model of a chaser space robot,
derived with respect to the moving target while accounting for the internal perturbations
due to constantly changing the center of mass, the inertial matrix, Coriolis, and centrifugal
terms of the coupled system; it also accounts for the external environmental disturbances.
The nonlinear model presented accurately represents the multibody coupled dynamics of
a space robot, which is pivotal for precise pose control. Simulation results presented
demonstrate the accuracy of the model for closed-loop control. In addition to the
theoretical contributions in mathematical modeling, this article also offers a
commercially viable solution for a wide range of in-orbit missions.}
}

@article{lincoln52083,
           month = {December},
          author = {Mrudul Chellapurath and Kyle Walker and Enrico Donato and Giacomo Picardi and Sergio Stefanni and Cecilia Laschi and Francesco Giorgio Serchi and Marcello Calisti},
           title = {Analysis of Station Keeping Performance of an Underwater Legged Robot},
       publisher = {IEEE},
         journal = {IEEE/ASME Transactions on Mechatronics},
             doi = {10.1109/TMECH.2021.3132779},
           pages = {1--12},
            year = {2021},
        keywords = {ARRAY(0x5568fbb49ef8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52083/},
        abstract = {Remotely operated vehicles (ROVs) can exploit contact with the substrate to enhance their station keeping capabilities. A negatively buoyant underwater legged robot can perform passive station keeping, relying on the frictional force to counteract disturbances acting on the robot. Unlike conventional propeller-based ROVs, this approach has similar, slightly higher efficiency while reducing disturbances to the substrate. Detailed analysis on the passive station keeping performance of an underwater legged robot was performed using Seabed Interaction Legged Vehicle for Exploration and Research 2 (SILVER2) as a reference platform, investigating the effect of leg configuration, net weight, and the nature of the substrate on station keeping performance. A numerical model was developed to study the effect of both geometrical and physical parameters on the station keeping performance, which accurately predicted the station keeping behavior of the robot during field tests. Finally, we defined a metric called station keeping efficiency for the evaluation of station keeping performance; the underwater legged robots showed higher station keeping efficiency (28\%) than commercial propeller-based ROVs (11\%), showing they could present an alternative for tasks such as environmental monitoring.}
}

@unpublished{lincoln47605,
       booktitle = {AAAI Conference on Artificial Intelligence 2022},
           month = {December},
           title = {Deep Movement Primitives: toward Breast Cancer Examination Robot},
          author = {Oluwatoin Sanni and Giorgio Bonvicini and Muhammad Arshad Khan and Pablo C. Lo ?pez-Custodio and Kiyanoush Nazari and Amir Ghalamzan Esfahani},
       publisher = {AAAI},
            year = {2021},
         journal = {Association for the Advancement of Artificial Intelligence},
        keywords = {ARRAY(0x5568fbb49f28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47605/},
        abstract = {Breast cancer is the most common type of cancer worldwide. A robotic system performing autonomous breast palpation can make a significant impact on the related health sector worldwide. However, robot programming for breast palpating with different geometries is very complex and unsolved. Robot learning from demonstrations (LfD) re- duces the programming time and cost. However, the available LfD are lacking the modelling of the manipulation path/trajectory as an explicit function of the visual sensory information. This paper presents a novel approach to manipulation path/trajectory planning called deep Movement Primitives that successfully generates the movements of a manipulator to reach a breast phantom and perform the palpation. We show the effectiveness of our approach by a series of real-robot experiments of reaching and palpating a breast phantom. The experimental results indicate our approach outperforms the state-of-the-art method.}
}

@inproceedings{lincoln46800,
       booktitle = {IEEE Automatic Speech Recognition and Understanding},
           month = {December},
           title = {Audio Embeddings Help to Learn Better Dialogue Policies},
          author = {Asier Lopez Zorrilla and M. Ines Torres and Heriberto Cuayahuitl},
       publisher = {IEEE},
            year = {2021},
        keywords = {ARRAY(0x5568fbb49f58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46800/},
        abstract = {Neural transformer architectures have gained a lot of interest for text-based dialogue management in the last few years. They have shown high learning capabilities for open domain dialogue with huge amounts of data and also for domain adaptation in task-oriented setups. But the potential benefits of exploiting the users' audio signal have rarely been explored in such frameworks. In this work, we combine text dialogue history representations generated by a GPT-2 model with audio embeddings obtained by the recently released Wav2Vec2 transformer model. We jointly fine-tune these models to learn dialogue policies via supervised learning and two policy gradient-based reinforcement learning algorithms. Our experimental results, using the DSTC2 dataset and a simulated user model capable of sampling audio turns, reveal that audio embeddings lead to overall higher task success (than without using audio embeddings) with statistically significant results across evaluation metrics and training algorithms.}
}

@inproceedings{lincoln47522,
       booktitle = {NeurIPS 2021 Workshop on Deployable Decision Making in Embodied Systems (DDM)},
           month = {December},
           title = {Reward-Based Environment States for Robot Manipulation Policy Learning},
          author = {Mouliets C{\'e}d{\'e}rick and Isabelle Ferran{\'e} and Heriberto Cuayahuitl},
            year = {2021},
        keywords = {ARRAY(0x5568fbb49f88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47522/},
        abstract = {Training robot manipulation policies is a challenging and open problem in robotics and artificial intelligence. In this paper we propose a novel and compact state representation based on the rewards predicted from an image-based task success
classifier. Our experiments{--}using the Pepper robot in simulation with two deep reinforcement learning algorithms on a grab-and-lift task{--}reveal that our proposed state representation can achieve up to 97\% task success using our best policies.}
}

@article{lincoln47035,
          volume = {190},
           month = {November},
          author = {Justin Le Louedec and Grzegorz Cielniak},
           title = {3D shape sensing and deep learning-based segmentation of strawberries},
       publisher = {Elsevier},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2021.106374},
            year = {2021},
        keywords = {ARRAY(0x5568fbb49fb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47035/},
        abstract = {Automation and robotisation of the agricultural sector are seen as a viable solution to socio-economic challenges
faced by this industry. This technology often relies on intelligent perception systems providing information about
crops, plants and the entire environment. The challenges faced by traditional 2D vision systems can be addressed
by modern 3D vision systems which enable straightforward localisation of objects, size and shape estimation, or
handling of occlusions. So far, the use of 3D sensing was mainly limited to indoor or structured environments. In
this paper, we evaluate modern sensing technologies including stereo and time-of-flight cameras for 3D
perception of shape in agriculture and study their usability for segmenting out soft fruit from background based
on their shape. To that end, we propose a novel 3D deep neural network which exploits the organised nature of
information originating from the camera-based 3D sensors. We demonstrate the superior performance and ef?
ficiency of the proposed architecture compared to the state-of-the-art 3D networks. Through a simulated study,
we also show the potential of the 3D sensing paradigm for object segmentation in agriculture and provide in?
sights and analysis of what shape quality is needed and expected for further analysis of crops. The results of this
work should encourage researchers and companies to develop more accurate and robust 3D sensing technologies
to assure their wider adoption in practical agricultural applications.}
}

@inproceedings{lincoln48667,
       booktitle = {BMVC},
           month = {November},
           title = {Gaussian map predictions for 3D surface feature localisation and counting},
          author = {Justin Le Louedec and Grzegorz Cielniak},
       publisher = {BMVA},
            year = {2021},
        keywords = {ARRAY(0x5568fbb49fe8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48667/},
        abstract = {In this paper, we propose to employ a Gaussian map representation to estimate precise location and count of 3D surface features, addressing the limitations of state-of-the-art methods based on density estimation which struggle in presence of local disturbances. Gaussian maps indicate probable object location and can be generated directly from keypoint annotations avoiding laborious and costly per-pixel annotations. We apply this method to the 3D spheroidal class of objects which can be projected into 2D shape representation enabling efficient processing by a neural network GNet, an improved UNet architecture, which generates the likely locations of surface features and their precise count. We demonstrate a practical use of this technique for counting strawberry achenes which is used as a fruit quality measure in phenotyping applications. The results of training the proposed system on several hundreds of 3D scans of strawberries from a publicly available dataset demonstrate the accuracy and precision of the system which outperforms the state-of-the-art density-based methods for this application.}
}

@article{lincoln52081,
          volume = {38},
          number = {3},
           month = {November},
          author = {Anna Astolfi and Giacomo Picardi and Marcello Calisti},
           title = {Multilegged Underwater Running With Articulated Legs},
       publisher = {IEEE},
            year = {2021},
         journal = {IEEE Transactions on Robotics},
             doi = {10.1109/TRO.2021.3118204},
           pages = {1841--1855},
        keywords = {ARRAY(0x5568fbb4a018)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52081/},
        abstract = {Drawing inspiration from the locomotion modalities of animals, legged robots demonstrated the potential to traverse irregular and unstructured environments. Successful approaches exploited single-leg templates, like the spring-loaded inverted pendulum (SLIP), as a reference for the control of multilegged machines. Nevertheless, the anchoring between the low-order model and the actual multilegged structure is still an open challenge. This article proposes a novel strategy to derive actuation inputs for a multilegged robot by expressing the control requirements in terms of jump height and forward speed (derived from the limit cycle). We found that these requirements could be associated with a specific maximum force, successively split on an arbitrary number of legs and their relative actuation sets. The proposed approach has been validated in multibody simulation and real-world experiments by employing the underwater hexapod robot SILVER2. Results show that locomotion performances of the low-order model are reflected by the simulated and actual robot, showing that the articulated-USLIP (a-USLIP) model can faithfully explain the multilegged behavior under the imposed control inputs once hydrodynamic parameters have been tuned. More importantly, the proposed controller can be translated to the terrestrial case with minimal modifications and extended with additional layers to obtain more complex behaviors.}
}

@article{lincoln47216,
          volume = {9},
           month = {November},
          author = {Tian Liu and Xuelong Sun and Cheng Hu and Qinbing Fu and Shigang Yue},
           title = {A Multiple Pheromone Communication System for Swarm Intelligence},
       publisher = {IEEE},
         journal = {IEEE Access},
             doi = {10.1109/ACCESS.2021.3124386},
            year = {2021},
        keywords = {ARRAY(0x5568fbb4a048)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47216/},
        abstract = {Pheromones are chemical substances essential for communication among social insects.
In the application of swarm intelligence to real micro mobile robots, the deployment of a single virtual
pheromone has emerged recently as a powerful real-time method for indirect communication. However,
these studies usually exploit only one kind of pheromones in their task, neglecting the crucial fact that in
the world of real insects, multiple pheromones play important roles in shaping stigmergic behaviors such
as foraging or nest building. To explore the multiple pheromones mechanism which enable robots to solve
complex collective tasks efficiently, we introduce an artificial multiple pheromone system (ColCOS{\ensuremath{\Phi}}) to
support swarm intelligence research by enabling multiple robots to deploy and react to multiple pheromones
simultaneously. The proposed system ColCOS{\ensuremath{\Phi}} uses optical signals to emulate different evaporating
chemical substances i.e. pheromones. These emulated pheromones are represented by trails displayed on a
wide LCD display screen positioned horizontally, on which multiple miniature robots can move freely. The
color sensors beneath the robots can detect and identify lingering "pheromones" on the screen. Meanwhile,
the release of any pheromone from each robot is enabled by monitoring its positional information over time
with an overhead camera. No other communication methods apart from virtual pheromones are employed in
this system. Two case studies have been carried out which have verified the feasibility and effectiveness of
the proposed system in achieving complex swarm tasks as empowered by multiple pheromones. This novel
platform is a timely and powerful tool for research into swarm intelligence.}
}

@article{lincoln41705,
          volume = {22},
          number = {10},
           month = {October},
          author = {Fanta Camara and Nicola Bellotto and Serhan Cosar and Dimitris Nathanael and Mathias Althoff and Jingyuan Wu and Johannes Ruenz and Andre Dietrich and Charles Fox},
           title = {Pedestrian Models for Autonomous Driving Part I: Low-Level Models, from Sensing to Tracking},
       publisher = {IEEE},
            year = {2021},
         journal = {IEEE Transactions on Intelligent Transport Systems},
             doi = {10.1109/TITS.2020.3006768},
           pages = {6131--6151},
        keywords = {ARRAY(0x5568fbb4a078)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41705/},
        abstract = {Abstract{--}Autonomous vehicles (AVs) must share space with pedestrians, both in carriageway cases such as cars at pedestrian crossings and off-carriageway cases such as delivery vehicles navigating through crowds on pedestrianized high-streets. Unlike static obstacles, pedestrians are active agents with complex, inter- active motions. Planning AV actions in the presence of pedestrians thus requires modelling of their probable future behaviour as well as detecting and tracking them. This narrative review article is Part I of a pair, together surveying the current technology stack involved in this process, organising recent research into a hierarchical taxonomy ranging from low-level image detection to high-level psychology models, from the perspective of an AV designer. This self-contained Part I covers the lower levels of this stack, from sensing, through detection and recognition, up to tracking of pedestrians. Technologies at these levels are found to be mature and available as foundations for use in high-level systems, such as behaviour modelling, prediction and interaction control.}
}

@inproceedings{lincoln52082,
       booktitle = {Annual Conference Towards Autonomous Robotic Systems},
           month = {October},
           title = {Statics Optimization of a Hexapedal Robot Modelled as a Stewart Platform},
          author = {Enrico Donato and Giacomo Picardi and Marcello Calisti},
       publisher = {Springer},
            year = {2021},
             doi = {10.1007/978-3-030-89177-0\_39},
        keywords = {ARRAY(0x5568fbb4a0a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52082/},
        abstract = {SILVER2 is an underwater legged robot designed with the aim of collecting litter on the seabed and sample the sediment to assess the presence of micro-plastics. Besides the original application, SILVER2 can also be a valuable tool for all underwater operations which require to interact with objects directly on the seabed. The advancement presented in this paper is to model SILVER2 as a Gough-Stewart platform, and therefore to enhance its ability to interact with the environment. Since the robot is equipped with six segmented legs with three actuated joints, it is able to make arbitrary movements in the six degrees of freedom. The robot?s performance has been analysed from both kinematics and statics points of view. The goal of this work is providing a strategy to harness the redundancy of SILVER2 by finding the optimal posture to maximize forces/torques that it can resist along/around constrained directions. Simulation results have been reported to show the advantages of the proposed method.}
}

@inproceedings{lincoln46669,
       booktitle = {Towards Autonomous Robotic Systems Conference},
           month = {October},
           title = {Deep semantic segmentation of 3D plant point clouds},
          author = {Karoline Heiwolt and Tom Duckett and Grzegorz Cielniak},
       publisher = {Springer International Publishing},
            year = {2021},
             doi = {10.1007/978-3-030-89177-0\_4},
        keywords = {ARRAY(0x5568fbb4a0d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46669/},
        abstract = {Plant phenotyping is an essential step in the plant breeding cycle, necessary to ensure food safety for a growing world population. Standard procedures for evaluating three-dimensional plant morphology and extracting relevant phenotypic characteristics are slow, costly, and in need of automation. Previous work towards automatic semantic segmentation of plants relies on explicit prior knowledge about the species and sensor set-up, as well as manually tuned parameters. In this work, we propose to use a supervised machine learning algorithm to predict per-point semantic annotations directly from point cloud data of whole plants and minimise the necessary user input. We train a PointNet++ variant on a fully annotated procedurally generated data set of partial point clouds of tomato plants, and show that the network is capable of distinguishing between the semantic classes of leaves, stems, and soil based on structural data only. We present both quantitative and qualitative evaluation results, and establish a proof of concept, indicating that deep learning is a promising approach towards replacing the current complex, laborious, species-specific, state-of-the-art plant segmentation procedures.}
}

@inproceedings{lincoln46453,
       booktitle = {Towards Autonomous Robotic Systems Conference},
           month = {October},
           title = {CRH*: A Deadlock Free Framework for Scalable Prioritised Path Planning in Multi-Robot Systems},
          author = {James Heselden and Gautham Das},
       publisher = {Springer International Publishing},
            year = {2021},
             doi = {10.1007/978-3-030-89177-0\_7},
        keywords = {ARRAY(0x5568fb96a0e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46453/},
        abstract = {Multi-robot system is an ever growing tool which is able to be applied to a wide range of industries to improve productivity and robustness, especially when tasks are distributed in space, time and functionality. Recent works have shown the benefits of multi-robot systems in fields such as warehouse automation, entertainment and agriculture. The work presented in this paper tackles the deadlock problem in multi-robot navigation, in which robots within a common work-space, are caught in situations where they are unable to navigate to their targets, being blocked by one another. This problem can be mitigated by efficient multi-robot path planning. Our work focused around the development of a scalable rescheduling algorithm named Conflict Resolution Heuristic A* (CRH*) for decoupled prioritised planning. Extensive experimental evaluation of CRH* was carried out in discrete event simulations of a fleet of autonomous agricultural robots. The results from these experiments proved that the algorithm was both scalable and deadlock-free. Additionally, novel customisation options were included to test further optimisations in system performance. Continuous Assignment and Dynamic Scoring showed to reduce the make-span of the routing whilst Combinatorial Heuristics showed to reduce the impact of outliers on priority orderings.}
}

@article{lincoln47016,
          volume = {59},
          number = {10},
           month = {October},
          author = {Hamid Isakhani and Shigang Yue and Caihua Xiong and Wenbin Chen},
           title = {Aerodynamic Analysis and Optimization of Gliding Locust Wing Using Nash Genetic Algorithm},
       publisher = {Aerospace Research Central},
            year = {2021},
         journal = {AIAA Journal},
             doi = {10.2514/1.J060298},
           pages = {4002--4013},
        keywords = {ARRAY(0x5568fba114b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47016/},
        abstract = {Natural fliers glide and minimize wing articulation to conserve energy for endured and long range flights. Elucidating the underlying physiology of such capability could potentially address numerous challenging problems in flight engineering. This study investigates the aerodynamic characteristics of an insect species called desert locust (Schistocerca gregaria) with an extraordinary gliding skills at low Reynolds number. Here, locust tandem wings are subjected to a computational fluid dynamics (CFD) simulation using 2D and 3D Navier-Stokes equations revealing fore-hindwing interactions, and the influence of their corrugations on the aerodynamic performance. Furthermore, the obtained CFD results are mathematically parameterized using PARSEC method and optimized based on a novel fusion of Genetic Algorithms and Nash game theory to achieve Nash equilibrium being the optimized wings.
It was concluded that the lift-drag (gliding) ratio of the optimized profiles were improved by at least 77\% and 150\% compared to the original wing and the published literature, respectively.
Ultimately, the profiles are integrated and analyzed using 3D CFD simulations that demonstrated a 14\% performance improvement validating the proposed wing models for further fabrication and rapid prototyping presented in the future study.}
}

@inproceedings{lincoln46480,
       booktitle = {Towards Autonomous Robotic Systems Conference (TAROS)},
           month = {October},
           title = {Predicting Artist Drawing Activity via Multi-Camera Inputs for Co-Creative Drawing},
          author = {Chipp Jansen and Elizabeth Sklar},
            year = {2021},
             doi = {10.1007/978-3-030-89177-0\_23},
         journal = {Proceedings of the 22nd Towards Autonomous Robotic Systems (TAROS) Conference},
        keywords = {ARRAY(0x5568fb9b5a48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46480/},
        abstract = {This paper presents the results of experimentation in computer vision based for the perception of the artist drawing with analog media (pen and paper), with the aim to contribute towards a human- robot co-creative drawing framework. Using data gathered from user studies with artists and illustrators, two types of CNN models were de- signed and evaluated to predict an artist?s activity (e.g. are they drawing or not?) and the position of the pen on the canvas based only on a multi- camera input of the drawing surface. Results of different combination of input sources are presented, with an overall mean accuracy of 95\% (std: 7\%) for predicting when the artist is present and 68\% (std: 15\%) for predicting when the artist is drawing; and mean squared normalised error of 0.0034 (std: 0.0099) of predicting the pen?s position on the drawing canvas. These results point toward an autonomous robotic system having an awareness of an artist at work via camera based input and contributes toward the development of a more fluid physical to digital workflow for creative content creation.}
}

@article{lincoln45627,
          volume = {6},
          number = {4},
           month = {October},
          author = {Riccardo Polvara and Francesco Del Duchetto and Gerhard Neumann and Marc Hanheide},
           title = {Navigate-and-Seek: a Robotics Framework for People Localization in Agricultural Environments},
       publisher = {IEEE},
            year = {2021},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2021.3094557},
           pages = {6577--6584},
        keywords = {ARRAY(0x5568fbb54978)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45627/},
        abstract = {The agricultural domain offers a working environment where many human laborers are nowadays employed to maintain or harvest crops, with huge potential for productivity gains through the introduction of robotic automation. Detecting and localizing humans reliably and accurately in such an environment, however, is a prerequisite to many  services offered by fleets of mobile robots collaborating with human workers. Consequently, in this paper, we expand on the concept of a topological particle filter (TPF) to accurately and individually localize and track workers in a farm environment, integrating information from heterogeneous sensors and combining local active sensing (exploiting a robot?s onboard sensing employing a Next-Best-Sense planning approach) and global localization (using affordable IoT GNSS devices). We validate the proposed approach in topologies created for the deployment of robotics fleets to support fruit pickers in a real farm environment. By combining multi-sensor observations on the topological level complemented by active perception through the NBS approach, we show that we can improve the accuracy of picker localization in comparison to prior work.}
}

@inproceedings{lincoln46635,
       booktitle = {TAROS2021},
           month = {October},
           title = {Maximising availability of transportation robots
through intelligent allocation of parking spaces},
          author = {Roopika Ravikanna and Marc Hanheide and Gautham Das and Zuyuan Zhu},
            year = {2021},
             doi = {10.1007/978-3-030-89177-0\_34},
        keywords = {ARRAY(0x5568fbb58d80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46635/},
        abstract = {Autonomous agricultural robots increasingly have an important role in tasks such as transportation, crop monitoring, weed detection etc. These tasks require the robots to travel to different locations in the field. Reducing time for this travel can greatly reduce the global task completion time and improve the availability of the robot to perform more number of tasks. Looking at in-field logistics robots for supporting human fruit pickers as a relevant scenario, this research deals with the design of various algorithms for automated allocation of parking spaces for the on-field robots, so as to make them most accessible to preferred areas of the field. These parking space allocation algorithms are tested
for their performance by varying initial parameters like the size of the field, number of farm workers in the field, position of the farm workers etc. Various experiments are conducted for this purpose on a simulated environment. Their results are studied and discussed for better understanding about the contribution of intelligent parking space allocation towards improving the overall time efficiency of task completion.}
}

@inproceedings{lincoln46646,
           month = {October},
          author = {Nikolaus Wagner and Grzegorz Cielniak},
       booktitle = {Towards Autonomous Robotic Systems Conference (TAROS)},
           title = {Inference of Mechanical Properties of Dynamic Objects through Active Perception},
       publisher = {Springer},
            year = {2021},
         journal = {Towards Autonomous Robotic Systems Conference (TAROS) 2021},
             doi = {10.1007/978-3-030-89177-0\_45},
           pages = {430--439},
        keywords = {ARRAY(0x5568fbba8840)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46646/},
        abstract = {Current robotic systems often lack a deeper understanding of their surroundings, even if they are equipped with visual sensors like RGB-D cameras. Knowledge of the mechanical properties of the objects in their immediate surroundings, however, could bring huge benefits to applications such as path planning, obstacle avoidance \& removal or estimating object compliance.
In this paper, we present a novel approach to inferring mechanical properties of dynamic objects with the help of active perception and frequency analysis of objects' stimulus responses. We perform FFT on a buffer of image flow maps to identify the spectral signature of objects and from that their eigenfrequency. Combining this with 3D depth information allows us to infer an object's mass without having to weigh it.
We perform experiments on a demonstrator with variable mass and stiffness to test our approach and provide an analysis on the influence of individual properties on the result. By simply applying a controlled amount of force to a system, we were able to infer mechanical properties of systems with an eigenfrequency of around 4.5 Hz in about 2 s. This lab-based feasibility study opens new exciting robotic applications targeting realistic, non-rigid objects such as plants, crops or fabric.}
}

@book{lincoln47294,
          editor = {Charles Fox and Junfeng Gao and Amir Ghalamzan Esfahani and Mini Saaj and Marc Hanheide and Simon Parsons},
           month = {October},
           title = {Towards Autonomous Robotic Systems},
          author = {Charles Fox and Junfeng Gao and Amir Ghalamzan Esfahani and Mini Saaj and Marc Hanheide and Simon Parsons},
       publisher = {Springer},
            year = {2021},
             doi = {10.1007/978-3-030-89177-0},
        keywords = {ARRAY(0x5568fbb7b240)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47294/},
        abstract = {22nd Annual Conference, TAROS 2021, Lincoln, UK, September 8?10, 2021, Proceedings}
}

@inproceedings{lincoln46371,
       booktitle = {2021 European Conference on Mobile Robots (ECMR)},
           month = {October},
           title = {Adaptive Selection of Informative Path Planning Strategies via Reinforcement Learning},
          author = {Taeyeong Choi and Grzegorz Cielniak},
       publisher = {IEEE},
            year = {2021},
             doi = {10.1109/ECMR50962.2021.9568796},
        keywords = {ARRAY(0x5568fb96a128)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46371/},
        abstract = {In our previous work, we designed a systematic policy to prioritize sampling locations to lead significant accuracy
improvement in spatial interpolation by using the prediction uncertainty of Gaussian Process Regression (GPR) as ?attraction force? to deployed robots in path planning. Although the integration with Traveling Salesman Problem (TSP) solvers was also shown to produce relatively short travel distance, we here hypothesise several factors that could decrease the overall prediction precision as well because sub-optimal locations may eventually be included in their paths. To address this issue, in this paper, we first explore ?local planning? approaches adopting various spatial ranges within which next sampling locations are prioritized to investigate their effects on the prediction performance as well as incurred travel distance. Also, Reinforcement Learning (RL)-based high-level controllers are trained to adaptively produce blended plans from a particular set of local planners to inherit unique strengths from that selection depending on latest prediction states. Our experiments on use cases of temperature monitoring robots demonstrate that the dynamic mixtures of planners can not only generate sophisticated, informative plans that a single planner could
not create alone but also ensure significantly reduced travel distances at no cost of prediction reliability without any assist of additional modules for shortest path calculation.}
}

@inproceedings{lincoln47322,
       booktitle = {2021 IEEE International Conference on Robotics and Automation (ICRA)},
           month = {October},
           title = {A Versatile Vision-Pheromone-Communication Platform for Swarm Robotics},
          author = {Tian Liu and Xuelong Sun and Cheng Hu and Qinbing Fu and Shigang Yue},
       publisher = {IEEE},
            year = {2021},
             doi = {10.1109/ICRA48506.2021.9561911},
        keywords = {ARRAY(0x5568fba2ff20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47322/},
        abstract = {This paper describes a versatile platform for swarm robotics research. It integrates multiple pheromone communication with a dynamic visual scene along with real time data transmission and localization of multiple-robots. The platform has been built for inquiries into social insect behavior and bio-robotics. By introducing a new research scheme to coordinate olfactory and visual cues, it not only complements current swarm robotics platforms which focus only on pheromone communications by adding visual interaction, but also may fill an important gap in closing the loop from bio-robotics to neuroscience. We have built a controllable dynamic visual environment based on our previously developed ColCOS\${$\backslash$}Phi\$ (a multi-pheromones platform) by enclosing the arena with LED panels and interacting with the micro mobile robots with a visual sensor. In addition, a wireless communication system has been developed to allow transmission of real-time bi-directional data between multiple micro robot agents and a PC host. A case study combining concepts from the internet of vehicles (IoV) and insect-vision inspired model has been undertaken to verify the applicability of the presented platform, and to investigate how complex scenarios can be facilitated by making use of this platform.}
}

@inproceedings{lincoln44427,
           month = {October},
          author = {Jose C. Mayoral and Lars Grimstad and P{\r a}l J. From and Grzegorz Cielniak},
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
           title = {Integration of a Human-aware Risk-based Braking System into an Open-Field Mobile Robot},
       publisher = {IEEE},
             doi = {10.1109/ICRA48506.2021.9561522},
           pages = {2435--2442},
            year = {2021},
        keywords = {ARRAY(0x5568fbb705d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44427/},
        abstract = {Safety integration components for robotic applications are a mandatory feature for any autonomous mobile
application, including human avoidance behaviors. This paper proposes a novel parametrizable scene risk evaluator for
open-field applications that use humans motion predictions and pre-defined hazard zones to estimate a braking factor.
Parameters optimization uses simulated data. The evaluation is carried out by simulated and real-time scenarios, showing the impact of human predictions in favor of risk reductions on agricultural applications.}
}

@inproceedings{lincoln44426,
           month = {October},
          author = {Nikolaus Wagner and Raymond Kirk and Marc Hanheide and Grzegorz Cielniak},
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
           title = {Efficient and Robust Orientation Estimation of Strawberries for Fruit Picking Applications},
       publisher = {IEEE},
             doi = {10.1109/ICRA48506.2021.9561848},
           pages = {13857--1386},
            year = {2021},
        keywords = {ARRAY(0x5568fbb70618)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44426/},
        abstract = {Recent developments in agriculture have highlighted the potential of as well as the need for the use of robotics. Various processes in this field can benefit from the proper use of state of the art technology [1], in terms of efficiency as well
as quality. One of these areas is the harvesting of ripe fruit. In order to be able to automate this process, a robotic
harvester needs to be aware of the full poses of the crop/fruit to be collected in order to perform proper path- and collision planning. The current state of the art mainly considers problems of detection and segmentation of fruit with localisation limited to the 3D position only. The reliable and real-time estimation of the respective orientations remains a mostly unaddressed problem. In this paper, we present a compact and efficient network architecture for estimating the orientation of soft fruit such as strawberries from colour and, optionally, depth images. The proposed system can be automatically trained in a realistic simulation environment. We evaluate the system?s performance on simulated datasets and validate its operation on publicly available images of strawberries to demonstrate its practical use. Depending on the amount of training data used, coverage of state space, as well as the availability of RGB-D or RGB
data only, mean errors of as low as 11? could be achieved.}
}

@article{lincoln46871,
          volume = {8},
          number = {5},
           month = {October},
          author = {Hamid Isakhani and Nicola Bellotto and Qinbing Fu and Shigang Yue},
           title = {Generative design and fabrication of a locust-inspired gliding wing prototype for micro aerial robots},
       publisher = {Oxford University Press},
            year = {2021},
         journal = {Journal of Computational Design and Engineering},
             doi = {10.1093/jcde/qwab040},
           pages = {1191--1203},
        keywords = {ARRAY(0x5568fbb4b1e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46871/},
        abstract = {Gliding is generally one of the most efficient modes of flight in natural fliers that can be further emphasised in the aircraft industry to reduce emissions and facilitate endured flights. Natural wings being fundamentally responsible for this phenomenon are developed over millions of years of evolution. Artificial wings on the other hand, are limited to the human-proposed conceptual design phase often leading to sub-optimal results. However, the novel Generative Design (GD) method claims to produce mechanically improved solutions based on robust and rigorous models of design conditions and performance criteria. This study investigates the potential applications of this Computer-Associated Design (CAsD) technology to generate novel micro aerial vehicle wing concepts that are structurally more stable and efficient. Multiple performance-driven solutions (wings) with high-level goals are generated by an infinite scale cloud computing solution executing a machine learning based GD algorithm. Ultimately, the highest performing CAsD concepts are numerically analysed, fabricated, and mechanically tested according to our previous study, and the results are compared to the literature for qualitative as well as quantitative analysis and validations. It was concluded that the GD-based tandem wings' (fore-\& hindwing) ability to withstand fracture failure without compromising structural rigidity was optimised by 78\% compared to its peer models. However, the weight was slightly increased by 11\% with 14\% drop in stiffness when compared to our models from previous study.}
}

@inproceedings{lincoln46862,
       booktitle = {Oxford Autonomous Intelligent Machines and Systems Conference 2021},
           month = {October},
           title = {Extending an Open Source Hardware Agri-Robot with Simulation and Plant Re-identification},
          author = {Harry Rogers and Benjamin Dawson and Garry Clawson and Charles Fox},
       publisher = {Oxford AIMS Conference 2021},
            year = {2021},
        keywords = {ARRAY(0x5568fbb4b1f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46862/},
        abstract = {Previous work constructed an open source hardware (OSH)
agri-robot platform for swarming agriculture research. We summarise
recent developments from the community on this platform as a case study
of how an OSH project can develop. The original platform has been
extended by contributions of a simulation package and a vision-based
plant-re-identification system used as a target for blockchain-based food
assurance. Gaining new participants in OSH projects requires explicit
instructions on how to contribute. The system hardware and software is
open-sourced at https://github.com/Harry-Rogers/PiCar as part of this
publication. We invite others to get involved and extend the platform.}
}

@article{lincoln44910,
          volume = {108},
           month = {September},
          author = {Sepehr Maleki and Sasan Maleki and Nicholas R. Jennings},
           title = {Unsupervised anomaly detection with LSTM autoencoders using statistical data-filtering},
       publisher = {Elsevier},
            year = {2021},
         journal = {Applied Soft Computing},
             doi = {10.1016/j.asoc.2021.107443},
           pages = {107443},
        keywords = {ARRAY(0x5568fbb4b228)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44910/},
        abstract = {To address one of the most challenging industry problems, we develop an enhanced training algorithm for anomaly detection in unlabelled sequential data such as time-series. We propose the outputs of a well-designed system are drawn from an unknown probability distribution, U, in normal conditions. We introduce a probability criterion based on the classical central limit theorem that allows evaluation of the likelihood that a data-point is drawn from U. This enables the labelling of the data on the fly. Non-anomalous data is passed to train a deep Long Short-Term Memory (LSTM) autoencoder that distinguishes anomalies when the reconstruction error exceeds a threshold. To illustrate our algorithm?s efficacy, we consider two real industrial case studies where gradually-developing and abrupt anomalies occur. Moreover, we compare our algorithm?s performance with four of the recent and widely used algorithms in the domain. We show that our algorithm achieves considerably better results in that it timely detects anomalies while others either miss or lag in doing so.}
}

@inproceedings{lincoln46475,
           month = {September},
          author = {Helen Harman and Elizabeth Sklar},
       booktitle = {19th International Conference on Practical Applications of Agents and Multi-Agent Systems},
           title = {A Practical Application of Market-based Mechanisms for Allocating Harvesting Tasks},
       publisher = {Springer},
         journal = {Advances in Practical Applications of Agents, Multi-Agent Systems and Social Good: The PAAMS Collection},
             doi = {10.1007/978-3-030-85739-4\_10},
            year = {2021},
        keywords = {ARRAY(0x5568fbb49b50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46475/},
        abstract = {Market-based task allocation mechanisms are designed to distribute a set of tasks fairly amongst a set of agents. Such mechanisms have been shown to be highly effective in simulation and when applied to multi-robot teams. Application of such mechanisms in real-world settings can present a range of practical challenges, such as knowing what is the best point in a complex process to allocate tasks and what information to consider in determining the allocation. The work presented here explores the application of market-based task allocation mechanisms to the problem of managing a heterogeneous human workforce to undertake activities associated with harvesting soft fruit. Soft fruit farms aim to maximise yield (the volume of fruit picked) while minimising labour time (and thus the cost of picking). Our work evaluates experimentally several different strategies for practical application of market-based mechanisms for allocating tasks to workers on soft fruit farms, identifying methods that appear best when simulated using a multi-agent model of farm activity.}
}

@inproceedings{lincoln46648,
           month = {September},
          author = {Usman A. Zahidi and Grzegorz Cielniak},
       booktitle = {13th International Conference, ICVS 2021},
         address = {International Conference on Computer Vision Systems ICVS 2021: Computer Vision Systems},
           title = {Active Learning for Crop-Weed Discrimination by Image Classification from Convolutional Neural Network?s Feature Pyramid Levels},
       publisher = {Springer Verlag},
             doi = {10.1007/978-3-030-87156-7\_20},
            year = {2021},
        keywords = {ARRAY(0x5568fba336e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46648/},
        abstract = {The amount of e?ort required for high-quality data acquisition and labelling for adequate supervised learning drives the need for building an e?cient and e?ective image sampling strategy. We propose a novel Batch Mode Active Learning that blends Region Convolutional Neural Network?s (RCNN) Feature Pyramid Network (FPN) levels together and employs t-distributed Stochastic Neighbour Embedding (t-SNE) classi?cation for selecting incremental batch based on feature similarity. Later, K-means clustering is performed on t-SNE instances for the selected sample size of images. Results show that t-SNE classi?cation on merged FPN feature maps outperforms the approach based on RGB images directly, random sampling and maximum entropy-based image sampling schemes. For comparison, we employ a publicly available data set of images of Sugar beet for a crop-weed discrimination task together with our newly acquired annotated images of Romaine and Apollo lettuce crops at di?erent growth stages. Batch sampling on all datasets by the proposed method shows that only 60\% of images are required to produce precision/recall statistics similar to the complete dataset. Two lettuce datasets used in our experiments are publicly available (Lettuce datasets: https://bit.ly/3g7Owc5) to facilitate further research opportunities.}
}

@inproceedings{lincoln46692,
       booktitle = {2021 International Joint Conference on Neural Networks (IJCNN)},
           month = {September},
           title = {Investigating Refractoriness in Collision Perception Neuronal Model},
          author = {Mu Hua and Qinbing Fu and Wenting Duan and Shigang Yue},
       publisher = {IEEE},
            year = {2021},
             doi = {10.1109/IJCNN52387.2021.9533965},
        keywords = {ARRAY(0x5568fb9bcc70)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46692/},
        abstract = {Currently, collision detection methods based on visual cues are still challenged by several factors including ultrafast approaching velocity and noisy signal. Taking inspiration from nature, though the computational models of lobula giant
movement detectors (LGMDs) in locust?s visual pathways have demonstrated positive impacts on addressing these problems, there remains potential for improvement. In this paper, we propose a novel method mimicking neuronal refractoriness, i.e. the refractory period (RP), and further investigate its functionality and efficacy in the classic LGMD neural network model for collision perception. Compared with previous works, the two phases constructing RP, namely the absolute refractory period (ARP) and relative refractory period (RRP) are computationally implemented through a ?link (L) layer? located between the photoreceptor and the excitation layers to realise the dynamic characteristic of RP in discrete time domain. The L layer, consisting of local time-varying thresholds, represents a sort of mechanism that allows photoreceptors to be activated individually and selectively by comparing the intensity of each photoreceptor to its corresponding local threshold established by its last output. More specifically, while the local threshold can merely be augmented by larger output, it shrinks exponentially over time. Our experimental outcomes show that, to some extent, the investigated mechanism not only enhances the LGMD model in terms of reliability and stability when faced with ultra-fast approaching objects, but also improves its performance against visual stimuli polluted by Gaussian or Salt-Pepper noise. This research demonstrates the modelling of refractoriness is effective in collision perception neuronal models, and promising to address the aforementioned collision detection challenges.}
}

@article{lincoln47918,
          volume = {453},
           month = {September},
          author = {Mian Muhammad Naeem Abid and Tehseen Zia and Mubeen Ghafoor and David Windridge},
           title = {Multi-view Convolutional Recurrent Neural Networks for Lung Cancer Nodule Identification},
       publisher = {Elsevier},
            year = {2021},
         journal = {Neurocomputing},
             doi = {10.1016/j.neucom.2020.06.144},
           pages = {299--311},
        keywords = {ARRAY(0x5568fba33a28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47918/},
        abstract = {Screening via low-dose Computer Tomography (CT) has been shown to reduce lung cancer mortality rates by at least 20\%. However, the assessment of large numbers of CT scans by radiologists is cost intensive, and potentially produces varying and inconsistent results for differing radiologists (and also for temporally-separated assessments by the same radiologist). To overcome these challenges, computer aided diagnosis systems based on deep learning methods have proved effective in automatic detection and classification of lung cancer. Latterly, interest has focused on the full utilization of the 3D information in CT scans using 3D-CNNs and related approaches. However, such approaches do not intrinsically correlate size and shape information between slices. In this work, an innovative approach Multi-view Convolutional Recurrent Neural Network (MV-CRecNet) is proposed that exploits shape, size and cross-slice variations while learning to identify lung cancer nodules from CT scans. The multiple-views that are passed to the model ensure better generalization and the learning of robust features. We evaluate the proposed MV-CRecNet model on the reference Lung Image Database Consortium and Image Database Resource Initiative and Early Lung Cancer Action Program datasets; six evaluation metrics are applied to eleven comparison models for testing. Results demonstrate that proposed methodology outperforms all of the models against all of the evaluation metrics.}
}

@article{lincoln43823,
          volume = {51},
          number = {9},
           month = {September},
          author = {Mubeen Ghafoor and Syed Ali Tariq and Tehseen Zia and Imtiaz Ahmad Taj and Assad Abbas and Ali Hassan and Albert Y. Zomaya},
           title = {Fingerprint Identification With Shallow Multifeature View Classifier},
       publisher = {IEEE Transactions on Cybernetics},
            year = {2021},
         journal = {IEEE Transactions on Cybernetics},
             doi = {10.1109/TCYB.2019.2957188},
           pages = {14515--4527},
        keywords = {ARRAY(0x5568fbb94348)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43823/},
        abstract = {This article presents an efficient fingerprint identification system that implements an initial classification for search-space reduction followed by minutiae neighbor-based feature encoding and matching. The current state-of-the-art fingerprint classification methods use a deep convolutional neural network (DCNN) to assign confidence for the classification prediction, and based on this prediction, the input fingerprint is matched with only the subset of the database that belongs to the predicted class. It can be observed for the DCNNs that as the architectures deepen, the farthest layers of the network learn more abstract information from the input images that result in higher prediction accuracies. However, the downside is that the DCNNs are data hungry and require lots of annotated (labeled) data to learn generalized network parameters for deeper layers. In this article, a shallow multifeature view CNN (SMV-CNN) fingerprint classifier is proposed that extracts: 1) fine-grained features from the input image and 2) abstract features from explicitly derived representations obtained from the input image. The multifeature views are fed to a fully connected neural network (NN) to compute a global classification prediction. The classification results show that the SMV-CNN demonstrated an improvement of 2.8\% when compared to baseline CNN consisting of a single grayscale view on an open-source database. Moreover, in comparison with the state-of-the-art residual network (ResNet-50) image classification model, the proposed method performs comparably while being less complex and more efficient during training. The result of classification-based fingerprint identification has shown that the search space is reduced by over 50\% without degradation of identification accuracies.}
}

@inproceedings{lincoln45983,
       booktitle = {Towards Autonomous Robotic Systems Conference (TAROS)},
           month = {September},
           title = {A Study on Dense and Sparse (Visual) Rewards in Robot Policy Learning},
          author = {Abdalkarim Mohtasib and Gerhard Neumann and Heriberto Cuayahuitl},
       publisher = {University of Lincoln},
            year = {2021},
        keywords = {ARRAY(0x5568fbbc4ef0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45983/},
        abstract = {Deep Reinforcement Learning (DRL) is a promising approach for teaching robots new behaviour. However, one of its main limitations is the need for carefully hand-coded reward signals by an expert. We argue that it is crucial to automate the reward learning process so that new skills can be taught to robots by their users. To address such automation, we consider task success classifiers using visual observations to estimate the rewards in terms of task success. In this work, we study the performance of multiple state-of-the-art deep reinforcement learning algorithms under different types of reward: Dense, Sparse, Visual Dense, and Visual Sparse rewards. Our experiments in various simulation tasks (Pendulum, Reacher, Pusher, and Fetch Reach) show that while DRL agents can learn successful behaviours using visual rewards when the goal targets are distinguishable, their performance may decrease if the task goal is not clearly visible. Our results also show that visual dense rewards are more successful than visual sparse rewards and that there is no single best algorithm for all tasks.}
}

@article{lincoln46543,
          volume = {8},
          number = {9},
           month = {September},
          author = {Stefan Sarkadi and Alex Rutherford and Peter McBurney and Simon Parsons and Iyad Rahwan},
           title = {The Evolution of Deception},
       publisher = {Royal Society},
            year = {2021},
         journal = {Royal Society Open Science},
             doi = {10.1098/rsos.201032},
        keywords = {ARRAY(0x5568fbbc4c10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46543/},
        abstract = {Deception plays a critical role in the dissemination of information, and has important consequences on the functioning of cultural, market-based and democratic institutions. Deception has been widely studied within the fields of philosophy, psychology, economics and political science. Yet, we still lack an understanding of how deception emerges in a society under competitive (evolutionary) pressures. This paper begins to fill this gap by bridging evolutionary models of social good--public goods games (PGGs)--with ideas from Interpersonal Deception Theory and Truth-Default Theory. This provides a well-founded analysis of the growth of deception in societies and the effectiveness of several approaches to reducing deception. Assuming that knowledge is a public good, we use extensive simulation studies to explore (i) how deception impacts the sharing and dissemination of knowledge in societies over time, (ii) how different types of knowledge sharing societies are affected by deception, and (iii) what type of policing and regulation is needed to reduce the negative effects of deception in knowledge sharing. Our results indicate that cooperation in knowledge sharing can be re-established in systems by introducing institutions that investigate and regulate both defection and deception using a decentralised case-by-case strategy. This provides evidence for the adoption of methods for reducing the use of deception in the world around us in order to avoid a Tragedy of The Digital Commons.}
}

@inproceedings{lincoln52079,
       booktitle = {IROS},
           month = {September},
           title = {Towards autonomous area inspection with a bio-inspired underwater legged robot},
          author = {Giacomo Picardi and Rossana Lovecchio and Marcello Calisti},
       publisher = {IEEE/RSJ},
            year = {2021},
             doi = {10.1109/IROS51168.2021.9636316},
        keywords = {ARRAY(0x5568fbbc4f08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52079/},
        abstract = {Recently, a new category of bio-inspired legged robots moving directly on the seabed have been proposed to complement the abilities of traditional underwater vehicles and to enhance manipulation and sampling tasks. So far, only tele-operated use of underwater legged robots has been reported and in this paper we attempt to fill such gap by presenting the first step towards autonomous area inspection. First, we present a 3 dimensional single-legged model for underwater hopping locomotion and derive a path following control strategy. Later, we adapt such control strategy to an underwater hexapod robot SILVER2 on the robotic simulator Webots. Finally, we simulate a full autonomous mission consisting in the inspection of an area over a pre-defined path, target recognition, transition to a safer gait and target approach. Our results show the feasibility of the approach and encourage the implementation of the presented control strategy on the robot SILVER2.}
}

@inproceedings{lincoln45570,
       booktitle = {Taros 2021},
           month = {September},
           title = {Design and Characterisation of a Variable-Stiffness Soft Actuator Based on Tendon Twisting},
          author = {William King and Luke Pooley and Philip Johnson and Khaled Elgeneidy},
            year = {2021},
        keywords = {ARRAY(0x5568fbbc4f68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45570/},
        abstract = {The field of soft robotics aims to address the challenges faced by traditional rigid robots in less structured and dynamic environments that require more adaptive interactions. Taking inspiration from biological organisms? such as octopus tentacles and elephant trunks, soft robots commonly use elastic materials and novel actuation methods to mimic the continuous deformation of their mostly soft bodies. While current robotic manipulators, such as those used in the DaVinci surgical robot, have seen use in precise minimally invasive surgeries applications, the capability of soft robotics to provide a greater degree of flexibility and inherently safe interactions shows great promise that motivates further study. Nevertheless, introducing softness consequently opens new challenges in achieving accurate positional control and sufficient force generation often required for manipulation tasks. In this paper, the feasibility of a stiffening mechanism based on tendon-twisting is investigated, as an alternative stiffening mechanism for soft actuators that can be easily scaled as needed based on tendon size, material properties, and arrangements, while offering simple means of controlling a gradual increase in stiffening during operation.}
}

@article{lincoln45212,
          volume = {9},
           month = {August},
          author = {Amir Ghalamzan Esfahani and Kiyanoush Nazari Sasikolomi and Hamidreza Hashempour and Fangxun Zhong},
           title = {Deep-LfD: Deep robot learning from demonstrations},
       publisher = {Elsevier},
            year = {2021},
         journal = {Software Impacts},
             doi = {10.1016/j.simpa.2021.100087},
           pages = {100087},
        keywords = {ARRAY(0x5568fba94340)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45212/},
        abstract = {Like other robot learning from demonstration (LfD) approaches, deep-LfD builds a task model from sample demonstrations. However, unlike conventional LfD, the deep-LfD model learns the relation between high dimensional visual sensory information and robot trajectory/path. This paper presents a dataset of successful needle insertion by da Vinci Research Kit into deformable objects based on which several deep-LfD models are built as a benchmark of models learning robot controller for the needle insertion task.}
}

@incollection{lincoln46316,
          number = {2354},
           month = {August},
          author = {Junfeng Gao and Jesper Cairo Westergaard and Erik Alexandersson},
          series = {Methods in Molecular Biology},
       booktitle = {Solanum tuberosum},
          editor = {David Dobnik and Kristina Gruden and {\v Z}iva Ram{\v s}ak and Anna Coll},
           title = {Computer Vision and Less Complex Image Analyses to Monitor Potato Traits in Fields},
         address = {New York},
       publisher = {Springer},
            year = {2021},
             doi = {10.1007/978-1-0716-1609-3\_13},
           pages = {273--299},
        keywords = {ARRAY(0x5568fba93dd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46316/},
        abstract = {Field phenotyping of crops has recently gained considerable attention leading to the development of new protocols for recording plant traits of interest. Phenotyping in field conditions can be performed by various cameras, sensors and imaging platforms. In this chapter, practical aspects as well as advantages and disadvantages of above-ground phenotyping platforms are highlighted with a focus on drone-based imaging and relevant image analysis for field conditions. It includes useful planning tips for experimental design as well as protocols, sources, and tools for image acquisition, pre-processing, feature extraction and machine learning highlighting the possibilities with computer vision. Several open and free resources are given to speed up data analysis for biologists.

This chapter targets professionals and researchers with limited computational background performing or wishing to perform phenotyping of field crops, especially with a drone-based platform. The advice and methods described focus on potato but can mostly be used for field phenotyping of any crops.}
}

@article{lincoln44192,
          volume = {8},
          number = {16},
           month = {August},
          author = {Fan Yang and Lei Shu and Yuli Yang and Guangjie Han and Simon Pearson and Kailiang Li},
           title = {Optimal Deployment of Solar Insecticidal Lamps over Constrained Locations in Mixed-Crop Farmlands},
       publisher = {IEEE},
            year = {2021},
         journal = {IEEE Internet of Things Journal},
             doi = {10.1109/JIOT.2021.3064043},
           pages = {13095--13114},
        keywords = {ARRAY(0x5568fba93d10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44192/},
        abstract = {Solar Insecticidal Lamps (SILs) play a vital role in green prevention and control of pests. By embedding SILs in Wireless Sensor Networks (WSNs), we establish a novel agricultural Internet of Things (IoT), referred to as the SILIoTs. In practice, the deployment of SIL nodes is determined by the geographical characteristics of an actual farmland, the constraints on the locations of SIL nodes, and the radio-wave propagation in complex agricultural environment. In this paper, we mainly focus on the constrained SIL Deployment Problem (cSILDP) in a mixed-crop farmland, where the locations used to deploy SIL nodes are a limited set of candidates located on the ridges. We formulate the cSILDP in this scenario as a Connected Set Cover (CSC) problem, and propose a Hole Aware Node Deployment Method (HANDM) based on the greedy algorithm to solve the constrained optimization problem. The HANDM is a two-phase method. In the first phase, a novel deployment strategy is utilised to guarantee only a single coverage hole in each iteration, based on which a set of suboptimal locations is found for the deployment of SIL nodes. In the second phase, according to the operations of deletion and fusion, the optimal locations are obtained to meet the requirements on complete coverage and connectivity. Experimental results show that our proposed method achieves better performance than the peer algorithms, specifically in terms of deployment cost.}
}

@article{lincoln46566,
           month = {August},
           title = {Argumentation Schemes for Clinical Decision Support},
          author = {Isabel Sassoon and Nadin Kokciyan and Sanjay Modgil and Simon Parsons},
       publisher = {IOS Press},
            year = {2021},
             doi = {10.3233/AAC-200550},
         journal = {Argument \& Computation},
        keywords = {ARRAY(0x5568fbbb1bd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46566/},
        abstract = {This paper demonstrates how argumentation schemes can be used in decision support systems that help clinicians in making treatment decisions. The work builds on the use of computational argumentation, a rigorous approach to reasoning with complex data that places strong emphasis on being able to justify and explain the decisions that are recommended. The main contribution of the paper is to present a novel set of specialised argumentation schemes that can be used in the context of a clinical decision support system to assist in reasoning about what treatments to offer. These schemes provide a mechanism for capturing clinical reasoning in such a way that it can be handled by the formal reasoning mechanisms of formal argumentation. The paper describes how the integration between argumentation schemes and formal argumentation may be carried out, sketches how this is achieved by an implementation that we have created, and illustrates the overall process on a small set of case studies.}
}

@article{lincoln46873,
          volume = {8},
           month = {August},
          author = {Qinbing Fu and Xuelong Sun and Tian liu and Cheng Hu and Shigang Yue},
           title = {Robustness of Bio-Inspired Visual Systems for Collision Prediction in Critical Robot Traffic},
       publisher = {Frontiers Media},
            year = {2021},
         journal = {Frontiers in Robotics and AI},
             doi = {doi:10.3389/frobt.2021.529872},
           pages = {529872},
        keywords = {ARRAY(0x5568fba939c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46873/},
        abstract = {Collision prevention sets a major research and development obstacle for intelligent robots
and vehicles. This paper investigates the robustness of two state-of-the-art neural network
models inspired by the locust?s LGMD-1 and LGMD-2 visual pathways as fast and low-energy collision alert systems in critical scenarios. Although both the neural circuits have
been studied and modelled intensively, their capability and robustness against real-time
critical traffic scenarios where real-physical crashes will happen have never been
systematically investigated due to difficulty and high price in replicating risky traffic with
many crash occurrences. To close this gap, we apply a recently published robotic platform
to test the LGMDs inspired visual systems in physical implementation of critical traffic
scenarios at low cost and high flexibility. The proposed visual systems are applied as the
only collision sensing modality in each micro-mobile robot to conduct avoidance by abrupt
braking. The simulated traffic resembles on-road sections including the intersection and
highway scenes wherein the roadmaps are rendered by coloured, artificial pheromones
upon a wide LCD screen acting as the ground of an arena. The robots with light sensors at
bottom can recognise the lanes and signals, tightly follow paths. The emphasis herein is
laid on corroborating the robustness of LGMDs neural systems model in different dynamic
robot scenes to timely alert potential crashes. This study well complements previous
experimentation on such bio-inspired computations for collision prediction in more critical
physical scenarios, and for the first time demonstrates the robustness of LGMDs inspired
visual systems in critical traffic towards a reliable collision alert system under constrained
computation power. This paper also exhibits a novel, tractable, and affordable robotic
approach to evaluate online visual systems in dynamic scenes.}
}

@article{lincoln47264,
          volume = {2},
           month = {August},
          author = {Steve Brewer and Simon Pearson and Roger Maull and Phil Godsiff and Jeremy G. Frey and Andrea Zisman and Gerard Parr and Andrew McMillan and Sarah Cameron and Hannah Blackmore and Louise Manning and Luc Bidaut},
           title = {A trust framework for digital food systems.},
       publisher = {Nature Research},
            year = {2021},
         journal = {Nature Food},
             doi = {10.1038/s43016-021-00346-1},
           pages = {543--545},
        keywords = {ARRAY(0x5568fbb6c000)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47264/},
        abstract = {The full potential for a digitally transformed food system has not yet been realised - or indeed imagined. Data flows across, and within, vast but largely decentralised and tiered supply chain networks. Data defines internal inputs, bi-directional flows of food, information and finance within the supply chain, and intended and extraneous outputs. Data exchanges can orchestrate critical network dependencies, define standards and underpin food safety. Poore and Nemecek1 hypothesised that digital technologies could drive system transformation for the public good by empowering personalised selection of foods with, for example, lower intrinsic greenhouse gas emissions. Here, we contend that the full potential of a digitally transformed food system can only be realised if permissioned and trusted data can flow seemlessly through complex, multi-lateral supply chains, effectively from farms through to the consumer.}
}

@incollection{lincoln48565,
       booktitle = {Handbook of Formal Argumentation, Volume 2},
          editor = {Dov Gabbay and Massimiliano Giacomin and Guillermo R. Simari and Matthias Thimm},
           month = {August},
           title = {Joint Attacks and Accrual in Argumentation Frameworks},
          author = {Antonis Bikakis and Andrea Cohen and Wolfgang Dvorak and Giorgos Flouris and Simon Parsons},
       publisher = {College Publications},
            year = {2021},
        keywords = {ARRAY(0x5568fba94040)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48565/},
        abstract = {While modelling arguments, it is often useful to represent ``joint attacks'', i.e., cases where multiple arguments jointly attack another (note that this is different from the case where multiple arguments attack another in isolation). Based on this remark, the notion of joint attacks has been proposed as a useful extension of classical Abstract Argumentation Frameworks, and has been shown to constitute a genuine extension in terms of expressive power.
In this chapter, we review various works considering the notion of joint attacks from various perspectives, including abstract and structured frameworks. Moreover, we present results detailing the relation among frameworks with joint attacks and classical argumentation frameworks, computational aspects, and applications of joint attacks. 
Last but not least, we propose a roadmap for future research on the subject, identifying gaps in current research and important research directions.}
}

@incollection{lincoln48566,
       booktitle = {Handbook of Formal Argumentation, Volume 2},
          editor = {Dov Gabby and Massimiliano Giacomin and Guillermo R. Simari and Matthias Thimm},
           month = {August},
           title = {Argumentation-based Dialogue},
          author = {Elizabeth Black and Nicolas Maudet and Simon Parsons},
       publisher = {College Publications},
            year = {2021},
        keywords = {ARRAY(0x5568fba8f5f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48566/},
        abstract = {Dialogue is fundamental to argumentation, providing a dialectical basis for establishing which arguments are acceptable.
Argumentation can also be used as the basis for dialogue. In such ``argumentation-based'' dialogues, participants take part in an exchange of arguments, and the mechanisms of argumentation are used to establish what participants take to be acceptable at the end of the exchange. This chapter considers such dialogues, discussing the elements that are required in order to carry out argumentation-based dialogues, giving examples, and discussing open issues.}
}

@book{lincoln50088,
           month = {July},
          author = {Fady Alnajjar and Christoph Bartneck and Paul Baxter and Tony Belpaeme and Massimiliano L. Cappuccio and Cinzia Di Dio and Friederike Eyssel and J{\"u}rgen Handke and Omar Mubin and Mohammad Obaid and Natalia Reich-Stiebert},
       booktitle = {Robots in Education},
         address = {New York},
           title = {Robots in Education: An Introduction to High-Tech Social Agents, Intelligent Tutors, and Curricular Tools},
       publisher = {Routledge},
             doi = {10.4324/9781003142706},
            year = {2021},
        keywords = {ARRAY(0x5568fb670400)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50088/},
        abstract = {Robots in Education is an accessible introduction to the use of robotics in formal learning, encompassing pedagogical and psychological theories as well as implementation in curricula. Today, a variety of communities across education are increasingly using robots as general classroom tutors, tools in STEM projects, and subjects of study. This volume explores how the unique physical and social-interactive capabilities of educational robots can generate bonds with students while freeing instructors to focus on their individualized approaches to teaching and learning. Authored by a uniquely interdisciplinary team of scholars, the book covers the basics of robotics and their supporting technologies; attitudes toward and ethical implications of robots in learning; research methods relevant to extending our knowledge of the field; and more.}
}

@article{lincoln46666,
           month = {July},
           title = {Complexity Space Modelling for Industrial Manufacturing 
Systems},
          author = {Lucas Freund and Salah Al-Majeed and Alan Millard},
       publisher = {University of Bahrain},
            year = {2021},
         journal = {International Journal of Computing and Digital Systems},
        keywords = {ARRAY(0x5568fbb52380)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46666/},
        abstract = {The static and dynamic complexity of an industrial engineered system are integrated in a complexity space modelling approach, where information complexity boundaries expand over time and serve as an indicator for system instability in a static complexity space. In a first step, model-based static and dynamic conceptions of complexity are introduced and described. The necessary capabilities are theoretically demonstrated, alongside a set of assumptions concerning the behavior of industrial system complexity and its functions as a core foundation for the proposed complexity space model. In a second step, the successful application of the proposed modelling approach on a real-world industrial system is presented. Case study results are briefly presented and discussed as a first proof of concept for the general applicability of the proposed modelling approach for current and future industrial systems. In a final step a short research outlook is provided.}
}

@inproceedings{lincoln45328,
       booktitle = {International Conference on Computer Music},
           month = {July},
           title = {MusicHastie: field-based hierarchical music representation},
          author = {Charles Fox},
       publisher = {ICMC},
            year = {2021},
        keywords = {ARRAY(0x5568fba93ad0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45328/},
        abstract = {MusicHastie is a hierarchical music representation language designed for use in human and automated composition and for human and machine learning based music study and analysis. It represents and manipulates musical structure in a semantic form based on concepts from Schenkerian analysis, western European art music and popular music notations, electronica and some non-western forms such as modes and ragas. The representation is designed to model one form of musical perception by human musicians so can be used to aid human understanding and memorization of popular music pieces. An open source MusicHastie to MIDI compiler is released as part of this publication, now including capabilities for electronica MIDI control commands to model structures such as filter sweeps in addition to keys, chords, rhythms, patterns, and melodies.}
}

@inproceedings{lincoln45327,
       booktitle = {International Conference on Computer Music},
           month = {July},
           title = {Open source hardware automated guitar player},
          author = {Andrew Henry and Charles Fox},
       publisher = {ICMC},
            year = {2021},
        keywords = {ARRAY(0x5568fba938f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45327/},
        abstract = {We present the first open source hardware (OSH) design and build of a physical robotic automated guitar player. Users? own instruments being different shapes and sizes, the system is designed to be used and/or modified to physically attach to a wide range of instruments. Design objectives include ease and low cost of build. Automation is split into three modules: the left-hand fretting, right-hand string picking, and right hand palm muting. Automation is performed using cheap electric linear solenoids. Software APIs are designed and implemented for both low level actuator control and high level music performance.}
}

@inproceedings{lincoln45559,
       booktitle = {International Joint Conference on Neural Networks (IJCNN)},
           month = {July},
           title = {Neural Task Success Classifiers for Robotic Manipulation from Few Real Demonstrations},
          author = {Abdalkarim Mohtasib and Amir Ghalamzan Esfahani and Nicola Bellotto and Heriberto Cuayahuitl},
       publisher = {IEEE},
            year = {2021},
        keywords = {ARRAY(0x5568fbbb80e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45559/},
        abstract = {Robots learning a new manipulation task from a small amount of demonstrations are increasingly demanded in different workspaces. A classifier model assessing the quality of actions can predict the successful completion of a task, which can be used by intelligent agents for action-selection. This paper presents a novel classifier that learns to classify task completion only from a few demonstrations. We carry out a comprehensive comparison of different neural classifiers, e.g. fully connected-based, fully convolutional-based, sequence2sequence-based, and domain adaptation-based classification. We also present a new dataset including five robot manipulation tasks, which is publicly available. We compared the performances of our novel classifier and the existing models using our dataset and the MIME dataset. The results suggest domain adaptation and timing-based features improve success prediction. Our novel model, i.e. fully convolutional neural network with domain adaptation and timing features, achieves an average classification accuracy of 97.3\% and 95.5\% across tasks in both datasets whereas state-of-the-art classifiers without domain adaptation and timing-features only achieve 82.4\% and 90.3\%, respectively.}
}

@inproceedings{lincoln46542,
           month = {July},
          author = {Dan Dai and Junfeng Gao and Simon Parsons and Elizabeth Sklar},
       booktitle = {4th UK-RAS Conference},
           title = {Small datasets for fruit detection with transfer learning},
       publisher = {UK-RAS},
             doi = {10.31256/Nf6Uh8Q},
           pages = {5--6},
            year = {2021},
        keywords = {ARRAY(0x5568fb9b5a60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46542/},
        abstract = {A common approach to the problem of fruit detection in images is to design a deep learning network and train a model to locate objects, using bounding boxes to identify regions containing fruit. However, this requires sufficient data and presents challenges for small datasets. Transfer learning, which acquires knowledge from a source domain and brings that to a new target domain, can produce improved performance in the target domain. The work discussed in this paper shows the application of transfer learning for fruit detection with small datasets and presents analysis between the number of training images in source and target domains.}
}

@inproceedings{lincoln46537,
       booktitle = {4th UK-RAS Conference},
           month = {July},
           title = {Assessing the probability of human injury during UV-C treatment of crops by robots},
          author = {Leonardo Guevara and Muhammad Khalid and Marc Hanheide and Simon Parsons},
       publisher = {UK-RAS},
            year = {2021},
             doi = {10.31256/Pj6Cz2L},
        keywords = {ARRAY(0x5568fbaee798)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46537/},
        abstract = {This paper describes a hazard analysis for an agricultural scenario where a crop is treated by a robot using UV-C light. 
Although human-robot interactions are not expected, it may be the case that unauthorized people approach the robot while it is operating. These potential human-robot interactions have been identified and modelled as Markov Decision Processes (MDP) and tested in the model checking tool PRISM.}
}

@inproceedings{lincoln46541,
       booktitle = {4th UK-RAS Conference},
           month = {July},
           title = {Assuring autonomy of robots in soft fruit production},
          author = {Muhammad Khalid and Leonardo Guevara and Marc Hanheide and Simon Parsons},
       publisher = {UK-RAS},
            year = {2021},
             doi = {10.31256/Ml6Ik7G},
        keywords = {ARRAY(0x5568fbaee7c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46541/},
        abstract = {This paper describes our work to assure safe autonomy in soft fruit production. The first step was hazard analysis, where all the possible hazards in representative scenarios were identified. Following this analysis, a three-layer safety architecture was identified that will minimise the occurrence of the identified hazards. Most of the hazards are minimised by upper layers, while unavoidable hazards are handled using emergency stops. In parallel, we are using probabilistic model checking to check the probability of a hazard's occurrence. The results from the model checking will be used to improve safety system architecture.}
}

@article{lincoln46522,
          volume = {21},
          number = {13},
           month = {July},
          author = {Liyun Gong and Miao Yu and Shouyong Jiang and Vassilis Cutsuridis and Simon Pearson},
           title = {Deep Learning Based Prediction on Greenhouse Crop Yield Combined TCN and RNN},
       publisher = {MDPI},
            year = {2021},
         journal = {Sensors},
             doi = {10.3390/s21134537},
           pages = {4537},
        keywords = {ARRAY(0x5568fbaee7f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46522/},
        abstract = {Currently, greenhouses are widely applied for plant growth, and environmental parameters can also be controlled in the modern greenhouse to guarantee the maximum crop yield. In order to optimally control greenhouses? environmental parameters, one indispensable requirement is to accurately predict crop yields based on given environmental parameter settings. In addition, crop yield forecasting in greenhouses plays an important role in greenhouse farming planning and management, which allows cultivators and farmers to utilize the yield prediction results to make knowledgeable management and financial decisions. It is thus important to accurately predict the crop yield in a greenhouse considering the benefits that can be brought by accurate greenhouse crop yield prediction. In this work, we have developed a new greenhouse crop yield prediction technique, by combining two state-of-the-arts networks for temporal sequence processing{--}temporal convolutional network (TCN) and recurrent neural network (RNN). Comprehensive evaluations of the proposed algorithm have been made on multiple datasets obtained from multiple real greenhouse sites for tomato growing. Based on a statistical analysis of the root mean square errors (RMSEs) between the predicted and actual crop yields, it is shown that the proposed approach achieves more accurate yield prediction performance than both traditional machine learning methods and other classical deep neural networks. Moreover, the experimental study also shows that the historical yield information is the most important factor for accurately predicting future crop yields.}
}

@article{lincoln47017,
          volume = {8},
          number = {6},
           month = {June},
          author = {Hamid Isakhani and Caihua Xiong and Wenbin Chen and Shigang Yue},
           title = {Towards locust-inspired gliding wing prototypes for micro aerial vehicle applications},
       publisher = {The Royal Society},
            year = {2021},
         journal = {Royal Society Open Science},
             doi = {10.1098/rsos.202253},
           pages = {202253},
        keywords = {ARRAY(0x5568fbaee828)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47017/},
        abstract = {In aviation, gliding is the most economical mode of flight explicitly appreciated by natural fliers. They achieve it by high-performance wing structures evolved over millions of years in nature. Among other prehistoric beings, locust (Schistocerca gregaria) is a perfect example of such natural glider capable of endured transatlantic flights that could inspire a practical solution to achieve similar capabilities on micro aerial vehicles. This study investigates the effects of haemolymph on the flexibility of several flying insect wings further showcasing the superior structural performance of locusts.
However, biomimicry of such aerodynamic and structural properties is hindered by the limitations of modern as well as conventional fabrication technologies in terms of availability and precision, respectively. Therefore, here we adopt finite element analysis (FEA) to investigate the manufacturing-worthiness of a 3D digitally reconstructed locust tandem wing, and propose novel combinations of economical and readily-available manufacturing methods to develop the model into prototypes that are structurally similar to their counterparts in nature while maintaining the optimum gliding ratio previously obtained in the aerodynamic simulations. Latter is evaluated in the future study and the former is assessed here via an experimental analysis of the flexural stiffness and maximum deformation rate.
Ultimately, a comparative study of the mechanical properties reveals the feasibility of each prototype for gliding micro aerial vehicle applications.}
}

@article{lincoln47917,
           month = {June},
           title = {AgroSupportAnalytics: A Cloud-based Complaints Management and Decision Support System for Sustainable Farming in Egypt},
          author = {Kamran Munir and Mubeen Ghafoor and Mohamed Khafagy and Hisham Ihshaish},
       publisher = {Elsevier},
            year = {2021},
             doi = {10.1016/j.eij.2021.06.002},
         journal = {Egyptian Informatics Journal},
        keywords = {ARRAY(0x5568fb9b5aa8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47917/},
        abstract = {Sustainable Farming requires up-to-date advice on crop diseases, patterns, and adequate prevention actions to face developing circumstances. Currently, in developing countries like Egypt, farmers? access to such information is extremely limited due to the agriculture support being either not available, inconsistent, or unreliable. The presented Cloud-based Complaints Management and Decision Support System for Sustainable Farming in Egypt, named as AgroSupportAnalytics, aims to resolve the problem of both the lack of support and advice for farmers, and the inconsistencies in doing so by current manual approach provided by agricultural experts. Key contribution is the development of an automated complaint management and decision support strategy, on the basis of extensive research on requirement analysis tailored for Egypt. The solution is grounded on the application of knowledge discovery and analysis on agricultural data and farmers? complaints, deployed on a Cloud platform, to provide farming stakeholders in Egypt with timely and suitable support. This paper presents the overall system architectural framework along with the information and storage services, which have been based on the requirements specifications phases of the project along with the historical data sets of past 10�year of farmers complaints and enquiries in Egypt.}
}

@article{lincoln47555,
          volume = {21},
          number = {3},
           month = {June},
          author = {Mohammed Al-Khafajiy and Safa Otoum and Thar Baker and Muhammad Asim and Zakaria Maamar and Moayad Aloqaily and Mark Taylor and Martin Randles},
           title = {Intelligent Control and Security of Fog Resources in Healthcare Systems via a Cognitive Fog Model},
       publisher = {ACM},
            year = {2021},
         journal = {ACM Transactions on Internet Technology},
             doi = {10.1145/3382770},
           pages = {1--23},
        keywords = {ARRAY(0x5568fba939e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47555/},
        abstract = {There have been significant advances in the field of Internet of Things (IoT) recently, which have not always considered security or data security concerns: A high degree of security is required when considering the sharing of medical data over networks. In most IoT-based systems, especially those within smart-homes and smart-cities, there is a bridging point (fog computing) between a sensor network and the Internet which often just performs basic functions such as translating between the protocols used in the Internet and sensor networks, as well as small amounts of data processing. The fog nodes can have useful knowledge and potential for constructive security and control over both the sensor network and the data transmitted over the Internet. Smart healthcare services utilise such networks of IoT systems. It is therefore vital that medical data emanating from IoT systems is highly secure, to prevent fraudulent use, whilst maintaining quality of service providing assured, verified and complete data. In this article, we examine the development of a Cognitive Fog (CF) model, for secure, smart healthcare services, that is able to make decisions such as opting-in and opting-out from running processes and invoking new processes when required, and providing security for the operational processes within the fog system. Overall, the proposed ensemble security model performed better in terms of Accuracy Rate, Detection Rate, and a lower False Positive Rate (standard intrusion detection measurements) than three base classifiers (K-NN, DBSCAN, and DT) using a standard security dataset (NSL-KDD).}
}

@article{lincoln44141,
          volume = {138},
          number = {24},
           month = {June},
          author = {Saeed D Mohan and Fred J Davis and Amir Badiee and Paul Hadley and Carrie A Twitchen and Simon Pearson},
           title = {Optical and thermal properties of commercial polymer film,modeling the albedo effect},
       publisher = {Wiley},
            year = {2021},
         journal = {Journal of Applied Polymer Science},
             doi = {10.1002/app.50 581},
           pages = {50581},
        keywords = {ARRAY(0x5568fb967e58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44141/},
        abstract = {Greenhouse cladding materials are an important part of greenhouse design.The cladding material controls the light transmission and distribution over theplants within the greenhouse, thereby exerting a major influence on the over-all yield. Greenhouse claddings are typically translucent materials offeringmore diffusive transmission than reflection; however, the reflective propertiesof the films offer a potential route to increasing the surface albedo of the localenvironment. We model thermal properties by modeling the films based ontheir optical transmissions and reflections. We can use this data to estimatetheir albedo and determine the amount of short wave radiation that will betransmitted/reflected/blocked by the materials and how it can influence thelocal environment.}
}

@article{lincoln45017,
          volume = {57},
          number = {6},
           month = {June},
          author = {Amir Badiee and John R. Wallbank and Jaime Pulido Fentanes and Emily Trill and Peter Scarlet and Yongchao Zhu and Grzegorz Cielniak and Hollie Cooper and James R. Blake and Jonathan G. Evans and Marek Zreda and K{\"o}hli Markus and Simon Pearson},
           title = {Using Additional Moderator to Control the Footprint of a COSMOS Rover for Soil Moisture Measurement},
       publisher = {Wiley},
            year = {2021},
         journal = {Water Resources Research},
             doi = {10.1029/2020WR028478},
           pages = {e2020WR028478},
        keywords = {ARRAY(0x5568fb6d5288)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45017/},
        abstract = {Cosmic Ray Neutron Probes (CRNP) have found application in soil moisture estimation due to their conveniently large ({\ensuremath{>}}100 m) footprints. Here we explore the possibility of using high density polyethylene (HDPE) moderator to limit the field of view, and hence the footprint, of a soil moisture sensor formed of 12 CRNP mounted on to a mobile robotic platform (Thorvald) for better in-field localisation of moisture variation. URANOS neutron scattering simulations are used to show that 5 cm of additional HDPE moderator (used to shield the upper surface and sides of the detector) is sufficient to (i), reduce the footprint of the detector considerably, (ii) approximately double the percentage of neutrons detected from within 5 m of the detector, and (iii), does not affect the shape of the curve used to convert neutron counts into soil moisture. Simulation and rover measurements for a transect crossing between grass and concrete additionally suggest that (iv), soil moisture changes can be sensed over a length scales of tens of meters or less (roughly an order of magnitude smaller than commonly used footprint distances), and (v), the additional moderator does not reduce the detected neutron count rate (and hence increase noise) as much as might be expected given the extent of the additional moderator. The detector with additional HDPE moderator was also used to conduct measurements on a stubble field over three weeks to test the rover system in measuring spatial and temporal soil moisture variation.}
}

@inproceedings{lincoln46574,
           month = {June},
          author = {Tsvetan Zhivkov and Adrian Gomez and Junfeng Gao and Elizabeth Sklar and Simon Parsons},
       booktitle = {EPSRC UK-RAS Network (2021). UKRAS21 Conference: Robotics at home Proceedings},
           title = {The need for speed: How 5G communication can support AI in the field},
       publisher = {UK-RAS},
             doi = {10.31256/On8Hj9U},
           pages = {55--56},
            year = {2021},
        keywords = {ARRAY(0x5568fbb9db28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46574/},
        abstract = {Using AI for agriculture requires the fast transmission and processing of large volumes of data. Cost-effective high speed processing may not be possible on-board agricultural vehicles, and suitably fast transmission may not be possible with older generation wireless communications. In response, the work presented here investigates the use of 5G wireless technology to support the deployment of AI in this context.}
}

@article{lincoln45058,
          volume = {2},
          number = {5},
           month = {May},
          author = {David Christian Rose and Jessica Lyon and Auvikki de Broon and Marc Hanheide and Simon Pearson},
           title = {Responsible Development of Autonomous Robots in Agriculture},
       publisher = {Springer Nature},
            year = {2021},
         journal = {Nature Food},
             doi = {10.1038/s43016-021-00287-9},
           pages = {306--309},
        keywords = {ARRAY(0x5568fb9bdf58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45058/},
        abstract = {Despite the potential contributions of autonomous robots to agricultural sustainability, social, legal and ethical issues threaten adoption.  We discuss how responsible innovation principles can be embedded into the user-centred design of autonomous robots and identify areas for further empirical research.}
}

@article{lincoln46134,
          volume = {21},
          number = {11},
           month = {May},
          author = {Jacopo Aguzzi and Corrado Costa and Marcello Calisti and Valerio Funari and Sergio Stefanni and Roberto Danovaro and Helena Gomes and Fabrizio Vecchi and Lewis Dartnell and Peter Weiss and Kathrin Nowak and Damianos Chatzievangelou and Simone Marini},
           title = {Research Trends and Future Perspectives in Marine Biomimicking Robotics},
            year = {2021},
         journal = {Sensors},
             doi = {10.3390/s21113778},
           pages = {3778},
        keywords = {ARRAY(0x5568fba938d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46134/},
        abstract = {Mechatronic and soft robotics are taking inspiration from the animal kingdom to create new high-performance robots. Here, we focused on marine biomimetic research and used innovative bibliographic statistics tools, to highlight established and emerging knowledge domains. A total of 6980 scientific publications retrieved from the Scopus database (1950?2020), evidencing a sharp research increase in 2003?2004. Clustering analysis of countries collaborations showed two major Asian-North America and European clusters. Three significant areas appeared: (i) energy provision, whose advancement mainly relies on microbial fuel cells, (ii) biomaterials for not yet fully operational soft-robotic solutions; and finally (iii), design and control, chiefly oriented to locomotor designs. In this scenario, marine biomimicking robotics still lacks solutions for the long-lasting energy provision, which presently hinders operation autonomy. In the research environment, identifying natural processes by which living organisms obtain energy is thus urgent to sustain energy-demanding tasks while, at the same time, the natural designs must increasingly inform to optimize energy consumption.}
}

@article{lincoln45569,
          volume = {8},
           month = {May},
          author = {Daniel De Barrie and Manjari Pandya and Harit Pandya and Marc Hanheide and Khaled Elgeneidy},
           title = {A Deep Learning Method for Vision Based Force Prediction of a Soft Fin Ray Gripper Using Simulation Data},
       publisher = {Frontiers Media},
            year = {2021},
         journal = {Frontiers in Robotics and AI},
             doi = {10.3389/frobt.2021.631371},
           pages = {631371},
        keywords = {ARRAY(0x5568fbb5a408)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45569/},
        abstract = {Soft robotic grippers are increasingly desired in applications that involve grasping of complex and deformable objects. However, their flexible nature and non-linear dynamics makes the modelling and control difficult. Numerical techniques such as Finite Element Analysis (FEA) present an accurate way of modelling complex deformations. However, FEA approaches are computationally expensive and consequently challenging to employ for real-time control tasks. Existing analytical techniques simplify the modelling by approximating the deformed gripper geometry. Although this approach is less computationally demanding, it is limited in design scope and can lead to larger estimation errors. In this paper, we present a learning based framework that is able to predict contact forces as well as stress distribution from soft Fin Ray Effect (FRE) finger images in real-time. These images are used to learn internal representations for deformations using a deep neural encoder, which are further decoded to contact forces and stress maps using separate branches. The entire network is jointly learned in an end-to-end fashion. In order to address the challenge of having sufficient labelled data for training, we employ FEA to generate simulated images to supervise our framework. This leads to an accurate prediction, faster inference and availability of large and diverse data for better generalisability. Furthermore, our approach is able to predict a detailed stress distribution that can guide grasp planning, which would be particularly useful for delicate objects. Our proposed approach is validated by comparing the predicted contact forces to the computed ground-truth forces from FEA as well as real force sensor. We rigorously evaluate the performance of our approach under variations in contact point, object material, object shape, viewing angle, and level of occlusion.}
}

@article{lincoln50873,
          volume = {8},
           month = {May},
          author = {Chipp Jansen and Elizabeth Sklar},
           title = {Exploring Co-creative Drawing Workflows},
       publisher = {Frontiers},
         journal = {Frontiers in Robotics and AI},
             doi = {10.3389/frobt.2021.577770},
            year = {2021},
        keywords = {ARRAY(0x5568fba93fe0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50873/},
        abstract = {This article presents the outcomes from a mixed-methods study of drawing practitioners (e.g., professional illustrators, fine artists, and art students) that was conducted in Autumn 2018 as a preliminary investigation for the development of a physical human-AI co-creative drawing system. The aim of the study was to discover possible roles that technology could play in observing, modeling, and possibly assisting an artist with their drawing. The study had three components: a paper survey of artists' drawing practises, technology usage and attitudes, video recorded drawing exercises and a follow-up semi-structured interview which included a co-design discussion on how AI might contribute to their drawing workflow. Key themes identified from the interviews were (1) drawing with physical mediums is a traditional and primary way of creation; (2) artists' views on AI varied, where co-creative AI is preferable to didactic AI; and (3) artists have a critical and skeptical view on the automation of creative work with AI. Participants' input provided the basis for the design and technical specifications of a co-creative drawing prototype, for which details are presented in this article. In addition, lessons learned from conducting the user study are presented with a reflection on future studies with drawing practitioners.}
}

@article{lincoln44566,
          volume = {78},
           month = {April},
          author = {Fanta Camara and Patrick Dickinson and Charles Fox},
           title = {Evaluating Pedestrian Interaction Preferences with a Game Theoretic Autonomous Vehicle in Virtual Reality},
       publisher = {Elsevier},
            year = {2021},
         journal = {Transportation Research Part F},
             doi = {10.1016/j.trf.2021.02.017},
           pages = {410--423},
        keywords = {ARRAY(0x5568fbb6d348)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44566/},
        abstract = {Abstract: Localisation and navigation of autonomous vehicles (AVs) in static environments are now solved
problems, but how to control their interactions with other road users in mixed traffic environments, especially
with pedestrians, remains an open question. Recent work has begun to apply game theory to model and control
AV-pedestrian interactions as they compete for space on the road whilst trying to avoid collisions. But this game
theory model has been developed only in unrealistic lab environments. To improve their realism, this study
empirically examines pedestrian behaviour during road crossing in the presence of approaching autonomous
vehicles in more realistic virtual reality (VR) environments. The autonomous vehicles are controlled using game
theory, and this study seeks to find the best parameters for these controls to produce comfortable interactions
for the pedestrians. In a first experiment, participants? trajectories reveal a more cautious crossing behaviour in
VR than in previous laboratory experiments. In two further experiments, a gradient descent approach is used to
investigate participants? preference for AV driving style. The results show that the majority of participants were
not expecting the AV to stop in some scenarios, and there was no change in their crossing behaviour in two
environments and with different car models suggestive of car and last-mile style vehicles. These results provide
some initial estimates for game theoretic parameters needed by future AVs in their pedestrian interactions and
more generally show how such parameters can be inferred from virtual reality experiments.}
}

@article{lincoln44001,
          volume = {6},
          number = {2},
           month = {April},
          author = {Adrian Salazar Gomez and E Aptoula and Simon Parsons and Simon Bosilj},
           title = {Deep Regression versus Detection for Counting in Robotic Phenotyping},
       publisher = {IEEE},
            year = {2021},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2021.3062586},
           pages = {2902--2907},
        keywords = {ARRAY(0x5568fbb67cd8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44001/},
        abstract = {Work in robotic phenotyping requires computer vision methods that estimate the number of fruit or grains in an image. To decide what to use, we compared three methods for counting fruit and grains, each method representative of a class of approaches from the literature. These are two methods based on density estimation and regression (single and multiple column), and one method based on object detection. We found that when the density of objects in an image is low, the approaches are comparable, but as the density increases, counting by regression becomes steadily more accurate than counting by detection. With more than a hundred objects per image, the error in the count predicted by detection-based methods is up to 5 times higher than when using regression-based ones.}
}

@inproceedings{lincoln45160,
       booktitle = {IX International Strawberry Symposium},
           month = {April},
           title = {The effect of light intensity and duration on yield and quality of everbearer and June-bearer strawberry cultivars in a LED lit multi-tiered vertical growing system},
          author = {K Swann and P Hadley and M. A. Hadley and Simon Pearson and Amir Badiee and C. Twitchen},
            year = {2021},
           pages = {359--366},
             doi = {10.17660/ActaHortic.2021.1309.52},
        keywords = {ARRAY(0x5568fba93d88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45160/},
        abstract = {This study aimed to provide insights into the efficient use of supplementary lighting for strawberry crops produced in a multi-tiered LED lit vertical growing system, ascertaining the optimal light intensity and duration, with comparative energy use and costs. Furthermore, the suitability of a premium everbearer strawberry cultivar with a high yield potential was compared with a standard winter glasshouse June-bearer cultivar currently used for out-of-season production in the UK. Three lighting durations (11, 16 and 22 h) provided by LEDs were combined with two light intensities (344 and 227 ?mol) to give six light treatments on each tier of a three-tiered system to grow the two cultivars. The everbearer showed a higher yield with a higher correlation with increased lighting and a greater proportion of reproductive growth than the Junebearer. Light intensity and duration increased yield with duration also increasing sugar content (?Brix). However, even with yields of over 100 t ha?1 recorded in this study, yields are likely to be insufficient to cover the cost of electricity.}
}

@inproceedings{lincoln47574,
          volume = {226},
           month = {April},
          author = {Zakaria Maamar and Mohammed Al-Khafajiy and Murtada Dohan},
       booktitle = {Advanced Information Networking and Applications},
           title = {An IoT Application Business-Model on Top of Cloud and Fog Nodes},
       publisher = {Springer},
            year = {2021},
         journal = {AINA 2021: Advanced Information Networking and Applications},
             doi = {10.1007/978-3-030-75075-6\_14},
           pages = {174--186},
        keywords = {ARRAY(0x5568fb674a00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47574/},
        abstract = {This paper discusses the design of a business model dedicated for IoT applications that would be deployed on top of cloud and fog resources. This business model features 2 constructs, flow (specialized into data and collaboration) and placement (specialized into processing and storage). On the one hand, the flow construct is about who sends what and to whom, who collaborates with whom, and what restrictions exist on what to send, to whom to send, and with whom to collaborate. On the other hand, the placement construct is about what and how to fragment, where to store, and what restrictions exist on what and how to fragment, and where to store. The paper also discusses the development of a system built-upon a deep learning model that recommends how the different flows and placements should be formed. These recommendations consider the technical capabilities of cloud and fog resources as well as the networking topology connecting these resources to things.}
}

@article{lincoln43748,
          volume = {433},
           month = {April},
          author = {Nina Dethlefs and Annika Schoene and Heriberto Cuayahuitl},
           title = {A Divide-and-Conquer Approach to Neural Natural Language Generation from Structured Data},
       publisher = {Elsevier},
            year = {2021},
         journal = {Neurocomputing},
             doi = {10.1016/j.neucom.2020.12.083},
           pages = {300--309},
        keywords = {ARRAY(0x5568fba940b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43748/},
        abstract = {Current approaches that generate text from linked data for complex real-world domains can face problems including rich and sparse vocabularies as well as learning from examples of long varied sequences. In this article, we propose a novel divide-and-conquer approach that automatically induces a hierarchy of ?generation spaces? from a dataset of semantic concepts and texts. Generation spaces are based on a notion of similarity of partial knowledge graphs that represent the domain and feed into a hierarchy of sequence-to-sequence or memory-to-sequence learners for concept-to-text generation. An advantage of our approach is that learning models are exposed to the most relevant examples during training which can avoid bias towards majority samples. We evaluate our approach on two common benchmark datasets and compare our hierarchical approach against a flat learning setup. We also conduct a comparison between sequence-to-sequence and memory-to-sequence learning models. Experiments show that our hierarchical approach overcomes issues of data sparsity and learns robust lexico-syntactic patterns, consistently outperforming flat baselines and previous work by up to 30\%. We also find that while memory-to-sequence models can outperform sequence-to-sequence models in some cases, the latter are generally more stable in their performance and represent a safer overall choice.}
}

@article{lincoln44628,
          volume = {8},
          number = {4},
           month = {April},
          author = {T. G. Thuruthel and G. Picardi and F. Iida and C. Laschi and M. Calisti},
           title = {Learning to stop: a unifying principle for legged locomotion in varying environments},
       publisher = {The Royal Society},
            year = {2021},
         journal = {Royal Society Open Science},
             doi = {10.1098/rsos.210223},
        keywords = {ARRAY(0x5568fbbc1b38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44628/},
        abstract = {Evolutionary studies have unequivocally proven the transition of living organisms from water to land. Consequently, it can be deduced that locomotion strategies must have evolved from one environment to the other. However, the mechanism by which this transition happened and its implications on bio-mechanical studies and robotics research have not been explored in detail. This paper presents a unifying control strategy for locomotion in varying environments based on the principle of ?learning to stop?. Using a common reinforcement learning framework, deep deterministic policy gradient, we show that our proposed learning strategy facilitates a fast and safe methodology for transferring learned controllers from the facile water environment to the harsh land environment. Our results not only propose a plausible mechanism for safe and quick transition of locomotion strategies from a water to land environment but also provide a novel alternative for safer and faster training of robots.}
}

@inproceedings{lincoln47575,
           month = {March},
          author = {Zakaria Maamar and Mohammed Al-Khafajiy},
       booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
           title = {Cloud-edge coupling to mitigate execution failures},
       publisher = {Association for Computing Machinery},
             doi = {10.1145/3412841.3442334},
           pages = {711--718},
            year = {2021},
        keywords = {ARRAY(0x5568fba940d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47575/},
        abstract = {This paper examines the doability of cloud-edge coupling to mitigate execution failures and hence, achieve business process continuity. These failures are the result of disruptions that impact the cycles of consuming cloud resources and/or edge resources. Cloud/Edge resources are subject to restrictions like limitedness and non-shareability that increase the complexity of resuming execution operations to the extent that some of these operations could be halted, which means failures. To mitigate failures, cloud and edge resources are synchronized using messages allowing proper consumption of these resources. A Microsoft Azure-based testbed simulating cloud-edge coupling is also presented in the paper.}
}

@article{lincoln52080,
          volume = {591},
           month = {March},
          author = {Cecilia Laschi and Marcello Calisti},
           title = {Soft robot reaches the deepest part of the ocean},
       publisher = {Nature Publishing Group},
            year = {2021},
         journal = {Nature},
             doi = {10.1038/d41586-021-00489-y},
           pages = {35--36},
        keywords = {ARRAY(0x5568fbb4dcb0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52080/},
        abstract = {A self-powered robot inspired by a fish can survive the extreme pressures at the bottom of the ocean?s deepest trench, thanks to its soft body and distributed electronic system {--} and might enable exploration of the uncharted ocean.}
}

@article{lincoln43642,
          volume = {214},
           month = {February},
          author = {Junfeng Gao and Jesper Cairo Westergaard and Ea H{\o}egh Riis Sundmark and Merethe Bagge and Erland Liljeroth and Erik Alexandersson},
           title = {Automatic late blight lesion recognition and severity quantification based on field imagery of diverse potato genotypes by deep learning},
       publisher = {Elsevier},
            year = {2021},
         journal = {Knowledge-Based Systems},
             doi = {10.1016/j.knosys.2020.106723},
           pages = {106723},
        keywords = {ARRAY(0x5568fba93ef0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43642/},
        abstract = {The plant pathogen Phytophthora infestans causes the severe disease late blight in potato, which can result in huge yield loss for potato production. Automatic and accurate disease lesion segmentation enables fast evaluation of disease severity and assessment of disease progress. In tasks requiring computer vision, deep learning has recently gained tremendous success for image classification, object detection and semantic segmentation. To test whether we could extract late blight lesions from unstructured field environments based on high-resolution visual field images and deep learning algorithms, we collected{$\sim$}500 field RGB images in a set of diverse potato genotypes with different disease severity (0\%?70\%), resulting in 2100 cropped images. 1600 of these cropped images were used as the dataset for training deep neural networks and 250 cropped images were randomly selected as the validation dataset. Finally, the developed model was tested on the remaining 250 cropped images. The results show that the values for intersection over union (IoU) of the classes background (leaf and soil) and disease lesion in the test dataset were 0.996 and 0.386, respectively. Furthermore, we established a linear relationship (R2=0.655) between manual visual scores of late blight and the number of lesions detected by deep learning at the canopy level. We also showed that imbalance weights of lesion and background classes improved segmentation performance, and that fused masks based on the majority voting of the multiple masks enhanced the correlation with the visual disease scores. This study demonstrates the feasibility of using deep learning algorithms for disease lesion segmentation and severity evaluation based on proximal imagery, which could aid breeding for crop resistance in field environments, and also benefit precision farming.}
}

@article{lincoln43751,
          volume = {8},
          number = {1},
           month = {February},
          author = {Peter McBurney and Simon Parsons},
           title = {Argument Schemes and Dialogue Protocols: Doug Walton's legacy in artificial intelligence},
       publisher = {College Publications},
            year = {2021},
         journal = {Journal of Applied Logics},
           pages = {263--286},
        keywords = {ARRAY(0x5568fbb8c738)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43751/},
        abstract = {This paper is intended to honour the memory of Douglas Walton (1942--2020), a Canadian philosopher of argumentation who died in January 2020.  Walton's contributions to argumentation theory have had a very strong influence on Artificial Intelligence (AI), particularly in  the design of autonomous software agents able to reason and argue with one another, and in the design of protocols to govern such interactions.  In this paper, we explore two of these contributions --- argumentation schemes and dialogue protocols --- by discussing how they may be applied to a pressing current research challenge in AI:  the automated assessment of explanations for automated decision-making systems.}
}

@article{lincoln43074,
          volume = {179},
           month = {February},
          author = {Asma Seddaoui and Mini Chakravarthini Saaj},
            note = {The paper is the outcome of a PhD I supervised at University of Surrey.},
           title = {Collision-free optimal trajectory generation for a space robot using genetic algorithm},
       publisher = {Elsevier},
            year = {2021},
         journal = {Acta Astronautica},
             doi = {10.1016/j.actaastro.2020.11.001},
           pages = {311--321},
        keywords = {ARRAY(0x5568fbb46e20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43074/},
        abstract = {Future on-orbit servicing and assembly missions will require space robots capable of manoeuvring safely around
their target. Several challenges arise when modelling, controlling and planning the motion of such systems,
therefore, new methodologies are required. A safe approach towards the grasping point implies that the space
robot must be able to use the additional degrees of freedom offered by the spacecraft base to aid the arm attain
the target and avoid collisions and singularities. The controlled-floating space robot possesses this particularity
of motion and will be utilised in this paper to design an optimal path generator. The path generator, based on a
Genetic Algorithm, takes advantage of the dynamic coupling effect and the controlled motion of the spacecraft
base to safely attain the target. It aims to minimise several objectives whilst satisfying multiple constraints. The
key feature of this new path generator is that it requires only the Cartesian position of the point to grasp as
an input, without prior knowledge a desired path. The results presented originate from the trajectory tracking
using a nonlinear adaptive}
}

@article{lincoln46356,
          volume = {120},
          number = {4},
           month = {February},
          author = {{\'A}lia Dos Santos and Natalia Fili and David S. Pearson and Yukti Hari-Gupta and Christopher P. Toseland},
           title = {High-throughput mechanobiology: Force modulation of ensemble biochemical and cell-based assays.},
       publisher = {Elsevier},
            year = {2021},
         journal = {Biophysical Journal},
             doi = {10.1016/j.bpj.2020.12.024},
           pages = {631--641},
        keywords = {ARRAY(0x5568fbb46e68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46356/},
        abstract = {Mechanobiology is focused on how the physical forces and mechanical properties of proteins, cells, and tissues contribute to physiology and disease. Although the response of proteins and cells to mechanical stimuli is critical for function, the tools to probe these activities are typically restricted to single-molecule manipulations. Here, we have developed a novel microplate reader assay to encompass mechanical measurements with ensemble biochemical and cellular assays, using a microplate lid modified with magnets. This configuration enables multiple static magnetic tweezers to function simultaneously across the microplate, thereby greatly increasing throughput. We demonstrate the broad applicability and versatility through in�vitro and in cellulo approaches. Overall, our methodology allows, for the first time (to our knowledge), ensemble biochemical and cell-based assays to be performed under force in high-throughput format. This approach substantially increases the availability of mechanobiology measurements.}
}

@article{lincoln43570,
          volume = {34},
          number = {1},
           month = {February},
          author = {Marin Lujak and Elizabeth I Sklar and Frederic Semet},
           title = {Agriculture fleet vehicle routing: A decentralised and dynamic problem},
       publisher = {IOS Press},
            year = {2021},
         journal = {AI Communications},
             doi = {10.3233/AIC-201581},
           pages = {55--71},
        keywords = {ARRAY(0x5568fbb87060)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43570/},
        abstract = {To date, the research on agriculture vehicles in general and Agriculture Mobile Robots (AMRs) in particular has focused on a single vehicle (robot) and its agriculture-specific capabilities. Very little work has explored the coordination of fleets of such vehicles in the daily execution of farming tasks. This is especially the case when considering overall fleet performance, its efficiency and scalability in the context of highly automated agriculture vehicles that perform tasks throughout multiple fields potentially owned by different farmers and/or enterprises. The potential impact of automating AMR fleet coordination on commercial agriculture is immense. Major conglomerates with large and heterogeneous fleets of agriculture vehicles could operate on huge land areas without human operators to effect precision farming. In this paper, we propose the Agriculture Fleet Vehicle Routing Problem (AF-VRP) which, to the best of our knowledge, differs from any other version of the Vehicle Routing Problem studied so far. We focus on the dynamic and decentralised version of this problem applicable in environments involving multiple agriculture machinery and farm owners where concepts of fairness and equity must be considered. Such a problem combines three related problems: the dynamic assignment problem, the dynamic 3-index assignment problem and the capacitated arc routing problem. We review the state-of-the-art and categorise solution approaches as centralised, distributed and decentralised, based on the underlining decision-making context. Finally, we discuss open challenges in applying distributed and decentralised coordination approaches to this problem.}
}

@inproceedings{lincoln42217,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {February},
           title = {Interactive Movement Primitives: Planning to Push Occluding Pieces for Fruit Picking},
          author = {Sariah Mghames and Marc Hanheide and Amir Ghalamzan Esfahani},
            year = {2021},
             doi = {10.1109/IROS45743.2020.9341728},
            note = {{\copyright} 2020 IEEE.  Personal use of this material is permitted.  Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.},
        keywords = {ARRAY(0x5568fba94388)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42217/},
        abstract = {Robotic technology is increasingly considered the major mean for fruit picking. However, picking fruits in a dense cluster imposes a challenging research question in terms of motion/path planning as conventional planning approaches may not find collision-free movements for the robot to reach-and-pick a ripe fruit within a dense cluster. In such cases, the robot needs to safely push unripe fruits to reach a ripe one. Nonetheless, existing approaches to planning pushing movements in cluttered environments either are computationally expensive or only deal with 2-D cases and are not suitable for fruit picking, where it needs to compute 3- D pushing movements in a short time. In this work, we present a path planning algorithm for pushing occluding fruits to reach-and-pick a ripe one. Our proposed approach, called Interactive Probabilistic Movement Primitives (I-ProMP), is not computationally expensive (its computation time is in the order of 100 milliseconds) and is readily used for 3-D problems. We demonstrate the efficiency of our approach with pushing unripe strawberries in a simulated polytunnel. Our experimental results confirm I-ProMP successfully pushes table top grown strawberries and reaches a ripe one.}
}

@article{lincoln48928,
           month = {February},
          author = {Tomas Vintr and Zhi Yan and Kerem Eyisoy and Filip Kubis and Jan Blaha and Jiri Ulrich and Chittaranjan Swaminathan and Sergio Molina Mellado and Tomasz Kucner and Martin Magnusson and Grzegorz Cielniak and Jan Faigl and Tom Duckett and Achim Lilienthal and Tomas Krajnik},
           title = {Natural criteria for comparison of pedestrian flow forecasting models},
       publisher = {IEEE},
         journal = {2020 IEEE/RJS International Conference on Intelligent Robots and Systems (IROS)},
             doi = {10.1109/IROS45743.2020.9341672},
           pages = {11197--11204},
            year = {2021},
        keywords = {ARRAY(0x5568fba94028)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48928/},
        abstract = {Models of human behaviour, such as pedestrian flows, are beneficial for safe and efficient operation of mobile robots. We present a new methodology for benchmarking of pedestrian flow models based on the afforded safety of robot navigation in human-populated environments. While previous evaluations of pedestrian flow models focused on their predictive capabilities, we assess their ability to support safe path planning and scheduling. Using real-world datasets gathered continuously over several weeks, we benchmark state-of-theart pedestrian flow models, including both time-averaged and time-sensitive models. In the evaluation, we use the learned models to plan robot trajectories and then observe the number of times when the robot gets too close to humans, using a predefined social distance threshold. The experiments show that while traditional evaluation criteria based on model fidelity differ only marginally, the introduced criteria vary significantly depending on the model used, providing a natural interpretation of the expected safety of the system. For the time-averaged flow models, the number of encounters increases linearly with the percentage operating time of the robot, as might be reasonably expected. By contrast, for the time-sensitive models, the number of encounters grows sublinearly with the percentage operating time, by planning to avoid congested areas and times.}
}

@inproceedings{lincoln46582,
       booktitle = {The 94 th Annual Conference of the Agricultural Economics Society (AES)},
           month = {January},
           title = {Current and Emergent Economic Impacts of Covid-19 and Brexit on UK Fresh Produce and Horticultural Businesses},
          author = {Lilian Korir and Archie Drake and Martin Collison and Carolina Camacho Villa and Elizabeth Sklar and Simon Pearson},
            year = {2021},
             doi = {10.22004/ag.econ.312068},
        keywords = {ARRAY(0x5568fb6cadd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46582/},
        abstract = {This paper describes a study designed to investigate the current and emergent impacts of Covid-19 and Brexit on UK horticultural businesses. Various characteristics of UK horticultural production, notably labour reliance and import dependence, make it an important sector for policymakers concerned to understand the effects of these disruptive events as we move from 2020 into 2021. The study design prioritised timeliness, using a rapid survey to gather information from a relatively small (n = 19) but indicative group of producers. The main novelty of the results is to suggest that a very substantial majority of producers either plan to scale back production in 2021 (47\%) or have been unable to make plans for 2021 because of uncertainty (37\%). The results also add to broader evidence that the sector has experienced profound labour supply challenges, with implications for labour cost and quality. The study discusses the implications of these insights from producers in terms of productivity and automation, as well as in terms of broader economic implications. Although automation is generally recognised as the long-term future for the industry (89\%), it appeared in the study as the second most referred short-term option (32\%) only after changes to labour schemes and policies (58\%). Currently, automation plays a limited role in contributing to the UK's horticultural workforce shortage due to economic and socio-political uncertainties. The conclusion highlights policy recommendations and future investigative intentions, as well as suggesting methodological and other discussion points for the research community.}
}

@article{lincoln46766,
           month = {January},
           title = {Current and Emergent Economic Impacts of Covid-19 and Brexit on UK Fresh Produce and Horticultural Businesses},
          author = {Lilian Korir and Archie Drake and Martin Collison and Carolina Camacho Villa and Elizabeth Sklar and Simon Pearson},
            year = {2021},
             doi = {10.22004/ag.econ.312068},
         journal = {ArXiv},
        keywords = {ARRAY(0x5568fb678fb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46766/},
        abstract = {This paper describes a study designed to investigate the current and emergent impacts of Covid-19 and Brexit on UK horticultural businesses. Various characteristics of UK horticultural production, notably labour reliance and import dependence, make it an important sector for policymakers concerned to understand the effects of these disruptive events as we move from 2020 into 2021. The study design prioritised timeliness, using a rapid survey to gather information from a relatively small (n = 19) but indicative group of producers. The main novelty of the results is to suggest that a very substantial majority of producers either plan to scale back production in 2021 (47\%) or have been unable to make plans for 2021 because of uncertainty (37\%). The results also add to broader evidence that the sector has experienced profound labour supply challenges, with implications for labour cost and quality.
The study discusses the implications of these insights from producers in terms of productivity and automation, as well as in terms of broader economic implications. Although automation is generally recognised as the long-term future for the industry (89\%), it appeared in the study as the second most referred short-term option (32\%) only after changes to labour schemes and policies (58\%). Currently, automation plays a limited role in contributing to the UK?s horticultural workforce shortage due to economic and socio-political uncertainties. The conclusion highlights policy recommendations and future investigative intentions, as well as suggesting methodological and other discussion points for the research community.}
}

@article{lincoln46149,
          volume = {40},
          number = {1},
           month = {January},
          author = {Giacomo Picardi and Helmut Hauser and Cecilia Laschi and Marcello Calisti},
           title = {Morphologically induced stability on an underwater legged robot with a deformable body},
            year = {2021},
         journal = {The International Journal of Robotics Research},
             doi = {10.1177/0278364919840426},
           pages = {435--448},
        keywords = {ARRAY(0x5568fba8f478)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46149/},
        abstract = {For robots to navigate successfully in the real world, unstructured environment adaptability is a prerequisite. Although this is typically implemented within the control layer, there have been recent proposals of adaptation through a morphing of the body. However, the successful demonstration of this approach has mostly been theoretical and in simulations thus far. In this work we present an underwater hopping robot that features a deformable body implemented as a deployable structure that is covered by a soft skin for which it is possible to manually change the body size without altering any other property (e.g. buoyancy or weight). For such a system, we show that it is possible to induce a stable hopping behavior instead of a fall, by just increasing the body size. We provide a mathematical model that describes the hopping behavior of the robot under the influence of shape-dependent underwater contributions (drag, buoyancy, and added mass) in order to analyze and compare the results obtained. Moreover, we show that for certain conditions, a stable hopping behavior can only be obtained through changing the morphology of the robot as the controller (i.e. actuator) would already be working at maximum capacity. The presented work demonstrates that, through the exploitation of shape-dependent forces, the dynamics of a system can be modified through altering the morphology of the body to induce a desirable behavior and, thus, a morphological change can be an effective alternative to the classic control.}
}

@article{lincoln43742,
           title = {A Novel Haptic Feature Set for the Classification of Interactive Motor Behaviors in Collaborative Object Transfer},
          author = {Zaid Al-saadi and Doganay Sirintuna and Ayse Kucukyilmaz and Cagatay Basdogan},
       publisher = {IEEE},
            year = {2021},
           pages = {1--1},
             doi = {10.1109/TOH.2020.3034244},
         journal = {IEEE Transactions on Haptics},
        keywords = {ARRAY(0x5568fba93920)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43742/},
        abstract = {Haptics provides a natural and intuitive channel of communication during the interaction of two humans in complex physical tasks, such as joint object transportation. However, despite the utmost importance of touch in physical interactions, the use of haptics is underrepresented when developing intelligent systems. This study explores the prominence of haptic data to extract information about underlying interaction patterns within human-human cooperation. For this purpose, we design salient haptic features describing the collaboration quality within a physical dyadic task and investigate the use of these features to classify the interaction patterns. We categorize the interaction into four discrete behavior classes. These classes describe whether the partners work in harmony or face conflicts while jointly transporting an object through translational or rotational movements. We test the proposed features on a physical human-human interaction (pHHI) dataset, consisting of data collected from 12 human dyads. Using these data, we verify the salience of haptic features by achieving a correct classification rate over 91\% using a Random Forest classifier.}
}

@article{lincoln46191,
           title = {Flagellate Underwater Robotics at Macroscale: Design, Modeling, and Characterization},
          author = {Costanza Armanini and Madiha Farman and Marcello Calisti and Francesco Giorgio-Serchi and Cesare Stefanini and Federico Renda},
            year = {2021},
           pages = {1--17},
             doi = {10.1109/TRO.2021.3094051},
         journal = {IEEE Transactions on Robotics},
        keywords = {ARRAY(0x5568fba93db8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46191/},
        abstract = {Prokaryotic flagellum is considered as the only known example of a biological ?wheel,? a system capable of converting the action of rotatory actuator into a continuous propulsive force. For this reason, flagella are an interesting case study in soft robotics and they represent an appealing source of inspiration for the design of underwater robots. A great number of flagellum-inspired devices exists, but these are all characterized by a size ranging in the micrometer scale and mostly realized with rigid materials. Here, we present the design and development of a novel generation of macroscale underwater propellers that draw their inspiration from flagellated organisms. Through a simple rotatory actuation and exploiting the capability of the soft material to store energy when interacting with the surrounding fluid, the propellers attain different helical shapes that generate a propulsive thrust. A theoretical model is presented, accurately describing and predicting the kinematic and the propulsive capabilities of the proposed solution. Different experimental trials are presented to validate the accuracy of the model and to investigate the performance of the proposed design. Finally, an underwater robot prototype propelled by four flagellar modules is presented.}
}

@incollection{lincoln45934,
       booktitle = {Future of Sustainable Agriculture in Saline Environments},
           title = {Salinization Threats to Agriculture across the North Sea Region},
          author = {Iain Gould and Jeroen De Waegemaeker and Domna Tzemi and Isobel Wright and Simon Pearson and Eric Ruto and Leena Karrasch and Laurids Siig Christensen and Henrik Aronsson and Susanne Eich-Greatorex and Gary Bosworth and Pier Vellinga},
       publisher = {Taylor and Francis},
            year = {2021},
           pages = {71--92},
             doi = {doi:10.1201/9781003112327-5},
        keywords = {ARRAY(0x5568fb9b99a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45934/},
        abstract = {Salinization represents a global threat to agricultural productivity and human livelihoods. Historically, much saline research has focussed on arid or semi-arid systems. The North Sea region of Europe has seen very little attention in salinity literature, however, under future climate predictions, this is likely to change. In this review, we outline the mechanisms of salinization across the North Sea region. These include the intrusion of saline groundwater, coastal flooding, irrigation and airborne salinization. The extent of each degradation process is explored for the United Kingdom, Belgium, the Netherlands, Germany, Denmark, Sweden and Norway. The potential threat of salinization across the North Sea varies in a complex and diverse manner. However, we find an overall lack of data, both of water monitoring and soil sampling, on salinity in the region. For agricultural systems in the region to adapt against future salinization risk, more extensive mapping and monitoring of salinization need to be conducted, along with the development of appropriate land management practices.}
}

@inproceedings{lincoln45349,
       booktitle = {UKRAS21},
           title = {Auction-based Task Allocation Mechanisms for Managing Fruit Harvesting Tasks},
          author = {Helen Harman and Elizabeth Sklar},
            year = {2021},
           pages = {47--48},
             doi = {10.31256/Dg2Zp9Q},
        keywords = {ARRAY(0x5568fba93bf0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45349/},
        abstract = {Multi-robot task allocation mechanisms are de-signed to distribute a set of activities fairly amongst a set of robots. Frequently, this can be framed as a multi-criteria optimisation problem, for example minimising cost while maximising rewards. In soft fruit farms, tasks, such as picking ripe fruit at harvest time, are assigned to human labourers. The work presented here explores the application of multi-robot task allocation mechanisms to the complex problem of managing a heterogeneous workforce to undertake activities associated with harvesting soft fruit.}
}

@inproceedings{lincoln45642,
       booktitle = {Towards Autonomous Robotic Systems Conference (TAROS)},
           title = {Benchmark of visual and 3D lidar SLAM systems in simulation environment for vineyards},
          author = {Ibrahim Hroob and Riccardo Polvara and Sergio Molina Mellado and Grzegorz Cielniak and Marc Hanheide},
            year = {2021},
         journal = {The 22nd Towards Autonomous Robotic Systems Conference},
        keywords = {ARRAY(0x5568fb9f3d40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45642/},
        abstract = {In this work, we present a comparative analysis of the trajectories estimated from various Simultaneous Localization and Mapping (SLAM) systems in a simulation environment for vineyards. Vineyard environment is challenging for SLAM methods, due to visual appearance changes over time, uneven terrain, and repeated visual patterns. For this reason, we created a simulation environment specifically for vineyards to help studying SLAM systems in such a challenging environment. We evaluated the following SLAM systems: LIO-SAM, StaticMapping, ORB-SLAM2, and RTAB-MAP in four different scenarios. The mobile robot used in this study is equipped with 2D and 3D lidars, IMU, and RGB-D camera (Kinect v2). The results show good and encouraging performance of RTAB-MAP in such an environment.}
}

@article{lincoln43690,
           title = {Applying Metalevel Argumentation Frameworks to Support Medical Decision Making},
          author = {Nadin Kokciyan and Isabel Sassoon and Elizabeth Sklar and Simon Parsons and Sanjay Modgil},
       publisher = {IEEE},
            year = {2021},
             doi = {10.1109/MIS.2021.3051420},
         journal = {IEEE Intelligent Systems},
        keywords = {ARRAY(0x5568fb9f3da0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43690/},
        abstract = {People are increasingly employing artificial intelligence as the basis for decision-support systems (DSSs) to assist them in making well-informed decisions. Adoption of DSS is challenging when such systems lack support, or evidence, for justifying their recommendations. DSSs are widely applied in the medical domain, due to the complexity of the domain and the sheer volume of  data that render manual processing difficult. This paper proposes a metalevel argumentation-based decision-support system that can reason with heterogeneous data (e.g. body measurements, electronic health records, clinical guidelines), while incorporating the preferences of the human beneficiaries of those decisions. The system constructs template-based explanations for the recommendations that it makes. The proposed framework has been implemented in a system to support stroke patients and its functionality has been tested in a pilot study. User feedback shows that the system can run effectively over an extended period.}
}

@article{lincoln45567,
           title = {A Time-Delay Feedback Neural Network for Discriminating Small, Fast-Moving Targets in Complex Dynamic Environments},
          author = {Hongxin Wang and Huatian Wang and Jiannan Zhao and Cheng Hu and Jigen Peng and Shigang Yue},
       publisher = {IEEE},
            year = {2021},
             doi = {10.1109/TNNLS.2021.3094205},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
        keywords = {ARRAY(0x5568fb9f3d88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45567/},
        abstract = {Discriminating small moving objects within complex visual environments is a significant challenge for autonomous micro robots that are generally limited in computational power. By exploiting their highly evolved visual systems, flying insects can effectively detect mates and track prey during rapid pursuits, even though the small targets equate to only a few pixels in their visual field. The high degree of sensitivity to small target movement is supported by a class of specialized neurons called small target motion detectors (STMDs). Existing STMD-based computational models normally comprise four sequentially arranged neural layers interconnected via feedforward loops to extract information on small target motion from raw visual inputs. However, feedback, another important regulatory circuit for motion perception, has not been investigated in the STMD pathway and its functional roles for small target motion detection are not clear. In this paper, we propose an STMD-based neural network with feedback connection (Feedback STMD), where the network output is temporally delayed, then fed back to the lower layers to mediate neural responses. We compare the properties of the model with and without the time-delay feedback loop, and find it shows preference for high-velocity objects. Extensive experiments suggest that the Feedback STMD achieves superior detection performance for fast-moving small targets, while significantly suppressing background false positive movements which display lower velocities. The proposed feedback model provides an effective solution in robotic visual systems for detecting fast-moving small targets that are always salient and potentially threatening.}
}

@article{lincoln47316,
           title = {Enhancing LGMD's Looming Selectivity for UAV With Spatial-Temporal Distributed Presynaptic Connections},
          author = {Jiannan Zhao and Hongxin Wang and Nicola Bellotto and Cheng Hu and Jigen Peng and Shigang Yue},
       publisher = {IEEE},
            year = {2021},
           pages = {1--15},
             doi = {10.1109/TNNLS.2021.3106946},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
        keywords = {ARRAY(0x5568fb9f3dd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47316/},
        abstract = {Collision detection is one of the most challenging tasks for Unmanned Aerial Vehicles (UAVs). This is especially true for small or micro UAVs, due to their limited computational power. In nature, flying insects with compact and simple visual systems demonstrate their remarkable ability to navigate and avoid collision in complex environments. A good example of this is provided by locusts. They can avoid collisions in a dense swarm through the activity of a motion-based visual neuron called the Lobula Giant Movement Detector (LGMD). The defining feature of the LGMD neuron is its preference for looming. As a flying insect?s visual neuron, LGMD is considered to be an ideal basis for building UAV?s collision detecting system. However, existing LGMD models cannot distinguish looming clearly from other visual cues such as complex background movements caused by UAV agile flights. To address this issue, we proposed a new model implementing distributed spatial-temporal synaptic interactions, which is inspired by recent findings in locusts? synaptic morphology. We first introduced the locally distributed excitation to enhance the excitation caused by visual motion with preferred velocities. Then radially extending temporal latency for inhibition is incorporated to compete with the distributed excitation and selectively suppress the non-preferred visual motions. This spatial-temporal competition between excitation and inhibition in our model is therefore tuned to preferred image angular velocity representing looming rather than background movements with these distributed synaptic interactions. Systematic experiments have been conducted to verify the performance of the proposed model for UAV agile flights. The results have demonstrated that this new model enhances the looming selectivity in complex flying scenes considerably, and has the potential to be implemented on embedded collision detection systems for small or micro UAVs.}
}

@inproceedings{lincoln43364,
       booktitle = {Brein Informatics},
           month = {December},
           title = {Recall Performance Improvement in a Bio-Inspired Model of the Mammalian Hippocampus},
          author = {Nikolas Andreakos and Shigang Yue and Vassilis Cutsuridis},
            year = {2020},
           pages = {319--328},
             doi = {10.1007/978-3-030-59277-6\_29},
        keywords = {ARRAY(0x5568fb9f3e30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43364/},
        abstract = {Mammalian hippocampus is involved in short-term formation of declarative memories. We employed a
bio-inspired neural model of hippocampal CA1 region consisting of a zoo of excitatory and inhibitory
cells. Cells? firing was timed to a theta oscillation paced by two distinct neuronal populations exhibiting
highly regular bursting activity, one tightly coupled to the trough and the other to the peak of theta. To
systematically evaluate the model?s recall performance against number of stored patterns, overlaps and
?active cells per pattern?, its cells were driven by a non-specific excitatory input to their dendrites. This
excitatory input to model excitatory cells provided context and timing information for retrieval of
previously stored memory patterns. Inhibition to excitatory cells? dendrites acted as a non-specific global
threshold machine that removed spurious activity during recall. Out of the three models tested, ?model 1?
recall quality was excellent across all conditions. ?Model 2? recall was the worst. The number of ?active
cells per pattern? had a massive effect on network recall quality regardless of how many patterns were
stored in it. As ?active cells per pattern? decreased, network?s memory capacity increased, interference
effects between stored patterns decreased, and recall quality improved. Key finding was that increased
firing rate of an inhibitory cell inhibiting a network of excitatory cells has a better success at removing
spurious activity at the network level and improving recall quality than increasing the synaptic strength of
the same inhibitory cell inhibiting the same network of excitatory cells, while keeping its firing rate fixed.}
}

@article{lincoln46137,
          volume = {27},
          number = {4},
           month = {December},
          author = {Jiaqi Liu and Saverio Iacoponi and Cecilia Laschi and Li Wen and Marcello Calisti},
           title = {Underwater Mobile Manipulation: A Soft Arm on a Benthic Legged Robot},
            year = {2020},
         journal = {IEEE Robotics \& Automation Magazine},
             doi = {10.1109/MRA.2020.3024001},
           pages = {12--26},
        keywords = {ARRAY(0x5568fb9f3e18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46137/},
        abstract = {Robotic systems that can explore the sea floor, collect marine samples, gather shallow water refuse, and perform other underwater tasks are interesting and important in several fields, from biology and ecology to off-shore industry. In this article, we present a robotic platform that is, to our knowledge, the first to combine benthic legged locomotion and soft continuum manipulation to perform real-world underwater mission-like experiments. We experimentally exploit inverse kinematics for spatial manipulation in a laboratory environment and then examine the robot's workspace extensibility, force, energy consumption, and grasping ability in different undersea scenarios.}
}

@inproceedings{lincoln42134,
       booktitle = {The IEEE International Conference on Advanced Robotics and Mechatronics (ARM)},
           month = {December},
           title = {Complementary Visual Neuronal Systems Model for Collision Sensing},
          author = {Qinbing Fu and Shigang Yue},
            year = {2020},
             doi = {10.1109/ICARM49381.2020.9195303},
        keywords = {ARRAY(0x5568fb9f3e60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42134/},
        abstract = {Inspired by insects? visual brains, this paper presents original modelling of a complementary visual neuronal systems model for real-time and robust collision sensing. Two categories of wide-?eld motion sensitive neurons, i.e., the lobula giant movement detectors (LGMDs) in locusts and the lobula plate tangential cells (LPTCs) in ?ies, have been studied, intensively. The LGMDs have speci?c selectivity to approaching objects in depth that threaten collision; whilst the LPTCs are only sensitive to translating objects in horizontal and vertical directions. Though each has been modelled and applied in various visual scenes including robot scenarios, little has been done on investigating their complementary functionality and selectivity when functioning together. To ?ll this vacancy, we introduce a hybrid model combining two LGMDs (LGMD-1 and LGMD2) with horizontally (rightward and leftward) sensitive LPTCs (LPTC-R and LPTC-L) specialising in fast collision perception. With coordination and competition between different activated neurons, the proximity feature by frontal approaching stimuli can be largely sharpened up by suppressing translating and receding motions. The proposed method has been implemented ingroundmicro-mobile robots as embedded systems. The multi-robot experiments have demonstrated the effectiveness and robustness of the proposed model for frontal collision sensing, which outperforms previous single-type neuron computation methods against translating interference.}
}

@inproceedings{lincoln42338,
       booktitle = {4th IEEE International Conference on Image Processing, Applications and Systems (IPAS)},
           month = {December},
           title = {Real-time Object Detection using Deep Learning for helping People with Visual Impairments},
          author = {Matteo Terreran and Andrea Tramontano and Jacobus Lock and Stefano Ghidoni and Nicola Bellotto},
       publisher = {IEEE},
            year = {2020},
             doi = {10.1109/IPAS50080.2020.9334933},
        keywords = {ARRAY(0x5568fb9f3ec0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42338/},
        abstract = {Object detection plays a crucial role in the development of Electronic Travel Aids (ETAs), capable to guide a person with visual impairments towards a target object in an unknown indoor environment. In such a scenario, the object detector runs on a mobile device (e.g. smartphone) and needs to be fast, accurate, and, most importantly, lightweight. Nowadays, Deep Neural Networks (DNN) have become the state-of-the-art solution for object detection tasks, with many works improving speed and accuracy by proposing new architectures or extending existing ones. A common strategy is to use deeper networks to get higher performance, but that leads to a higher computational cost which makes it impractical to integrate them on mobile devices with limited computational power. In this work we compare different object detectors to find a suitable candidate to be implemented on ETAs, focusing on lightweight models capable of working in real-time on mobile devices with a good accuracy. In particular, we select two models: SSD Lite with Mobilenet V2 and Tiny-DSOD. Both models have been tested on the popular OpenImage dataset and a new dataset, called Office dataset, collected to further test models? performance and robustness in a real scenario inspired by the actual perception challenges of a user with visual impairments.}
}

@inproceedings{lincoln53891,
       booktitle = {TAROS 2020: Towards Autonomous Robotic Systems},
           month = {December},
           title = {An Experiment on Human-Robot Interaction in a Simulated Agricultural Task},
          author = {Zhuoling Huang and Genki Miyauchi and Adrian Salazar Gomez and Richie Bird and Amar Singh Kalsi and Chipp Jansen and Zeyang Liu and Simon Parsons and Elizabeth Sklar},
            year = {2020},
             doi = {10.1007/978-3-030-63486-5\_25},
        keywords = {ARRAY(0x5568fb9f3ea8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53891/},
        abstract = {On the farm of the future, a human agriculturist collaborates with both human and automated labourers in order to perform a wide range of tasks. Today, changes in traditional farming practices motivate robotics researchers to consider ways in which automated devices and intelligent systems can work with farmers to address diverse needs of farming. Because farming tasks can be highly specialised, though often repetitive, a human-robot approach is a natural choice. The work presented here investigates a collaborative task in which a human and robot share decision making about the readiness of strawberries for harvesting, based on visual inspection. Two different robot behaviours are compared: one in which the robot provides decisions with more false positives and one in which the robot provides decisions with more false negatives. Preliminary experimental results conducted with human subjects are presented and show that the robot behaviour with more false positives is preferred in completing this task.}
}

@inproceedings{lincoln49496,
       booktitle = {21st Towards Autonomous Robotic Systems Conference},
           month = {December},
           title = {Modelling and Control of an End-Over-End Walking Robot},
          author = {Manu H. Nair and Mini Saaj and Amir G. Esfahani},
       publisher = {Springer},
            year = {2020},
             doi = {10.1007/978-3-030-63486-5\_15},
        keywords = {ARRAY(0x5568fb9f3ef0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49496/},
        abstract = {Over the last few decades, Space robots have found their applications in various in-orbit operations. The Canadarm2 and the European Robotic Arm (ERA), onboard the International Space Station (ISS), are exceptional examples of supervised robotic manipulators (RMs) used for station assembly and mainte?nance. However, in the case of in-space assembly of structures, like Large-Aperture Space Telescope (LAT) with an aperture larger than the Hubble Space Telescope (HST) and James Webb Space Telescope (JWST), missions are still in their infancy; this is heavily attributed to the limitations of current state-of-the-art Robotics, Automation and Autonomous Systems (RAAS) for the extreme space environ?ment. To address this challenge, this paper introduces the modelling and control of a candidate robotic architecture, inspired by Canadarm2 and ERA, for in-situ assembly of LAT. The kinematic and dynamic models of a five degrees-of-freedom (DoF) End-Over-End Walking robot's (E-Walker's) first phase of motion is pre?sented. A closed-loop feedback system validates the system's accurate gait pat?tern. The simulation results presented show that a Proportional-Integral-Derivative (PID) controller is able to track the desired joint angles without exceeding the joint torque limits; this ensures precise motion along the desired trajectory for one full cycle comprising of Phase-1 and Phase-2 respectively. The gait pattern of the E-Walker for the next phases is also briefly discussed.}
}

@inproceedings{lincoln40186,
       booktitle = {21st Towards Autonomous Robotic Systems Conference},
           month = {December},
           title = {Towards Safer Robot Motion: Using a Qualitative Motion Model to Classify Human-Robot Spatial Interaction},
          author = {Laurence Roberts-Elliott and Manuel Fernandez-Carmona and Marc Hanheide},
       publisher = {Springer},
            year = {2020},
        keywords = {ARRAY(0x5568fb9f3f50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40186/},
        abstract = {For adoption of Autonomous Mobile Robots (AMR) across a breadth of industries, they must navigate around humans in a way which is safe and which humans perceive as safe, but without greatly compromising efficiency. This work aims to classify the Human-Robot Spatial Interaction (HRSI) situation of an interacting human and robot, to be applied in Human-Aware Navigation (HAN) to account for situational context. We develop qualitative probabilistic models of relative human and robot movements in various HRSI situations to classify situations, and explain our plan to develop per-situation probabilistic models of socially legible HRSI to predict human and robot movement. In future work we aim to use these predictions to generate qualitative constraints in the form of metric cost-maps for local robot motion planners, enforcing more efficient and socially legible trajectories which are both physically safe and perceived as safe.}
}

@article{lincoln46135,
          volume = {12},
          number = {6},
           month = {December},
          author = {Saverio Iacoponi and Marcello Calisti and Cecilia Laschi},
           title = {Simulation and Analysis of Microspines Interlocking Behavior on Rocky Surfaces: An In-Depth Study of the Isolated Spine},
         journal = {Journal of Mechanisms and Robotics},
             doi = {10.1115/1.4047725},
            year = {2020},
        keywords = {ARRAY(0x5568fb9f3f38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46135/},
        abstract = {Microspine grippers address a large variety of possible applications, especially in field robotics and manipulation in extreme environments. Predicting and modeling the gripper behavior remains a major challenge to this day. One of the most complex aspects of these predictions is how to model the spine to rock interaction of the spine tip with the local asperity. This paper proposes a single spine model, in order to fill the gap of knowledge in this specific field. A new model for the anchoring resistance of a single spine is proposed and discussed. The model is then applied to a simulation campaign. With the aid of simulations and analytic functions, we correlated performance characteristics of a spine with a set of quantitative, macroscopic variables related to the spine, the substrate and its usage. Eventually, this paper presents some experimental comparison tests and discusses traversal phenomena observed during the tests.}
}

@article{lincoln43255,
          volume = {39},
           month = {November},
          author = {Gerard Canal and Rita Borgo and Andrew Coles and Archie Drake and Dong Huynh and Perry Keller and Senka Krivi{\'c} and Paul Luff and Quratul-ain Mahesar and Luc Moreau and Simon Parsons and Menisha Patel and Elizabeth Sklar},
           title = {Building Trust in Human-Machine Partnerships},
         journal = {Computer Law \& Security Review},
             doi = {10.1016/j.clsr.2020.105489},
           pages = {105489},
            year = {2020},
        keywords = {ARRAY(0x5568fb9f3f80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43255/},
        abstract = {Artificial Intelligence (AI) is bringing radical change to our lives. Fostering trust in this technology requires the technology to be transparent, and one route to transparency is to make the decisions that are reached by AIs explainable to the humans that interact with them. This paper lays out an exploratory approach to developing explainability and trust, describing the specific technologies that we are adopting, the social and organizational context in which we are working, and some of the challenges that we are addressing.}
}

@article{lincoln46141,
          volume = {20},
          number = {22},
           month = {November},
          author = {Giacomo Picardi and Clara Borrelli and Augusto Sarti and Giovanni Chimienti and Marcello Calisti},
           title = {A Minimal Metric for the Characterization of Acoustic Noise Emitted by Underwater Vehicles},
            year = {2020},
         journal = {Sensors},
             doi = {10.3390/s20226644},
           pages = {6644},
        keywords = {ARRAY(0x5568fb9f3fe0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46141/},
        abstract = {Underwater robots emit sound during operations which can deteriorate the quality of acoustic data recorded by on-board sensors or disturb marine fauna during in vivo observations. Notwithstanding this, there have only been a few attempts at characterizing the acoustic emissions of underwater robots in the literature, and the datasheets of commercially available devices do not report information on this topic. This work has a twofold goal. First, we identified a setup consisting of a camera directly mounted on the robot structure to acquire the acoustic data and two indicators (i.e., spectral roll-off point and noise introduced to the environment) to provide a simple and intuitive characterization of the acoustic emissions of underwater robots carrying out specific maneuvers in specific environments. Second, we performed the proposed analysis on three underwater robots belonging to the classes of remotely operated vehicles and underwater legged robots. Our results showed how the legged device produced a clearly different signature compared to remotely operated vehicles which can be an advantage in operations that require low acoustic disturbance. Finally, we argue that the proposed indicators, obtained through a standardized procedure, may be a useful addition to datasheets of existing underwater robots}
}

@article{lincoln42179,
          volume = {198},
           month = {October},
          author = {Petra Bosilj and Iain Gould and Tom Duckett and Grzegorz Cielniak},
           title = {Estimating soil aggregate size distribution from images using pattern spectra},
       publisher = {Elsevier},
            year = {2020},
         journal = {Biosystems Engineering},
             doi = {10.1016/j.biosystemseng.2020.07.012},
           pages = {63--77},
        keywords = {ARRAY(0x5568fb9f3fc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42179/},
        abstract = {A method for quantifying aggregate size distribution from the images of soil samples is introduced. Knowledge of soil aggregate size distribution can help to inform soil management practices for the sustainable growth of crops. While current in-field approaches are mostly subjective, obtaining quantifiable results in a laboratory is labour- and time-intensive. Our goal is to develop an imaging technique for quantitative analysis of soil aggregate size distribution, which could provide the basis of a tool for rapid assessment of soil structure. The prediction accuracy of pattern spectra descriptors based on hierarchical representations from attribute morphology are analysed, as well as the impact of using images of different quality and scales. The method is able to handle greater sample complexity than the previous approaches, while working with smaller samples sizes that are easier to handle. The results show promise for size analysis of soils with larger structures, and minimal sample preparation, as typical of soil assessment in agriculture.}
}

@article{lincoln46870,
          volume = {114},
           month = {October},
          author = {Qinbing Fu and Shigang Yue},
           title = {Modelling Drosophila motion vision pathways for decoding the direction of translating objects against cluttered moving backgrounds},
       publisher = {Springer},
            year = {2020},
         journal = {Biological Cybernetics},
             doi = {10.1007/s00422-020-00841-x},
           pages = {443--460},
        keywords = {ARRAY(0x5568fb9f4010)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46870/},
        abstract = {Decoding the direction of translating objects in front of cluttered moving backgrounds, accurately and efficiently, is still a challenging problem. In nature, lightweight and low-powered flying insects apply motion vision to detect a moving target in highly variable environments during flight, which are excellent paradigms to learn motion perception strategies. This paper investigates the fruit fly Drosophila motion vision pathways and presents computational modelling based on cutting-edge physiological researches. The proposed visual system model features bio-plausible ON and OFF pathways, wide-field horizontal-sensitive (HS) and vertical-sensitive (VS) systems. The main contributions of this research are on two aspects: 1) the proposed model articulates the forming of both direction-selective (DS) and direction-opponent (DO) responses revealed as principal features of motion perception neural circuits, in a feed-forward manner; 2) it also shows robust direction selectivity to translating objects in front of cluttered moving backgrounds, via the modelling of spatiotemporal dynamics including combination of motion pre-filtering mechanisms and ensembles of local correlators inside both the ON and OFF pathways, which works effectively to suppress irrelevant background motion or distractors, and to improve the dynamic response. Accordingly, the direction of translating objects is decoded as global responses of both the HS and VS systems with positive or negative output indicating preferred-direction (PD) or null-direction (ND) translation. The experiments have verified the effectiveness of the proposed neural system model, and demonstrated its responsive preference to faster-moving, higher-contrast and larger-size targets embedded in cluttered moving backgrounds.}
}

@inproceedings{lincoln44709,
       booktitle = {2020 The 4th International Conference on Advances in Artificial Intelligence},
           month = {October},
           title = {Learning Symbolic Action Definitions from Unlabelled Image Pairs},
          author = {Helen Harman and Pieter Simoens},
            year = {2020},
           pages = {72--78},
             doi = {10.1145/3441417.3441419},
        keywords = {ARRAY(0x5568fb9f4070)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44709/},
        abstract = {Task planners and goal recognisers often require symbolic models of an agent?s behaviour. These models are usually manually developed, which can be a time consuming and error prone process. Therefore, our work transforms unlabelled pairs of images, showing the state before and after an action has been executed, into reusable action definitions. Each action definition consist of a set of parameters, effects and preconditions. To evaluate these action definitions, states were generated and a task planner invoked. Problems with large state spaces were solved using the action definitions learnt from smaller state spaces. On average, the task plans contained 5.46 actions and planning took 0.06 seconds. Moreover, when 20 \% of transitions were missing, our approach generated the correct number of objects, action definitions and plans 70 \% of the time.}
}

@incollection{lincoln42872,
           month = {October},
          author = {Fanta Camara and Serhan Cosar and Nicola Bellotto and Natasha Merat and Charles Fox},
          series = {River Publishers Series in Transport Technology},
       booktitle = {Human Factors in Intelligent Vehicles},
          editor = {Cristina Olaverri-Monreal and Fernando Garc{\'i}a-Fern{\'a}ndez and Rosaldo J. F. Rossetti},
           title = {Continuous Game Theory Pedestrian Modelling Method for Autonomous Vehicles},
       publisher = {River Publishers},
            year = {2020},
        keywords = {ARRAY(0x5568fb9f4058)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42872/},
        abstract = {Autonomous Vehicles (AVs) must interact with other road users. They must understand and adapt to complex pedestrian behaviour, especially during crossings where priority is not clearly defined. This includes feedback effects
such as modelling a pedestrian?s likely behaviours resulting from changes in the AVs behaviour. For example, whether a pedestrian will yield if the AV accelerates, and vice versa. To enable such automated interactions, it is necessary for the AV to possess a statistical model of the pedestrian?s responses to its own actions. A previous work demonstrated a proof-of- concept method to fit parameters to a simplified model based on data from a highly artificial discrete laboratory task with human subjects. The method was based on LIDAR-based person tracking, game theory, and Gaussian process analysis. The present study extends this method to enable analysis of more realistic continuous human experimental data. It shows for the first time how game-theoretic predictive parameters can be fit into pedestrians natural and continuous motion during road-crossings, and how predictions can be made about their interactions with AV controllers in similar real-world settings.}
}

@inproceedings{lincoln42806,
       booktitle = {5th International Workshop on Non-Intrusive Load Monitoring},
           month = {October},
           title = {Lightweight Non-Intrusive Load Monitoring Employing Pruned Sequence-to-Point Learning},
          author = {Jack Barber and Heriberto Cuayahuitl and Mingjun Zhong and Wempen Luan},
       publisher = {ACM Conference Proceedings},
            year = {2020},
             doi = {10.1145/1122445.1122456},
        keywords = {ARRAY(0x5568fb9f40a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42806/},
        abstract = {Non-intrusive load monitoring (NILM) is the process in which a household?s total power consumption is used to determine the power consumption of household appliances. 
Previous work has shown that sequence-to-point (seq2point) learning is one of the most promising methods for tackling NILM. This process uses a sequence of aggregate power data to map a target appliance's power consumption at the midpoint of that window of power data.
However, models produced using this method contain upwards of thirty million weights, meaning that the models require large volumes of resources to perform disaggregation. This paper addresses this problem by pruning the weights learned by such a model, which results in a lightweight NILM algorithm for the purpose of being deployed on mobile devices such as smart meters. The pruned seq2point learning algorithm was applied to the REFIT data, experimentally showing that the performance was retained comparing to the original seq2point learning whilst the number of weights was reduced by 87{$\backslash$}\%. Code:https://github.com/JackBarber98/pruned-nilm}
}

@inproceedings{lincoln42419,
       booktitle = {2020 IEEE/RSJ International Conference on Intelligent Robots and Systems},
           month = {October},
           title = {Incorporating Spatial Constraints into a Bayesian Tracking Framework for Improved Localisation in Agricultural Environments},
          author = {Waqas Khan and Gautham Das and Marc Hanheide and Grzegorz Cielniak},
       publisher = {IEEE},
            year = {2020},
        keywords = {ARRAY(0x5568fb9f4100)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42419/},
        abstract = {Global navigation satellite system (GNSS) has been considered as a panacea for positioning and tracking since the last decade. However, it suffers from severe limitations in terms of accuracy, particularly in highly cluttered and indoor environments. Though real-time kinematics (RTK) supported GNSS promises extremely accurate localisation, employing such services are expensive, fail in occluded environments and are unavailable in areas where cellular base stations are not accessible. It is, therefore, necessary that the GNSS data is to be filtered if high accuracy is required. Thus, this article presents a GNSS-based particle filter that exploits the spatial constraints imposed by the environment. In the proposed setup, the state prediction of the sample set follows a restricted motion according to the topological map of the environment. This results in the transition of the samples getting confined between specific discrete points, called the topological nodes, defined by a topological map. This is followed by a refinement stage where the full set of predicted samples goes through weighting and resampling, where the weight is proportional to the predicted particle?s proximity with the GNSS measurement. Thus, a discrete space continuous-time Bayesian filter is proposed, called the Topological Particle Filter (TPF). 
The proposed TPF is put to test by localising and tracking fruit pickers inside polytunnels. Fruit pickers inside polytunnels can only follow specific paths according to the topology of the tunnel. These paths are defined in the topological map of the polytunnels and are fed to TPF to tracks fruit pickers. Extensive datasets are collected to demonstrate the improved discrete tracking of strawberry pickers inside polytunnels thanks to the exploitation of the environmental constraints.}
}

@inproceedings{lincoln48338,
       booktitle = {Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {October},
           title = {On Robotic In-Orbit Assembly of Large Aperture Space Telescopes},
          author = {Manu H. Nair and Chakravarthini M. Saaj and Amir G. Esfahani},
       publisher = {IEEE},
            year = {2020},
        keywords = {ARRAY(0x5568fb9f40e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48338/},
        abstract = {Space has found itself amidst numerous missions  benefitting the life on Earth and for mankind to explore further.
The space community has been in the move of launching various on-orbit missions, tackling the extremities of the space environment, with the use of robots, for performing tasks like assembly, maintenance, repairs, etc. The urge to explore further in the universe for scientific benefits has found the rise of modular Large-Space Telescopes (LASTs). With respect to the challenges of the in-space assembly of LAST, a five Degrees-of Freedom (DoF) End-Over-End Walking Robot (E-Walker) is presented in this paper. The Dynamical Model and Gait Pattern of the E-Walker is discussed with reference to the different phases of its motion. For the initial verification of the E-Walker model, a PID controller was used to make the E-Walker follow the desired trajectory. A mission concept discussing a potential strategy of assembling a 25m LAST with 342 Primary Mirror Units (PMUs) is briefly discussed. Simulation results show the 
precise tracking of the E-Walker along a desired trajectory is achieved without exceeding the joint torques.}
}

@inproceedings{lincoln49489,
       booktitle = {15th International Symposium on Artificial Intelligence, Robotics and Automation in Space (i-SAIRAS 2020)},
           month = {October},
           title = {Advances in Robotic In-Orbit Assembly of Large Aperture Space Telescopes},
          author = {Manu H. Nair and Mini Saaj and Sam Adlen and Amir G, Esfahani and Steve Eckersley},
       publisher = {European Space Agency},
            year = {2020},
        keywords = {ARRAY(0x5568fb9f4130)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49489/},
        abstract = {Modular Large Aperture Space Telescopes (LAST) hold the key to future astronomical missions in search of the origin of the cosmos. Robotics and Autonomous Systems technology would be required to meet the challenges associated with the assembly of such high value infrastructure in orbit. In this paper an End-Over-End walking robot is selected to assemble a 25m LAST. The dynamical model, control architecture and gait pattern of the E-Walker are discussed. The key mission requirements are stated along with the strategies for scheduling the assembly process. A mission concept of operations (ConOps) is proposed for assembling the 25m LAST. Simulation results show the precise trajectory tracking of the EWalker for the chosen mission scenario.}
}

@inproceedings{lincoln42213,
           month = {October},
          author = {Nikos Mavrakis and Rustam Stolkin and Amir Ghalamzan Esfahani},
       booktitle = {The IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           title = {Estimating An Object?s Inertial Parameters By Robotic Pushing: A Data-Driven Approach},
         journal = {The IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2020)},
             doi = {10.1109/IROS45743.2020.9341112},
           pages = {9537--9544},
            year = {2020},
        keywords = {ARRAY(0x5568fb9f4190)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42213/},
        abstract = {Estimating the inertial properties of an object can make robotic manipulations more efficient, especially in extreme environments. This paper presents a novel method of estimating the 2D inertial parameters of an object, by having a robot applying a push on it. We draw inspiration from previous analyses on quasi-static pushing mechanics, and introduce a data-driven model that can accurately represent these mechan- ics and provide a prediction for the object?s inertial parameters. We evaluate the model with two datasets. For the first dataset, we set up a V-REP simulation of seven robots pushing objects with large range of inertial parameters, acquiring 48000 pushes in total. For the second dataset, we use the object pushes from the MIT M-Cube lab pushing dataset. We extract features from force, moment and velocity measurements of the pushes, and train a Multi-Output Regression Random Forest. The experimental results show that we can accurately predict the 2D inertial parameters from a single push, and that our method retains this robust performance under various surface types.}
}

@inproceedings{lincoln49491,
       booktitle = {71st International Astronautical Congress},
           month = {October},
           title = {In-Space Robotic Assembly and Servicing of High-Value Infrastructure},
          author = {Manu H. Nair and Chakravarthini Mini Saaj and Amir G. Esfahani and Angadh Nanjangud and Steve Eckersley and Paolo Bianco},
       publisher = {International Astronautical Federation},
            year = {2020},
        keywords = {ARRAY(0x5568fb9f4178)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49491/},
        abstract = {With the advances in Robotics, Automation and Autonomous Systems (RAAS), the horizon of space
exploration has grown, and there is a need to develop space-qualified intelligent robots for future missions. Building
upon the heritage of successful surface exploration rover and lander missions to the Moon, Mars and Asteroids, the
space community worldwide is now pushing the frontiers of in-orbit robotics. Doubtlessly, RAAS will facilitate a
range of manufacturing, assembly, servicing and active debris removal missions. Resources published by space
agencies and major companies worldwide clearly indicate that mankind will start witnessing in-orbit robotic
missions within the next decade. This includes but not limited to building modular Large-Aperture Space Telescopes
(LAST), synthetic aperture radar, radiofrequency antennas, in-space power generation stations, mobile servicing
stations for repairing and maintenance of satellites and possibly large-scale infrastructure for space tourism. Out of
the many potential missions RAAS could support, in-orbit robotic assembly and construction of LAST is gaining
more popularity with the intent to understand the rate of growth of the cosmos and also for Earth Observation (EO).
However, there are numerous technical challenges associated with assembling LAST in space, including its
manufacturing and stowing into current and planned launch vehicles. To address these issues, a segmented design
approach for LAST is considered in this paper; the modular mirror units will be robotically assembled in orbit. The
in-space assembly of a modular 25m LAST mission concept is presented using a five Degrees-of-Freedom End-
Over-End Walking Robot (E-Walker). The design and gait pattern of the E-Walker is introduced first. The key
mission requirements including the requirements for the Robotic System, Space Telescope and Assembly are
discussed along with the strategies for scheduling the assembly process. Four main mission scenarios, subcategorised
into eleven mission scenarios are discussed in detail with a maximum of four E-Walkers. A trade-off
analysis was conducted to identify feasible mission scenarios and inferences are drawn accordingly to the best
mission concept of operations (ConOps) to realise the assembly of the 25m LAST. The results are based on the
overall mission mass-power budget, cost, control and motion planning complexity for the different mission scenarios
addressed in this paper. This study is a stepping stone towards proving the feasibility of the E-Walker for assembling
LAST; such advancements in orbital robotics will prove advantageous for building and servicing other high-value
infrastructure in space.}
}

@article{lincoln43697,
          volume = {12},
          number = {19},
           month = {October},
          author = {Dionysis Bochtis and Lefteris Benos and Maria Lampridi and Vasso Marinoudi and Simon Pearson and Claus G. S{\o}rensen},
           title = {Agricultural Workforce Crisis in Light of the COVID-19 Pandemic},
            year = {2020},
         journal = {Sustainability},
             doi = {10.3390/su12198212},
           pages = {8212},
        keywords = {ARRAY(0x5568fb9f41c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43697/},
        abstract = {COVID-19 and the restrictive measures towards containing the spread of its infections have seriously affected the agricultural workforce and jeopardized food security. The present study aims at assessing the COVID-19 pandemic impacts on agricultural labor and suggesting strategies to mitigate them. To this end, after an introduction to the pandemic background, the negative consequences on agriculture and the existing mitigation policies, risks to the agricultural workers were benchmarked across the United States? Standard Occupational Classification system. The individual tasks associated with each occupation in agricultural production were evaluated on the basis of potential COVID-19 infection risk. As criteria, the most prevalent virus transmission mechanisms were considered, namely the possibility of touching contaminated surfaces and the close proximity of workers. The higher risk occupations within the sector were identified, which facilitates the allocation of worker protection resources to the occupations where they are most needed. In particular, the results demonstrated that 50\% of the agricultural workforce and 54\% of the workers? annual income are at moderate to high risk. As a consequence, a series of control measures need to be adopted so as to enhance the resilience and sustainability of the sector as well as protect farmers including physical distancing, hygiene practices, and personal protection equipment.}
}

@article{lincoln42612,
          volume = {35},
          number = {6},
           month = {September},
          author = {Gary Bosworth and Liz Price and Martin Collison and Charles Fox},
           title = {Unequal Futures of Rural Mobility:�Challenges for a ?Smart Countryside?},
       publisher = {Sage},
            year = {2020},
         journal = {Local Economy},
             doi = {10.1177/0269094220968231},
           pages = {586--608},
        keywords = {ARRAY(0x5568fb9f4220)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42612/},
        abstract = {Current transport strategy in the UK is strongly urban-focused, with assumptions that technological advances in mobility will simply trickle down into rural areas. This paper challenges such a view and instead draws on rural development thinking aligned to a ?Smart Countryside? which emphasises the need for place-based approaches. Survey and interview methods are employed to develop a framework of rural needs associated with older people, younger people and businesses. This framework is employed to assess a range of mobility innovations that could most effectively address these needs in different rural contexts. In presenting visions of future rural mobility, the paper also identifies key infrastructure as well as institutional and financial changes that are required to facilitate the roll-out of new technologies across rural areas.}
}

@inproceedings{lincoln49494,
       booktitle = {Model Based Space Systems and Software Engineering MBSE2020},
           month = {September},
           title = {Cloud SF ? A continuous Integration Framework for the Design and Validation of Cyber-Physical Systems},
          author = {Gianmaria Bullegas and Anurag Kapur and Mini Saaj and Manu H. Nair and Adrian Pop and Peter Fritzson},
       publisher = {European Space Agency},
            year = {2020},
        keywords = {ARRAY(0x5568fb9f4208)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49494/},
        abstract = {The extensive use of virtual prototyping methods has become an indispensable tool in the context of
Model-Based Design of complex space missions. Modelling the behaviour of such missions often requires
considering systems that are composed of physical subsystems (usually from different physical domains)
together with computing and networking. Perpetual Labs is developing a new software platform for collaborative design of CPS called Cloud System Factory (CloudSF). It enables all the stakeholders of a complex engineering system to exchange system data and engineering artefacts independently of the specific tools that they are using. The proposed benefits of the CloudSF platform will be demonstrated and measured through the application
of said platform to the model-based design and verification of a robotic system for on-orbit assembly of
telescopic structures using an End-Over-End Walking robot, called the E-Walker.}
}

@article{lincoln42446,
          volume = {10},
          number = {1},
           month = {September},
          author = {Michelle T. Fountain and Amir Badiee and Sebastian Hemer and Alvaro Delgado and Michael Mangan and Colin Dowding and Frederick Davis and Simon Pearson},
           title = {The use of light spectrum blocking films to reduce populations of Drosophila suzukii Matsumura in fruit crops},
       publisher = {Nature Publishing Group},
            year = {2020},
         journal = {Scientific Reports},
             doi = {10.1038/s41598-020-72074-8},
        keywords = {ARRAY(0x5568fb67d328)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42446/},
        abstract = {Spotted wing drosophila, Drosophila suzukii, is a serious invasive pest impacting the production of
multiple fruit crops, including soft and stone fruits such as strawberries, raspberries and cherries.
Effective control is challenging and reliant on integrated pest management which includes the use
of an ever decreasing number of approved insecticides. New means to reduce the impact of this pest
that can be integrated into control strategies are urgently required. In many production regions,
including the UK, soft fruit are typically grown inside tunnels clad with polyethylene based materials.
These can be modified to filter specific wavebands of light. We investigated whether targeted spectral
modifications to cladding materials that disrupt insect vision could reduce the incidence of D. suzukii.
We present a novel approach that starts from a neuroscientific investigation of insect sensory systems
and ends with infield testing of new cladding materials inspired by the biological data. We show D.
suzukii are predominantly sensitive to wavelengths below 405 nm (ultraviolet) and above 565 nm
(orange \& red) and that targeted blocking of lower wavebands (up to 430 nm) using light restricting
materials reduces pest populations up to 73\% in field trials.}
}

@article{lincoln42433,
          volume = {7},
          number = {116},
           month = {September},
          author = {Francesco Del Duchetto and Paul Baxter and Marc Hanheide},
           title = {Are You Still With Me? Continuous Engagement Assessment From a Robot's Point of View},
       publisher = {Frontiers Media S.A.},
            year = {2020},
         journal = {Frontiers in Robotics and AI},
             doi = {10.3389/frobt.2020.00116},
        keywords = {ARRAY(0x5568fb966df0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42433/},
        abstract = {Continuously measuring the engagement of users with a robot in a Human-Robot Interaction (HRI) setting paves the way toward in-situ reinforcement learning, improve metrics of interaction quality, and can guide interaction design and behavior optimization. However, engagement is often considered very multi-faceted and difficult to capture in a workable and generic computational model that can serve as an overall measure of engagement. Building upon the intuitive ways humans successfully can assess situation for a degree of engagement when they see it, we propose a novel regression model (utilizing CNN and LSTM networks) enabling robots to compute a single scalar engagement during interactions with humans from standard video streams, obtained from the point of view of an interacting robot. The model is based on a long-term dataset from an autonomous tour guide robot deployed in a public museum, with continuous annotation of a numeric engagement assessment by three independent coders. We show that this model not only can predict engagement very well in our own application domain but show its successful transfer to an entirely different dataset (with different tasks, environment, camera, robot and people). The trained model and the software is available to the HRI community, at https://github.com/LCAS/engagement\_detector, as a tool to measure engagement in a variety of settings.}
}

@inproceedings{lincoln34791,
          volume = {48},
           month = {September},
          author = {Sreedevi Kottayil and Panagiotis Tsoleridis and Kacper Rossa and Richard Connors and Charles Fox},
       booktitle = {15th World Conference on Transport Research},
           title = {Investigation of Driver Route Choice Behaviour using Bluetooth Data},
       publisher = {Elsevier},
            year = {2020},
         journal = {Transportation Research Procedia},
             doi = {10.1016/j.trpro.2020.08.065},
           pages = {632--645},
        keywords = {ARRAY(0x5568fbbbd770)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34791/},
        abstract = {Many local authorities use small-scale transport models to manage their transportation networks. These may assume drivers? behaviour to be rational in choosing the fastest route, and thus that all drivers behave the same given an origin and destination, leading to simplified aggregate flow models, fitted to anonymous traffic flow measurements. Recent price falls in traffic sensors, data storage, and compute power now enable Data Science to empirically test such assumptions, by using per-driver data to infer route selection from sensor observations and compare with optimal route selection. A methodology is presented using per-driver data to analyse driver route choice behaviour in transportation networks. Traffic flows on multiple measurable routes for origin destination pairs are compared based on the length of each route. A driver rationality index is defined by considering the shortest physical route between an origin-destination pair. The proposed method is intended to aid calibration of parameters used in traffic assignment models e.g. weights in generalized cost formulations or dispersion within stochastic user equilibrium models. The method is demonstrated using raw sensor datasets collected through Bluetooth sensors in the area of Chesterfield, Derbyshire, UK. The results for this region show that routes with a significant difference in lengths of their paths have the majority (71\%) of drivers using the optimal path but as the difference in length decreases, the probability of suboptimal route choice decreases (27\%). The methodology can be used for extended research considering the impact on route choice of other factors including travel time and road specific conditions.}
}

@inproceedings{lincoln43687,
           month = {September},
          author = {Hamid Isakhani and Shigang Yue and Caihua Xiong and Wenbin Chen and Xuelong Sun and Tian liu},
       booktitle = {5th International Conference on Advanced Robotics and Mechatronics (ICARM)},
           title = {Fabrication and Mechanical Analysis of Bioinspired Gliding-optimized Wing Prototypes for Micro Aerial Vehicles},
       publisher = {IEEE},
            year = {2020},
         journal = {2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM)},
             doi = {10.1109/ICARM49381.2020.9195392},
           pages = {602--608},
        keywords = {ARRAY(0x5568fb9c06e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43687/},
        abstract = {Gliding is the most efficient flight mode that is explicitly appreciated by natural fliers. This is achieved by high-performance structures developed over millions of years of evolution. One such prehistoric insect, locust (Schistocerca gregaria) is a perfect example of a natural glider capable of endured transatlantic flights, which could potentially inspire numerous solutions to the problems in aerospace engineering. However, biomimicry of such aerodynamic properties is hindered by the limitations of conventional as well as modern fabrication technologies in terms of precision and availability, respectively. Therefore, we explore and propose novel combinations of economical manufacturing methods to develop various locust-inspired tandem wing prototypes (i.e. fore and hindwings), for further wind tunnel based aerodynamic studies. Additionally, we determine the flexural stiffness and maximum deformation rate of our prototypes and compare it to their counterparts in nature and literature, recommending the most suitable artificial bioinspired wing for gliding micro aerial vehicle applications.}
}

@inproceedings{lincoln43680,
           month = {September},
          author = {Tian Liu and Xuelong Sun and Cheng Hu and Qinbing Fu and Hamid Isakhani and Shigang Yue},
       booktitle = {2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM)},
           title = {Investigating Multiple Pheromones in Swarm Robots - A Case Study of Multi-Robot Deployment},
       publisher = {IEEE},
             doi = {10.1109/ICARM49381.2020.9195311},
           pages = {595--601},
            year = {2020},
        keywords = {ARRAY(0x5568fba14808)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43680/},
        abstract = {Social insects are known as the experts in handling complex task in a collective smart way although their small brains contain only limited computation resources and sensory information. It is believed that pheromones play a vital role in shaping social insects' collective behaviours. One of the key points underlying the stigmergy is the combination of different pheromones in a specific task. In the swarm intelligence field, pheromone inspired studies usually focus one single pheromone at a time, so it is not clear how effectively multiple pheromones could be employed for a collective strategy in the real physical world. In this study, we investigate multiple pheromone-based deployment strategy for swarm robots inspired by social insects. The proposed deployment strategy uses two kinds of artificial pheromones; the attractive and the repellent pheromone that enables micro robots to be distributed in desired positions with high efficiency. The strategy is assessed systematically by both simulation and real robot experiments using a novel artificial pheromone platform ColCOS{\ensuremath{\Phi}}. Results from the simulation and real robot experiments both demonstrate the effectiveness of the proposed strategy and reveal the role of multiple pheromones. The feasibility of the ColCOS{\ensuremath{\Phi}} platform, and its potential for further robotic research on multiple pheromones are also verified. Our study of using different pheromones for one collective swarm robotics task may help or inspire biologists in real insects' research.}
}

@article{lincoln43658,
          volume = {8},
           month = {September},
          author = {Cheng Hu and Caihua Xiong and Jigen Peng and Shigang Yue},
           title = {Coping With Multiple Visual Motion Cues Under Extremely Constrained Computation Power of Micro Autonomous Robots},
       publisher = {IEEE},
            year = {2020},
         journal = {IEEE Access},
             doi = {10.1109/ACCESS.2020.3016893},
           pages = {159050--159066},
        keywords = {ARRAY(0x5568fbab1ef8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43658/},
        abstract = {The perception of different visual motion cues is crucial for autonomous mobile robots to react to or interact with the dynamic visual world. It is still a great challenge for a micro mobile robot to cope with dynamic environments due to the restricted computational resources and the limited functionalities of its visual systems. In this study, we propose a compound visual neural system to automatically extract and fuse different visual motion cues in real-time using the extremely constrained computation power of micro mobile robots. The proposed visual system contains multiple bio-inspired visual motion perceptive neurons each with a unique role, for example to extract collision visual cues, darker collision cue and directional motion cues. In the embedded system, these multiple visual neurons share a similar presynaptic network to minimise the consumption of computation resources. In the postsynaptic part of the system, visual cues pass results to corresponding action neurons using lateral inhibition mechanism. The translational motion cues, which are identified by comparing pairs of directional cues, are given the highest priority, followed by the darker colliding cues and approaching cues. Systematic experiments with both virtual visual stimuli and real-world scenarios have been carried out to validate the system's functionality and reliability. The proposed methods have demonstrated that (1) with extremely limited computation power, it is still possible for a micro mobile robot to extract multiple visual motion cues robustly in a complex dynamic environment; (2) the cues extracted can be fused with a lateral inhibited postsynaptic network, thus enabling the micro robots to respond effectively with different actions, accordingly to different states, in real-time. The proposed embedded visual system has been modularised and can be easily implemented in other autonomous mobile platforms for real-time applications. The system could also be used by neurophysiologists to test new hypotheses pertaining to biological visual neural systems.}
}

@inproceedings{lincoln43365,
       booktitle = {9th International Conference, Living Machines 2020},
           month = {September},
           title = {Improving Recall in an Associative Neural Network Model of the Hippocampus},
          author = {Nikolas Andreakos and Shigang Yue and Vassilis Cutsuridis},
       publisher = {Springer Nature},
            year = {2020},
        keywords = {ARRAY(0x5568fbab6458)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43365/},
        abstract = {The mammalian hippocampus is involved in auto-association and hetero-association of declarative
memories. We employed a bio-inspired neural model of hippocampal CA1 region to systematically
evaluate its mean recall quality against different number of stored patterns, overlaps and active cells per
pattern. Model consisted of excitatory (pyramidal cells) and four types of inhibitory cells: axo-axonic,
basket, bistratified, and oriens lacunosum-moleculare cells. Cells were simplified compartmental models
with complex ion channel dynamics. Cells? firing was timed to a theta oscillation paced by two distinct
neuronal populations exhibiting highly regular bursting activity, one tightly coupled to the trough and the
other to the peak of theta. During recall excitatory input to network excitatory cells provided context and
timing information for retrieval of previously stored memory patterns. Dendritic inhibition acted as a nonspecific
global threshold machine that removed spurious activity during recall. Simulations showed recall
quality improved when the network?s memory capacity increased as the number of active cells per pattern
decreased. Furthermore, increased firing rate of a presynaptic inhibitory threshold machine inhibiting a
network of postsynaptic excitatory cells has a better success at removing spurious activity at the network
level and improving recall quality than increased synaptic efficacy of the same threshold machine on the
same network of excitatory cells, while keeping its firing rate fixed.}
}

@inproceedings{lincoln41283,
           month = {August},
          author = {Soran Parsa and Disha Kamale and Sariah Mghames and Kiyanoush Nazari and Tommaso Pardi and Aravinda Srinivasan and Gerhard Neumann and Marc Hanheide and Amir Ghalamzan Esfahani},
       booktitle = {CASE 2020- International Conference on Automation Science and Engineering},
           title = {Haptic-guided shared control grasping: collision-free manipulation},
       publisher = {IEEE},
         journal = {International Conference on Automation Science and Engineering (CASE)},
             doi = {10.1109/CASE48305.2020.9216789},
            year = {2020},
        keywords = {ARRAY(0x5568fbb4d7a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41283/},
        abstract = {We propose a haptic-guided shared control system that provides an operator with force cues during reach-to-grasp phase of tele-manipulation. The force cues inform the operator of grasping configuration which allows collision-free autonomous post-grasp movements. Previous studies showed haptic guided shared control significantly reduces the complexities of the teleoperation. We propose two architectures of shared control in which the operator is informed about (1) the local gradient of the collision cost, and (2) the grasping configuration suitable for collision-free movements of an aimed pick-and-place task. We demonstrate the efficiency of our proposed shared control systems by a series of experiments with Franka Emika robot. Our experimental results illustrate our shared control systems successfully inform the operator of predicted collisions between the robot and an obstacle in the robot?s workspace. We learned that informing the operator of the global information about the grasping configuration associated with minimum collision cost of post-grasp movements results in a reach-to-grasp time much shorter than the case in which the operator is informed about the local-gradient information of the collision cost.}
}

@techreport{lincoln42273,
           month = {August},
            type = {Project Report},
           title = {The Future of Rural Mobility Study (FoRMS)},
          author = {Gary Bosworth and Charles Fox and Liz Price and Martin Collison},
       publisher = {Midlands Connect},
            year = {2020},
     institution = {Midlands Connect},
        keywords = {ARRAY(0x5568fbb7a8b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42273/},
        abstract = {Recognising the urban-focus of many national and regional transport strategies, the purpose of this project is to explore how emerging technologies could support rural economies across the Midlands. Fundamentally, the rationale for the study is to begin with an assessment of rural needs and then exploring a range of mobility innovations, including social innovations as well as technologies, that can provide place-based solutions designed for more rural areas. This avoids the National Transport Strategy assumption that new mobility innovations will inevitably occur in urban areas and then be rolled out across more rural places. While economic realities mean that many private sector transport innovations can start out in urban centres, their rural impacts may be quite different and require alternative responses from rural planners and policy-makers.}
}

@article{lincoln39037,
          volume = {12},
          number = {3},
           month = {July},
          author = {Serhan Cosar and Manuel Fernandez-Carmona and Roxana Agrigoroaie and Jordi Pages and Francois Ferland and Feng Zhao and Shigang Yue and Nicola Bellotto and Adriana Tapus},
           title = {ENRICHME: Perception and Interaction of an Assistive Robot for the Elderly at Home},
       publisher = {Springer},
            year = {2020},
         journal = {International Journal of Social Robotics},
             doi = {10.1007/s12369-019-00614-y},
           pages = {779--805},
        keywords = {ARRAY(0x5568fbb691f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39037/},
        abstract = {Recent technological advances enabled modern robots to become part of our daily life. In particular, assistive robotics emerged as an exciting research topic that can provide solutions to improve the quality of life of elderly and vulnerable people. This paper introduces the robotic platform developed in the ENRICHME project, with particular focus on its innovative perception and interaction capabilities. The project?s main goal is to enrich the day-to-day experience of elderly people at home with technologies that enable health monitoring, complementary care, and social support. The paper presents several modules created to provide cognitive stimulation services for elderly users with mild cognitive impairments. The ENRICHME robot was tested in three pilot sites around Europe (Poland, Greece, and UK) and proven to be an effective assistant for the elderly at home.}
}

@article{lincoln40049,
          volume = {31},
          number = {12},
           month = {July},
          author = {Iain J Gould and Isobel Wright and Martin Collison and Eric Ruto and Gary Bosworth and Simon Pearson},
           title = {The impact of coastal flooding on agriculture: a case study of Lincolnshire, United Kingdom},
       publisher = {Wiley},
            year = {2020},
         journal = {Land Degradation \& Development},
             doi = {10.1002/ldr.3551},
           pages = {1545--1559},
        keywords = {ARRAY(0x5568fbb382f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40049/},
        abstract = {Under future climate predictions the incidence of coastal flooding is set to rise. Many coastal regions at risk, such as those surrounding the North Sea, comprise large areas of low-lying and productive agricultural land. Flood risk assessments typically emphasise the economic consequences of coastal  flooding on urban areas and national infrastructure. Impacts on agricultural land have seen less attention, and considerations tend to omit the long term effects of soil salinity. The aim of this study is to develop a universal framework to evaluate the economic impact of coastal flooding to agriculture. We incorporated existing flood models, satellite acquired crop data, soil salinity and crop sensitivity to give a novel and detailed assessment of salt damage to agricultural productivity over time. We focussed our case study on low-lying, highly productive agricultural land with a history of flooding in Lincolnshire, UK. The potential impact of agricultural flood damage varied across our study region.Assuming typical cropping does not change post-flood, financial losses range from {\pounds}1,366/ha to {\pounds}5,526/ha per inundation; these losses would be reduced by between 35\% up to 85\% in the likely event  that an alternative, more salt-tolerant, cropping, regime is implemented post-flood. These losses are substantially higher than loses calculated on the same areas using established flood risk assessment framework conventionally used for freshwater flood assessments, with differences attributed to our longer term salt damage projections impacting over several years. This suggests flood protection policy needs to consider local and long terms impacts of flooding on agricultural land.}
}

@article{lincoln41706,
           month = {July},
           title = {Pedestrian Models for Autonomous Driving Part II: High-Level Models of Human Behavior},
          author = {Fanta Camara and Nicola Bellotto and Serhan Cosar and Florian Weber and Dimitris Nathanael and Matthias Althoff and Jingyuan Wu and Johannes Ruenz and Andre Dietrich and Gustav Markkula and Anna Schieben and Fabio Tango and Natasha Merat and Charles Fox},
       publisher = {IEEE},
            year = {2020},
             doi = {10.1109/TITS.2020.3006767},
         journal = {IEEE Transactions on Intelligent Transport Systems},
        keywords = {ARRAY(0x5568fba4aea0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41706/},
        abstract = {Abstract{--}Autonomous vehicles (AVs) must share space with pedestrians, both in carriageway cases such as cars at pedestrian crossings and off-carriageway cases such as delivery vehicles navigating through crowds on pedestrianized high-streets. Unlike static obstacles, pedestrians are active agents with complex, inter- active motions. Planning AV actions in the presence of pedestrians thus requires modelling of their probable future behaviour as well as detecting and tracking them. This narrative review article is Part II of a pair, together surveying the current technology stack involved in this process, organising recent research into a hierarchical taxonomy ranging from low-level image detection to high-level psychological models, from the perspective of an AV designer. This self-contained Part II covers the higher levels of this stack, consisting of models of pedestrian behaviour, from prediction of individual pedestrians? likely destinations and paths, to game-theoretic models of interactions between pedestrians and autonomous vehicles. This survey clearly shows that, although there are good models for optimal walking behaviour, high-level psychological and social modelling of pedestrian behaviour still remains an open research question that requires many conceptual issues to be clarified. Early work has been done on descriptive and qualitative models of behaviour, but much work is still needed to translate them into quantitative algorithms for practical AV control.}
}

@article{lincoln46139,
          volume = {15},
          number = {5},
           month = {July},
          author = {Mrudul Chellapurath and Sergio Stefanni and Graziano Fiorito and Angelo Maria Sabatini and Cecilia Laschi and Marcello Calisti},
           title = {Locomotory behaviour of the intertidal marble crab (Pachygrapsus marmoratus) supports the underwater spring-loaded inverted pendulum as a fundamental model for punting in animals},
            year = {2020},
         journal = {Bioinspiration \& Biomimetics},
             doi = {10.1088/1748-3190/ab968c},
           pages = {055004},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46139/},
        abstract = {In aquatic pedestrian locomotion the dynamics of terrestrial and aquatic environments are coupled. Here we study terrestrial running and aquatic punting locomotion of the marine-living crab Pachygrapsus marmoratus. We detected both active and passive phases of running and punting through the observation of crab locomotory behaviour in standardized settings and by three-dimensional kinematic analysis of its dynamic gaits using high-speed video cameras. Variations in different stride parameters were studied and compared. The comparison was done based on the dimensionless parameter the Froude number (Fr) to account for the effect of buoyancy and size variability among the crabs. The underwater spring-loaded inverted pendulum (USLIP) model better fitted the dynamics of aquatic punting. USLIP takes account of the damping effect of the aquatic environment, a variable not considered by the spring-loaded inverted pendulum (SLIP) model in reduced gravity. Our results highlight the underlying principles of aquatic terrestrial locomotion by comparing it with terrestrial locomotion. Comparing punting with running, we show and increased stride period, decreased duty cycle and orientation of the carapace more inclined with the horizontal plane, indicating the significance of fluid forces on the dynamics due to the aquatic environment. Moreover, we discovered periodicity in punting locomotion of crabs and two different gaits, namely, long-flight punting and short-flight punting, distinguished by both footfall patterns and kinematic parameters. The generic fundamental model which belongs to all animals performing both terrestrial and aquatic legged locomotion has implications for control strategies, evolution and translation to robotic artefacts.}
}

@article{lincoln48336,
          volume = {4},
          number = {3},
           month = {July},
          author = {Amr Mohamed and Chakravarthini Saaj and Asma Seddaoui and Manu Nair},
           title = {Linear controllers for free-flying and controlled-floating space robots: a new perspective},
       publisher = {MedCrave Group},
            year = {2020},
         journal = {Aeronautics and Aerospace Open Access Journal},
             doi = {10.15406/aaoaj.2020.04.00112},
           pages = {97--114},
        keywords = {ARRAY(0x5568fbb8c3d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48336/},
        abstract = {Autonomous space robots are crucial for performing future in-orbit operations, including 
servicing of a spacecraft, assembly of large structures, maintenance of other space assets 
and active debris removal. Such orbital missions require servicer spacecraft equipped with 
one or more dexterous manipulators. However, unlike its terrestrial counterpart, the base 
of the robotic manipulator is not fixed in inertial space; instead, it is mounted on the base?spacecraft, which itself possess both translational and rotational motions. Additionally, the 
system will be subjected to extreme environmental perturbations, parametric uncertainties 
and system constraints due to the dynamic coupling between the manipulator and the 
base-spacecraft. This paper presents the dynamic model of the space robot and a three?stage control algorithm for this highly dynamic non-linear system. In this approach, feed?forward compensation and feed-forward linearization techniques are used to decouple and 
linearize the highly non-linear system respectively. This approach allows the use of the 
linear Proportional-Integral-Derivative (PID) controller and Linear Quadratic Regulator 
(LQR) in the final stages. Moreover, this paper covers a simulation-based trade-off analysis 
to determine both proposed linear controllers? efficacy. This assessment considers precise 
trajectory tracking requirements whilst minimizing power consumption and improving 
robustness during the close-range operation with the target spacecraft.}
}

@inproceedings{lincoln43819,
           month = {July},
          author = {Hamid Isakhani and Caihua Xiong and Shigang Yue and Wenbin Chen},
       booktitle = {2020 17th International Conference on Ubiquitous Robots (UR)},
           title = {A Bioinspired Airfoil Optimization Technique Using Nash Genetic Algorithm},
       publisher = {IEEE},
             doi = {10.1109/UR49135.2020.9144868},
           pages = {506--513},
            year = {2020},
        keywords = {ARRAY(0x5568fba4a9a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43819/},
        abstract = {Natural fliers glide and minimize wing articulation to conserve energy for endured and long range flights. Elucidating the underlying physiology of such capability could potentially address numerous challenging problems in flight engineering. However, primitive nature of the bioinspired research impedes such achievements, hence to bypass these limitations, this study introduces a bioinspired non-cooperative multiple objective optimization methodology based on a novel fusion of PARSEC, Nash strategy, and genetic algorithms to achieve insect-level aerodynamic efficiencies. The proposed technique is validated on a conventional airfoil as well as the wing crosssection of a desert locust (Schistocerca gregaria) at low Reynolds number, and we have recorded a 77\% improvement in its gliding ratio.}
}

@article{lincoln41703,
          volume = {9},
           month = {July},
          author = {Xuelong Sun and Shigang Yue and Michael Mangan},
           title = {A decentralised neural model explaining optimal integration of navigational strategies in insects},
       publisher = {eLife Sciences Publications},
         journal = {eLife},
             doi = {10.7554/eLife.54026},
            year = {2020},
        keywords = {ARRAY(0x5568fbb46ac0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41703/},
        abstract = {Insect navigation arises from the coordinated action of concurrent guidance systems but the neural mechanisms through which each functions, and are then coordinated, remains unknown. We propose that insects require distinct strategies to retrace familiar routes (route-following) and directly return from novel to familiar terrain (homing) using different aspects of frequency encoded views that are processed in different neural pathways. We also demonstrate how the Central Complex and Mushroom Bodies regions of the insect brain may work in tandem to coordinate the directional output of different guidance cues through a contextually switched ring-attractor inspired by neural recordings. The resultant unified model of insect navigation reproduces behavioural data from a series of cue conflict experiments in realistic animal environments and offers testable hypotheses of where and how insects process visual cues, utilise the different information that they provide and coordinate their outputs to achieve the adaptive behaviours observed in the wild.}
}

@article{lincoln42805,
          volume = {396},
           month = {July},
          author = {Heriberto Cuayahuitl},
            note = {The final published version of this article can be accessed online at https://www.journals.elsevier.com/neurocomputing/},
           title = {A Data-Efficient Deep Learning Approach for Deployable Multimodal Social Robots},
       publisher = {Elsevier},
            year = {2020},
         journal = {Neurocomputing},
             doi = {10.1016/j.neucom.2018.09.104},
           pages = {587--598},
        keywords = {ARRAY(0x5568fbb85cd8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42805/},
        abstract = {The deep supervised and reinforcement learning paradigms (among others) have the potential to endow interactive multimodal social robots with the ability of acquiring skills autonomously. But it is still not very clear yet how they can be best deployed in real world applications. As a step in this direction, we propose a deep learning-based approach for efficiently training a humanoid robot to play multimodal games---and use the game of `Noughts {$\backslash$}\& Crosses' with two variants as a case study. Its minimum requirements for learning to perceive and interact are based on a few hundred example images, a few  example multimodal dialogues and physical demonstrations of robot manipulation, and automatic simulations. In addition, we propose novel algorithms for robust visual game tracking and for competitive policy learning with high winning rates, which substantially outperform DQN-based baselines. While an automatic evaluation shows evidence that the proposed approach can be easily extended to new games with competitive robot behaviours, a human evaluation with 130 humans playing with the \{{$\backslash$}it Pepper\} robot confirms that highly accurate visual perception is required for successful game play.}
}

@article{lincoln42133,
           month = {July},
           title = {Modelling Drosophila motion vision pathways for decoding the direction of translating objects against cluttered moving backgrounds},
          author = {Qinbing Fu and Shigang Yue},
       publisher = {Springer},
            year = {2020},
             doi = {10.1007/s00422-020-00841-x},
         journal = {Biological Cybernetics},
        keywords = {ARRAY(0x5568fbb85c90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42133/},
        abstract = {Decoding the direction of translating objects in front of cluttered moving backgrounds, accurately and ef?ciently, is still a challenging problem. In nature, lightweight and low-powered ?ying insects apply motion vision to detect a moving target in highly variable environments during ?ight, which are excellent paradigms to learn motion perception strategies. This paper investigates the fruit ?y Drosophila motion vision pathways and presents computational modelling based on cuttingedge physiological researches. The proposed visual system model features bio-plausible ON and OFF pathways, wide-?eld horizontal-sensitive (HS) and vertical-sensitive (VS) systems. The main contributions of this research are on two aspects: (1) the proposed model articulates the forming of both direction-selective and direction-opponent responses, revealed as principalfeaturesofmotionperceptionneuralcircuits,inafeed-forwardmanner;(2)italsoshowsrobustdirectionselectivity to translating objects in front of cluttered moving backgrounds, via the modelling of spatiotemporal dynamics including combination of motion pre-?ltering mechanisms and ensembles of local correlators inside both the ON and OFF pathways, which works effectively to suppress irrelevant background motion or distractors, and to improve the dynamic response. Accordingly, the direction of translating objects is decoded as global responses of both the HS and VS systems with positive ornegativeoutputindicatingpreferred-direction or null-direction translation.The experiments have veri?ed the effectiveness of the proposed neural system model, and demonstrated its responsive preference to faster-moving, higher-contrast and larger-size targets embedded in cluttered moving backgrounds.}
}

@inproceedings{lincoln39957,
       booktitle = {ICRA 2020},
           month = {July},
           title = {Enhancing Grasp Pose Computation in Gripper Workspace Spheres},
          author = {Mohamed Sorour and Khaled Elgeneidy and Marc Hanheide and Aravinda Srinivasan},
            year = {2020},
        keywords = {ARRAY(0x5568fba4b0e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39957/},
        abstract = {In this paper, enhancement to the novel grasp planning algorithm based on gripper workspace spheres is presented. Our development requires a registered point cloud of the target from different views, assuming no prior knowledge of the object, nor any of its properties. This work features
a new set of metrics for grasp pose candidates evaluation, as well as exploring the impact of high object sampling on grasp success rates. In addition to gripper position sampling, we now perform orientation sampling about the x, y, and z-axes, hence the grasping algorithm no longer require object orientation estimation. Successful experiments have been conducted on a simple jaw gripper (Franka Panda gripper) as well as a complex, high Degree of Freedom (DoF) hand (Allegro hand) as a proof of its versatility. Higher grasp success rates of 76\% and 85:5\% respectively has been reported by real world experiments.}
}

@article{lincoln41718,
          volume = {31},
          number = {6},
           month = {June},
          author = {Daqi Liu and Nicola Bellotto and Shigang Yue},
           title = {Deep Spiking Neural Network for Video-based Disguise Face Recognition Based on Dynamic Facial Movements},
       publisher = {IEEE},
            year = {2020},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
             doi = {10.1109/TNNLS.2019.2927274},
           pages = {1843--1855},
        keywords = {ARRAY(0x5568fb6f7990)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41718/},
        abstract = {With  the  increasing  popularity  of  social  media  andsmart  devices,  the  face  as  one  of  the  key  biometrics  becomesvital  for  person  identification.  Amongst  those  face  recognitionalgorithms, video-based face recognition methods could make useof  both  temporal  and  spatial  information  just  as  humans  do  toachieve  better  classification  performance.  However,  they  cannotidentify individuals when certain key facial areas like eyes or noseare disguised by heavy makeup or rubber/digital masks. To thisend, we propose a novel deep spiking neural network architecturein this study. It takes dynamic facial movements, the facial musclechanges induced by speaking or other activities, as the sole input.An  event-driven  continuous  spike-timing  dependent  plasticitylearning  rule  with  adaptive  thresholding  is  applied  to  train  thesynaptic weights. The experiments on our proposed video-baseddisguise  face  database  (MakeFace  DB)  demonstrate  that  theproposed learning method performs very well - it achieves from95\% to  100\% correct classification rates  under various realisticexperimental  scenarios}
}

@inproceedings{lincoln43425,
           month = {June},
          author = {Justin Le Louedec and Hector A. Montes and Tom Duckett and Grzegorz Cielniak},
       booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
           title = {Segmentation and detection from organised 3D point clouds: a case study in broccoli head detection},
       publisher = {IEEE},
             doi = {10.1109/CVPRW50498.2020.00040},
           pages = {285--293},
            year = {2020},
        keywords = {ARRAY(0x5568fba4a858)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43425/},
        abstract = {Autonomous harvesting is becoming an important challenge and necessity in agriculture, because of the lack of labour and the growth of population needing to be fed. Perception is a key aspect of autonomous harvesting and is very challenging due to difficult lighting conditions, limited sensing technologies, occlusions, plant growth, etc. 3D vision approaches can bring several benefits addressing the aforementioned challenges such as localisation, size estimation, occlusion handling and shape analysis. In this paper, we propose a novel approach using 3D information for detecting broccoli heads based on Convolutional Neural Networks (CNNs), exploiting the organised nature of the point clouds originating from the RGBD sensors. The proposed algorithm, tested on real-world datasets, achieves better performances than the state-of-the-art, with better accuracy and generalisation in unseen scenarios, whilst significantly reducing inference time, making it better suited for real-time in-field applications.}
}

@inproceedings{lincoln40182,
       booktitle = {IEEE RoboSoft 2020},
           month = {June},
           title = {Structural Optimization of Adaptive Soft Fin Ray Fingers with Variable Stiffening Capability},
          author = {Khaled Elgeneidy and Khaled Goher},
       publisher = {IEEE},
            year = {2020},
             doi = {10.1109/RoboSoft48309.2020.9115969},
        keywords = {ARRAY(0x5568fb678c58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40182/},
        abstract = {Soft and adaptable grippers are desired for their ability to operate effectively in unstructured or dynamically changing environments, especially when interacting with delicate or deformable targets. However, utilizing soft bodies often comes at the expense of reduced carrying payload and limited performance in high-force applications. Hence, methods for achieving variable stiffness soft actuators are being investigated to broaden the applications of soft grippers. This paper investigates the structural optimization of adaptive soft fingers based on the Fin Ray? effect (Soft Fin Ray), featuring a passive stiffening mechanism that is enabled via layer jamming between deforming flexible ribs. A finite element model of the proposed Soft Fin Ray structure is developed and experimentally validated, with the aim of enhancing the layer jamming behavior for better grasping performance. The results showed that through structural optimization, initial contact forces before jamming can be minimized and final contact forces after jamming can be significantly enhanced, without downgrading the desired passive adaptation to objects. Thus, applications for Soft Fin Ray fingers can range from adaptive delicate grasping to high-force manipulation tasks.}
}

@inproceedings{lincoln45041,
       booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
           month = {June},
           title = {Segmentation and detection from organised 3D point clouds: a case study in broccoli head detection},
          author = {Justin Le Louedec and Hector Montes and Tom Duckett and Grzegorz Cielniak},
       publisher = {IEEE},
            year = {2020},
        keywords = {ARRAY(0x5568fba497b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45041/},
        abstract = {Autonomous harvesting is becoming an important challenge and necessity in agriculture, because of the lack of labour and the growth of population needing to be fed. Perception is a key aspect of autonomous harvesting and is very challenging due to difficult lighting conditions, limited sensing technologies, occlusions, plant growth, etc. 3D vision approaches can bring several benefits addressing the aforementioned challenges such as localisation, size estimation, occlusion handling and shape analysis. In this paper, we propose a novel approach using 3D information for detecting broccoli heads based on Convolutional Neural Networks (CNNs), exploiting the organised nature of the point clouds originating from the RGBD sensors. The proposed algorithm, tested on real-world datasets, achieves better performances than the state-of-the-art, with better accuracy and generalisation in unseen scenarios, whilst significantly reducing inference time, making it better suited for real-time in-field applications.}
}

@article{lincoln41120,
          volume = {5},
          number = {3},
           month = {June},
          author = {Riccardo Polvara and Manuel Fernandez-Carmona and Marc Hanheide and Gerhard Neumann},
           title = {Next-Best-Sense: a multi-criteria robotic exploration strategy for RFID tags discovery},
       publisher = {IEEE},
            year = {2020},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2020.3001539},
           pages = {4477--4484},
        keywords = {ARRAY(0x5568fba4a8a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41120/},
        abstract = {Automated exploration is one of the most relevant applications of autonomous robots. In this paper, we suggest a novel online coverage algorithm called Next-Best-Sense (NBS), an extension of the Next-Best-View class of exploration algorithms that optimizes the exploration task balancing multiple criteria. This novel algorithm is applied to the problem of localizing all Radio Frequency Identification (RFID) tags with a mobile robotic platform that is equipped with a RFID reader. We cast this problem as a coverage planning problem by defining a basic sensing operation -- a scan with the RFID reader -- as the field of ?view? of the sensor. NBS evaluates candidate locations with a global utility function which combines utility values for travel distance, information gain, sensing time, battery status and RFID information gain, generalizing the use of Multi-Criteria Decision Making. We developed an RFID reader and tag model in the Gazebo simulator for validation. Experiments performed both in simulation and with a real robot suggest that our NBS approach can successfully localize all the RFID tags while minimizing navigation metrics such sensing operations, total traveling distance and battery consumption. The code developed is publicly available on the authors' repository.}
}

@article{lincoln42131,
          volume = {8},
           month = {June},
          author = {Qinbing Fu and Huatian Wang and Jigen Peng and Shigang Yue},
           title = {Improved Collision Perception Neuronal System Model with Adaptive Inhibition Mechanism and Evolutionary Learning},
       publisher = {IEEE},
            year = {2020},
         journal = {IEEE Access},
             doi = {10.1109/ACCESS.2020.3001396},
           pages = {108896--108912},
        keywords = {ARRAY(0x5568fba4ab10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42131/},
        abstract = {Accurate and timely perception of collision in highly variable environments is still a challenging problem for arti?cial visual systems. As a source of inspiration, the lobula giant movement detectors (LGMDs) in locust?s visual pathways have been studied intensively, and modelled as quick collision detectors against challenges from various scenarios including vehicles and robots. However, the state-of-the-art LGMD models have not achieved acceptable robustness to deal with more challenging scenarios like the various vehicle driving scenes, due to the lack of adaptive signal processing mechanisms. To address this problem, we propose an improved neuronal system model, called LGMD+, that is featured by novel modelling of spatiotemporal inhibition dynamics with biological plausibilities including 1) lateral inhibitionswithglobalbiasesde?nedbyavariantofGaussiandistribution,spatially,and2)anadaptivefeedforward inhibition mediation pathway, temporally. Accordingly, the LGMD+ performs more effectively to detect merely approaching objects threatening head-on collision risks by appropriately suppressing motion distractors caused by vibrations, near-miss or approaching stimuli with deviations from the centre view. Through evolutionary learning with a systematic dataset of various crash and non-collision driving scenarios, the LGMD+ shows improved robustness outperforming the previous related methods. After evolution, its computational simplicity, ?exibility and robustness have also been well demonstrated by real-time experiments of autonomous micro-mobile robots.}
}

@article{lincoln41217,
           month = {June},
           title = {Road users rarely use explicit communication when interacting in today?s traffic: implications for automated vehicles},
          author = {Yee Mun Lee and Ruth Madigan and Oscar Giles and Laura Garach?Morcillo and Gustav Markkula and Charles Fox and Fanta Camara and Markus Rothmueller and Signe Alexandra Vendelbo?Larsen and Pernille Holm Rasmussen and Andre Dietrich and Dimitris Nathanael and Villy Portouli and Anna Schieben and Natasha Merat},
       publisher = {Springer},
            year = {2020},
             doi = {10.1007/s10111-020-00635-y},
         journal = {Cognition, Technology \& Work},
        keywords = {ARRAY(0x5568fba4a948)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41217/},
        abstract = {To be successful, automated vehicles (AVs) need to be able to manoeuvre in mixed traffic in a way that will be accepted by
road users, and maximises traffic safety and efficiency. A likely prerequisite for this success is for AVs to be able to commu-
nicate effectively with other road users in a complex traffic environment. The current study, conducted as part of the European
project interACT, investigates the communication strategies used by drivers and pedestrians while crossing the road at six
observed locations, across three European countries. In total, 701 road user interactions were observed and annotated, using
an observation protocol developed for this purpose. The observation protocols identified 20 event categories, observed from
the approaching vehicles/drivers and pedestrians. These included information about movement, looking behaviour, hand
gestures, and signals used, as well as some demographic data. These observations illustrated that explicit communication
techniques, such as honking, flashing headlights by drivers, or hand gestures by drivers and pedestrians, rarely occurred.
This observation was consistent across sites. In addition, a follow-on questionnaire, administered to a sub-set of the observed
pedestrians after crossing the road, found that when contemplating a crossing, pedestrians were more likely to use vehicle-
based behaviour, rather than communication cues from the driver. Overall, the findings suggest that vehicle-based movement
information such as yielding cues are more likely to be used by pedestrians while crossing the road, compared to explicit
communication cues from drivers, although some cultural differences were observed. The implications of these findings are
discussed with respect to design of suitable external interfaces and communication of intent by future automated vehicles.}
}

@article{lincoln40882,
           month = {June},
           title = {Robot Perception of Static and Dynamic Objects with an Autonomous Floor Scrubber},
          author = {Zhi Yan and Simon Schreiberhuber and Georg Halmetschlager and Tom Duckett and Markus Vincze and Nicola Bellotto},
       publisher = {Springer},
            year = {2020},
             doi = {10.1007/s11370-020-00324-9},
         journal = {Intelligent Service Robotics},
        keywords = {ARRAY(0x5568fba49678)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40882/},
        abstract = {This paper presents the perception system of a new professional cleaning robot for large public places. The proposed system is based on multiple sensors including 3D and 2D lidar, two RGB-D cameras and a stereo camera. The two lidars together with an RGB-D camera are used for dynamic object (human) detection and tracking, while the second RGB-D and stereo camera are used for detection of static objects (dirt and ground objects). A learning and reasoning module for spatial-temporal representation of the environment based on the perception pipeline is also introduced. Furthermore, a new dataset collected with the robot in several public places, including a supermarket, a warehouse and an airport, is released.Baseline results on this dataset for further research and comparison are provided. The proposed system has been fully implemented into the Robot Operating System (ROS) with high modularity, also publicly available to the community.}
}

@inproceedings{lincoln42389,
           month = {May},
          author = {Adam Binch and Gautham Das and Jaime Pulido Fentanes and Marc Hanheide},
       booktitle = {2020 IEEE International Conference on Robotics and Automation (ICRA)},
           title = {Context Dependant Iterative Parameter Optimisation for Robust Robot Navigation},
       publisher = {IEEE},
             doi = {10.1109/ICRA40945.2020.9196550},
           pages = {3937--3943},
            year = {2020},
        keywords = {ARRAY(0x5568fb9dcc00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42389/},
        abstract = {Progress in autonomous mobile robotics has seen significant advances in the development of many algorithms for motion control and path planning. However, robust performance from these algorithms can often only be expected if the parameters controlling them are tuned specifically for the respective robot model, and optimised for specific scenarios in the environment the robot is working in. Such parameter tuning can, depending on the underlying algorithm, amount to a substantial combinatorial challenge, often rendering extensive manual tuning of these parameters intractable. In this paper, we present a framework that permits the use of different navigation actions and/or parameters depending on the spatial context of the navigation task, while considering the respective navigation algorithms themselves mostly as a "black box", and find suitable parameters by means of an iterative optimisation, improving for performance metrics in simulated environments. We present a genetic algorithm incorporated into the framework and empirically show that the resulting parameter sets lead to substantial performance improvements in both simulated and real-world environments in the domain of agricultural robots.}
}

@article{lincoln38163,
          volume = {117},
           month = {May},
          author = {Ibrahim Albayati and Andrey Postnikov and Simon Pearson and Ronald Bickerton and Argyrios Zolotas and Chris Bingham},
           title = {Power and Energy Analysis for a Commercial Retail Refrigeration System Responding to a Static Demand Side Response},
       publisher = {Elsevier},
            year = {2020},
         journal = {International Journal of Electrical Power \& Energy Systems},
             doi = {10.1016/j.ijepes.2019.105645},
           pages = {105645},
        keywords = {ARRAY(0x5568fb9dcc48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38163/},
        abstract = {The paper considers the impact of Demand Side Response events on supply power profile and energy efficiency of widely distributed aggregated loads applied across commercial refrigeration systems. Responses to secondary grid frequency static DSR events are investigated. Experimental trials are conducted on a system of refrigerators representing a small retail store, and subsequently on the refrigerators of an operational superstore in the UK. Energy consumption and energy savings during 3 hours of operation, pre and post-secondary DSR, are discussed. In addition, a simultaneous secondary DSR event is realised across three operational retail stores located in different geographical regions of the UK. A Simulink model for a 3{\ensuremath{\Phi}} power network is used to investigate the impact of a synchronised return to normal operation of the aggregated refrigeration systems post DSR on the local power network. Results show {\texttt{\char126}}1\% drop in line voltage due to the synchronised return to operation. An analysis of energy consumption shows that DSR events can facilitate energy savings of between 3.8\% and 9.3\% compared to normal operation. This is a result of the refrigerators operating more efficiently during and shortly after the DSR. The use of aggregated refrigeration loads can contribute to the necessary load-shed by 97.3\% at the beginning of DSR and 27\% during 30 minutes DSR, based on a simultaneous DSR event carried out on three retail stores.}
}

@inproceedings{lincoln43349,
           month = {May},
          author = {Li Sun and Daniel Adolfsson and Martin Magnusson and Henrik Andreasson and Ingmar Posner and Tom Duckett},
       booktitle = {2020 IEEE International Conference on Robotics and Automation (ICRA)},
           title = {Localising Faster: Efficient and precise lidar-based robot localisation in large-scale environments},
       publisher = {IEEE},
             doi = {10.1109/ICRA40945.2020.9196708},
           pages = {4386--4392},
            year = {2020},
        keywords = {ARRAY(0x5568fb9dcc30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43349/},
        abstract = {This paper proposes a novel approach for global localisation of mobile robots in large-scale environments. Our method leverages learning-based localisation and filtering-based localisation, to localise the robot efficiently and precisely through seeding Monte Carlo Localisation (MCL) with a deep learned distribution. In particular, a fast localisation system rapidly estimates the 6-DOF pose through a deep-probabilistic model (Gaussian Process Regression with a deep kernel), then a precise recursive estimator refines the estimated robot pose according to the geometric alignment. More importantly, the Gaussian method (i.e. deep probabilistic localisation) and non-Gaussian method (i.e. MCL) can be integrated naturally via importance sampling. Consequently, the two systems can be integrated seamlessly and mutually benefit from each other. To verify the proposed framework, we provide a case study in large-scale localisation with a 3D lidar sensor. Our experiments on the Michigan NCLT long-term dataset show that the proposed method is able to localise the robot in 1.94 s on average (median of 0.8 s) with precision 0.75 m in a large-scale environment of approximately 0.5 km 2 .}
}

@article{lincoln46143,
          volume = {5},
          number = {42},
           month = {May},
          author = {G. Picardi and M. Chellapurath and S. Iacoponi and S. Stefanni and C. Laschi and M. Calisti},
           title = {Bioinspired underwater legged robot for seabed exploration with low environmental disturbance},
            year = {2020},
         journal = {Science Robotics},
             doi = {10.1126/scirobotics.aaz1012},
           pages = {eaaz1012},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46143/},
        abstract = {Robots have the potential to assist and complement humans in the study and exploration of extreme and hostile environments. For example, valuable scientific data have been collected with the aid of propeller-driven autonomous and remotely operated vehicles in underwater operations. However, because of their nature as swimmers, such robots are limited when closer interaction with the environment is required. Here, we report a bioinspired underwater legged robot, called SILVER2, that implements locomotion modalities inspired by benthic animals (organisms that harness the interaction with the seabed to move; for example, octopi and crabs). Our robot can traverse irregular terrains, interact delicately with the environment, approach targets safely and precisely, and hold position passively and silently. The capabilities of our robot were validated through a series of field missions in real sea conditions in a depth range between 0.5 and 12 meters.}
}

@article{lincoln48337,
          volume = {65},
          number = {10},
           month = {May},
          author = {Lucy Jackson and Chakravarthini M. Saaj and Asma Seddaoui and Calem Whiting and Steve Eckersley and Simon Hadfield},
           title = {Downsizing an orbital space robot: A dynamic system based evaluation},
       publisher = {Elsevier},
            year = {2020},
         journal = {Advances in Space Research},
             doi = {10.1016/j.asr.2020.03.004},
           pages = {2247--2262},
        keywords = {ARRAY(0x5568fb9dccd8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48337/},
        abstract = {Small space robots have the potential to revolutionise space exploration by facilitating the on-orbit assembly of infrastructure, in shorter time scales, at reduced costs. Their commercial appeal will be further improved if such a system is also capable of performing on-orbit servicing missions, in line with the current drive to limit space debris and prolong the lifetime of satellites already in orbit. Whilst there have been a limited number of successful demonstrations of technologies capable of these on-orbit operations, the systems remain large and bespoke. The recent surge in small satellite technologies is changing the economics of space and in the near future, downsizing a space robot might become be a viable option with a host of benefits. This industry wide shift means some of the technologies for use with
a downsized space robot, such as power and communication subsystems, now exist. However, there are still dynamic and control issues that need to be overcome before a downsized space robot can be capable of undertaking useful missions. This paper first outlines these issues, before analyzing the effect of downsizing a system on its operational capability. Therefore presenting the smallest controllable system such that the benefits of a small space robot can be achieved with current technologies. The sizing of the base spacecraft and manipulator are addressed here. The design presented consists of a 3 link, 6 degrees of freedom robotic manipulator mounted on a 12U form factor satellite. The feasibility of this 12U space robot was evaluated in simulation and the in-depth results presented here support the hypothesis that a small space robot is a viable solution for in-orbit operations.}
}

@inproceedings{lincoln45011,
           month = {May},
          author = {Tsvetan Zhivkov and Elizabeth Sklar},
       booktitle = {3rd UK-RAS Conference},
           title = {Modelling variable communication signal strength for experiments with multi-robot teams},
       publisher = {UK-RAS},
             doi = {10.31256/Ld2Re8B},
           pages = {128--130},
            year = {2020},
        keywords = {ARRAY(0x5568fb9dccc0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45011/},
        abstract = {Reliable communication is a critical factor for ensuring robust performance of multi-robot teams. A selection of results are presented here comparing the impact of poor network quality on team performance under several conditions. Two different processes for emulating degraded network signal strength are compared in a physical environment: modelled signal degradation (MSD), approximated according to increasing distance from a connected network node (ie robot), versus effective signal degradation (ESD). The results of both signal strength processes exhibit similar trends, demonstrating that ESD in a physical environment can be modelled relatively well using MSD.}
}

@inproceedings{lincoln40029,
       booktitle = {8th Transport Research Arena TRA 2020},
           month = {April},
           title = {Examining Pedestrian-Autonomous Vehicle Interactions in Virtual Reality},
          author = {Fanta Camara and Patrick Dickenson and Natasha Merat and Charles Fox},
            year = {2020},
        keywords = {ARRAY(0x5568fba5cc50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40029/},
        abstract = {Autonomous vehicles now have well developed algorithms and open source software for localisation and
navigation in static environments but their future interactions with other road users in mixed traffic
environments, especially with pedestrians, raise some concerns. Pedestrian behaviour is complex to model and
unpredictable, thus creating a big challenge for self-driving cars. This paper examines pedestrian behaviour
during crossing scenarios with a game theoretic autonomous vehicle in virtual reality. In a first experiment, we
recorded participants? trajectories and found that they were crossing more cautiously in VR than in previous
laboratory experiments. In two other experiments, we used a gradient descent approach to investigate
participants? preference for a certain AV driving style. We found that the majority of them were not expecting the
car to stop in these scenarios. These results suggest that VR is an interesting tool for testing autonomous vehicle
algorithms and for finding out about pedestrian preferences.}
}

@article{lincoln39383,
          volume = {5},
          number = {2},
           month = {April},
          author = {Daniel De Barrie and Rebecca Margetts and Khaled Goher},
           title = {SIMPA: Soft-Grasp Infant Myoelectric Prosthetic Arm},
       publisher = {IEEE},
            year = {2020},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2019.2963820},
           pages = {699--704},
        keywords = {ARRAY(0x5568fbb72d50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39383/},
        abstract = {Myoelectric prosthetic arms have primarily focused on adults, despite evidence showing the benefits of early adoption. This work presents SIMPA, a low-cost 3D-printed prosthetic arm with soft grippers. The arm has been designed using CAD and 3D-scanning, and manufactured using
predominantly 3D-printing techniques. A voluntary opening control system utilizing an armband-based sEMG has been developed concurrently. Grasp tests have resulted in an average effectiveness of 87\%, with objects in excess of 400g being securely grasped. The results highlight the effectiveness of soft grippers as an end device in prosthetics, as well as the viability of toddler scale myoelectric devices.}
}

@article{lincoln33420,
          volume = {50},
          number = {4},
           month = {April},
          author = {Hongxin Wang and Jigen Peng and Shigang Yue},
            note = {The final published version of this article can be accessed online at https://ieeexplore.ieee.org/document/8485659},
           title = {A Directionally Selective Small Target Motion Detecting Visual Neural Network in Cluttered Backgrounds},
       publisher = {IEEE},
            year = {2020},
         journal = {IEEE Transactions on Cybernetics},
             doi = {10.1109/TCYB.2018.2869384},
           pages = {1541--1555},
        keywords = {ARRAY(0x5568fba428f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33420/},
        abstract = {Discriminating targets moving against a cluttered background is a huge challenge, let alone detecting a target as small as one or a few pixels and tracking it in flight. In the insect's visual system, a class of specific neurons, called small target motion detectors (STMDs), have been identified as showing exquisite selectivity for small target motion. Some of the STMDs have also demonstrated direction selectivity which means these STMDs respond strongly only to their preferred motion direction. Direction selectivity is an important property of these STMD neurons which could contribute to tracking small targets such as mates in flight. However, little has been done on systematically modeling these directionally selective STMD neurons. In this paper, we propose a directionally selective STMD-based neural network for small target detection in a cluttered background. In the proposed neural network, a new correlation mechanism is introduced for direction selectivity via correlating signals relayed from two pixels. Then, a lateral inhibition mechanism is implemented on the spatial field for size selectivity of the STMD neurons. Finally, a population vector algorithm is used to encode motion direction of small targets. Extensive experiments showed that the proposed neural network not only is in accord with current biological findings, i.e., showing directional preferences, but also worked reliably in detecting small targets against cluttered backgrounds.}
}

@inproceedings{lincoln47565,
           month = {April},
          author = {Mohammed Al-Khafajiy and Shatha Ghareeb and Rawaa Al-Jumeily and Rusul Almurshedi and Aseel Hussien and Thar Baker and Yaser Jararweh},
       booktitle = {2019 12th International Conference on Developments in eSystems Engineering (DeSE)},
           title = {A Holistic Study on Emerging IoT Networking Paradigms},
       publisher = {IEEE},
             doi = {10.1109/DeSE.2019.00175},
           pages = {943--949},
            year = {2020},
        keywords = {ARRAY(0x5568fbbbce10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47565/},
        abstract = {With the emerge of Internet of Things, billions of devices and humans are connected directly or indirectly to the internet. This significant growth in the number of connected devices rises the needs for a new development for the current network paradigm (e.g., cloud computing). The new network paradigm, such as fog computing, along with its related edge computing paradigms, are seen as promising solutions for handling the large volume of securely-critical and delay-sensitive data that is being produced by the IoT nodes. In this paper, we give a brief overview on the IoT related computing paradigms, including their similarities and differences as well as challenges. Next, we provide a summary of the challenges and processing and storage capabilities of each network paradigm.}
}

@incollection{lincoln47572,
           month = {April},
          author = {Mohammed Al-Khafajiy and Thar Baker and Aseel Hussien and Alison Cotgrave},
       booktitle = {Unmanned Aerial Vehicles in Smart Cities},
           title = {UAV and Fog Computing for IoE-Based Systems: A Case Study on Environment Disasters Prediction and Recovery Plans},
       publisher = {Springer},
            year = {2020},
         journal = {UAV and Fog Computing for IoE-Based Systems: A Case Study on Environment Disasters Prediction and Recovery Plans},
             doi = {10.1007/978-3-030-38712-9\_8},
           pages = {133--152},
        keywords = {ARRAY(0x5568fb9c9d20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47572/},
        abstract = {In the past few years, an exponential upsurge in the development and use of the Internet of Everything (IoE)-based systems has evolved. IoE-based systems bring together the power of embedded smart things (e.g., sensors and actuators), flying-things (e.g., drones), and machine learning and data processing mediums (e.g., fog and edge computing) to create intelligent and powerful networked systems. These systems benefit various aspects of our modern smart cities{--}ranging from healthcare and smart homes to smart motorways, for example, via making informed decisions. In IoE-based systems, sensors sense the surrounding environment and return data for processing: Unmanned aerial vehicles (UAVs) survey and scan areas that are difficult to reach by human beings (e.g., oceans and mountains), and machine learning algorithms are used to classify data, interpret and learn from collected data over fog and edge computing nodes. In fact, the integration of UAVs, fog computing and machine learning provides fast, cost-effective and safe deployments for many civil and military applications. While fog computing is a new network paradigm of distributed computing nodes at the edge of the network, fog extends the cloud?s capability to the edge to provide better quality of service (QoS), and it is particularly suitable for applications that have strict requirements on latency and reliability. Also, fog computing has the advantage of providing the support of mobility, location awareness, scalability and efficient integration with other systems such as cloud computing. Fog computing and UAV are an integral part of the future information and communication technologies (ICT) that are able to achieve higher functionality, optimised resources utilisation and better management to improve both quality of service (QoS) and quality of experiences (QoE). Such systems that can combine both these technologies are natural disaster prediction systems, which could use fog-based algorithms to predict and warn for upcoming disaster threats, such as floods. The fog computing algorithms use data to make decisions and predictions from both the embedded-sensors, such as environmental sensors and data from flying-things, such as data from UAV that include live images and videos.}
}

@inproceedings{lincoln42418,
       booktitle = {6th International Conference on Control, Automation and Robotics (ICCAR)},
           month = {April},
           title = {Agri-Cost-Maps ? Integration of Environmental Constraints into Navigation Systems for Agricultural Robot},
          author = {Vignesh Raja Ponnambalam and Jaime Pulido Fentanes and Gautham Das and Grzegorz Cielniak and Jon Glenn Omholt Gjevestad and Pal From},
       publisher = {IEEE},
            year = {2020},
             doi = {10.1109/ICCAR49639.2020.9108030},
        keywords = {ARRAY(0x5568fba1b388)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42418/},
        abstract = {Robust navigation is a key ability for agricultural robots. Such robots must operate safely minimizing their impact on the soil and avoiding crop damage. This paper proposes a method for unified incorporation of the application-specific constraints into the navigation system of robots deployed in different agricultural environments. The constraints are incorporated as an additional cost-map layer into the ROS navigation stack. These so-called Agri-Cost-Maps facilitate the transition from the tailored navigation systems typical for the current generation of agricultural robots to a more flexible ROS-based navigation framework that can be easily deployed for different agricultural applications. We demonstrate the applicability of this framework in three different agricultural scenarios, evaluate its benefits in simulation and demonstrate its validity in a real-world setting.}
}

@inproceedings{lincoln42458,
       booktitle = {6th International Conference on Control, Automation and Robotics (ICCAR)},
           month = {April},
           title = {Agri-Cost-Maps - Integration of Environmental Constraints into Navigation Systems for Agricultural Robots},
          author = {Vignesh Raja Ponnambalam and Jaime Pulido Fentanes and Gautham Das and Grzegorz Cielniak and Jon Glenn Omholt Gjevestad and P{\r a}l Johan From},
       publisher = {IEEE},
            year = {2020},
             doi = {10.1109/ICCAR49639.2020.9108030},
        keywords = {ARRAY(0x5568fbb0b5b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42458/},
        abstract = {Robust navigation is a key ability for agricultural robots. Such robots must operate safely minimizing their impact on the soil and avoiding crop damage. This paper proposes a method for unified incorporation of the application-specific constraints into the navigation system of robots deployed in different agricultural environments. The constraints are incorporated as an additional cost-map layer into the ROS navigation stack. These so-called Agri-Cost-Maps facilitate the transition from the tailored navigation systems typical for the current generation of agricultural robots to a more flexible ROS-based navigation framework that can be easily deployed for different agricultural applications. We demonstrate the applicability of this framework in three different agricultural scenarios, evaluate its benefits in simulation and demonstrate its validity in a real-world setting.}
}

@inproceedings{lincoln46369,
           month = {April},
          author = {Pratik Somaiya and Marc Hanheide and Grzegorz Cielniak},
       booktitle = {UKRAS20 Conference: ?Robots into the real world?},
           title = {Unsupervised Anomaly Detection for Safe Robot Operations},
       publisher = {UKRAS},
             doi = {10.31256/Wg7Ap8J},
           pages = {154--156},
            year = {2020},
        keywords = {ARRAY(0x5568fbb67348)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46369/},
        abstract = {Faults in robot operations are risky, particularly when robots are operating in the same environment as humans. Early detection of such faults is necessary to prevent further escalation and endangering human life. However, due to sensor noise and unforeseen faults in robots, creating a model for fault prediction is difficult. Existing supervised data-driven approaches rely on large amounts of labelled data for detecting anomalies, which is impractical in real applications. In this paper, we present an unsupervised machine learning approach for this purpose, which requires only data corresponding to the normal operation of the robot. We demonstrate how to fuse multi-modal information from robot motion sensors and evaluate the proposed framework in multiple scenarios collected from a real mobile robot.}
}

@article{lincoln41285,
          volume = {5},
          number = {2},
           month = {April},
          author = {Tommaso Pardi and Valerio Ortenzi and Colin Fairbairn and Tony Pipe and Amir Ghalamzan Esfahani and Rustam Stolkin},
           title = {Planning maximum-manipulability cutting paths},
       publisher = {IEEE},
            year = {2020},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2020.2970949},
           pages = {1999--2006},
        keywords = {ARRAY(0x5568fbbb8920)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41285/},
        abstract = {This paper presents a method for constrained motion planning from vision, which enables a robot to move its end-effector over an observed surface, given start and destination points. The robot has no prior knowledge of the surface shape but observes it from a noisy point cloud. We consider the multi-objective optimisation problem of finding robot trajectories which maximise the robot?s manipulability throughout the motion, while also minimising surface-distance travelled between the two points. This work has application in industrial problems of rough robotic cutting, e.g., demolition of the legacy nuclear plant, where the cut path needs not be precise as long as it achieves dismantling. We show how detours in the path can be leveraged to increase the manipulability of the robot at all points along the path. This helps to avoid singularities while maximising the robot?s capability to make small deviations during task execution. We show how a sampling-based planner can be projected onto the Riemannian manifold of a curved surface, and extended to include a term which maximises manipulability. We present the results of empirical experiments, with both simulated and real robots, which are tasked with moving over a variety of different surface shapes. Our planner enables successful task completion while ensuring significantly greater manipulability when compared against a conventional RRT* planner.}
}

@article{lincoln40529,
          volume = {2},
          number = {12},
           month = {April},
          author = {Wayne Martindale and Simon Pearson and Mark Swainson and Lilian Korir and Isobel Wright and Arnold M. Opiyo and Benard Karanja and Samuel Nyalala and Mahesh Kumar},
           title = {Framing food security and food loss statistics for incisive supply chain improvement and knowledge transfer between Kenyan, Indian and United Kingdom food manufacturers},
       publisher = {Emerald},
            year = {2020},
         journal = {Emerald Open Research},
             doi = {10.35241/emeraldopenres.13414.1},
        keywords = {ARRAY(0x5568fba1a788)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40529/},
        abstract = {The application of global indices of nutrition and food sustainability in public health and the improvement of product profiles has facilitated effective actions that increase food security. In the research reported here we develop index measurements further so that they can be applied to food categories and be used by food processors and manufacturers for specific food supply chains. This research considers how they can be used to assess the sustainability of supply chain operations by stimulating more incisive food loss and waste reduction planning. The research demonstrates how an index driven approach focussed on improving both nutritional delivery and reducing food waste will result in improved food security and sustainability. Nutritional improvements are focussed on protein supply and reduction of food waste on supply chain losses and the methods are tested using the food systems of Kenya and India where the current research is being deployed. Innovative practices will emerge when nutritional improvement and waste reduction actions demonstrate market success, and this will result in the co-development of food manufacturing infrastructure and innovation programmes. The use of established indices of sustainability and security enable comparisons that encourage knowledge transfer and the establishment of cross-functional indices that quantify national food nutrition, security and sustainability. The research presented in this initial study is focussed on applying these indices to specific food supply chains for food processors and manufacturers.}
}

@inproceedings{lincoln44710,
          volume = {34},
          number = {10},
           month = {April},
          author = {Helen Harman and Pieter Simoens},
       booktitle = {The Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)},
           title = {Action Graphs for Goal Recognition Problems with Inaccurate Initial States (Student Abstract)},
       publisher = {PKP Publishing Services Network},
            year = {2020},
         journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
             doi = {10.1609/aaai.v34i10.7174},
           pages = {13805--13806},
        keywords = {ARRAY(0x5568fbb4a4e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44710/},
        abstract = {Goal recognisers attempt to infer an agent's intentions from a sequence of observations. Approaches that adapt classical planning techniques to goal recognition have previously been proposed but, generally, they assume the initial world state is accurately defined. In this paper, a state is inaccurate if any fluent's value is unknown or incorrect. To cope with this, a cyclic Action Graph, which models the order constraints between actions, is traversed to label each node with their distance from each hypothesis goal. These distances are used to calculate the posterior goal probabilities. Our experimental results, for 15 different domains, demonstrate that our approach is unaffected by an inaccurately defined initial state.}
}

@article{lincoln35778,
          volume = {98},
          number = {1},
           month = {April},
          author = {Serhan Cosar and Nicola Bellotto},
           title = {Human Re-Identification with a Robot Thermal Camera using Entropy-based Sampling},
       publisher = {Springer},
            year = {2020},
         journal = {Journal of Intelligent and Robotic Systems},
             doi = {10.1007/s10846-019-01026-w},
           pages = {85--102},
        keywords = {ARRAY(0x5568fbb376e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35778/},
        abstract = {Human re-identification is an important feature of domestic service robots, in particular for elderly monitoring and assistance, because it allows them to perform personalized tasks and human-robot interactions. However vision-based re-identification systems are subject to limitations due to human pose and poor lighting conditions. This paper presents a new re-identification method for service robots using thermal images. In robotic applications, as the number and size of thermal datasets is limited, it is hard to use approaches that require huge amount of training samples. We propose a re-identification system that can work using only a small amount of data. During training, we perform entropy-based sampling to obtain a thermal dictionary for each person. Then, a symbolic representation is produced by converting each video into sequences of dictionary elements. Finally, we train a classifier using this symbolic representation and geometric distribution within the new representation domain. The experiments are performed on a new thermal dataset for human re-identification, which includes various situations of human motion, poses and occlusion, and which is made publicly available for research purposes. The proposed approach has been tested on this dataset and its improvements over standard approaches have been demonstrated.}
}

@inproceedings{lincoln41273,
           month = {April},
          author = {Xiaodong Li and Charles Fox and Shaun Coutts},
       booktitle = {UKRAS20},
           title = {Deep learning for robotic strawberry harvesting},
       publisher = {UK-RAS},
             doi = {10.31256/Bj3Kl5B},
           pages = {80--82},
            year = {2020},
        keywords = {ARRAY(0x5568fbb499b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41273/},
        abstract = {Abstract{--}We develop a novel machine learning based robotic
strawberry harvesting system for fruit counting, sizing/weighting,
and yield prediction.}
}

@article{lincoln47559,
          volume = {137},
           month = {March},
          author = {Mohammed Al-Khafajiy and Thar Baker and Muhammad Asim and Zehua Guo and Rajiv Ranjan and Antonella Longo and Deepak Puthal and Mark Taylor},
           title = {COMITMENT: A Fog Computing Trust Management Approach},
       publisher = {Elsevier},
            year = {2020},
         journal = {Journal of Parallel and Distributed Computing},
             doi = {10.1016/j.jpdc.2019.10.006},
           pages = {1--16},
        keywords = {ARRAY(0x5568fbb61540)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47559/},
        abstract = {As an extension of cloud computing, fog computing is considered to be relatively more secure than cloud computing due to data being transiently maintained and analyzed on local fog nodes closer to data sources. However, there exist several security and privacy concerns when fog nodes collaborate and share data to execute certain tasks. For example, offloading data to a malicious fog node can result into an unauthorized collection or manipulation of users? private data. Cryptographic-based techniques can prevent external attacks, but are not useful when fog nodes are already authenticated and part of a networks using legitimate identities. We therefore resort to trust to identify and isolate malicious fog nodes and mitigate security, respectively. In this paper, we present a fog COMputIng Trust manageMENT (COMITMENT) approach that uses quality of service and quality of protection history measures from previous direct and indirect fog node interactions for assessing and managing the trust level of the nodes within the fog computing environment. Using COMITMENT approach, we were able to reduce/identify the malicious attacks/interactions among fog nodes by approximately 66\%, while reducing the service response time by approximately 15s.}
}

@inproceedings{lincoln40509,
       booktitle = {Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction},
           month = {March},
           title = {Automatic Assessment and Learning of Robot Social Abilities},
          author = {Francesco Del Duchetto and Paul Baxter and Marc Hanheide},
            year = {2020},
           pages = {561--563},
             doi = {10.1145/3371382.3377430},
        keywords = {ARRAY(0x5568fbb49a00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40509/},
        abstract = {One of the key challenges of current state-of-the-art robotic deployments in public spaces, where the robot is supposed to interact with humans, is the generation of behaviors that are engaging for the users. Eliciting engagement during an interaction, and maintaining it after the initial phase of the interaction, is still an issue to be overcome. There is evidence that engagement in learning activities is higher in the presence of a robot, particularly if novel [1], but after the initial engagement state, long and non-interactive behaviors are detrimental to the continued engagement of the users [5, 16]. Overcoming this limitation requires to design robots with enhanced social abilities that go past monolithic behaviours and introduces in-situ learning and adaptation to the specific users and situations. To do so, the robot must have the ability to perceive the state of the humans participating in the interaction and use this feedback for the selection of its own actions over time [27].}
}

@inproceedings{lincoln47564,
           month = {March},
          author = {Mohammed Al-Khafajiy and Thar Baker and Atif Waraich and Omar Alfandi and Aseel Hussien},
       booktitle = {2019 IEEE/ACS 16th International Conference on Computer Systems and Applications (AICCSA)},
           title = {Enabling High Performance Fog Computing through Fog-2-Fog Coordination Model},
       publisher = {IEEE},
             doi = {10.1109/AICCSA47632.2019.9035353},
           pages = {1--6},
            year = {2020},
        keywords = {ARRAY(0x5568fbad0a78)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47564/},
        abstract = {Fog computing is a promising network paradigm in the IoT area as it has a great potential to reduce processing time for time-sensitive IoT applications. However, fog can get congested very easily due to fog resources limitations in term of capacity and computational power. In this paper, we tackle the issue of fog congestion through a request offloading algorithm. The result shows that the performance of fogs nodes can be increased be sharing fog's overload over several fog nodes. The proposed offloading algorithm could have the potential to achieve a sustainable network paradigm and highlights the significant benefits of fog offloading for the future networking paradigm.}
}

@article{lincoln44711,
          volume = {12},
          number = {2},
           month = {March},
          author = {Helen Harman and Pieter Simoens},
           title = {Action graphs for proactive robot assistance in smart environments},
       publisher = {IOS Press},
            year = {2020},
         journal = {Journal of Ambient Intelligence and Smart Environments},
             doi = {10.3233/AIS-200556},
           pages = {79--99},
        keywords = {ARRAY(0x5568fb9bcb20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44711/},
        abstract = {Smart environments can already observe the actions of a human through pervasive sensors. Based on these observations, our work aims to predict the actions a human is likely to perform next. Predictions can enable a robot to proactively assist humans by autonomously executing an action on their behalf. In this paper, Action Graphs are introduced to model the order constraints between actions. Action Graphs are derived from a problem defined in Planning Domain Definition Language (PDDL). When an action is observed, the node values are updated and next actions predicted. Subsequently, a robot executes one of the predicted actions if it does not impact the flow of the human by obstructing or delaying them. Our Action Graph approach is applied to a kitchen domain.}
}

@article{lincoln41223,
          volume = {16},
           month = {March},
          author = {Junfeng Gao and Andrew French and Michael Pound and Yong He and Tony Pridmore and Jan Pieters},
           title = {Deep convolutional neural networks for image-based Convolvulus sepium detection in sugar beet fields},
       publisher = {BMC},
            year = {2020},
         journal = {Plant Methods},
             doi = {10.1186/s13007-020-00570-z},
           pages = {19},
        keywords = {ARRAY(0x5568fbad0dc0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41223/},
        abstract = {Background
Convolvulus sepium (hedge bindweed) detection in sugar beet fields remains a challenging problem due to variation in appearance of plants, illumination changes, foliage occlusions, and different growth stages under field conditions. Current approaches for weed and crop recognition, segmentation and detection rely predominantly on conventional machine-learning techniques that require a large set of hand-crafted features for modelling. These might fail to generalize over different fields and environments.

Results
Here, we present an approach that develops a deep convolutional neural network (CNN) based on the tiny YOLOv3 architecture for C. sepium and sugar beet detection. We generated 2271 synthetic images, before combining these images with 452 field images to train the developed model. YOLO anchor box sizes were calculated from the training dataset using a k-means clustering approach. The resulting model was tested on 100 field images, showing that the combination of synthetic and original field images to train the developed model could improve the mean average precision (mAP) metric from 0.751 to 0.829 compared to using collected field images alone. We also compared the performance of the developed model with the YOLOv3 and Tiny YOLO models. The developed model achieved a better trade-off between accuracy and speed. Specifically, the average precisions (APs@IoU0.5) of C. sepium and sugar beet were 0.761 and 0.897 respectively with 6.48 ms inference time per image (800 {$\times$} 1200) on a NVIDIA Titan X GPU environment.}
}

@article{lincoln36114,
          volume = {31},
          number = {3},
           month = {March},
          author = {Hongxin Wang and Jigen Peng and Xuqiang Zheng and Shigang Yue},
           title = {A Robust Visual System for Small Target Motion Detection Against Cluttered Moving Backgrounds},
       publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
            year = {2020},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
             doi = {10.1109/TNNLS.2019.2910418},
           pages = {839--853},
        keywords = {ARRAY(0x5568fbb70498)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36114/},
        abstract = {Monitoring small objects against cluttered moving backgrounds is a huge challenge to future robotic vision systems. As a source of inspiration, insects are quite apt at searching for mates and tracking prey, which always appear as small dim speckles in the visual field. The exquisite sensitivity of insects for small target motion, as revealed recently, is coming from a class of specific neurons called small target motion detectors (STMDs). Although a few STMD-based models have been proposed, these existing models only use motion information for small target detection and cannot discriminate small targets from small-target-like background features (named fake features). To address this problem, this paper proposes a novel visual system model (STMD+) for small target motion detection, which is composed of four subsystems--ommatidia, motion pathway, contrast pathway, and mushroom body. Compared with the existing STMD-based models, the additional contrast pathway extracts directional contrast from luminance signals to eliminate false positive background motion. The directional contrast and the extracted motion information by the motion pathway are integrated into the mushroom body for small target discrimination. Extensive experiments showed the significant and consistent improvements of the proposed visual system model over the existing STMD-based models against fake features.}
}

@inproceedings{lincoln40456,
       booktitle = {The 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
           month = {February},
           title = {Evaluation of 3D Vision Systems for Detection of Small Objects in Agricultural Environments},
          author = {Justin Le Louedec and Bo Li and Grzegorz Cielniak},
       publisher = {SciTePress},
            year = {2020},
             doi = {10.5220/0009182806820689},
        keywords = {ARRAY(0x5568fba6b278)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40456/},
        abstract = {3D information provides unique information about shape, localisation and relations between objects, not found
in standard 2D images. This information would be very beneficial in a large number of applications in agriculture such as fruit picking, yield monitoring, forecasting and phenotyping. In this paper, we conducted a
study on the application of modern 3D sensing technology together with the state-of-the-art machine learning
algorithms for segmentation and detection of strawberries growing in real farms. We evaluate the performance
of two state-of-the-art 3D sensing technologies and showcase the differences between 2D and 3D networks
trained on the images and point clouds of strawberry plants and fruit. Our study highlights limitations of the
current 3D vision systems for the detection of small objects in outdoor applications and sets out foundations for
future work on 3D perception for challenging outdoor applications such as agriculture.}
}

@article{lincoln40216,
          volume = {9},
          number = {1},
           month = {February},
          author = {Riccardo Polvara and Massimiliano Patacchiola and Marc Hanheide and Gerhard Neumann},
           title = {Sim-to-Real Quadrotor Landing via Sequential Deep Q-Networks and Domain Randomization},
       publisher = {MDPI},
            year = {2020},
         journal = {Robotics},
             doi = {doi:10.3390/robotics9010008},
        keywords = {ARRAY(0x5568fb9ff048)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40216/},
        abstract = {The autonomous landing of an Unmanned Aerial Vehicle (UAV) on a marker is one of the most challenging problems in robotics. Many solutions have been proposed, with the best results achieved via customized geometric features and external sensors. This paper discusses for the first time the use of deep reinforcement learning as an end-to-end learning paradigm to find a policy for UAVs autonomous landing. Our method is based on a divide-and-conquer paradigm that splits a task into sequential sub-tasks, each one assigned to a Deep Q-Network (DQN), hence the name Sequential Deep Q-Network (SDQN). Each DQN in an SDQN is activated by an internal trigger, and it represents a component of a high-level control policy, which can navigate the UAV towards the marker. Different technical solutions have been implemented, for example combining vanilla and double DQNs, and the introduction of a partitioned buffer replay to address the problem of sample efficiency. One of the main contributions of this work consists in showing how an SDQN trained in a simulator via domain randomization, can effectively generalize to real-world scenarios of increasing complexity. The performance of SDQNs is comparable with a state-of-the-art algorithm and human pilots while being quantitatively better in noisy conditions.}
}

@inproceedings{lincoln42101,
           month = {February},
          author = {Raymond Kirk and Michael Mangan and Grzegorz Cielniak},
       booktitle = {UKRAS20 Conference: ?Robots into the real world? Proceedings},
           title = {Feasibility Study of In-Field Phenotypic Trait Extraction for Robotic Soft-Fruit Operations},
       publisher = {UKRAS},
             doi = {doi:10.31256/Uk4Td6I},
           pages = {21--23},
            year = {2020},
        keywords = {ARRAY(0x5568fb6b8518)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42101/},
        abstract = {There are many agricultural applications that would benefit from robotic monitoring of soft-fruit, examples include harvesting and yield forecasting. Autonomous mobile robotic platforms enable digitisation of horticultural processes in-field reducing labour demand and increasing efficiency through con- tinuous operation. It is critical for vision-based fruit detection methods to estimate traits such as size, mass and volume for quality assessment, maturity estimation and yield forecasting. Estimating these traits from a camera mounted on a mobile robot is a non-destructive/invasive approach to gathering qualitative fruit data in-field. We investigate the feasibility of using vision- based modalities for precise, cheap, and real time computation of phenotypic traits: mass and volume of strawberries from planar RGB slices and optionally point data. Our best method achieves a marginal error of 3.00cm3 for volume estimation. The planar RGB slices can be computed manually or by using common object detection methods such as Mask R-CNN.}
}

@article{lincoln40108,
          volume = {11},
          number = {81},
           month = {February},
          author = {M Bartlett and C Costescu and Paul Baxter and S Thill},
           title = {Requirements for Robotic Interpretation of Social Signals ?in the Wild?: Insights from Diagnostic Criteria of Autism Spectrum Disorder},
       publisher = {MDPI},
            year = {2020},
         journal = {MDPI Information},
             doi = {10.3390/info11020081},
           pages = {1--20},
        keywords = {ARRAY(0x5568fbb4fe70)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40108/},
        abstract = {The last few decades have seen widespread advances in technological means to characterise
observable aspects of human behaviour such as gaze or posture. Among others, these developments
have also led to significant advances in social robotics. At the same time, however, social robots
are still largely evaluated in idealised or laboratory conditions, and it remains unclear whether
the technological progress is sufficient to let such robots move ?into the wild?. In this paper, we
characterise the problems that a social robot in the real world may face, and review the technological
state of the art in terms of addressing these. We do this by considering what it would entail
to automate the diagnosis of Autism Spectrum Disorder (ASD). Just as for social robotics, ASD
diagnosis fundamentally requires the ability to characterise human behaviour from observable
aspects. However, therapists provide clear criteria regarding what to look for. As such, ASD diagnosis
is a situation that is both relevant to real-world social robotics and comes with clear metrics. Overall,
we demonstrate that even with relatively clear therapist-provided criteria and current technological
progress, the need to interpret covert behaviour cannot yet be fully addressed. Our discussions have
clear implications for ASD diagnosis, but also for social robotics more generally. For ASD diagnosis,
we provide a classification of criteria based on whether or not they depend on covert information
and highlight present-day possibilities for supporting therapists in diagnosis through technological
means. For social robotics, we highlight the fundamental role of covert behaviour, show that the
current state-of-the-art is unable to characterise this, and emphasise that future research should tackle
this explicitly in realistic settings.}
}

@article{lincoln39575,
          volume = {280},
          number = {3},
           month = {February},
          author = {Bowei Chen and Jingmin Huang and Yufei Huang and Stefanos Kollias and Shigang Yue},
           title = {Combining  guaranteed and spot markets in display advertising: Selling guaranteed page views with stochastic demand},
       publisher = {Elsevier},
            year = {2020},
         journal = {European Journal of Operational Research},
             doi = {10.1016/j.ejor.2019.07.067},
           pages = {1144--1159},
        keywords = {ARRAY(0x5568fbafd490)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39575/},
        abstract = {While page views are often sold instantly through real-time auctions when users visit Web pages, they can also be sold in advance via guaranteed contracts. In this paper, we combine guaranteed and spot markets in display advertising, and present a dynamic programming model to study how a media seller should optimally allocate and price page
views between guaranteed contracts and advertising auctions. This optimisation problem is challenging because the allocation and pricing of guaranteed contracts endogenously affects the expected revenue from advertising auctions in the future. We take into consideration several distinct characteristics regarding the media buyers? purchasing behaviour, such as risk aversion, stochastic demand arrivals, and devise a scalable and efficient algorithm to solve the optimisation problem. Our work is one of a few studies that investigate the auction-based posted price guaranteed contracts for display advertising. The proposed model is further empirically validated with a display advertising data set from a UK supply-side platform. The results show that the optimal pricing and allocation strategies from our model can significantly increase the media seller?s expected total revenue, and the model suggests different optimal strategies based on the level of competition in advertising auctions.}
}

@article{lincoln37350,
          volume = {37},
          number = {1},
           month = {January},
          author = {Jaime Pulido Fentanes and Amir Badiee and Tom Duckett and Jonathan Evans and Simon Pearson and Grzegorz Cielniak},
           title = {Kriging?based robotic exploration for soil moisture mapping using a cosmic?ray sensor},
       publisher = {Wiley Periodicals, Inc.},
            year = {2020},
         journal = {Journal of Field Robotics},
             doi = {10.1002/rob.21914},
           pages = {122--136},
        keywords = {ARRAY(0x5568fba4b1b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37350/},
        abstract = {Soil moisture monitoring is a fundamental process to enhance agricultural outcomes and to protect the environment. The traditional methods for measuring moisture content in the soil are laborious and expensive, and therefore there is a growing interest in developing sensors and technologies which can reduce the effort and costs. In this work, we propose to use an autonomous mobile robot equipped with a state?of?the?art noncontact soil moisture sensor building moisture maps on the fly and automatically selecting the most optimal sampling locations. We introduce an autonomous exploration strategy driven by the quality of the soil moisture model indicating areas of the field where the information is less precise. The sensor model follows the Poisson distribution and we demonstrate how to integrate such measurements into the kriging framework. We also investigate a range of different exploration strategies and assess their usefulness through a set of evaluation experiments based on real soil moisture data collected from two different fields. We demonstrate the benefits of using the adaptive measurement interval and adaptive sampling strategies for building better quality soil moisture models. The presented method is general and can be applied to other scenarios where the measured phenomena directly affect the acquisition time and need to be spatially mapped.}
}

@inproceedings{lincoln46145,
       booktitle = {2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {January},
           title = {Design, Modeling and Testing of a Flagellum-inspired Soft Underwater Propeller Exploiting Passive Elasticity},
          author = {Marcello Calisti and Francesco Giorgio-Serchi and Cesare Stefanini and Madiha Farman and Irfan Hussain and Costanza Armanini and Dongming Gan and Lakmal Seneviratne and Federico Renda},
            year = {2020},
           pages = {3328--3334},
             doi = {10.1109/IROS40897.2019.8967700},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46145/},
        abstract = {Flagellated micro-organism are regarded as excellent swimmers within their size scales. This, along with the simplicity of their actuation and the richness of their dynamics makes them a valuable source of inspiration to design continuum, self-propelled underwater robots. Here we introduce a soft, flagellum-inspired system which exploits the compliance of its own body to passively attain a range of geometrical configurations from the interaction with the surrounding fluid. The spontaneous formation of stable helical waves along the length of the flagellum is responsible for the generation of positive net thrust. We investigate the relationship between actuation frequency and material elasticity in determining the steady-state configuration of the system and its thrust output. This is ultimately used to perform a parameter identification procedure of an elastodynamic model aimed at investigating the scaling laws in the propulsion of flagellated robots.}
}

@article{lincoln39125,
          volume = {10},
           month = {January},
          author = {Piotr Chudzik and Arthur Mitchell and Mohammad Alkaseem and Yingie Wu and Shibo Fang and Taghread Hudaib and Simon Pearson and Bashir Al-Diri},
           title = {Mobile Real-Time Grasshopper Detection and Data Aggregation Framework},
       publisher = {Springer},
            year = {2020},
         journal = {Scientific Reports},
             doi = {10.1038/s41598-020-57674-8},
           pages = {1150},
        keywords = {ARRAY(0x5568fb9bcd60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39125/},
        abstract = {nsects of the family Orthoptera: Acrididae including grasshoppers and locust devastate crops and eco-systems around the globe. The effective control of these insects requires large numbers of trained extension agents who try to spot concentrations of the insects on the ground so that they can be destroyed before they take flight. This is a challenging and difficult task. No automatic detection system is yet available to increase scouting productivity, data scale and fidelity. Here we demonstrate MAESTRO, a novel grasshopper detection framework that deploys deep learning within RBG images
to detect insects. MAeStRo uses a state-of-the-art two-stage training deep learning approach. the framework can be deployed not only on desktop computers but also on edge devices without internet connection such as smartphones. MAeStRo can gather data using cloud storage for further research and in-depth analysis. In addition, we provide a challenging new open dataset (GHCID) of highly variable grasshopper populations imaged in inner Mongolia. the detection performance of the stationary method and the mobile App are 78 and 49 percent respectively; the stationary method requires around 1000 ms to analyze a single image, whereas the mobile app uses only around 400 ms per image. The algorithms are purely data-driven and can be used for other detection tasks in agriculture (e.g. plant disease detection) and beyond. This system can play a crucial role in the collection and analysis of data to enable more effective control of this critical global pest.}
}

@misc{lincoln40031,
           month = {January},
           title = {Use and citation of paper "Empirical game theory of pedestrian interaction for autonomous vehicles" by the Royal Society's "Digital technologies and human transformations" policy workshop.},
          author = {Royal Society Royal Society and Charles Fox},
            year = {2020},
         journal = {Digital technologies and human transformations},
        keywords = {ARRAY(0x5568fb9be390)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40031/},
        abstract = {The use of tools has always conditioned and been conditioned by humans and their societies. From stone-age implements, to writing and printing, to the mechanisation of manufacturing, technology design and use have always been entwined with the evolution of human capabilities. Digital technologies are transforming human experiences, and significant questions about how individuals interact with digital technologies, and how
these technologies mediate interactions between people, follow. To explore the implications of this wave of technological change, the Royal Society convened a series of workshops in 2019.}
}

@article{lincoln39423,
          volume = {20},
          number = {1},
           month = {January},
          author = {Raymond Kirk and Grzegorz Cielniak and Michael Mangan},
           title = {L*a*b*Fruits: A Rapid and Robust Outdoor Fruit Detection System Combining Bio-Inspired Features with One-Stage Deep Learning Networks},
       publisher = {MDPI},
            year = {2020},
         journal = {Sensors},
             doi = {10.3390/s20010275},
           pages = {275},
        keywords = {ARRAY(0x5568fbb5a7f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39423/},
        abstract = {Automation of agricultural processes requires systems that can accurately detect and classify produce in real industrial environments that include variation in fruit appearance due to illumination, occlusion, seasons, weather conditions, etc. In this paper, we combine a visual processing approach inspired by colour-opponent theory in humans with recent advancements in one-stage deep learning networks to accurately, rapidly and robustly detect ripe soft fruits (strawberries) in real industrial settings and using standard (RGB) camera input. The resultant system was tested on an existent data-set captured in controlled conditions as well our new real-world data-set captured on a real strawberry farm over two months. We utilise F1 score, the harmonic mean of precision and recall, to show our system matches the state-of-the-art detection accuracy ( F1: 0.793 vs. 0.799) in controlled conditions; has greater generalisation and robustness to variation of spatial parameters (camera viewpoint) in the real-world data-set ( F1: 0.744); and at a fraction of the computational cost allowing classification at almost 30fps. We propose that the L*a*b*Fruits system addresses some of the most pressing limitations of current fruit detection systems and is well-suited to application in areas such as yield forecasting and harvesting. Beyond the target application in agriculture, this work also provides a proof-of-principle whereby increased performance is achieved through analysis of the domain data, capturing features at the input level rather than simply increasing model complexity.}
}

@article{lincoln35535,
          volume = {37},
          number = {1},
           month = {January},
          author = {Petra Bosilj and Erchan Aptoula and Tom Duckett and Grzegorz Cielniak},
           title = {Transfer learning between crop types for semantic segmentation of crops versus weeds in precision agriculture},
       publisher = {Wiley},
            year = {2020},
         journal = {Journal of Field Robotics},
             doi = {10.1002/rob.21869},
           pages = {7--19},
        keywords = {ARRAY(0x5568fbab65d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35535/},
        abstract = {Agricultural robots rely on semantic segmentation for distinguishing between crops and weeds in order to perform selective treatments, increase yield and crop health while reducing the amount of chemicals used. Deep learning approaches have recently achieved both excellent classification performance and real-time execution. However, these techniques also rely on a large amount of training data, requiring a substantial labelling effort, both of which are scarce in precision agriculture. Additional design efforts are required to achieve commercially viable performance levels under varying environmental conditions and crop growth stages. In this paper, we explore the role of knowledge transfer between deep-learning-based classifiers for different crop types, with the goal of reducing the retraining time and labelling efforts required for a new crop. We examine the classification performance on three datasets with different crop types and containing a variety of weeds, and compare the performance and retraining efforts required when using data labelled at pixel level with partially labelled data obtained through a less time-consuming procedure of annotating the segmentation output. We show that transfer learning between different crop types is possible, and reduces training times for up to \$80{$\backslash$}\%\$. Furthermore, we show that even when the data used for re-training is imperfectly annotated, the classification performance is within \$2{$\backslash$}\%\$ of that of networks trained with laboriously annotated pixel-precision data.}
}

@article{lincoln35151,
           month = {January},
          author = {Claudio Coppola and Serhan Cosar and Diego R. Faria and Nicola Bellotto},
           title = {Social Activity Recognition on Continuous RGB-D Video Sequences},
       publisher = {Springer},
         journal = {International Journal of Social Robotics},
             doi = {10.1007/s12369-019-00541-y},
           pages = {1--15},
            year = {2020},
        keywords = {ARRAY(0x5568fbab6488)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35151/},
        abstract = {Modern service robots are provided with one or more sensors, often including RGB-D cameras, to perceive objects and humans in the environment. This paper proposes a new system for the recognition of human social activities from a continuous stream of RGB-D data. Many of the works until now have succeeded in recognising activities from clipped videos in datasets, but for robotic applications it is important to be able to move to more realistic scenarios in which such activities are not manually selected. For this reason, it is useful to detect the time intervals when humans are performing social activities, the recognition of which can contribute to trigger human-robot interactions or to detect situations of potential danger. The main contributions of this research work include a novel system for the recognition of social activities from continuous RGB-D data, combining temporal segmentation and classification, as well as a model for learning the proximity-based priors of the social activities. A new public dataset with RGB-D videos of social and individual activities is also provided and used for evaluating the proposed solutions. The results show the good performance of the system in recognising social activities from continuous RGB-D data.}
}

@article{lincoln36535,
          volume = {44},
          number = {2},
           month = {January},
          author = {Zhi Yan and Tom Duckett and Nicola Bellotto},
           title = {Online Learning for 3D LiDAR-based Human Detection: Experimental Analysis of Point Cloud Clustering and Classification Methods},
       publisher = {Springer},
            year = {2020},
         journal = {Autonomous Robots},
             doi = {10.1007/s10514-019-09883-y},
           pages = {147--164},
        keywords = {ARRAY(0x5568fba6b770)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36535/},
        abstract = {This paper presents a system for online learning of human classifiers by mobile service robots using 3D{\texttt{\char126}}LiDAR sensors, and its experimental evaluation in a large indoor public space. The learning framework requires a minimal set of labelled samples (e.g. one or several samples) to initialise a classifier. The classifier is then retrained iteratively during operation of the robot. New training samples are generated automatically using multi-target tracking and a pair of "experts" to estimate false negatives and false positives. Both classification and tracking utilise an efficient real-time clustering algorithm for segmentation of 3D point cloud data. We also introduce a new feature to improve human classification in sparse, long-range point clouds. We provide an extensive evaluation of our the framework using a 3D LiDAR dataset of people moving in a large indoor public space, which is made available to the research community. The experiments demonstrate the influence of the system components and improved classification of humans compared to the state-of-the-art.}
}

@book{lincoln39209,
           month = {January},
           title = {Intelligent Data Mining and Fusion Systems in Agriculture},
          author = {Xanthoula Eirini Pantazi and Dimitrios Moshou and Dionysis Bochtis},
       publisher = {Elsevier},
            year = {2020},
        keywords = {ARRAY(0x5568fbba1bd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39209/},
        abstract = {ntelligent Data Mining and Fusion Systems in Agriculture presents methods of computational intelligence and data fusion that have applications in agriculture for the non-destructive testing of agricultural products and crop condition monitoring. Sections cover the combination of sensors with artificial intelligence architectures in precision agriculture, including algorithms, bio-inspired hierarchical neural maps, and novelty detection algorithms capable of detecting sudden changes in different conditions. This book offers advanced students and entry-level professionals in agricultural science and engineering, geography and geoinformation science an in-depth overview of the connection between decision-making in agricultural operations and the decision support features offered by advanced computational intelligence algorithms.}
}

@article{lincoln42876,
           title = {Space Invaders: Pedestrian Proxemic Utility Functions and Trust Zones for Autonomous Vehicle Interactions},
          author = {Fanta Camara and Charles Fox},
       publisher = {Springer},
            year = {2020},
             doi = {10.1007/s12369-020-00717-x},
         journal = {International Journal of Social Robotics},
        keywords = {ARRAY(0x5568fbb98fe8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42876/},
        abstract = {Understanding pedestrian proxemic utility and trust will help autonomous vehicles to plan and control interactions with pedestrians more safely and efficiently. When pedestrians cross the road in front of human-driven vehicles, the two agents use knowledge of each other?s preferences to negotiate and to determine who will yield to the other. Autonomous vehicles will require similar understandings, but previous work has shown a need for them to be provided
in the form of continuous proxemic utility functions, which are not available from previous proxemics stud-
ies based on Hall?s discrete zones. To fill this gap, a new Bayesian method to infer continuous pedestrian
proxemic utility functions is proposed, and related to a new definition of ?physical trust requirement? (PTR)
for road-crossing scenarios. The method is validated on simulation data then its parameters are inferred empirically from two public datasets. Results show that pedestrian proxemic utility is best described by a hyperbolic function, and that trust by the pedestrian is required in a discrete ?trust zone? which emerges naturally from simple physics. The PTR concept is then shown to be capable of generating and explaining the
empirically observed zone sizes of Hall's discrete theory of proxemics.}
}

@inproceedings{lincoln41701,
       booktitle = {IEEE WCCI 2020-IJCNN regular session},
           title = {Competition between ON and OFF Neural Pathways Enhancing Collision Selectivity},
          author = {Fang Lei and Zhiping Peng and Vassilis Cutsuridis and Mei Liu and Yicheng Zhang and Shigang Yue},
            year = {2020},
             doi = {10.1109/IJCNN48605.2020.9207131},
        keywords = {ARRAY(0x5568fba6d8b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41701/},
        abstract = {The LGMD1 neuron of locusts shows strong looming-sensitive property for both light and dark objects. Although a few LGMD1 models have been proposed, they are not reliable to inhibit the translating motion under certain conditions compare to the biological LGMD1 in the locust. To address this issue, we propose a bio-plausible model to enhance the collision selectivity by inhibiting the translating motion. The proposed model contains three parts, the retina to lamina layer for receiving luminance change signals, the lamina to medulla layer for extracting motion cues via ON and OFF pathways separately, the medulla to lobula layer for eliminating translational excitation with neural competition. We tested the model by synthetic stimuli and real physical stimuli. The experimental results demonstrate that the proposed LGMD1 model has a strong preference for objects in direct collision course-it can detect looming objects in
different conditions while completely ignoring translating objects.}
}

@article{lincoln41544,
           title = {Experimental Analysis of a Spatialised Audio Interface for People with Visual Impairments},
          author = {Jacobus Lock and Iain Gilchrist and Grzegorz Cielniak and Nicola Bellotto},
       publisher = {Association for Computing Machinery},
            year = {2020},
         journal = {ACM Transactions on Accessible Computing},
        keywords = {ARRAY(0x5568fbb58ff0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41544/},
        abstract = {Sound perception is a fundamental skill for many people with severe sight impairments. The research presented in this paper is part of an ongoing project with the aim to create a mobile guidance aid to help people with vision impairments find objects within an unknown indoor environment. This system requires an effective non-visual interface and uses bone-conduction headphones to transmit audio instructions to the user. It has been implemented and tested with spatialised audio cues, which convey the direction of a predefined target in 3D space. We present an in-depth evaluation of the audio interface with several experiments that involve a large number of participants, both blindfolded and with actual visual impairments, and analyse the pros and cons of our design choices. In addition to producing results comparable to the state-of-the-art, we found that Fitts?s Law (a predictive model for human movement) provides a suitable a metric that can be used to improve and refine the quality of the audio interface in future mobile navigation aids.}
}

@article{lincoln40137,
           title = {Haptic-Guided Teleoperation of a 7-DoF Collaborative Robot Arm with an Identical Twin Master},
          author = {Jayant Singh and Aravinda Ramakrishnan Srinivasan and Gerhard Neumann and Ayse Kucukyilmaz},
       publisher = {IEEE},
            year = {2020},
           pages = {1--1},
             doi = {10.1109/TOH.2020.2971485},
         journal = {IEEE Transactions on Haptics},
        keywords = {ARRAY(0x5568fbb7e9a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40137/},
        abstract = {In this study, we describe two techniques to enable haptic-guided teleoperation using 7-DoF cobot arms as master and slave devices. A shortcoming of using cobots as master-slave systems is the lack of force feedback at the master side. However, recent developments in cobot technologies have brought in affordable, flexible, and safe torque-controlled robot arms, which can be programmed to generate force feedback to mimic the operation of a haptic device. In this study, we use two Franka Emika Panda robot arms as a twin master-slave system to enable haptic-guided teleoperation. We propose a two layer mechanism to implement force feedback due to 1) object interactions in the slave workspace, and 2) virtual forces, e.g. those that can repel from static obstacles in the remote environment or provide task-related guidance forces. We present two different approaches for force rendering and conduct an experimental study to evaluate the performance and usability of these approaches in comparison to teleoperation without haptic guidance. Our results indicate that the proposed joint torque coupling method for rendering task forces improves energy requirements during haptic guided telemanipulation, providing realistic force feedback by accurately matching the slave torque readings at the master side.}
}

@article{lincoln43704,
           title = {A bioinspired angular velocity decoding neural network  model for visually guided flights},
          author = {Huatian Wang and Qinbing Fu and Hongxin Wang and Paul Baxter and Jigen Peng and Shigang Yue},
       publisher = {Elsevier},
            year = {2020},
             doi = {10.1016/j.neunet.2020.12.008},
         journal = {Neural Networks},
        keywords = {ARRAY(0x5568fbab6368)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43704/},
        abstract = {Efficient and robust motion perception systems are important pre-requisites for achieving visually guided flights in future micro air vehicles. As a source of inspiration, the visual neural networks of flying insects such as honeybee and Drosophila provide ideal examples on which to base artificial motion perception models. In this paper, we have used this approach to develop a novel method that solves the fundamental problem of estimating angular velocity for visually guided flights. Compared with previous models, our elementary motion detector (EMD) based model uses a separate texture estimation pathway to effectively decode angular velocity, and demonstrates considerable independence from the spatial frequency and contrast of the gratings. Using the Unity development platform the model is further tested for tunnel centering and terrain following paradigms in order to reproduce the visually guided flight behaviors of honeybees. In a series of controlled trials, the virtual bee utilizes the proposed angular velocity control schemes to accurately navigate through a patterned tunnel, maintaining a suitable distance from the  undulating textured terrain. The results are consistent with both neuron spike recordings and behavioral path recordings of real honeybees, thereby demonstrating the model?s potential for implementation in micro air  vehicles which have only visual sensors.}
}

@article{lincoln39226,
          volume = {6},
          number = {4},
           month = {December},
          author = {Ch. Achillas and Dionysis Bochtis and D. Aidonis and V. Marinoudi and D. Folinas},
           title = {Voice-driven fleet management system for agricultural operations},
       publisher = {Elsevier},
            year = {2019},
         journal = {Information Processing in Agriculture},
             doi = {10.1016/j.inpa.2019.03.001},
           pages = {471--478},
        keywords = {ARRAY(0x5568fbb5ad98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39226/},
        abstract = {Food consumption is constantly increasing at global scale. In this light, agricultural production also needs to increase in order to satisfy the relevant demand for agricultural products. However, due to by environmental and biological factors (e.g. soil compaction) the weight and size of the machinery cannot be further physically optimized. Thus, only marginal improvements are possible to increase equipment effectiveness. On the contrary, late technological advances in ICT provide the ground for significant improvements in agri-production efficiency. In this work, the V-Agrifleet tool is presented and demonstrated. V-Agrifleet is developed to provide a ?hands-free? interface for information exchange and an ?Olympic view? to all coordinated users, giving them the ability for decentralized decision-making. The proposed tool can be used by the end-users (e.g. farmers, contractors, farm associations, agri-products storage and processing facilities, etc.) order to optimize task and time management. The visualized documentation of the fleet performance provides valuable information for the evaluation management level giving the opportunity for improvements in the planning of next operations. Its vendor-independent architecture, voice-driven interaction, context awareness functionalities and operation planning support constitute V-Agrifleet application a highly innovative agricultural machinery operational aiding system.}
}

@article{lincoln37181,
          volume = {113},
           month = {December},
          author = {George Onoufriou and Ronald Bickerton and Simon Pearson and Georgios Leontidis},
            note = {Partners included: Tesco and IMS-Evolve},
           title = {Nemesyst: A Hybrid Parallelism Deep Learning-Based Framework Applied for Internet of Things Enabled Food Retailing Refrigeration Systems},
       publisher = {Elsevier},
            year = {2019},
         journal = {Computers in Industry},
             doi = {10.1016/j.compind.2019.103133},
           pages = {103133},
        keywords = {ARRAY(0x5568fba28508)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37181/},
        abstract = {Deep Learning has attracted considerable attention across multiple application domains, including computer vision, signal processing and natural language processing. Although quite a few single node deep learning frameworks exist, such as tensorflow, pytorch and keras, we still lack a complete process- ing structure that can accommodate large scale data processing, version control, and deployment, all while staying agnostic of any specific single node framework. To bridge this gap, this paper proposes a new, higher level framework, i.e. Nemesyst, which uses databases along with model sequentialisation to allow processes to be fed unique and transformed data at the point of need. This facilitates near real-time application and makes models available for further training or use at any node that has access to the database simultaneously. Nemesyst is well suited as an application framework for internet of things aggregated control systems, deploying deep learning techniques to optimise individual machines in massive networks. To demonstrate this framework, we adopted a case study in a novel domain; deploying deep learning to optimise the high speed control of electrical power consumed by a massive internet of things network of retail refrigeration systems in proportion to load available on the UK Na- tional Grid (a demand side response). The case study demonstrated for the first time in such a setting how deep learning models, such as Recurrent Neural Networks (vanilla and Long-Short-Term Memory) and Generative Adversarial Networks paired with Nemesyst, achieve compelling performance, whilst still being malleable to future adjustments as both the data and requirements inevitably change over time.}
}

@inproceedings{lincoln40135,
       booktitle = {EDUROBOTICS 2018},
           month = {December},
           title = {Engaging Learners in Dialogue Interactivity Development for Mobile Robots},
          author = {Paul Baxter and Francesco Del Duchetto and Marc Hanheide},
       publisher = {Springer, Cham},
            year = {2019},
             doi = {10.1007/978-3-030-18141-3\_12},
        keywords = {ARRAY(0x5568fbb610c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40135/},
        abstract = {The use of robots in educational and STEM engagement activities is widespread. In this paper we describe a system developed for engaging learners with the design of dialogue-based interactivity for mobile robots. With an emphasis on a web-based solution that is grounded in both a real robot system and a real application domain (a museum guide robot) our intent is to enhance the benefits to both driving research through potential user-group engagement, and enhancing motivation by providing a real application context for the learners involved. The proposed system is designed to be highly scalable to both many simultaneous users and to users of different age groups, and specifically enables direct deployment of implemented systems onto both real and simulated robots. Our observations from preliminary events, involving both children and adults, support the view that the system is both usable and successful in supporting engagement with the dialogue interactivity problem presented to the participants, with indications that this engagement can persist over an extended period of time.}
}

@article{lincoln39137,
           month = {December},
          author = {Qinbing Fu and Cheng Hu and Jigen Peng and Claire Rind and Shigang Yue},
           title = {A Robust Collision Perception Visual Neural Network with Specific Selectivity to Darker Objects},
       publisher = {IEEE},
         journal = {IEEE Transactions on Cybernetics},
             doi = {10.1109/TCYB.2019.2946090},
           pages = {1--15},
            year = {2019},
        keywords = {ARRAY(0x5568fbba1c18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39137/},
        abstract = {Building an ef?cient and reliable collision perception visual system is a challenging problem for future robots and autonomous vehicles. The biological visual neural networks, which have evolved over millions of years in nature and are working perfectly in the real world, could be ideal models for designing arti?cial vision systems. In the locust?s visual pathways, a lobula giant movement detector (LGMD), that is, the LGMD2, has been identi?ed as a looming perception neuron that responds most strongly to darker approaching objects relative to their backgrounds; similar situations which many ground vehicles and robots are often faced with. However, little has been done on modeling the LGMD2 and investigating its potential in robotics and vehicles. In this article, we build an LGMD2 visual neural network which possesses the similar collision selectivity of an LGMD2 neuron in locust via the modeling of biased-ON and -OFF pathways splitting visual signals into parallel ON/OFF channels. With stronger inhibition (bias) in the ON pathway, this model responds selectively to darker looming objects. The proposed model has been tested systematically with a range of stimuli including real-world scenarios. It has also been implemented in a micro-mobile robot and tested with real-time experiments. The experimental results have veri?ed the effectiveness and robustness of the proposed model for detecting darker looming objects against various dynamic and cluttered backgrounds.}
}

@article{lincoln35842,
          volume = {23},
           month = {December},
          author = {Bruce Grieve and Tom Duckett and Martin Collison and Lesley Boyd and Jon West and Yin Hujun and Farshad Arvin and Simon Pearson},
           title = {The challenges posed by global broadacre crops in delivering smart agri-robotic solutions: A fundamental rethink is required.},
       publisher = {Elsevier},
            year = {2019},
         journal = {Global Food Security},
             doi = {10.1016/j.gfs.2019.04.011},
           pages = {116--124},
        keywords = {ARRAY(0x5568fbb92a08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35842/},
        abstract = {Threats to global food security from multiple sources, such as population growth, ageing farming populations, meat consumption trends, climate-change effects on abiotic and biotic stresses, the environmental impacts of agriculture are well publicised. In addition, with ever increasing tolerance of pest, diseases and weeds there is growing pressure on traditional crop genetic and protective chemistry technologies of the ?Green Revolution?. To ease the burden of these challenges, there has been a move to automate and robotise aspects of the farming process. This drive has focussed typically on higher value sectors, such as horticulture and viticulture, that have relied on seasonal manual labour to maintain produce supply. In developed economies, and increasingly developing nations, pressure on labour supply has become unsustainable and forced the need for greater mechanisation and higher labour productivity. This paper creates the case that for broadacre crops, such as cereals, a wholly new approach is necessary, requiring the establishment of an integrated biology \& physical engineering infrastructure, which can work in harmony with current breeding, chemistry and agronomic solutions. For broadacre crops the driving pressure is to sustainably intensify production; increase yields and/or productivity whilst reducing environmental impact. Additionally, our limited understanding of the complex interactions between the variations in pests, weeds, pathogens, soils, water, environment and crops is inhibiting growth in resource productivity and creating yield gaps. We argue that for agriculture to deliver knowledge based sustainable intensification requires a new generation of Smart Technologies, which combine sensors and robotics with localised and/or cloud-based Artificial Intelligence (AI).}
}

@article{lincoln44909,
          volume = {85},
           month = {December},
          author = {Sepehr Maleki and Chris Bingham},
           title = {Robust hierarchical clustering for novelty identification in sensor networks: With applications to industrial systems},
       publisher = {Elsevier},
            year = {2019},
         journal = {Applied Soft Computing Journal},
             doi = {10.1016/j.asoc.2019.105771},
           pages = {105771},
        keywords = {ARRAY(0x5568fbb69678)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44909/},
        abstract = {The paper proposes a new, robust cluster-based classification technique for Novelty Identification
in sensor networks that possess a high degree of correlation among data streams. During normal
operation, a uniform cluster across objects (sensors) is generated that indicates the absence of
novelties. Conversely, in presence of novelty, the associated sensor is clustered distinctly from the
remaining sensors, thereby isolating the data stream which exhibits the novelty. It is shown how
small perturbations (stemming from noise, for instance) can affect the performance of traditional
clustering methods, and that the proposed variant exhibits a robustness to such influences. Moreover,
the proposed method is compared with a recently reported technique, and shown that it performs
365\% faster computationally. To provide an application case study, the technique is used to identify
emerging fault modes in a sensor network on a sub-15MW industrial gas turbine in presence of other
abrupt, but normal changes that visually might otherwise be interpreted as malfunctions.}
}

@article{lincoln47556,
          volume = {100},
           month = {November},
          author = {Mohammed Al-Khafajiy and Thar Baker and Hilal Al-Libawy and Zakaria Maamar and Moayad Aloqaily and Yaser Jararweh},
           title = {Improving fog computing performance via Fog-2-Fog collaboration},
       publisher = {Elsevier},
            year = {2019},
         journal = {Future Generation Computer Systems},
             doi = {10.1016/j.future.2019.05.015},
           pages = {266--280},
        keywords = {ARRAY(0x5568fbab1f70)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47556/},
        abstract = {In the Internet of Things (IoT) era, a large volume of data is continuously emitted from a plethora of connected devices. The current network paradigm, which relies on centralised data centres (aka Cloud computing), has become inefficient to respond to IoT latency concern. To address this concern, fog computing allows data processing and storage ?close? to IoT devices. However, fog is still not efficient due to spatial and temporal distribution of these devices, which leads to fog nodes? unbalanced loads. This paper proposes a new fog-2-fog (f2f) collaboration model that promotes offloading incoming requests among fog nodes, according to their load and processing capabilities, via a novel load balancing known as Fog Resource manAgeMEnt Scheme (FRAMES). A formal mathematical model of  f2f and FRAMES has been formulated, and a set of experiments has been carried out demonstrating the technical doability of f2f collaboration. The performance of the proposed fog load balancing model is compared to other load balancing models.}
}

@article{lincoln36668,
          volume = {366},
           month = {November},
          author = {Heriberto Cuayahuitl and Donghyeon Lee and Seonghan Ryu and Yongjin Cho and Sungja Choi and Satish Indurthi and Seunghak Yu and Hyungtak Choi and Inchul Hwang and Jihie Kim},
           title = {Ensemble-Based Deep Reinforcement Learning for Chatbots},
       publisher = {Elsevier},
            year = {2019},
         journal = {Neurocomputing},
             doi = {10.1016/j.neucom.2019.08.007},
           pages = {118--130},
        keywords = {ARRAY(0x5568fba060c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36668/},
        abstract = {Trainable chatbots that exhibit fluent and human-like conversations remain a big challenge in artificial intelligence. Deep Reinforcement Learning (DRL) is promising for addressing this challenge, but its successful application remains an open question. This article describes a novel ensemble-based approach applied to value-based DRL chatbots, which use finite action sets as a form of meaning representation. In our approach, while dialogue actions are derived from sentence clustering, the training datasets in our ensemble are derived from dialogue clustering. The latter aim to induce specialised agents that learn to interact in a particular style. In order to facilitate neural chatbot training using our proposed approach, we assume dialogue data in raw text only ? without any manually-labelled data. Experimental results using chitchat data reveal that (1) near human-like dialogue policies can be induced, (2) generalisation to unseen data is a difficult problem, and (3) training an ensemble of chatbot agents is essential for improved performance over using a single agent. In addition to evaluations using held-out data, our results are further supported by a human evaluation that rated dialogues in terms of fluency, engagingness and consistency ? which revealed that our proposed dialogue rewards strongly correlate with human judgements.}
}

@inproceedings{lincoln36370,
           month = {November},
          author = {Mohamed Sorour and Khaled Elgeneidy and Aravinda Srinivasan and Marc Hanheide},
       booktitle = {2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           title = {Grasping Unknown Objects Based on Gripper Workspace Spheres},
       publisher = {IEEE},
            year = {2019},
         journal = {Proceedings of the 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019)},
             doi = {10.1109/IROS40897.2019.8967989},
           pages = {1541--1547},
        keywords = {ARRAY(0x5568fb9c0910)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36370/},
        abstract = {In this paper, we present a novel grasp planning algorithm for unknown objects given a registered point cloud of the target from different views. The proposed methodology requires no prior knowledge of the object, nor offline learning. In our approach, the gripper kinematic model is used to generate a point cloud of each finger workspace, which is then filled with spheres. At run-time, first the object is segmented, its major axis is computed, in a plane perpendicular to which, the main grasping action is constrained. The object is then
uniformly sampled and scanned for various gripper poses that assure at least one object point is located in the workspace of each finger. In addition, collision checks with the object or the table are performed using computationally inexpensive gripper shape approximation. Our methodology is both time efficient (consumes less than 1.5 seconds in average) and versatile. Successful experiments have been conducted on a simple jaw gripper (Franka Panda gripper) as well as a complex, high Degree of Freedom (DoF) hand (Allegro hand).}
}

@article{lincoln39027,
          volume = {9},
          number = {23},
           month = {November},
          author = {Luca Baronti and Mark Alston and Nikos Mavrakis and Amir Masoud Ghalamzan Esfahani and Marco Castellani},
           title = {Primitive Shape Fitting in Point Clouds Using the Bees Algorithm},
       publisher = {MDPI},
            year = {2019},
         journal = {Advances in Automation and Robotics},
             doi = {10.3390/app9235198},
        keywords = {ARRAY(0x5568fba5eeb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39027/},
        abstract = {In this study, the problem of fitting shape primitives to point cloud scenes was tackled 2 as a parameter optimisation procedure and solved using the popular Bees Algorithm. Tested on three sets of clean and differently blurred point cloud models, the Bees Algorithm obtained performances comparable to those obtained using the state-of-the-art RANSAC method, and superior to those obtained by an evolutionary algorithm. Shape fitting times were compatible with the real-time application. The main advantage of the Bees Algorithm over standard methods is that it doesn?t rely on ad hoc assumptions about the nature of the point cloud model like RANSAC approximation tolerance.}
}

@inproceedings{lincoln36758,
       booktitle = {IEEE Intelligent Transportation Systems Conference},
           month = {November},
           title = {A heuristic model for pedestrian intention estimation},
          author = {Fanta Camara and Natasha Merat and Charles Fox},
       publisher = {IEEE},
            year = {2019},
             doi = {10.1109/ITSC.2019.8917195},
        keywords = {ARRAY(0x5568fba7e300)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36758/},
        abstract = {Understanding pedestrian behaviour and controlling interactions with pedestrians is of critical importance for autonomous vehicles, but remains a complex and challenging problem. This study infers pedestrian intent during possible road-crossing interactions, to assist autonomous vehicle decisions to yield or not yield when approaching them, and tests a simple heuristic model of intent on pedestrian-vehicle trajectory data for the first time. It relies on a heuristic approach based
on the observed positions of the agents over time. The method can predict pedestrian crossing intent, crossing or stopping, with 96\% accuracy by the time the pedestrian reaches the curbside, on the standard Daimler pedestrian dataset. This result is important in demarcating scenarios which have a clear winner and can be predicted easily with the simple heuristic, from those which may require more complex game-theoretic models to predict and control.}
}

@inproceedings{lincoln42331,
       booktitle = {The 2019 IEEE International Geoscience and Remote Sensing Symposium (IGARSS2019)},
           month = {November},
           title = {Learning spectral and spatial features based on generative adversarial network for hyperspectral image super-resolution},
          author = {Ruituo Jiang and Xu Li and Ang Gao and Lixin Li and Hongying Meng and Shigang Yue and Lei Zhang},
            year = {2019},
             doi = {10.1109/IGARSS.2019.8900228},
        keywords = {ARRAY(0x5568fbb77570)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42331/},
        abstract = {Super-resolution (SR) of hyperspectral images (HSIs) aims to enhance the spatial/spectral resolution of hyperspectral imagery and the super-resolved results will benefit many remote sensing applications. A generative adversarial network for HSIs super-resolution (HSRGAN) is proposed in this paper. Specifically, HSRGAN constructs spectral and spatial blocks with residual network in generator to effectively learn spectral and spatial features from HSIs. Furthermore, a new loss function which combines the pixel-wise loss and adversarial loss together is designed to guide the generator to recover images approximating the original HSIs and with finer texture details. Quantitative and qualitative results demonstrate that the proposed HSRGAN is superior to the state of the art methods like SRCNN and SRGAN for HSIs spatial SR.}
}

@inproceedings{lincoln37261,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019) Workshops},
           month = {November},
           title = {Towards game theoretic AV controllers: measuring pedestrian behaviour in Virtual Reality},
          author = {Fanta Camara and Patrick Dickinson and Natasha Merat and Charles Fox},
       publisher = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019) Workshops},
            year = {2019},
        keywords = {ARRAY(0x5568fbb5ad50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37261/},
        abstract = {Understanding pedestrian interaction is of great importance for autonomous vehicles (AVs). The present study investigates pedestrian behaviour during crossing scenarios with an autonomous vehicle using Virtual Reality. The self-driving car is driven by a game theoretic controller which adapts its driving style to pedestrian crossing behaviour. We found that subjects value collision avoidance about 8 times more than saving 0.02 seconds. A previous lab study found time saving to be more important than collision avoidance in a highly unrealistic board game style version of the game. The present result suggests that the VR simulation reproduces real world road-crossings better than the lab study and provides a reliable test-bed for the development of game theoretic models for AVs.}
}

@inproceedings{lincoln37750,
       booktitle = {International Conference on Intelligent Robots and Systems (IROS)},
           month = {November},
           title = {Semantically Assisted Loop Closure in SLAM Using NDT Histograms},
          author = {Anestis Zaganidis and Alexandros Zerntev and Tom Duckett and Grzegorz Cielniak},
            year = {2019},
        keywords = {ARRAY(0x5568fb67b970)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37750/},
        abstract = {Precise knowledge of pose is of great importance for reliable operation of mobile robots in outdoor environments. Simultaneous localization and mapping (SLAM) is the online construction of a map during exploration of an environment. One of the components of SLAM is loop closure detection, identifying that the same location has been visited and is present on the existing map, and localizing against it. We have shown in previous work that using semantics from a deep segmentation network in conjunction with the Normal Distributions Transform point cloud registration improves the robustness, speed and accuracy of lidar odometry. In this work we extend the method for loop closure detection, using the labels already available from local registration into NDT Histograms, and we present a SLAM pipeline based on Semantic assisted NDT and PointNet++. We experimentally demonstrate on sequences from the KITTI benchmark that the map descriptor we propose outperforms NDT Histograms without semantics, and we validate its use on a SLAM task.}
}

@article{lincoln44708,
          volume = {19},
          number = {22},
           month = {November},
          author = {Helen Harman and Keshav Chintamani and Pieter Simoens},
           title = {Robot Assistance in Dynamic Smart Environments{--}A Hierarchical Continual Planning in the Now Framework},
       publisher = {MDPI},
            year = {2019},
         journal = {Sensors},
             doi = {10.3390/s19224856},
           pages = {4856},
        keywords = {ARRAY(0x5568fbab6260)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44708/},
        abstract = {By coupling a robot to a smart environment, the robot can sense state beyond the perception range of its onboard sensors and gain greater actuation capabilities. Nevertheless, incorporating the states and actions of Internet of Things (IoT) devices into the robot?s onboard planner increases the computational load, and thus can delay the execution of a task. Moreover, tasks may be frequently replanned due to the unanticipated actions of humans. Our framework aims to mitigate these inadequacies. In this paper, we propose a continual planning framework, which incorporates the sensing and actuation capabilities of IoT devices into a robot?s state estimation, task planing and task execution. The robot?s onboard task planner queries a cloud-based framework for actuators, capable of the actions the robot cannot execute. Once generated, the plan is sent to the cloud back-end, which will inform the robot if any IoT device reports a state change affecting its plan. Moreover, a Hierarchical Continual Planning in the Now approach was developed in which tasks are split-up into subtasks. To delay the planning of actions that will not be promptly executed, and thus to reduce the frequency of replanning, the first subtask is planned and executed before the subsequent subtask is. Only information relevant to the current (sub)task is provided to the task planner. We apply our framework to a smart home and office scenario in which the robot is tasked with carrying out a human?s requests. A prototype implementation in a smart home, and simulator-based evaluation results, are presented to demonstrate the effectiveness of our framework.}
}

@inproceedings{lincoln36793,
       booktitle = {International Workshop on Assistive Engineering and Information Technology (AEIT 2019)},
           month = {November},
           title = {Bone-Conduction Audio Interface to Guide People with Visual Impairments},
          author = {Jacobus Lock and Iain Gilchrist and Grzegorz Cielniak and Nicola Bellotto},
            year = {2019},
        keywords = {ARRAY(0x5568fbb80690)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36793/},
        abstract = {The ActiVis project's aim is to build a mobile guidance aid to help people with limited vision find objects in an unknown environment. This system uses bone-conduction headphones to transmit audio signals to the user and requires an effective non-visual interface. To this end, we propose a new audio-based interface that uses a spatialised signal to convey a target?s position on the horizontal plane. The vertical position on the median plan is given by adjusting the tone?s pitch to overcome the audio localisation limitations of bone-conduction headphones. This interface is validated through a set of experiments with blindfolded and visually impaired participants.}
}

@article{lincoln43351,
          volume = {121},
           month = {November},
          author = {Cheng Zhao and Li Sun and Zhi Yan and Gerhard Neumann and Tom Duckett and Rustam Stolkin},
           title = {Learning Kalman Network: A deep monocular visual odometry for on-road driving},
       publisher = {Elsevier},
            year = {2019},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2019.07.004},
           pages = {103234},
        keywords = {ARRAY(0x5568fbaf2740)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43351/},
        abstract = {This paper proposes a Learning Kalman Network (LKN) based monocular visual odometry (VO), i.e. LKN-VO, for on-road driving. Most existing learning-based VO focus on ego-motion estimation by comparing the two most recent consecutive frames. By contrast, the LKN-VO incorporates a learning ego-motion estimation through the current measurement, and a discriminative state estimator through a sequence of previous measurements. Superior to the model-based monocular VO, a more accurate absolute scale can be learned by LKN without any geometric constraints. In contrast to the model-based Kalman Filter (KF), the optimal model parameters of LKN can be obtained from dynamic and deterministic outputs of the neural network without elaborate human design. LKN is a hybrid approach where we achieve the non-linearity of the observation model and the transition model though deep neural networks, and update the state following the Kalman probabilistic mechanism. In contrast to the learning-based state estimator, a sparse representation is further proposed to learn the correlations within the states from the car?s movement behaviour, thereby applying better filtering on the 6DOF trajectory for on-road driving. The experimental results show that the proposed LKN-VO outperforms both model-based and learning state-estimator-based monocular VO on the most well-cited on-road driving datasets, i.e. KITTI and Apolloscape. In addition, LKN-VO is integrated with dense 3D mapping, which can be deployed for simultaneous localization and mapping in urban environments.}
}

@inproceedings{lincoln37348,
           month = {October},
          author = {Francesco Del Duchetto and Paul Baxter and Marc Hanheide},
       booktitle = {International Conference on Robot \& Human Interactive Communication (RO-MAN)},
         address = {New Delhi},
           title = {Lindsey the Tour Guide Robot - Usage Patterns in a Museum Long-Term Deployment},
       publisher = {IEEE},
             doi = {10.1109/RO-MAN46459.2019.8956329},
            year = {2019},
        keywords = {ARRAY(0x5568fb6d4928)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37348/},
        abstract = {The long-term deployment of autonomous robots co-located with humans in real-world scenarios remains a challenging problem. In this paper, we present the ``Lindsey'' tour guide robot system in which we attempt to increase the social capability of current state-of-the-art robotic technologies. The robot is currently deployed at a museum displaying local archaeology where it is providing guided tours and information to visitors. The robot is operating autonomously daily, navigating around the museum and engaging with the public, with on-site assistance from roboticists only in cases of hardware/software malfunctions. In a deployment lasting seven months up to now, it has travelled nearly 300km and has delivered more than 2300 guided tours. First, we describe the robot framework and the management interfaces implemented. We then analyse the data collected up to now with the goal of understanding and modelling the visitors' behavior in terms of their engagement with the technology. These data suggest that while short-term engagement is readily gained, continued engagement with the robot tour guide is likely to require more refined and robust socially interactive behaviours. The deployed system presents us with an opportunity to empirically address these issues.}
}

@article{lincoln36962,
          volume = {4},
          number = {4},
           month = {October},
          author = {Tomas Krajnik and Tomas Vintr and Sergi Molina Mellado and Jaime Pulido Fentanes and Grzegorz Cielniak and Oscar Martinez Mozos and George Broughton and Tom Duckett},
           title = {Warped Hypertime Representations for Long-Term Autonomy of Mobile Robots},
       publisher = {IEEE},
            year = {2019},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2019.2926682},
           pages = {3310--3317},
        keywords = {ARRAY(0x5568fbb853d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36962/},
        abstract = {This letter presents a novel method for introducing time into discrete and continuous spatial representations used in mobile robotics, by modeling long-term, pseudo-periodic variations caused by human activities or natural processes. Unlike previous approaches, the proposed method does not treat time and space separately, and its continuous nature respects both the temporal and spatial continuity of the modeled phenomena. The key idea is to extend the spatial  model with a set of wrapped time dimensions that represent the periodicities of the observed events. By performing clustering over this extended representation, we obtain a model that allows the prediction of probabilistic distributions of future states and events in both discrete and continuous spatial representations. We apply the proposed algorithm to several long-term datasets acquired by mobile robots and show that the method enables a robot to predict future states of representations with different dimensions. The experiments further show that the method achieves more accurate predictions than the previous state of the art.}
}

@article{lincoln36914,
          volume = {66},
           month = {October},
          author = {Ruth Madigan and Sina Nordhoff and Charles Fox and Roja Ezzati Amina and Tyron Louw and Marc Wilbrink and Anna Schieben and Natasha Merat},
           title = {Understanding interactions between Automated Road Transport Systems and other road users: A video analysis},
       publisher = {Elsevier},
            year = {2019},
         journal = {Transportation Research Part F},
             doi = {10.1016/j.trf.2019.09.006},
           pages = {196--213},
        keywords = {ARRAY(0x5568fbab5fc0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36914/},
        abstract = {If automated vehicles (AVs) are to move efficiently through the traffic environment, there is a need for them to interact and communicate with other road users in a comprehensible and predictable manner. For this reason, an understanding of the interaction requirements of other road users is needed. The current study investigated these requirements through an analysis of 22 hours of video footage of the CityMobil2 AV demonstrations in La Rochelle (France) and Trikala (Greece). Manual and automated video-analysis techniques were used to identify typical interactions patterns between AVs and other road users. Results indicate that road infrastructure and road user factors had a major impact on the type of interactions that arose between AVs and other road users. Road infrastructure features such as road width, and the presence or absence of zebra crossings had an impact on road users? trajectory decisions while approaching an AV. Where possible, pedestrians and cyclists appeared to leave as much space as possible between their trajectories and that of the AV. However, in situations where the infrastructure did not allow for the separation of traffic, risky behaviours were more likely to emerge, with cyclists, in particular, travelling closely alongside the AVs on narrow paths of the road, rather than waiting for the AV to pass. In addition, the types of interaction varied considerably across socio-demographic groups, with females and older users more likely to show cautionary behaviour around the AVs than males, or younger road users. Overall, the results highlight the importance of implementing the correct infrastructure to support the safe introduction of AVs, while also ensuring that the behaviour of the AV matches other road users? expectations as closely as possible in order to avoid traffic conflicts.}
}

@article{lincoln38234,
          volume = {4},
          number = {35},
           month = {October},
          author = {Emmanuel Senft and S{\'e}verin Lemaignan and Paul Baxter and Madeleine Bartlett and Tony Belpaeme},
           title = {Teaching robots social autonomy from in situ human guidance},
       publisher = {American Association for the Advancement of Science},
            year = {2019},
         journal = {Science Robotics},
             doi = {10.1126/scirobotics.aat1186},
           pages = {eaat1186},
        keywords = {ARRAY(0x5568fba8c5c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38234/},
        abstract = {Striking the right balance between robot autonomy and human control is a core challenge in social robotics, in both technical and ethical terms. On the one hand, extended robot autonomy offers the potential for increased human productivity and for the off-loading of physical and cognitive tasks. On the other hand, making the most of human technical and social expertise, as well as maintaining accountability, is highly desirable. This is particularly relevant in domains such as medical therapy and education, where social robots hold substantial promise, but where there is a high cost to poorly performing autonomous systems, compounded by ethical concerns. We present a field study in which we evaluate SPARC (supervised progressively autonomous robot competencies), an innovative approach addressing this challenge whereby a robot progressively learns appropriate autonomous behavior from in situ human demonstrations and guidance. Using online machine learning techniques, we demonstrate that the robot could effectively acquire legible and congruent social policies in a high-dimensional child-tutoring situation needing only a limited number of demonstrations while preserving human supervision whenever desirable. By exploiting human expertise, our technique enables rapid learning of autonomous social and domain-specific policies in complex and nondeterministic environments. Last, we underline the generic properties of SPARC and discuss how this paradigm is relevant to a broad range of difficult human-robot interaction scenarios.}
}

@inproceedings{lincoln46192,
       booktitle = {IEEE/MTS Oceans},
           month = {October},
           title = {Surveying and cleaning plastic pollution in the sediment: SILVER+ approach},
          author = {Giacomo Picardi and Saverio Iacoponi and Mrudul Chellapurath and Cecilia Laschi and Marcello Calisti},
         address = {Marsellie},
            year = {2019},
             doi = {10.1109/OCEANSE.2019.8867331},
        keywords = {ARRAY(0x5568fb9f9bf0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46192/},
        abstract = {Nowadays there is growing awareness on the issue of plastic pollution in the oceans. The use of robotic platforms might help increasing our understanding on the problem and possibly contribute to the solution. Recent studies pointed out that the majority of plastic litter eventually sinks to the bottom of the sea, but traditional swimming robots are unsuitable to carry out a systematic survey to validate this claim due to their limitations in the interaction with the seabed. For this reason we developed SILVER+, a platform for investigating the presence of micro and macro plastics litter in the sediment and possibly undertaking cleaning actions. SILVER stands for Seabed Interaction Legged Vehicle for Exploration and Research and it features an hexapod robot, SILVER2, which harnesses the interaction with the seabed to move and operate in the benthic environment. In this paper we present the general architecture of the SILVER+ platform, the design and development of SILVER2 and the results of preliminary tests to assess the effectiveness of the platform to effectively operate in the benthic environment.}
}

@article{lincoln37631,
           month = {October},
          author = {Ayse Kucukyilmaz and Illimar Issak},
           title = {Online Identification of Interaction Behaviors from Haptic Data during Collaborative Object Transfer},
       publisher = {IEEE},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2019.2945261},
           pages = {1--1},
            year = {2019},
        keywords = {ARRAY(0x5568fbab6338)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37631/},
        abstract = {Joint object transfer is a complex task, which is less structured and less specific than what is existing in several industrial settings. When two humans are involved in such a task, they cooperate through different modalities to understand the interaction states during operation and mutually adapt to one another?s actions. Mutual adaptation implies that both partners can identify how well they collaborate (i.e. infer about the interaction state) and act accordingly. These interaction states can define whether the partners work in harmony, face conflicts, or remain passive during interaction. Understanding how two humans work together during physical interactions is important when exploring the ways a robotic assistant should operate under similar settings. This study acts as a first step to implement an automatic classification mechanism during ongoing collaboration to identify the interaction state during object co-manipulation. 
The classification is done on a dataset consisting of data from 40 subjects, who are partnered to form 20 dyads. The dyads experiment in a physical human-human interaction (pHHI) scenario to move an object in an haptics-enabled virtual environment to reach predefined goal configurations. In this study, we propose a sliding-window approach for feature extraction and demonstrate the online classification methodology to identify interaction patterns. We evaluate our approach using 1) a support vector machine classifier (SVMc) and 2) a Gaussian Process classifier (GPc) for multi-class classification, and achieve over 80\% accuracy with both classifiers when identifying general interaction types.}
}

@article{lincoln36072,
          volume = {251},
           month = {October},
          author = {Andrey Postnikov and Ibrahim Albayati and Simon Pearson and Chris Bingham and Ronald Bickerton and Argyrios Zolotas},
           title = {Facilitating static firm frequency response with aggregated networks of commercial food refrigeration systems},
       publisher = {Elsevier},
            year = {2019},
         journal = {Applied Energy},
             doi = {10.1016/j.apenergy.2019.113357},
           pages = {113357},
        keywords = {ARRAY(0x5568fba146a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36072/},
        abstract = {Aggregated electrical loads from massive numbers of distributed retail refrigeration systems could have a significant role in frequency balancing services. To date, no study has realised effective engineering applications of static firm frequency response to these aggregated networks. Here, the authors present a novel and validated approach that enables large scale control of distributed retail refrigeration assets. The authors show a validated model that simulates the operation of retail refrigerators comprising centralised compressor packs feeding multiple in-store display cases. The model was used to determine an optimal control strategy that both minimised the engineering risk to the pack during shut down and potential impacts to food safety. The authors show that following a load shedding frequency response trigger the pack should be allowed to maintain operation but with increased suction pressure set-point. This reduces compressor load whilst enabling a continuous flow of refrigerant to food cases. In addition, the authors simulated an aggregated response of up to three hundred compressor packs (over 2 MW capacity), with refrigeration cases on hysteresis and modulation control. Hysteresis control, compared to modulation, led to undesired load oscillations when the system recovers after a frequency balancing event. Transient responses of the system during the event showed significant fluctuations of active power when compressor network responds to both primary and secondary parts of a frequency balancing event. Enabling frequency response within this system is demonstrated by linking the aggregated refrigeration loads with a simplified power grid model that simulates a power loss incident.}
}

@inproceedings{lincoln39415,
       booktitle = {70th International Astronautical Congress},
           month = {October},
           title = {Towards On-Orbit Assembly of Large Space Telescopes: Mission Architectures, Concepts, and Analyses},
          author = {Angadh Nanjangud and Craig I. Underwood and Chakravarthini M. Saaj and Alex Young and Peter C. Blacker and Steve Eckersley and Martin Sweeting and Paolo Bianco},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39415/}
}

@article{lincoln36571,
           month = {October},
           title = {Haptic-guided shared control for needle grasping optimization in minimally invasive robotic surgery},
          author = {Mario Selvaggio and Amir Ghalamzan Esfahani and Rocco Moccia and Fanny Ficuciello and Bruno Siciliano},
            year = {2019},
         journal = {IEEE/RSJ International Conference Intelligent Robotic System},
        keywords = {ARRAY(0x5568fbb69018)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36571/},
        abstract = {During suturing tasks performed with minimally invasive surgical robots, configuration singularities and joint limits often force surgeons to interrupt the task and re- grasp the needle using dual-arm movements. This yields an increased operator?s cognitive load, time-to-completion, fatigue and performance degradation. In this paper, we propose a haptic-guided shared control method for grasping the needle with the Patient Side Manipulator (PSM) of the da Vinci robot avoiding such issues. We suggest a cost function consisting of (i) the distance from robot joint limits and (ii) the task-oriented manipulability over the suturing trajectory. We evaluate the cost and its gradient on the needle grasping manifold that allows us to obtain the optimal grasping pose for joint-limit and singularity free movements of the needle during suturing. Then, we compute force cues that are applied to the Master Tool Manipulator (MTM) of the da Vinci to guide the operator towards the optimal grasp. As such, our system helps the operator to choose a grasping configuration allowing the robot to avoid joint limits and singularities during post-grasp suturing movements. We show the effectiveness of our proposed haptic- guided shared control method during suturing using both simulated and real experiments. The results illustrate that our approach significantly improves the performance in terms of needle re-grasping.}
}

@article{lincoln39231,
          volume = {11},
          number = {18},
           month = {September},
          author = {Maria G. Lampridi and Claus G. S{\o}rensen and Dionysis Bochtis},
           title = {Agricultural Sustainability: A Review of Concepts and Methods},
            year = {2019},
         journal = {Sustainability},
             doi = {10.3390/su11185120},
           pages = {5120},
        keywords = {ARRAY(0x5568fbaa1c70)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39231/},
        abstract = {This paper presents a methodological framework for the systematic literature review of agricultural sustainability studies. The framework synthesizes all the available literature review criteria and introduces a two-level analysis facilitating systematization, data mining, and methodology analysis. The framework was implemented for the systematic literature review of 38 crop agricultural sustainability assessment studies at farm-level for the last decade. The investigation of the methodologies used is of particular importance since there are no standards or norms for the sustainability assessment of farming practices. The chronological analysis revealed that the scientific community?s interest in agricultural sustainability is increasing in the last three years. The most used methods include indicator-based tools, frameworks, and indexes, followed by multicriteria methods. In the reviewed studies, stakeholder participation is proved crucial in the determination of the level of sustainability. It should also be mentioned that combinational use of methodologies is often observed, thus a clear distinction of methodologies is not always possible}
}

@article{lincoln47557,
          volume = {78},
          number = {17},
           month = {September},
          author = {Mohammed Al-Khafajiy and Thar Baker and Carl Chalmers and Muhammad Asim and Hoshang Kolivand and Muhammad Fahim and Atif Waraich},
           title = {Remote health monitoring of elderly through wearable sensors},
       publisher = {Springer},
            year = {2019},
         journal = {Multimedia Tools and Applications},
             doi = {10.1007/s11042-018-7134-7},
           pages = {24681--24706},
        keywords = {ARRAY(0x5568fbb61840)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47557/},
        abstract = {Due to a rapidly increasing aging population and its associated challenges in health and social care, Ambient Assistive Living has become the focal point for both researchers and industry alike. The need to manage or even reduce healthcare costs while improving the quality of service is high government agendas. Although, technology has a major role to play in achieving these aspirations, any solution must be designed, implemented and validated using appropriate domain knowledge. In order to overcome these challenges, the remote real-time monitoring of a person?s health can be used to identify relapses in conditions, therefore, enabling early intervention. Thus, the development of a smart healthcare monitoring system, which is capable of observing elderly people remotely, is the focus of the research presented in this paper. The technology outlined in this paper focuses on the ability to track a person?s physiological data to detect specific disorders which can aid in Early Intervention Practices. This is achieved by accurately processing and analysing the acquired sensory data while transmitting the detection of a disorder to an appropriate career. The finding reveals that the proposed system can improve clinical decision supports while facilitating Early Intervention Practices. Our extensive simulation results indicate a superior performance of the proposed system: low latency (96\% of the packets are received with less than 1 millisecond) and low packets-lost (only 2.2\% of total packets are dropped). Thus, the system runs efficiently and is cost-effective in terms of data acquisition and manipulation.}
}

@article{lincoln47560,
          volume = {56},
           month = {August},
          author = {Zakaria Maamar and Thar Baker and Noura Faci and Mohammed Al-Khafajiy and Emir Ugljanin and Yacine Atif and Mohamed Sellami},
           title = {Weaving cognition into the internet-of-things: Application to water leaks},
       publisher = {Elsevier},
            year = {2019},
         journal = {Cognitive Systems Research},
             doi = {10.1016/j.cogsys.2019.04.001},
           pages = {233--245},
        keywords = {ARRAY(0x5568fb670d48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47560/},
        abstract = {Despite the growing interest in the Internet-of-Things, many organizations remain reluctant to integrating things into their business processes. Different reasons justify this reluctance including things? limited capabilities to act upon the cyber-physical surrounding in which they operate. To address this specific limitation, this paper examines thing empowerment with cognitive capabilities that would make them for instance, selective of the next business processes in which they would participate. The selection is based on things? restrictions like limitedness and goals to achieve like improved reputation. For demonstration purposes, water leaks are used as a case study. A BPEL-based business process driving the fixing of water leaks is implemented involving different cognitive things like moisture sensor.}
}

@article{lincoln36279,
          volume = {184},
           month = {August},
          author = {Vasso Marinoudi and Claus Sorensen and Simon Pearson and Dionysis Bochtis},
           title = {Robotics and labour in agriculture. A context consideration},
       publisher = {Elsevier},
            year = {2019},
         journal = {Biosystems Engineering},
             doi = {10.1016/j.biosystemseng.2019.06.013},
           pages = {111--121},
        keywords = {ARRAY(0x5568fbaaea68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36279/},
        abstract = {Over the last century, agriculture transformed from a labour-intensive industry towards mechanisation and power-intensive production systems, while over the last 15 years agri- cultural industry has started to digitise. Through this transformation there was a continuous labour outflow from agriculture, mainly from standardized tasks within production process. Robots and artificial intelligence can now be used to conduct non-standardised tasks (e.g. fruit picking, selective weeding, crop sensing) previously reserved for human workers and at economically feasible costs. As a consequence, automation is no longer restricted to stan- dardized tasks within agricultural production (e.g. ploughing, combine harvesting). In addition, many job roles in agriculture may be augmented but not replaced by robots. Robots in many instances will work collaboratively with humans. This new robotic ecosystem creates complex ethical, legislative and social impacts. A key question, we consider here, is what are the short and mid-term effects of robotised agriculture on sector jobs and employment? The presented work outlines the conditions, constraints, and inherent re- lationships between labour input and technology input in bio-production, as well as, pro- vides the procedural framework and research design to be followed in order to evaluate the effect of adoption automation and robotics in agriculture.}
}

@article{lincoln37396,
          volume = {42},
          number = {8},
           month = {August},
          author = {A. Seddaoui and Mini Saaj},
            note = {cited By 0},
           title = {Combined nonlinear H? controller for a controlled-floating space robot},
       publisher = {Aerospace Research Central},
            year = {2019},
         journal = {Journal of Guidance, Control, and Dynamics},
             doi = {10.2514/1.G003811},
           pages = {1878--1885},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37396/}
}

@article{lincoln39389,
          volume = {42},
          number = {8},
           month = {August},
          author = {Asma Seddaoui and Chakravarthini M. Saaj},
           title = {Combined Nonlinear H? Controller for a Controlled-Floating Space Robot},
       publisher = {Aerospace Research Central},
            year = {2019},
         journal = {Journal of Guidance, Control, and Dynamics},
             doi = {10.2514/1.G003811},
           pages = {1878--1885},
        keywords = {ARRAY(0x5568fb6eefd8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39389/}
}

@inproceedings{lincoln42330,
       booktitle = {2019 IEEE International Conference on Image Processing (ICIP2019)},
           month = {August},
           title = {Learning spatial and spectral features via 2D-1D generative adversarial network for hyperspectral image super-resolution},
          author = {Ruituo Jiang and Xu Li and Shaohui Mei and Shigang Yue and Lei Zhang},
            year = {2019},
             doi = {10.1109/ICIP.2019.8803200},
         journal = {2019 IEEE International Conference on Image Processing (ICIP2019)},
        keywords = {ARRAY(0x5568fbaae2d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42330/},
        abstract = {Three-dimensional (3D) convolutional networks have been proven to be able to explore spatial context and spectral information simultaneously for super-resolution (SR). However, such kind of network can?t be practically designed very
?deep? due to the long training time and GPU memory limitations involved in 3D convolution. Instead, in this paper, spatial context and spectral information in hyperspectral images (HSIs) are explored using Two-dimensional (2D) and Onedimenional (1D) convolution, separately. Therefore, a novel 2D-1D generative adversarial network architecture (2D-1DHSRGAN) is proposed for SR of HSIs. Specifically, the generator network consists of a spatial network and a spectral network, in which spatial network is trained with the least absolute deviations loss function to explore spatial context by 2D convolution and spectral network is trained with the spectral angle mapper (SAM) loss function to extract spectral information by 1D convolution. Experimental results over two real HSIs demonstrate that the proposed 2D-1D-HSRGAN clearly outperforms several state-of-the-art algorithms.}
}

@inproceedings{lincoln36396,
           month = {August},
          author = {Sergi Molina and Grzegorz Cielniak and Tom Duckett},
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           title = {Go with the Flow: Exploration and Mapping of Pedestrian Flow Patterns from Partial Observations},
       publisher = {IEEE},
             doi = {10.1109/ICRA.2019.8794434},
           pages = {9725--9731},
            year = {2019},
        keywords = {ARRAY(0x5568fbb76e08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36396/},
        abstract = {Understanding how people are likely to behave in an environment is a key requirement for efficient and safe robot navigation. However, mobile platforms are subject to spatial and temporal constraints, meaning that only partial observations of human activities are typically available to a robot, while the activity patterns of people in a given environment may also change at different times. To address these issues we present as the main contribution an exploration strategy for acquiring models of pedestrian flows, which decides not only the locations to explore but also the times when to explore them. The approach is driven by the uncertainty from multiple Poisson processes built from past observations. The approach is evaluated using two long-term pedestrian datasets, comparing its performance against uninformed exploration strategies. The results show that when using the uncertainty in the exploration policy, model accuracy increases, enabling faster learning of human motion patterns.}
}

@inproceedings{lincoln37413,
          volume = {2019-M},
           month = {August},
          author = {A. Seddaoui and C. Saaj and S. Eckersley},
            note = {cited By 0},
       booktitle = {2019 International Conference on Robotics and Automation (ICRA)},
           title = {Adaptive H? Controller for Precise Manoeuvring of a Space Robot},
       publisher = {IEEE},
            year = {2019},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
             doi = {10.1109/ICRA.2019.8794374},
           pages = {4746--4752},
        keywords = {ARRAY(0x5568fbb62330)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37413/},
        abstract = {A space robot working in a controlled-floating mode can be used for performing in-orbit telescope assembly through simultaneously controlling the motion of the spacecraft base and its robotic arm. Handling and assembling optical mirrors requires the space robot to achieve slow and precise manoeuvres regardless of the disturbances and errors in the trajectory. The robustness offered by the nonlinear H ? controller, in the presence of environmental disturbances and parametric uncertainties, makes it a viable solution. However, using fixed tuning parameters for this controller does not always result in the desired performance as the arm's trajectory is not known a priori for orbital assembly missions. In this paper, a complete study on the impact of the different tuning parameters is performed and a new adaptive H ? controller is developed based on bounded functions. The simulation results presented show that the proposed adaptive H ? controller guarantees robustness and precise tracking using a minimal amount of forces and torques for assembly operations using a small space robot.}
}

@inproceedings{lincoln38253,
           month = {August},
          author = {Tomas Vintr and Zhi Yan and Tom Duckett and Tomas Krajnik},
       booktitle = {2019 International Conference on Robotics and Automation (ICRA)},
           title = {Spatio-temporal representation for long-term anticipation of human presence in service robotics},
       publisher = {IEEE},
             doi = {10.1109/ICRA.2019.8793534},
           pages = {2620--2626},
            year = {2019},
        keywords = {ARRAY(0x5568fb678d18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38253/},
        abstract = {We propose an efficient spatio-temporal model for mobile autonomous robots operating in human populated
environments. Our method aims to model periodic temporal patterns of people presence, which are based on peoples?
routines and habits. The core idea is to project the time onto a set of wrapped dimensions that represent the periodicities of people presence. Extending a 2D spatial model with this multi-dimensional representation of time results in a memory efficient spatio-temporal model. This model is capable of long-term predictions of human presence, allowing mobile robots to schedule their services better and to plan their paths. The experimental evaluation, performed over datasets gathered by a robot over a period of several weeks, indicates that the proposed
 method achieves more accurate predictions than the previous state of the art used in robotics.}
}

@article{lincoln39230,
          volume = {12},
          number = {15},
           month = {August},
          author = {Efthymios Rodias and Remigio Berruto and Dionysis Bochtis and Alessandro Sopegno and Patrizia Busato},
           title = {Green, Yellow, and Woody Biomass Supply-Chain Management: A Review},
            year = {2019},
         journal = {Energies},
             doi = {10.3390/en12153020},
           pages = {3020},
        keywords = {ARRAY(0x5568fb6724f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39230/},
        abstract = {Various sources of biomass contribute significantly in energy production globally given a series of constraints in its primary production. Green biomass sources (such as perennial grasses), yellow biomass sources (such as crop residues), and woody biomass sources (such as willow) represent the three pillars in biomass production by crops. In this paper, we conducted a comprehensive review on research studies targeted to advancements at biomass supply-chain management in connection to these three types of biomass sources. A framework that classifies the works in problem-based and methodology-based approaches was followed. Results show the use of modern technological means and tools in current management-related problems. From the review, it is evident that the presented up-to-date trends on biomass supply-chain management and the potential for future advanced approach applications play a crucial role on business and sustainability efficiency of biomass supply chain}
}

@article{lincoln35584,
          volume = {25},
          number = {3},
           month = {August},
          author = {Qinbing Fu and Hongxin Wang and Cheng Hu and Shigang Yue},
           title = {Towards Computational Models and Applications of Insect Visual Systems for Motion Perception: A Review},
       publisher = {MIT Press},
            year = {2019},
         journal = {Artificial life},
             doi = {10.1162/artl\_a\_00297},
           pages = {263--311},
        keywords = {ARRAY(0x5568fbba6a38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35584/},
        abstract = {Motion perception is a critical capability determining a variety of aspects of insects' life, including avoiding predators, foraging and so forth. A good number of motion detectors have been identified in the insects' visual pathways. Computational modelling of these motion detectors has not only been providing effective solutions to artificial intelligence, but also benefiting the understanding of complicated biological visual systems. These biological mechanisms through millions of years of evolutionary development will have formed solid modules for constructing dynamic vision systems for future intelligent machines. This article reviews the computational motion perception models originating from biological research of insects' visual systems in the literature. These motion perception models or neural networks comprise the looming sensitive neuronal models of lobula giant movement detectors (LGMDs) in locusts, the translation sensitive neural systems of direction selective neurons (DSNs) in fruit flies, bees and locusts, as well as the small target motion detectors (STMDs) in dragonflies and hover flies. We also review the applications of these models to robots and vehicles. Through these modelling studies, we summarise the methodologies that generate different direction and size selectivity in motion perception. At last, we discuss about multiple systems integration and hardware realisation of these bio-inspired motion perception models.}
}

@article{lincoln35606,
          volume = {16},
          number = {4},
           month = {August},
          author = {Khaled Goher and Sulaiman Fadlallah},
           title = {Control of a Two-wheeled Machine with Two-directions Handling Mechanism Using PID and PD-FLC Algorithms},
       publisher = {Springer},
            year = {2019},
         journal = {International Journal of Automation and Computing},
             doi = {10.1007/s11633-019-1172-0},
           pages = {511--533},
        keywords = {ARRAY(0x5568fba20fc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35606/},
        abstract = {This paper presents a novel five degrees of freedom (DOF) two-wheeled robotic machine (TWRM) that delivers solutions
for both industrial and service robotic applications by enlarging the vehicle?s workspace and increasing its flexibility. Designing a two-wheeled robot with five degrees of freedom creates a high challenge for the control, therefore the modelling and design of such robot should be precise with a uniform distribution of mass over the robot and the actuators. By employing the Lagrangian modelling approach, the TWRM?s mathematical model is derived and simulated in Matlab/Simulink?. For stabilizing the system?s highly nonlinear model, two control approaches were developed and implemented: proportional-integral-derivative (PID) and fuzzy logic control (FLC)
strategies. Considering multiple scenarios with different initial conditions, the proposed control strategies? performance has been assessed.}
}

@article{lincoln47558,
          volume = {78},
          number = {14},
           month = {July},
          author = {Mohammed Al-Khafajiy and Hoshang Kolivand and Thar Baker and David Tully and Atif Waraich},
           title = {Smart hospital emergency system via mobile-based requesting services},
       publisher = {Springer},
            year = {2019},
         journal = {Multimedia Tools and Applications},
             doi = {10.1007/s11042-019-7274-4},
           pages = {20087--20111},
        keywords = {ARRAY(0x5568fbb4e100)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47558/},
        abstract = {In recent years, the UK?s emergency call and response has shown elements of great strain as of today. The strain on emergency call systems estimated by a 9 million calls (including both landline and mobile) made in 2014 alone. Coupled with an increasing population and cuts in government funding, this has resulted in lower percentages of emergency response vehicles at hand and longer response times. In this paper, we highlight the main challenges of emergency services and overview of previous solutions. In addition, we propose a new system call Smart Hospital Emergency System (SHES). The main aim of SHES is to save lives through improving communications between patient and emergency services. Utilising the latest of technologies and algorithms within SHES is aiming to increase emergency communication throughput, while reducing emergency call systems issues and making the process of emergency response more efficient. Utilising health data held within a personal smartphone, and internal tracked data (GPU, Accelerometer, Gyroscope etc.), SHES aims to process the mentioned data efficiently, and securely, through automatic communications with emergency services, ultimately reducing communication bottlenecks. Live video-streaming through real-time video communication protocols is also a focus of SHES to improve initial communications between emergency services and patients. A prototype of this system has been developed. The system has been evaluated by a preliminary usability, reliability, and communication performance study.}
}

@inproceedings{lincoln36661,
           month = {July},
          author = {Barkan Ugurlu and Merve Acer and Duygun E. Barkana and Ikilem Gocek and Ayse Kucukyilmaz and Yunus Z. Arslan and Halil Basturk and Evren Samur and Emre Ugur and Ramazan Unal and Ozkan Bebek},
       booktitle = {2019 IEEE 16th International Conference on Rehabilitation Robotics (ICORR)},
           title = {A Soft+Rigid Hybrid Exoskeleton Concept in Scissors-Pendulum Mode: A Suit for Human State Sensing and an Exoskeleton for Assistance},
       publisher = {IEEE},
             doi = {10.1109/ICORR.2019.8779394},
           pages = {518--523},
            year = {2019},
        keywords = {ARRAY(0x5568fbab9288)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36661/},
        abstract = {In this paper, we present a novel concept that can enable the human aware control of exoskeletons through the
integration of a soft suit and a robotic exoskeleton. Unlike the state-of-the-art exoskeleton controllers which mostly rely on lumped human-robot models, the proposed concept makes use of the independent state measurements concerning the human user and the robot. The ability to observe the human state independently is the key factor in this approach. In order to realize such a system from the hardware point of view, we propose a system integration frame that combines a soft suit for human state measurement and a rigid exoskeleton for human assistance. We identify the technological requirements that are necessary for the realization of such a system with a particular emphasis on soft suit integration. We also propose a template model, named scissor pendulum, that may encapsulate the dominant dynamics of the human-robot combined model to synthesize a controller for human state regulation. A series of simulation experiments were conducted to check the controller performance. As a result, satisfactory human state regulation was attained, adequately confirming that the proposed system could potentially improve exoskeleton-aided applications.}
}

@inproceedings{lincoln36870,
          volume = {11673},
           month = {July},
          author = {Sercan Sari and Ayse Kucukyilmaz},
       booktitle = {Mobile Web and Intelligent Information Systems},
           title = {VR-Fit: Walking-in-Place Locomotion with Real Time Step Detection for VR-Enabled Exercise},
       publisher = {Springer},
            year = {2019},
             doi = {10.1007/978-3-030-27192-3\_20},
           pages = {255--266},
        keywords = {ARRAY(0x5568fbb51738)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36870/},
        abstract = {With recent advances in mobile and wearable technologies, virtual reality (VR) found many applications in daily use. Today, a mobile device can be converted into a low-cost immersive VR kit thanks to the availability of do-it-yourself viewers in the shape of simple cardboards and compatible software for 3D rendering. These applications involve interacting with stationary scenes or moving in between spaces within a VR environment. VR locomotion can be enabled through a variety of methods, such as head movement tracking, joystick-triggered motion and through mapping natural movements to translate to virtual locomotion. In this study, we implemented a walk-in-place (WIP) locomotion method for a VR-enabled exercise application. We investigate the utility of WIP for exercise purposes, and compare it with joystick-based locomotion in terms of step performance and subjective qualities of the activity, such as enjoyment, encouragement for exercise and ease of use. Our technique uses vertical accelerometer data to estimate steps taken during walking or running, and locomotes the user?s avatar accordingly in virtual space. We evaluated our technique in a controlled experimental study with 12 people. Results indicate that the way users control the simulated locomotion affects how they interact with the VR simulation, and influence the subjective sense of immersion and the perceived quality of the interaction. In particular, WIP encourages users to move further, and creates a more enjoyable and interesting experience in comparison to joystick-based navigation.}
}

@article{lincoln39229,
          volume = {9},
          number = {7},
           month = {July},
          author = {Naoum Tsolakis and Dimitrios Bechtsis and Dionysis Bochtis},
           title = {AgROS: A Robot Operating System Based Emulation Tool for Agricultural Robotics},
            year = {2019},
         journal = {Agronomy},
             doi = {10.3390/agronomy9070403},
           pages = {403},
        keywords = {ARRAY(0x5568fb67fbe8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39229/},
        abstract = {This research aims to develop a farm management emulation tool that enables agrifood producers to effectively introduce advanced digital technologies, like intelligent and autonomous unmanned ground vehicles (UGVs), in real-world field operations. To that end, we first provide a critical taxonomy of studies investigating agricultural robotic systems with regard to: (i) the analysis approach, i.e., simulation, emulation, real-world implementation; (ii) farming operations; and (iii) the farming type. Our analysis demonstrates that simulation and emulation modelling have been extensively applied to study advanced agricultural machinery while the majority of the extant research efforts focuses on harvesting/picking/mowing and fertilizing/spraying activities; most studies consider a generic agricultural layout. Thereafter, we developed AgROS, an emulation tool based on the Robot Operating System, which could be used for assessing the efficiency of real-world robot systems in customized fields. The AgROS allows farmers to select their actual field from a map layout, import the landscape of the field, add characteristics of the actual agricultural layout (e.g., trees, static objects), select an agricultural robot from a predefined list of commercial systems, import the selected UGV into the emulation environment, and test the robot?s performance in a quasi-real-world environment. AgROS supports farmers in the ex-ante analysis and performance evaluation of robotized precision farming operations while lays the foundations for realizing ?digital twins? in agriculture}
}

@inproceedings{lincoln35684,
       booktitle = {The 2019 International Joint Conference on Neural Networks (IJCNN)},
           month = {July},
           title = {Visual Cue Integration for Small Target Motion Detection in Natural Cluttered Backgrounds},
          author = {Hongxin Wang and Jigen Peng and Qinbing Fu and Huatian Wang and Shigang Yue},
       publisher = {IEEE},
            year = {2019},
        keywords = {ARRAY(0x5568fbb7e558)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35684/},
        abstract = {The robust detection of small targets against cluttered background is important for future arti?cial visual systems in searching and tracking applications. The insects? visual systems have demonstrated excellent ability to avoid predators, ?nd prey or identify conspeci?cs ? which always appear as small dim speckles in the visual ?eld. Build a computational model of the insects? visual pathways could provide effective solutions to detect small moving targets. Although a few visual system models have been proposed, they only make use of small-?eld visual features for motion detection and their detection results often contain a number of false positives. To address this issue, we develop a new visual system model for small target motion detection against cluttered moving backgrounds. Compared to the existing models, the small-?eld and wide-?eld visual features are separately extracted by two motion-sensitive neurons to detect small target motion and background motion. These two types of motion information are further integrated to ?lter out false positives. Extensive experiments showed that the proposed model can outperform the existing models in terms of detection rates.}
}

@inproceedings{lincoln35685,
       booktitle = {The 2019 International Joint Conference on Neural Networks},
           month = {July},
           title = {Angular Velocity Estimation of Image Motion Mimicking the Honeybee Tunnel Centring Behaviour},
          author = {Huatian Wang and Qinbing Fu and Hongxin Wang and Jigen Peng and Paul Baxter and Cheng Hu and Shigang Yue},
       publisher = {IEEE},
            year = {2019},
        keywords = {ARRAY(0x5568fb9fc850)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35685/},
        abstract = {Insects use visual information to estimate angular velocity of retinal image motion, which determines a variety of ?ight behaviours including speed regulation, tunnel centring and visual navigation. For angular velocity estimation, honeybees show large spatial-independence against visual stimuli, whereas the previous models have not ful?lled such an ability. To address this issue, we propose a bio-plausible model for estimating the image motion velocity based on behavioural experiments of the honeybee ?ying through patterned tunnels. The proposed model contains mainly three parts, the texture estimation layer for spatial information extraction, the delay-and-correlate layer for temporal information extraction and the decoding layer for angular velocity estimation. This model produces responses that are largely independent of the spatial frequency in grating experiments. And the model has been implemented in a virtual bee for tunnel centring simulations. The results coincide with both electro-physiological neuron spike and behavioural path recordings, which indicates our proposed method provides a better explanation of the honeybee?s image motion detection mechanism guiding the tunnel centring behaviour.}
}

@inproceedings{lincoln37347,
           month = {July},
          author = {Manuel Fernandez Carmona and Tejas Parekh and Marc Hanheide},
       booktitle = {TAROS 2019: Towards Autonomous Robotic Systems},
           title = {Making the Case for Human-Aware Navigation in Warehouses},
       publisher = {Springer, Cham},
             doi = {10.1007/978-3-030-25332-5\_38},
           pages = {449--453},
            year = {2019},
        keywords = {ARRAY(0x5568fb9b5e98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37347/},
        abstract = {This work addresses the performance of several local planners for navigation of autonomous pallet trucks in the presence of humans in a simulated warehouse as well as a complementary approach developed within the ILIAD project. 
Our focus is to stress the open problem of a safe manoeuvrability of pallet trucks in the presence of moving humans. 
We propose a variation of ROS navigation stack that includes in the planning process a model of the human robot interaction.}
}

@inproceedings{lincoln35954,
       booktitle = {International Joint Conference on Neural Networks (IJCNN)},
           month = {July},
           title = {Deep Reinforcement Learning for Chatbots Using Clustered Actions and Human-Likeness Rewards},
          author = {Heriberto Cuayahuitl and Donghyeon Lee and Seonghan Ryu and Sungja Choi and Inchul Hwang and Jihie Kim},
       publisher = {IEEE},
            year = {2019},
             doi = {10.1109/IJCNN.2019.8852376},
        keywords = {ARRAY(0x5568fbb8de20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35954/},
        abstract = {Training chatbots using the reinforcement learning paradigm is challenging due to high-dimensional states, infinite action spaces and the difficulty in specifying the reward function. We address such problems using clustered actions instead of infinite actions, and a simple but promising reward function based on human-likeness scores derived from human-human dialogue data. We train Deep Reinforcement Learning (DRL) agents using chitchat data in raw text{--}without any manual annotations. Experimental results using different splits of training data report the following. First, that our agents learn reasonable policies in the environments they get familiarised with, but their performance drops substantially when they are exposed to a test set of unseen dialogues. Second, that the choice of sentence embedding size between 100 and 300 dimensions is not significantly different on test data. Third, that our proposed human-likeness rewards are reasonable for training chatbots as long as they use lengthy dialogue histories of ?10 sentences.}
}

@inproceedings{lincoln36187,
       booktitle = {The 2019 IEEE International Conference on Advanced Robotics and Mechatronics (ICARM)},
           month = {July},
           title = {ColCOS{\ensuremath{\Phi}}: A Multiple Pheromone Communication System for Swarm Robotics and Social Insects Research},
          author = {Xuelong Sun and Tian liu and Cheng Hu and Qinbing Fu and Shigang Yue},
       publisher = {IEEE},
            year = {2019},
        keywords = {ARRAY(0x5568fbad4548)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36187/},
        abstract = {In the last few decades we have witnessed how the pheromone of social insect has become a rich inspiration source of swarm robotics. By utilising the virtual pheromone in physical swarm robot system to coordinate individuals and realise direct/indirect inter-robot communications like the social insect, stigmergic behaviour has emerged. However, many studies only take one single pheromone into account in solving swarm problems, which is not the case in real insects. In the real social insect world, diverse behaviours, complex collective performances and ?exible transition from one state to another are guided by different kinds of pheromones and their interactions. Therefore, whether multiple pheromone based strategy can inspire swarm robotics research, and inversely how the performances of swarm robots controlled by multiple pheromones bring inspirations to explain the social insects? behaviours will become an interesting question. Thus, to provide a reliable system to undertake the multiple pheromone study, in this paper, we speci?cally proposed and realised a multiple pheromone communication system called ColCOS{\ensuremath{\Phi}}. This system consists of a virtual pheromone sub-system wherein the multiple pheromone is represented by a colour image displayed on a screen, and the micro-robots platform designed for swarm robotics applications. Two case studies are undertaken to verify the effectiveness of this system: one is the multiple pheromone based on an ant?s forage and another is the interactions of aggregation and alarm pheromones. The experimental results demonstrate the feasibility of ColCOS{\ensuremath{\Phi}} and its great potential in directing swarm robotics and social insects research.}
}

@inproceedings{lincoln39422,
       booktitle = {20th Annual Conference, TAROS 2019},
           month = {July},
           title = {System Design and Control of a Di-Wheel Rover},
          author = {John Koleosho and Chakravarthini Saaj},
       publisher = {Springer},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39422/}
}

@article{lincoln47561,
          volume = {6},
           month = {June},
          author = {Khouloud Boukadi and Noura Faci and Zakaria Maamar and Emir Ugljanin and Mohamed Sellami and Thar Baker and Mohammed Al-Khafajiy},
           title = {Norm-based and commitment-driven agentification of the Internet of Things},
       publisher = {Elsevier},
            year = {2019},
         journal = {Internet of Things},
             doi = {10.1016/j.iot.2019.02.002},
           pages = {100042},
        keywords = {ARRAY(0x5568fb6d4b38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47561/},
        abstract = {There are no doubts that the Internet-of-Things (IoT) has conquered the ICT industry to the extent that many governments and organizations are already rolling out many anywhere,anytime online services that IoT sustains. However, like any emerging and disruptive technology, multiple obstacles are slowing down IoT practical adoption including the passive nature and privacy invasion of things. This paper examines how to empower things with necessary capabilities that would make them proactive and responsive. This means things can, for instance reach out to collaborative peers, (un)form dynamic communities when necessary, avoid malicious peers, and be ?questioned? for their actions. To achieve such empowerment, this paper presents an approach for agentifying things using norms along with commitments that operationalize these norms. Both norms and commitments are specialized into social (i.e., application independent) and business (i.e., application dependent), respectively. Being proactive, things could violate commitments at run-time, which needs to be detected through monitoring. In this paper, thing agentification is illustrated with a case study about missing children and demonstrated with a testbed that uses different IoT-related technologies such as Eclipse Mosquitto broker and Message Queuing Telemetry Transport protocol. Some experiments conducted upon this testbed are also discussed.}
}

@article{lincoln36203,
          volume = {26},
          number = {2},
           month = {June},
          author = {Hoang-Long Cao and Pablo G. Esteban and Madeleine Bartlett and Paul Baxter and Tony Belpaeme and Erik Billing and Haibin Cai and Mark Coeckelbergh and Cristina Costescu and Daniel David and Albert De Beir and Daniel Hernandez and James Kennedy and Honghai Liu and Silviu Matu and Alexandre Mazel and Amit Pandey and Kathleen Richardson and Emmanuel Senft and Serge Thill and Greet Van de Perre and Bram Vanderborght and David Vernon and Kutoma Wakanuma and Hui Yu and Xiaolong Zhou and Tom Ziemke},
           title = {Robot-Enhanced Therapy: Development and Validation of Supervised Autonomous Robotic System for Autism Spectrum Disorders Therapy},
       publisher = {IEEE},
            year = {2019},
         journal = {IEEE Robotics \& Automation Magazine},
             doi = {doi:10.1109/MRA.2019.2904121},
           pages = {49--58},
        keywords = {ARRAY(0x5568fb67d358)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36203/},
        abstract = {Robot-assisted therapy (RAT) offers potential advantages for improving the social skills of children with autism spectrum disorders (ASDs). This article provides an overview of the developed technology and clinical results of the EC-FP7-funded Development of Robot-Enhanced therapy for children with AutisM spectrum disorders (DREAM) project, which aims to develop the next level of RAT in both clinical and technological perspectives, commonly referred to as robot-enhanced therapy (RET). Within this project, a supervised autonomous robotic system is collaboratively developed by an interdisciplinary consortium including psychotherapists, cognitive scientists, roboticists, computer scientists, and ethicists, which allows robot control to exceed classical remote control methods, e.g., Wizard of Oz (WoZ), while ensuring safe and ethical robot behavior. Rigorous clinical studies are conducted to validate the efficacy of RET. Current results indicate that RET can obtain an equivalent performance compared to that of human standard therapy for children with ASDs. We also discuss the next steps of developing RET robotic systems.}
}

@inproceedings{lincoln36395,
          volume = {11649},
           month = {June},
          author = {Alexander Gabriel and Serhan Cosar and Nicola Bellotto and Paul Baxter},
       booktitle = {Towards Autonomous Robotic Systems},
           title = {A Dataset for Action Recognition in the Wild},
       publisher = {Springer},
            year = {2019},
             doi = {doi:10.1007/978-3-030-23807-0\_30},
           pages = {362--374},
        keywords = {ARRAY(0x5568fb9cffc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36395/},
        abstract = {The development of autonomous robots for agriculture depends on a successful approach to recognize user needs as well as datasets reflecting the characteristics of the domain. Available datasets for 3D Action Recognition generally feature controlled lighting and framing while recording subjects from the front. They mostly reflect good recording conditions and therefore fail to account for the highly variable conditions the robot would have to work with in the field, e.g. when providing in-field logistic support for human fruit pickers as in our scenario. Existing work on Intention Recognition mostly labels plans or actions as intentions, but neither of those fully capture the extend of human intent. In this work, we argue for a holistic view on human Intention Recognition and propose a set of recording conditions, gestures and behaviors that better reflect the environment and conditions an agricultural robot might find itself in. We demonstrate the utility of the dataset by means of evaluating two human detection methods: bounding boxes and skeleton extraction.}
}

@article{lincoln44712,
          volume = {19},
          number = {12},
           month = {June},
          author = {Helen Harman and Pieter Simoens},
           title = {Action Graphs for Performing Goal Recognition Design on Human-Inhabited Environments},
       publisher = {MDPI},
            year = {2019},
         journal = {Sensors},
             doi = {10.3390/s19122741},
           pages = {2741},
        keywords = {ARRAY(0x5568fb687070)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44712/},
        abstract = {Goal recognition is an important component of many context-aware and smart environment services; however, a person?s goal often cannot be determined until their plan nears completion. Therefore, by modifying the state of the environment, our work aims to reduce the number of observations required to recognise a human?s goal. These modifications result in either: Actions in the available plans being replaced with more distinctive actions; or removing the possibility of performing some actions, so humans are forced to take an alternative (more distinctive) plan. In our solution, a symbolic representation of actions and the world state is transformed into an Action Graph, which is then traversed to discover the non-distinctive plan prefixes. These prefixes are processed to determine which actions should be replaced or removed. For action replacement, we developed an exhaustive approach and an approach that shrinks the plans then reduces the non-distinctive plan prefixes, namely Shrink?Reduce. Exhaustive is guaranteed to find the minimal distinctiveness but is more computationally expensive than Shrink?Reduce. These approaches are compared using a test domain with varying amounts of goals, variables and values, and a realistic kitchen domain. Our action removal method is shown to increase the distinctiveness of various grid-based navigation problems, with a width/height ranging from 4 to 16 and between 2 and 14 randomly selected goals, by an average of 3.27 actions in an average time of 4.69 s, whereas a state-of-the-art approach often breaches a 10 min time limit.}
}

@misc{lincoln36226,
           month = {June},
           title = {Patient, carer and staff perceptions of robotics in rehabilitation: protocol of a systematic review and qualitative meta-synthesis},
          author = {Despina Laparidou and Ffion Curtis and Khaled Goher and Ayse Kucukyilmaz and Marion Walker and Joseph Akanuwe and Niro Siriwardena},
       publisher = {PROSPERO International prospective register of systematic reviews},
            year = {2019},
        keywords = {ARRAY(0x5568fbb048d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36226/},
        abstract = {Registration of a systematic review and qualitative meta-synthesis protocol.}
}

@inproceedings{lincoln36285,
       booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
           month = {June},
           title = {Projections for Approximate Policy Iteration Algorithms},
          author = {R. Akrour and J. Pajarinen and Gerhard Neumann and J. Peters},
       publisher = {Proceedings of Machine Learning Research},
            year = {2019},
           pages = {181--190},
        keywords = {ARRAY(0x5568fba22598)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36285/},
        abstract = {Approximate policy iteration is a class of reinforcement learning (RL) algorithms where the policy is encoded using a function approximator and which has been especially prominent in RL with continuous action spaces. In this class of RL algorithms, ensuring increase of the policy return during policy update often requires to constrain the change in action distribution. Several approximations exist in the literature to solve this constrained policy update problem. In this paper, we propose to improve over such solutions by introducing a set of projections that transform the constrained problem into an unconstrained one which is then solved by standard gradient descent. Using these projections, we empirically demonstrate that our approach can improve the policy update solution and the control over exploration of existing approximate policy iteration algorithms.}
}

@inproceedings{lincoln36286,
          volume = {97},
           month = {June},
          author = {Philipp Becker and Harit Pandya and Gregor Gebhardt and Cheng Zhao and C. James Taylor and Gerhard Neumann},
          series = {Proceedings of Machine Learning Research},
       booktitle = {Proceedings of the 36th International Conference on Machine Learning},
         address = {Long Beach, California, USA},
           title = {Recurrent Kalman Networks: Factorized Inference in High-Dimensional Deep Feature Spaces},
       publisher = {Proceedings of Machine Learning Research},
            year = {2019},
           pages = {544--552},
        keywords = {ARRAY(0x5568fbac4820)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36286/},
        abstract = {In order to integrate uncertainty estimates into deep time-series modelling, Kalman Filters (KFs) (Kalman et al., 1960) have been integrated with deep learning models, however, such approaches typically rely on approximate inference tech- niques such as variational inference which makes learning more complex and often less scalable due to approximation errors. We propose a new deep approach to Kalman filtering which can be learned directly in an end-to-end manner using backpropagation without additional approximations. Our approach uses a high-dimensional factorized latent state representation for which the Kalman updates simplify to scalar operations and thus avoids hard to backpropagate, computationally heavy and potentially unstable matrix inversions. Moreover, we use locally linear dynamic models to efficiently propagate the latent state to the next time step. The resulting network architecture, which we call Recurrent Kalman Network (RKN), can be used for any time-series data, similar to a LSTM (Hochreiter \& Schmidhuber, 1997) but uses an explicit representation of uncertainty. As shown by our experiments, the RKN obtains much more accurate uncertainty estimates than an LSTM or Gated Recurrent Units (GRUs) (Cho et al., 2014) while also showing a slightly improved prediction performance and outperforms various recent generative models on an image imputation task.}
}

@article{lincoln37436,
          volume = {6},
          number = {3},
           month = {June},
          author = {S.M. Mustaza and Y. Elsayed and C. Lekakou and C. Saaj and J. Fras},
            note = {cited By 1},
           title = {Dynamic modeling of fiber-reinforced soft manipulator: A visco-hyperelastic material-based continuum mechanics approach},
       publisher = {Mary Ann Liebert},
            year = {2019},
         journal = {Soft Robotics},
             doi = {10.1089/soro.2018.0032},
           pages = {305--317},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37436/},
        abstract = {Robot-assisted surgery is gaining popularity worldwide and there is increasing scientific interest to explore the potential of soft continuum robots for minimally invasive surgery. However, the remote control of soft robots is much more challenging compared with their rigid counterparts. Accurate modeling of manipulator dynamics is vital to remotely control the diverse movement configurations and is particularly important for safe interaction with the operating environment. However, current dynamic models applied to soft manipulator systems are simplistic and empirical, which restricts the full potential of the new soft robots technology. Therefore, this article provides a new insight into the development of a nonlinear dynamic model for a soft continuum manipulator based on a material model. The continuum manipulator used in this study is treated as a composite material and a modified nonlinear Kelvin?Voigt material model is utilized to embody the visco-hyperelastic dynamics of soft silicone. The Lagrangian approach is applied to derive the equation of motion of the manipulator. Simulation and experimental results prove that this material modeling approach sufficiently captures the nonlinear time- and rate-dependent behavior of a soft manipulator. Material model-based closed-loop trajectory control was implemented to further validate the feasibility of the derived model and increase the performance of the overall system.}
}

@inproceedings{lincoln34950,
       booktitle = {RoboSoft 2019},
           month = {June},
           title = {Characterising 3D-printed Soft Fin Ray Robotic Fingers with Layer Jamming Capability for Delicate Grasping},
          author = {Khaled Elgeneidy and Peter Lightbody and Simon Pearson and Gerhard Neumann},
            year = {2019},
        keywords = {ARRAY(0x5568fbaaa0f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34950/},
        abstract = {Motivated by the growing need within the agrifood industry to automate the handling of delicate produce, this paper presents soft robotic fingers utilising the Fin Ray effect to passively and gently adapt to delicate targets. The proposed Soft Fin Ray fingers feature thin ribs and are entirely 3D printed from a flexible material (NinjaFlex) to enhance their shape adaptation, compared to the original Fin Ray fingers. To overcome their reduced force generation, the effects of
the angle and spacing of the flexible ribs were experimentally characterised. The results showed that at large displacements, layer jamming between tilted flexible ribs can significantly enhance the force generation, while minimal contact forces can be still maintained at small displacements for delicate grasping.}
}

@inproceedings{lincoln35548,
           month = {May},
          author = {Petra Bosilj and Iain Gould and Tom Duckett and Grzegorz Cielniak},
       booktitle = {14th International Symposium on Mathematical Morphology},
           title = {Pattern Spectra from Different Component Trees for Estimating Soil Size Distribution},
       publisher = {Springer},
         journal = {International Symposium on Mathematical Morphology},
           pages = {415--427},
            year = {2019},
        keywords = {ARRAY(0x5568fba11ef0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35548/},
        abstract = {We study the pattern spectra in context of soil structure analysis. Good soil structure is vital for sustainable crop growth. Accurate and fast measuring methods can contribute greatly to soil management decisions. However, the current in-field approaches contain a degree of subjectivity, while obtaining quantifiable results through laboratory techniques typically involves sieving the soil which is labour- and time-intensive. We aim to replace this physical sieving process through image analysis, and investigate the effectiveness of pattern spectra to capture the size distribution of the soil aggregates. We calculate the pattern spectra from partitioning hierarchies in addition to the traditional max-tree. The study is posed as an image retrieval problem, and confirms the ability of pattern spectra and suitability of different partitioning trees to re-identify soil samples in different arrangements and scales.}
}

@inproceedings{lincoln35691,
       booktitle = {The 15th International Conference on Artificial Intelligence Applications and Innovations},
           month = {May},
           title = {An LGMD Based Competitive Collision Avoidance Strategy for UAV},
          author = {Jiannan Zhao and Xingzao Ma and Qinbing Fu and Cheng Hu and Shigang Yue},
       publisher = {Springer},
            year = {2019},
             doi = {10.1007/978-3-030-19823-7\_6},
        keywords = {ARRAY(0x5568fb67f540)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35691/},
        abstract = {Building a reliable and e?cient collision avoidance system for unmanned aerial vehicles (UAVs) is still a challenging problem. This research takes inspiration from locusts, which can ?y in dense swarms for hundreds of miles without collision. In the locust?s brain, a visual pathway of LGMD-DCMD (lobula giant movement detector and descending contra-lateral motion detector) has been identi?ed as collision perception system guiding fast collision avoidance for locusts, which is ideal for designing arti?cial vision systems. However, there is very few works investigating its potential in real-world UAV applications. In this paper, we present an LGMD based competitive collision avoidance method for UAV indoor navigation. Compared to previous works, we divided the UAV?s ?eld of view into four sub?elds each handled by an LGMD neuron. Therefore, four individual competitive LGMDs (C-LGMD) compete for guiding the directional collision avoidance of UAV. With more degrees of freedom compared to ground robots and vehicles, the UAV can escape from collision along four cardinal directions (e.g. the object approaching from the left-side triggers a rightward shifting of the UAV). Our proposed method has been validated by both simulations and real-time quadcopter arena experiments.}
}

@inproceedings{lincoln35586,
       booktitle = {15th International Conference on Artificial Intelligence Applications and Innovations},
           month = {May},
           title = {A Visual Neural Network for Robust Collision Perception in Vehicle Driving Scenarios},
          author = {Qinbing Fu and Nicola Bellotto and Huatian Wang and F. Claire Rind and Hongxin Wang and Shigang Yue},
       publisher = {Springer},
            year = {2019},
             doi = {10.1007/978-3-030-19823-7\_5},
        keywords = {ARRAY(0x5568fbb87bb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35586/},
        abstract = {This research addresses the challenging problem of visual collision detection in very complex and dynamic real physical scenes, specifically, the vehicle driving scenarios. This research takes inspiration from a large-field looming sensitive neuron, i.e., the lobula giant movement detector (LGMD) in the locust's visual pathways, which represents high spike frequency to rapid approaching objects. Building upon our previous models, in this paper we propose a novel inhibition mechanism that is capable of adapting to different levels of background complexity. This adaptive mechanism works effectively to mediate the local inhibition strength and tune the temporal latency of local excitation reaching the LGMD neuron. As a result, the proposed model is effective to extract colliding cues from complex dynamic visual scenes. We tested the proposed method using a range of stimuli including simulated movements in grating backgrounds and shifting of a natural panoramic scene, as well as vehicle crash video sequences. The experimental results demonstrate the proposed method is feasible for fast collision perception in real-world situations with potential applications in future autonomous vehicles.}
}

@inproceedings{lincoln35595,
           month = {May},
          author = {Huatian Wang and Qinbing Fu and Hongxin Wang and Jigen Peng and Shigang Yue},
       booktitle = {15th International Conference on Artificial Intelligence Applications and Innovations},
           title = {Constant Angular Velocity Regulation for Visually Guided Terrain Following},
       publisher = {Springer},
             doi = {10.1007/978-3-030-19823-7\_50},
           pages = {597--608},
            year = {2019},
        keywords = {ARRAY(0x5568fba53f68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35595/},
        abstract = {Insects use visual cues to control their flight behaviours. By estimating the angular velocity of the visual stimuli and regulating it to a constant value, honeybees can perform a terrain following task which keeps the certain height above the undulated ground. For mimicking this behaviour in a bio-plausible computation structure, this paper presents a new angular velocity decoding model based on the honeybee's behavioural experiments. The model consists of three parts, the texture estimation layer for spatial information extraction, the motion detection layer for temporal information extraction and the decoding layer combining information from pervious layers to estimate the angular velocity. Compared to previous methods on this field, the proposed model produces responses largely independent of the spatial frequency and contrast in grating experiments. The angular velocity based control scheme is proposed to implement the model into a bee simulated by the game engine Unity. The perfect terrain following above patterned ground and successfully flying over irregular textured terrain show its potential for micro unmanned aerial vehicles' terrain following.}
}

@article{lincoln35699,
          volume = {19},
          number = {9},
           month = {May},
          author = {Li Sun and Cheng Zhao and Zhi Yan and Pengcheng Liu and Tom Duckett and Rustam Stolkin},
           title = {A Novel Weakly-supervised approach for RGB-D-based Nuclear Waste Object Detection and Categorization},
       publisher = {IEEE},
            year = {2019},
         journal = {IEEE Sensors Journal},
             doi = {10.1109/JSEN.2018.2888815},
           pages = {3487--3500},
        keywords = {ARRAY(0x5568fbae6390)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35699/},
        abstract = {This  paper  addresses  the  problem  of  RGBD-based detection  and  categorization  of   waste  objects  for  nuclear  de- commissioning.  To  enable  autonomous  robotic  manipulation   for nuclear decommissioning, nuclear waste objects must be detected and categorized. However, as a  novel industrial application, large amounts  of  annotated  waste  object  data  are  currently  unavailable. To overcome this problem, we propose a weakly-supervised learning  approach  which   is  able  to  learn  a  deep  convolutional neural  network  (DCNN)  from  unlabelled  RGBD  videos  while requiring  very  few  annotations.  The  proposed  method  also  has the  potential  to  be  
applied  to  other  household  or  industrial applications. We evaluate our approach on the  Washington RGB- D  object  recognition  benchmark,  achieving  the  state-of-the-art performance  among semi-supervised methods. More importantly, we  introduce  a  novel  dataset,  i.e.   Birmingham  nuclear  waste simulants  dataset,  and  evaluate  our  proposed  approach  on  this  novel industrial object recognition challenge. We further propose a  complete  real-time  pipeline   for  RGBD-based  detection  and categorization of nuclear waste simulants. Our weakly-supervised  approach  has  demonstrated  to  be  highly  effective  in  solving  a novel  RGB-D  object  
detection  and  recognition  application  with limited human annotations.}
}

@inproceedings{lincoln39623,
       booktitle = {15th ESA Symposium on Advanced Space Technologies in Robotics and Automation},
           month = {May},
           title = {Robotic Architectures for the On-Orbit Assembly of Large Space Telescopes},
          author = {Angadh Nanjangud and Chakravarthini M Saaj and Peter C. Blacker and Alex Young and Craig I. Underwood and Steve Eckersley and Martin Sweeting and Paolo Bianco},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39623/}
}

@article{lincoln39225,
          volume = {181},
           month = {May},
          author = {Efthymios C. Rodias and Maria Lampridi and Alessandro Sopegno and Remigio Berruto and George Banias and Dionysis Bochtis and Patrizia Busato},
           title = {Optimal energy performance on allocating energy crops},
         journal = {Biosystems Engineering},
             doi = {10.1016/j.biosystemseng.2019.02.007},
           pages = {11--27},
            year = {2019},
        keywords = {ARRAY(0x5568fba5ea98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39225/},
        abstract = {There is a variety of crops that may be considered as potential biomass production crops. In order to select the best suitable for cultivation crop for a given area, a number of several factors should be taken into account. During the crop selection process, a common framework should be followed focussing on financial or energy performance. Combining multiple crops and multiple fields for the extraction of the best allocation requires a model to evaluate various and complex factors given a specific objective. This paper studies the maximisation of total energy gained from the biomass production by energy crops, reduced by the energy costs of the production process. The tool calculates the energy balance using multiple crops allocated to multiple fields. Both binary programming and linear programming methods are employed to solve the allocation problem. Each crop is assigned to a field (or a combination of crops are allocated to each field) with the aim of maximising the energy balance provided by the production system. For the demonstration of the tool, a hypothetical case study of three different crops cultivated for a decade (Miscanthus x giganteus, Arundo donax, and Panicum virgatum) and allocated to 40 dispersed fields around a biogas plant in Italy is presented. The objective of the best allocation is the maximisation of energy balance showing that the linear solution is slightly better than the binary one in the basic scenario while focussing on suggesting alternative scenarios that would have an optimal energy balance.}
}

@article{lincoln36284,
          volume = {4},
          number = {2},
           month = {April},
          author = {F. Brandherm and J. Peters and Gerhard Neumann and R. Akrour},
           title = {Learning Replanning Policies with Direct Policy Search},
            year = {2019},
         journal = {IEEE Robotics and Automation Letters (RA-L)},
             doi = {10.1109/LRA.2019.2901656},
           pages = {2196 --2203},
        keywords = {ARRAY(0x5568fb9f05c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36284/},
        abstract = {Direct policy search has been successful in learning challenging real world robotic motor skills by learning open-loop movement primitives with high sample efficiency. These primitives can be generalized to different contexts with varying initial configurations and goals. Current state-of-the-art contextual policy search algorithms can however not adapt to changing, noisy context measurements. Yet, these are common characteristics of real world robotic tasks. Planning a trajectory ahead based on an inaccurate context that may change during the motion often results in poor accuracy, especially with highly dynamical tasks. To adapt to updated contexts, it is sensible to learn trajectory replanning strategies. We propose a framework to learn trajectory replanning policies via contextual policy search and demonstrate that they are safe for the robot, that they can be learned efficiently and that they outperform non-replanning policies for problems with partially observable or perturbed context}
}

@article{lincoln41510,
          volume = {159},
           month = {April},
          author = {Yanchao Zhang and Junfeng Gao and Haiyan Cen and Yongliang Lu and Xiaoyue Yu and Yong He and Jan G. Pieters},
           title = {Automated spectral feature extraction from hyperspectral images to differentiate weedy rice and barnyard grass from a rice crop},
       publisher = {Elsevier},
            year = {2019},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2019.02.018},
           pages = {42--49},
        keywords = {ARRAY(0x5568fb6d62d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41510/},
        abstract = {Barnyard grass (Echinochloa crusgalli) and weedy rice (Oryza sativa f. spontanea) are two common and troublesome weed species in rice (Oryza sativa L.) crop. They cause significant yield loss in rice production while it is difficult to differentiate them for site-specific weed management. In this paper, we aimed to develop a classification model with important spectral features to recognize these two weeds and rice based on hyperspectral imaging techniques. There were 287 plant leaf samples in total which were scanned by the hyperspectral imaging systems within the spectral range from 380 nm to 1080 nm. After obtaining hyperspectral images, we first developed an algorithmic pipeline to automatically extract spectral features from line scan hyperspectral images. Then the raw spectral features were subjected to wavelet transformation for noise reduction. Random forests and support vector machine models were developed with the optimal hyperparameters to compare their performances in the test set. Moreover, feature selection was explored through successive projection algorithm (SPA). It is shown that the weighted support vector machine with 6 spectral features selected by SPA can achieve 100\%, 100\%, and 92\% recognition rates for barnyard grass, weedy rice and rice, respectively. Furthermore, the selected 6 wavelengths (415 nm, 561 nm, 687 nm, 705 nm, 735 nm, 1007 nm) have the potential to design a customized optical sensor for these two weeds and rice discrimination in practice.}
}

@inproceedings{lincoln47566,
           month = {April},
          author = {Zakaria Maamar and Thar Baker and Noura Faci and Emir Ugljanin and Mohammed Al-Khafajiy and Vanilson Bur{\'e}gio},
       booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
           title = {Towards a seamless coordination of cloud and fog: illustration through the internet-of-things},
       publisher = {ACM},
             doi = {10.1145/3297280.3297477},
           pages = {2008--2015},
            year = {2019},
        keywords = {ARRAY(0x5568fbae6348)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47566/},
        abstract = {With the increasing popularity of the Internet-of-Things (IoT), organizations are revisiting their practices as well as adopting new ones so they can deal with an ever-growing amount of sensed and actuated data that IoT-compliant things generate. Some of these practices are about the use of cloud and/or fog computing. The former promotes "anything-as-a-service" and the latter promotes "process data next to where it is located". Generally presented as competing models, this paper discusses how cloud and fog could work hand-in-hand through a seamless coordination of their respective "duties". This coordination stresses out the importance of defining where the data of things should be sent (either cloud, fog, or cloud\&fog concurrently) and in what order (either cloud then fog, fog then cloud, or fog\&cloud concurrently). Applications' concerns with data such as latency, sensitivity, and freshness dictate both the appropriate recipients and the appropriate orders. For validation purposes, a healthcare-driven IoT application along with an in-house testbed, that features real sensors and fog and cloud platforms, have permitted to carry out different experiments that demonstrate the technical feasibility of the coordination model.}
}

@article{lincoln35601,
          volume = {9},
          number = {4},
           month = {April},
          author = {Maria Lampridi and Dimitrios Kateris and Giorgos Vasileiadis and Simon Pearson and Claus S{\o}rensen and Athanasios Balafoutis and Dionysis Bochtis},
           title = {A Case-Based Economic Assessment of Robotics Employment in Precision Arable Farming},
       publisher = {MDPI},
            year = {2019},
         journal = {Agronomy},
             doi = {10.3390/agronomy9040175},
           pages = {175},
        keywords = {ARRAY(0x5568fbba6678)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35601/},
        abstract = {The need to intensify agriculture to meet increasing nutritional needs, in combination with the evolution of unmanned autonomous systems has led to the development of a series of ?smart? farming technologies that are expected to replace or complement conventional machinery and human labor. This paper proposes a preliminary methodology for the economic analysis of the employment of robotic systems in arable farming. This methodology is based on the basic processes for estimating the use cost for agricultural machinery. However, for the case of robotic systems, no average norms for the majority of the operational parameters are available. Here, we propose a novel estimation process for these parameters in the case of robotic systems. As a case study, the operation of light cultivation has been selected due the technological readiness for this type of operation.}
}

@inproceedings{lincoln39625,
       booktitle = {5th CEAS Conference on Guidance, Navigation and Control (EuroGNC)},
           month = {April},
           title = {Controlling a Non-Linear Space Robot using Linear Controllers},
          author = {A.W.I Mohamed and C. M. Saaj and A. Seddaoui and S. Eckersley},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39625/}
}

@article{lincoln39227,
          volume = {11},
          number = {6},
           month = {March},
          author = {Theodora Angelopoulou and Nikolaos Tziolas and Athanasios Balafoutis and George Zalidis and Dionysis Bochtis},
           title = {Remote Sensing Techniques for Soil Organic Carbon Estimation: A Review},
            year = {2019},
         journal = {Remote Sensing},
             doi = {10.3390/rs11060676},
           pages = {676},
        keywords = {ARRAY(0x5568fb67dc88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39227/},
        abstract = {Towards the need for sustainable development, remote sensing (RS) techniques in the Visible-Near Infrared?Shortwave Infrared (VNIR?SWIR, 400?2500 nm) region could assist in a more direct, cost-effective and rapid manner to estimate important indicators for soil monitoring purposes. Soil reflectance spectroscopy has been applied in various domains apart from laboratory conditions, e.g., sensors mounted on satellites, aircrafts and Unmanned Aerial Systems. The aim of this review is to illustrate the research made for soil organic carbon estimation, with the use of RS techniques, reporting the methodology and results of each study. It also aims to provide a comprehensive introduction in soil spectroscopy for those who are less conversant with the subject. In total, 28 journal articles were selected and further analysed. It was observed that prediction accuracy reduces from Unmanned Aerial Systems (UASs) to satellite platforms, though advances in machine learning techniques could further assist in the generation of better calibration models. There are some challenges concerning atmospheric, radiometric and geometric corrections, vegetation cover, soil moisture and roughness that still need to be addressed. The advantages and disadvantages of each approach are highlighted and future considerations are also discussed at the end.}
}

@article{lincoln35035,
          volume = {20},
           month = {March},
          author = {Simon Pearson and David May and Georgios Leontidis and Mark Swainson and Steve Brewer and Luc Bidaut and Jeremy Frey and Gerard Parr and Roger Maull and Andrea Zisman},
           title = {Are Distributed Ledger Technologies the Panacea for Food Traceability?},
       publisher = {Elsevier},
            year = {2019},
         journal = {Global Food Security},
             doi = {10.1016/j.gfs.2019.02.002},
           pages = {145--149},
        keywords = {ARRAY(0x5568fbacb028)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35035/},
        abstract = {Distributed Ledger Technology (DLT), such as blockchain, has the potential to transform supply chains. It can provide a cryptographically secure and immutable record of transactions and associated metadata (origin, contracts, process steps, environmental variations, microbial records, etc.) linked across whole supply chains. The ability to trace food items within and along a supply chain is legally required by all actors within the chain. It is critical to food safety, underpins trust and global food trade. However, current food traceability systems are not linked between all actors within the supply chain. Key metadata on the age and process history of a food is rarely transferred when a product is bought and sold through multiple steps within the chain. Herein, we examine the potential of massively scalable DLT to securely link the entire food supply chain, from producer to end user. Under such a paradigm, should a food safety or quality issue ever arise, authorized end users could instantly and accurately trace the origin and history of any particular food item. This novel and unparalleled technology could help underpin trust for the safety of all food, a critical component of global food security. In this paper, we investigate the (I) data requirements to develop DLT technology across whole supply chains, (ii) key challenges and barriers to optimizing the complete system, and (iii) potential impacts on production efficiency, legal compliance, access to global food markets and the safety of food. Our conclusion is that while DLT has the potential to transform food systems, this can only be fully realized through the global development and agreement on suitable data standards and governance. In addition, key technical issues need to be resolved including challenges with DLT scalability, privacy and data architectures.}
}

@article{lincoln36281,
          volume = {20},
          number = {54},
           month = {February},
          author = {Maximilian H{\"u}ttenrauch and Sosic Adrian and Gerhard Neumann},
           title = {Deep Reinforcement Learning for Swarm Systems},
       publisher = {Journal of Machine Learning Research},
            year = {2019},
         journal = {Journal of Machine Learning Research},
           pages = {1--31},
        keywords = {ARRAY(0x5568fbaca908)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36281/},
        abstract = {Recently, deep reinforcement learning (RL) methods have been applied successfully to multi-agent scenarios. Typically, the observation vector for decentralized decision making is represented by a concatenation of the (local) information an agent gathers about other agents. However, concatenation scales poorly to swarm systems with a large number of homogeneous agents as it does not exploit the fundamental properties inherent to these systems: (i) the agents in the swarm are interchangeable and (ii) the exact number of agents in the swarm is irrelevant. Therefore, we propose a new state representation for deep multi-agent RL based on mean embeddings of distributions, where we treat the agents as samples and use the empirical mean embedding as input for a decentralized policy. We define different feature spaces of the mean embedding using histograms, radial basis functions and neural networks trained end-to-end. We evaluate the representation on two well-known problems from the swarm literature in a globally and locally observable setup. For the local setup we furthermore introduce simple communication protocols. Of all approaches, the mean embedding representation using neural network features enables the richest information exchange between neighboring agents, facilitating the development of complex collective strategies.}
}

@inproceedings{lincoln47568,
           month = {February},
          author = {Mohammed Al-Khafajiy and Thar Baker and Hilal Al-Libawy and Atif Waraich and Carl Chalmers and Omar Alfandi},
       booktitle = {2018 11th International Conference on Developments in eSystems Engineering (DeSE)},
           title = {Fog Computing Framework for Internet of Things Applications},
       publisher = {IEEE},
             doi = {doi:10.1109/DeSE.2018.00017},
           pages = {71--77},
            year = {2019},
        keywords = {ARRAY(0x5568fba2fc80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47568/},
        abstract = {Within the Internet of Things (IoT) era, a big volume of data is generated/gathered every second from billions of connected devices. The current network paradigm, which relies on centralised data centres (a.k.a. Cloud computing), becomes impractical solution for IoT data storing and processing due to the long distance between the data source (e.g., sensors) and designated data centres. In other words, by the time the data reaches a far data centre, the importance of the data would be vanished. Therefore, the network topologies have been evolved to permit data processing and storage at the edge of the network, introducing what so-called "Fog computing". The later will obviously lead to improvements in quality of service (QoS) via processing and responding quickly and efficiently to varieties of data processing requests. Therefore, understanding Fog computing architecture and its role in improving QoS is a paramount research topic. In this research, we are proposing a Fog computing architecture and framework to improve QoS for IoT applications. Proposed system supports cooperation among Fog nodes in a given location, in order to permit data processing in a shared mode, hence satisfies QoS and serves largest number of service requests. The proposed framework could have the potential in achieving sustainable network paradigm and highlights significant benefits of Fog computing into the computing ecosystem.}
}

@inproceedings{lincoln37442,
          volume = {Part F},
           month = {February},
          author = {L. Jackson and C. Saaj and A. Seddaoui and C. Whiting and S. Eckersley and M. Ferris},
            note = {cited By 0},
       booktitle = {5th International Conference on Mechatronics and Robotics Engineering},
           title = {Design of a small space robot for on-orbit assembly missions},
       publisher = {ACM},
            year = {2019},
         journal = {ACM International Conference Proceeding Series},
             doi = {10.1145/3314493.3314520},
           pages = {107--112},
        keywords = {ARRAY(0x5568fbb58378)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37442/},
        abstract = {Intelligent robots have revolutionised terrestrial assembly and servicing processes, while low-cost small satellites have transformed the economics of space. This paper dovetails both technologies and proposes an innovative design for a small space robot that is potentially capable of assembly operations in-orbit. The drive for such missions stems from the growing commercial interests and scientific benefits offered by massive structures in space, such as the future large aperture astronomical or Earth Observation telescopes. However, limitations in the lifting capacity of launch vehicles currently impose severe restrictions on the size of the self-deployable monolithic telescope structure that can be carried. As a result, there is a growing demand for advancing the capabilities of space robots to assemble modular components in-orbit. To assess the feasibility of a small space robot for future in-space assembly missions, a detailed design is outlined and analysed in this paper. The trade-off between the manipulator configuration and its base spacecraft sizing is presented. This coherent design exercise is driven by various mission requirements that consider the constraints of a small spacecraft as well as its extreme operating environment.}
}

@article{lincoln38395,
          volume = {28},
          number = {1},
           month = {February},
          author = {J. Ganzer-Ripoll and N. Criado and M. Lopez-Sanchez and Simon Parsons and J.A. Rodriguez-Aguilar},
            note = {cited By 0},
           title = {Combining Social Choice Theory and Argumentation: Enabling Collective Decision Making},
            year = {2019},
         journal = {Group Decision and Negotiation},
             doi = {10.1007/s10726-018-9594-6},
           pages = {127--173},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38395/}
}

@incollection{lincoln39234,
          volume = {953},
           month = {February},
          author = {Dimitrios Bechtsis and Vasileios Moisiadis and Naoum Tsolakis and Dimitrios Vlachos and Dionysis Bochtis},
       booktitle = {Information and Communication Technologies in Modern Agricultural Development},
           title = {Unmanned Ground Vehicles in Precision Farming Services: An Integrated Emulation Modelling Approach},
       publisher = {Springer},
            year = {2019},
             doi = {doi:10.1007/978-3-030-12998-9\_13},
           pages = {177--190},
        keywords = {ARRAY(0x5568fbaa8180)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39234/},
        abstract = {Autonomous systems are a promising alternative for safely executing precision farming activities in a 24/7 perspective. In this context Unmanned Ground Vehicles (UGVs) are used in custom agricultural fields, with sophisticated sensors and data fusion techniques for real-time mapping and navigation. The aim of this study is to present a simulation software tool for providing effective and efficient farming activities in orchard fields and demonstrating the applicability of simulation in routing algorithms, hence increasing productivity, while dynamically addressing operational and tactical level uncertainties. The three dimensional virtual world includes the field layout and the static objects (orchard trees, obstacles, physical boundaries) and is constructed in the open source Gazebo simulation software while the Robot Operating System (ROS) and the implemented algorithms are tested using a custom vehicle. As a result a routing algorithm is executed and enables the UGV to pass through all the orchard trees while dynamically avoiding static and dynamic obstacles. Unlike existing sophisticated tools, the developed mechanism could accommodate an extensive variety of agricultural activities and could be transparently transferred from the simulation environment to real world ROS compatible UGVs providing user-friendly and highly customizable navigation.}
}

@incollection{lincoln39235,
          volume = {953},
           month = {February},
          author = {Claus Aage Gr{\o}n S{\o}rensen and Dimitrios Kateris and Dionysis Bochtis},
       booktitle = {Information and Communication Technologies in Modern Agricultural Development},
           title = {ICT Innovations and Smart Farming},
       publisher = {Springer},
            year = {2019},
             doi = {doi:10.1007/978-3-030-12998-9\_1},
           pages = {1--19},
        keywords = {ARRAY(0x5568fba54010)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39235/},
        abstract = {Agriculture plays a vital role in the global economy with the majority of the rural population in developing countries depending on it. The depletion of natural resources makes the improvement of the agricultural production more important but also more difficult than ever. This is the reason that although the demand is constantly growing, Information and Communication Technology (ICT) offers to producers the adoption of sustainability and improvement of their daily living conditions. ICT offers timely and updated relevant information such as weather forecast, market prices, the occurrence of new diseases and varieties, etc. The new knowledge offers a unique opportunity to bring the production enhancing technologies to the farmers and empower themselves with modern agricultural technology and act accordingly for increasing the agricultural production in a cost effective and profitable manner. The use of ICT itself or combined with other ICT systems results in productivity improvement and better resource use and reduces the time needed for farm management, marketing, logistics and quality assurance.}
}

@article{lincoln39224,
          volume = {178},
           month = {February},
          author = {Efthymios C. Rodias and Alessandro Sopegno and Remigio Berruto and Dionysis Bochtis and Eugenio Cavallo and Patrizia Busato},
           title = {A combined simulation and linear programming method for scheduling organic fertiliser application},
       publisher = {Elsevier},
            year = {2019},
         journal = {Biosystems Engineering},
             doi = {10.1016/j.biosystemseng.2018.11.002},
           pages = {233--243},
        keywords = {ARRAY(0x5568fb6d1e98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39224/},
        abstract = {Logistics have been used to analyse agricultural operations, such as chemical application, mineral or organic fertilisation and harvesting-handling operations. Recently, due to national or European commitments concerning livestock waste management, this waste is being applied in many crops instead of other mineral fertilisers. The organic fertiliser produced has a high availability although most of the crops it is applied to have strict timeliness issues concerning its application. Here, organic fertilizer (as liquid manure) distribution logistic system is modelled by using a combined simulation and linear programming method. The method applies in certain crops and field areas taking into account specific agronomical, legislation and other constraints with the objective of minimising the optimal annual cost. Given their direct connection with the organic fertiliser distribution, the operations of cultivation and seeding were included. In a basic scenario, the optimal cost was assessed for both crops in total cultivated area of 120 ha. Three modified scenarios are presented. The first regards one more tractor as being available and provides a reduction of 3.8\% in the total annual cost in comparison with the basic scenario. In the second and third modified scenarios fields having high nitrogen demand next to the farm are considered with one or two tractors and savings of 2.5\% and 6.1\%, respectively, compared to the basic scenario are implied. Finally, it was concluded that the effect of distance from the manure production to the location of the fields could reduce costs by 6.5\%.}
}

@article{lincoln35398,
          volume = {11},
          number = {2},
           month = {January},
          author = {Yongchao Zhu and Xuan Li and Simon Pearson and Dongli Wu and Ruijing Sun and Sarah Johnson and James Wheeler and Shibo Fang},
           title = {Evaluation of Fengyun-3C Soil Moisture Products Using In-Situ Data from the Chinese Automatic Soil Moisture Observation Stations: A Case Study in Henan Province, China},
            year = {2019},
         journal = {Water},
             doi = {doi:10.3390/w11020248},
           pages = {248},
        keywords = {ARRAY(0x5568fbb8ff40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35398/},
        abstract = {Soil moisture (SM) products derived from passive satellite missions are playing an increasingly important role in agricultural applications, especially crop monitoring and disaster warning. Evaluating the dependability of satellite-derived soil moisture products on a large scale is crucial. In this study, we assessed the level 2 (L2) SM product from the Chinese Fengyun-3C (FY-3C) radiometer against in-situ measurements collected from the Chinese Automatic Soil Moisture Observation Stations (CASMOS) during a one-year period from 1 January 2016 to 31 December 2016 across Henan in China. In contrast, we also investigated the skill of the Advanced Microwave Scanning Radiometer 2 (AMSR2) and Soil Moisture Active/Passive (SMAP) SM products simultaneously. Four statistical parameters were used to evaluate these products? reliability: mean difference, root-mean-square error (RMSE), unbiased RMSE (ubRMSE), and the correlation coefficient. Our assessment results revealed that the FY-3C L2 SM product generally showed a poor correlation with the in-situ SM data from CASMOS on both temporal and spatial scales. The AMSR2 L3 SM product of JAXA (Japan Aerospace Exploration Agency) algorithm had a similar level of skill as FY-3C in the study area. The SMAP L3 SM product outperformed the FY-3C temporally but showed lower performance in capturing the SM spatial variation. A time-series analysis indicated that the correlations and estimated error varied systematically through the growing periods of the key crops in our study area. FY-3C L2 SM data tended to overestimate soil moisture during May, August, and September when the crops reached maximum vegetation density and tended to underestimate the soil moisture content during the rest of the year. The comparison between the statistical parameters and the ground vegetation water content (VWC) further showed that the FY-3C SM product performed much better under a low VWC condition ({\ensuremath{<}}0.3 kg/m2) than a high VWC condition ({\ensuremath{>}}0.3 kg/m2), and the performance generally decreased with increased VWC. To improve the accuracy of the FY-3C SM product, an improved algorithm that can better characterize the variations of the ground VWC should be applied in the future.}
}

@article{lincoln40818,
          volume = {325},
           month = {January},
          author = {Gautham Das and Philip J. Vance and Dermot Kerr and Sonya A. Coleman and Thomas M. McGinnity and Jian K. Liu},
           title = {Computational modelling of salamander retinal ganglion cells using machine learning approaches},
       publisher = {Elsevier},
            year = {2019},
         journal = {Neurocomputing},
             doi = {10.1016/j.neucom.2018.10.004},
           pages = {101--112},
        keywords = {ARRAY(0x5568fbab1c58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40818/},
        abstract = {Artificial vision using computational models that can mimic biological vision is an area of ongoing research. One of the main themes within this research is the study of the retina and in particular, retinal ganglion cells which are responsible for encoding the visual stimuli. A common approach to modelling the internal processes of retinal ganglion cells is the use of a linear ? non-linear cascade model, which models the cell?s response using a linear filter followed by a static non-linearity. However, the resulting model is generally restrictive as it is often a poor estimator of the neuron?s response. In this paper we present an alternative to the linear ? non-linear model by modelling retinal ganglion cells using a number of machine learning techniques which have a proven track record for learning complex non-linearities in many different domains. A comparison of the model predicted spike rate shows that the machine learning models perform better than the standard linear ? non-linear approach in the case of temporal white noise stimuli.}
}

@inproceedings{lincoln36201,
       booktitle = {2nd UK-RAS Robotics and Autonomous Systems Conference},
           month = {January},
           title = {Towards a Dataset of Activities for Action Recognition in Open Fields},
          author = {Alexander Gabriel and Nicola Bellotto and Paul Baxter},
       publisher = {UK-RAS},
            year = {2019},
           pages = {64--67},
        keywords = {ARRAY(0x5568fb6d17c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36201/},
        abstract = {In an agricultural context, having autonomous robots that can work side-by-side with human workers provide a range of productivity benefits. In order for this to be achieved safely and effectively, these autonomous robots require the ability to understand a range of human behaviors in order to facilitate task communication and coordination. The recognition of human actions is a key part of this, and is the focus of this paper. Available datasets for Action Recognition generally feature controlled lighting and framing while recording subjects from the front. They mostly reflect good recording conditions but fail to model the data a robot will have to work with in the field, such as varying distance and lighting conditions. In this work, we propose a set of recording conditions, gestures and behaviors that better reflect the environment an agricultural
robot might find itself in and record a dataset with a range of sensors that demonstrate these conditions.}
}

@article{lincoln35570,
           month = {January},
           title = {Choosing grasps to enable collision-free post-grasp manipulations},
          author = {Tommaso Pardi and Rustam Stolkin and Amir Ghalamzan Esfahani},
       publisher = {IEEE},
            year = {2019},
             doi = {10.1109/HUMANOIDS.2018.8625027},
         journal = {IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids)},
        keywords = {ARRAY(0x5568fbb04c18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35570/},
        abstract = {Consider the task of grasping the handle of a door, and then pushing it until the door opens. These two fundamental robotics problems (selecting secure grasps of a hand on an object, e.g. the door handle, and planning collision-free trajectories of a robot arm that will move that object along a desired path) have predominantly been studied separately from one another. Thus, much of the grasping literature overlooks the fundamental purpose of grasping objects, which is typically to make them move in desirable ways. Given a desired post-grasp trajectory of the object, different choices of grasp will often determine whether or not collision-free post-grasp motions of the arm can be found, which will deliver that trajectory. We address this problem by examining a number of possible stable grasping configurations on an object. For each stable grasp, we explore the motion space of the manipulator which would be needed for post-grasp motions, to deliver the object along the desired trajectory. A criterion, based on potential fields in the post-grasp motion space, is used to assign a collision-cost to each grasp. A grasping configuration is then selected which enables the desired post-grasp object motion while minimising the proximity of all robot parts to obstacles during motion. We demonstrate our method with peg-in-hole and pick-and-place experiments in cluttered scenes, using a Franka Panda robot. Our approach is effective in selecting appropriate grasps, which enable both stable grasp and also desired post-grasp movements without collisions. We also show that, when grasps are selected based on grasp stability alone, without consideration for desired post-grasp manipulations, the corresponding post-grasp movements of the manipulator may result in collisions.}
}

@inproceedings{lincoln45010,
       booktitle = {2nd UK-RAS ROBOTICS AND AUTONOMOUS SYSTEMS CONFERENCE},
           month = {January},
           title = {Establishing Continuous Communication through Dynamic Team Behaviour Switching},
          author = {Tsvetan Zhivkov and Eric Schneider and Elizabeth Sklar},
       publisher = {UK-RAS19 Conference},
            year = {2019},
             doi = {10.31256/UKRAS19.22},
        keywords = {ARRAY(0x5568fbb54480)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45010/},
        abstract = {Maintaining continuous communication is an important factor that contributes to the success of multi-robot systems. Most research involving multi-robot teams is conducted in controlled laboratory settings, where continuous communication is assumed, typically because there is a wireless network (wifi) that keeps all the robots connected. But for multi-robot teams to operate successfully ?in the wild?, it is crucial to consider how communication can be maintained when signals fail or robots move out of range. This paper presents a novel ?leader-follower behaviour? with dynamic role switching and messaging that supports uninterrupted communication, regardless of network perturbations. A series of experiments were conducted in which it is shown how network perturbations effect performance, comparing a baseline with the new leaderfollower behaviour. The experiments record metrics on team success, given the two conditions. These results are significant for real-world multi-robot systems applications that require continuous communication amongst team members.}
}

@inproceedings{lincoln39207,
       booktitle = {Smart Industry Workshop 2019},
           month = {January},
           title = {MODEL BASED 3D POINT CLOUD SEGMENTATION FOR AUTOMATED SELECTIVE BROCCOLI HARVESTING},
          author = {Hector Montes and Tom Duckett and Grzegorz Cielniak},
            year = {2019},
        keywords = {ARRAY(0x5568fba5d640)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39207/},
        abstract = {Segmentation of 3D objects in cluttered scenes is a highly relevant problem. Given a 3D point cloud produced by a depth sensor, the goal is to separate objects of interest in the foreground from other elements in the background. We research 3D imaging methods to accurately segment and identify broccoli plants in the field. The ability to separate parts into different sets of sensor readings is an important task towards this goal. Our research is focused on the broccoli head segmentation problem as a first step towards size estimation of each broccoli crop in order to establish whether or not it is suitable for cutting.}
}

@inproceedings{lincoln47567,
           month = {January},
          author = {Mohammed Al-Khafajiy and Thar Baker and Atif Waraich and Dhiya Al-Jumeily and Abir Hussain},
       booktitle = {2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC Companion)},
           title = {IoT-Fog Optimal Workload via Fog Offloading},
       publisher = {IEEE},
             doi = {doi:10.1109/UCC-Companion.2018.00081},
           pages = {359--364},
            year = {2019},
        keywords = {ARRAY(0x5568fbbc3d28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47567/},
        abstract = {Billions of devises are expected to be connected to the Internet of Things network in the near future, therefore, a considerable amount of data will be generated, and gathered every second. The current network paradigm, which relies on centralised data-centres (a.k.a. Cloud computing), becomes impractical solution for IoT data due to the long distance between the data source and designated data-center. In other words, the amount of time taken by data to travel to a data-centre makes the importance of the data vanished. Therefore, the network topology have been evolved to permit data processing at the edge of the network, introducing what so-called "Fog computing". The later will obviously lead to improvements in quality of service via efficient and quick responding to sensors requests. In this paper, we are proposing a fog computing architecture and framework to enhance QoS via request offloading method. The proposed method employ a collaboration strategy among fog nodes in order to permit data processing in a shared mode, hence satisfies QoS and serves largest number of IoT requests. The proposed framework could have the potential in achieving sustainable network paradigm and highlights significant benefits of fog computing into the computing ecosystem.}
}

@inproceedings{lincoln34713,
       booktitle = {International Conference on Intelligent Robots and Systems (IROS 2018)},
           month = {January},
           title = {Contact Detection and Size Estimation Using a Modular Soft Gripper with Embedded Flex Sensors},
          author = {Khaled Elgeneidy and Gerhard Neumann and Simon Pearson and Michael Jackson and Niels Lohse},
            year = {2019},
        keywords = {ARRAY(0x5568fbae6498)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34713/},
        abstract = {Grippers made from soft elastomers are able to passively and gently adapt to their targets allowing deformable objects to be grasped safely without causing bruise or damage. However, it is difficult to regulate the contact forces due to the lack of contact feedback for such grippers. In this paper, a modular soft gripper is presented utilizing interchangeable soft pneumatic actuators with embedded flex sensors as fingers of the gripper. The fingers can be assembled in different configurations using 3D printed connectors. The paper investigates the potential of utilizing the simple sensory feedback from the flex and pressure sensors to make additional meaningful inferences regarding the contact state and grasped object size. We study the effect of the grasped object size and contact type on the combined feedback from the embedded flex sensors of opposing fingers. Our results show that a simple linear relationship exists between the grasped object size and the final flex sensor reading at fixed input conditions, despite the variation in object weight and contact type. Additionally, by simply monitoring the time series response from the flex sensor, contact can be detected by comparing the response to the known free-bending response at the same input conditions. Furthermore, by utilizing the measured internal pressure supplied to the soft fingers, it is possible to distinguish between power and pinch grasps, as the contact type affects the rate of change in the flex sensor readings against the internal pressure.}
}

@inproceedings{lincoln36001,
       booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {January},
           title = {Learning Monocular Visual Odometry with Dense 3D Mapping from Dense 3D Flow},
          author = {Cheng Zhao and Li Sun and Pulak Purkait and Tom Duckett and Rustam Stolkin},
       publisher = {IEEE},
            year = {2019},
             doi = {10.1109/IROS.2018.8594151},
        keywords = {ARRAY(0x5568fbb01b18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36001/},
        abstract = {This paper introduces a fully deep learning approach to monocular SLAM, which can perform simultaneous localization using a neural network for learning visual odometry (L-VO) and dense 3D mapping. Dense 2D flow and a depth image are generated from monocular images by sub-networks, which are then used by a 3D flow associated layer in the L-VO network to generate dense 3D flow. Given this 3D flow, the dual-stream L-VO network can then predict the 6DOF relative pose and furthermore reconstruct the vehicle trajectory. In order to learn the correlation between motion directions, the Bivariate Gaussian modeling is employed in the loss function. The L-VO network achieves an overall performance of 2.68 \% for average translational error and 0.0143?/m for average rotational error on the KITTI odometry benchmark. Moreover, the learned depth is leveraged to generate a dense 3D map. As a result, an entire visual SLAM system, that is, learning monocular odometry combined with dense 3D mapping, is achieved.}
}

@misc{lincoln34922,
           month = {January},
           title = {Use and citation of  paper "Fox et al (2018), ?When should the chicken cross the road? Game theory for autonomous vehicle - human interactions conference paper?" by the Law Commission to review and potentially change the law of the UK on autonomous vehicles.   Cited in their consultation report,  "Automated Vehicles: A joint preliminary consultation paper" on p174, ref 651.},
          author = {Charles Fox},
            year = {2019},
         journal = {Automated Vehicles: A joint preliminary consultation paper},
        keywords = {ARRAY(0x5568fba64378)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34922/},
        abstract = {Topic of this consultation: The Centre for Connected and Automated Vehicles (CCAV) has
asked the Law Commission of England and Wales and the Scottish Law Commission to
examine options for regulating automated road vehicles. It is a three-year project, running from
March 2018 to March 2021. This preliminary consultation paper focuses on the safety of
passenger vehicles.
Driving automation refers to a broad range of vehicle technologies. Examples range from
widely-used technologies that assist human drivers (such as cruise control) to vehicles that
drive themselves with no human intervention. We concentrate on automated driving systems
which do not need human drivers for at least part of the journey.
This paper looks at are three key themes. First, we consider how safety can be assured before
and after automated driving systems are deployed. Secondly, we explore criminal and civil
liability. Finally, we examine the need to adapt road rules for artificial intelligence.}
}

@article{lincoln34502,
          volume = {156},
           month = {January},
          author = {Rafael Ceasar Tieppo and Thiago Lib{\'o}rio Romanelli and Marcos Milan and Claus Aage Gr{\o}n S{\o}rensen and Dionysis Bochtis},
           title = {Modeling cost and energy demand in agricultural machinery fleets for soybean and maize cultivated using a no-tillage system},
       publisher = {Elsevier},
            year = {2019},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2018.11.032},
           pages = {282--292},
        keywords = {ARRAY(0x5568fba74c20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34502/},
        abstract = {Climate, area expansion and the possibility to grow soybean and maize within a same season using the no-tillage system and mechanized agriculture are factors that promoted the agriculture growth in Mato Grosso State ? Brazil. Mechanized operations represent around 23\% of production costs for maize and soybean, demanding a considerably powerful machinery. Energy balance is a tool to verify the sustainability level of mechanized system. Regarding the sustainability components profit and environment, this study aims to develop a deterministic model for agricultural machinery costs and energy demand for no-tillage system production of soybean and maize crops. In addition, scenario simulation aids to analyze the influence of fleet sizing regarding cost and energy demand. The development of the deterministic model consists on equations and data retrieved from literature. A simulation was developed for no-tillage soybean production system in Brazil, considering three basic mechanized operations (sowing, spraying and harvesting). Thereby, for those operations, three sizes of machinery commercially available and regularly used (small, medium, large) and seven levels of cropping area (500, 1000, 2000, 4000, 6000, 8000 and 10,000 ha) were used. The developed model was consistent for predictions of power demand, fuel consumption and costs. We noticed that the increase in area size implies in more working time for the machinery, which decreases the cost difference among the combinations. The greatest difference for the smallest area (500 ha) was 22.1 and 94.8\% for sowing and harvesting operations, respectively. For 4000 and 10,000 ha, the difference decreased to 1.30 and 0.20\%. Simulated scenarios showed the importance of determining operational cost and energy demand when energy efficiency is desired.}
}

@inproceedings{lincoln40837,
       booktitle = {2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           title = {Improving Local Trajectory Optimisation using Probabilistic Movement Primitives},
          author = {Ashith Babu and Peter Lightbody and Gautham Das and Pengcheng Liu and Sebastian Gomez-Gonzalez and Gerhard Neumann},
       publisher = {IEEE},
            year = {2019},
           pages = {2666--2671},
             doi = {10.1109/IROS40897.2019.8967980},
        keywords = {ARRAY(0x5568fbb75ac8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40837/},
        abstract = {Local trajectory optimisation techniques are a powerful tool for motion planning. However, they often get stuck in local optima depending on the quality of the initial solution and consequently, often do not find a valid (i.e. collision free) trajectory. Moreover, they often require fine tuning of a cost function to obtain the desired motions. In this paper, we address both problems by combining local trajectory optimisation with learning from demonstrations. The human expert demonstrates how to reach different target end-effector locations in different ways. From these demonstrations, we estimate a trajectory distribution, represented by a Probabilistic Movement Primitive (ProMP). For a new target location, we sample different trajectories from the ProMP and use these trajectories as initial solutions for the local optimisation. As the ProMP generates versatile initial solutions for the optimisation, the chance of finding poor local minima is significantly reduced. Moreover, the learned trajectory distribution is used to specify the smoothness costs for the optimisation, resulting in solutions of similar shape as the demonstrations. We demonstrate the effectiveness of our approach in several complex obstacle avoidance scenarios.}
}

@article{lincoln38396,
          volume = {11649},
          author = {T. Flyr and Simon Parsons},
            note = {cited By 0},
           title = {Towards Adversarial Training for Mobile Robots},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-23807-0\_17},
           pages = {197--208},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38396/}
}

@inproceedings{lincoln39418,
       booktitle = {20th Annual Conference, TAROS 2019},
           title = {The Downsizing of a Free-Flying Space Robot},
          author = {Lucy Jackson and Chakravarthini M. Saaj and Asma Seddaoui and Calem Whiting and Steve Eckersley and Mark Ferris},
       publisher = {Springer},
            year = {2019},
           pages = {480--483},
             doi = {10.1007/978-3-030-25332-5},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39418/}
}

@inproceedings{lincoln39621,
          volume = {11650},
          author = {John Koleosho and Chakravarthini  M. Saaj},
       booktitle = {Towards Autonomous Robotic Systems},
           title = {System Design and Control of a Di-Wheel Rover},
       publisher = {Springer},
             doi = {10.1007/978-3-030-25332-5\_35},
           pages = {409--421},
            year = {2019},
        keywords = {ARRAY(0x5568fbb90678)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39621/},
        abstract = {Traditionally, wheeled rovers are used for planetary surface exploration and six-wheeled chassis designs based on the Rocker-Bogie suspension system have been tested successfully on Mars. However, it is difficult to explore craters and crevasses using large six or four-wheeled rovers. Innovative designs based on smaller Di-Wheel Rovers might be better suited for such challenging terrains. A Di-Wheel Rover is a self - balancing two-wheeled mobile robot that can move in all directions within a two-dimensional plane, as well as stand upright by balancing on two wheels.

This paper presents the outcomes of a feasibility study on a Di-Wheel Rover for planetary exploration missions. This includes developing its chassis design based on the hardware and software requirements, prototyping, and subsequent testing. The main contribution of this paper is the design of a self-balancing control system for the Di-Wheel Rover. This challenging design exercise was successfully completed through extensive experimentation thereby validating the performance of the Di-Wheel Rover. The details on the structural design, tuning controller gains based on an inverted pendulum model, and testing on different ground surfaces are described in this paper. The results presented in this paper give a new insight into designing low-cost Di-Wheel Rovers and clearly, there is a potential to use Di-Wheel Rovers for future planetary exploration.}
}

@inproceedings{lincoln36413,
       booktitle = {Proc. of the Int. Conf. on Image Analysis and Processing (ICIAP)},
           title = {ActiVis: Mobile Object Detection and Active Guidance for People with Visual Impairments},
          author = {Jacobus Lock and A. G. Tramontano and S. Ghidoni and Nicola Bellotto},
            year = {2019},
        keywords = {ARRAY(0x5568fb9ff6a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36413/},
        abstract = {The ActiVis project aims to deliver a mobile system that is able to guide a person with visual impairments towards a target object or area in an unknown indoor environment. For this, it uses new developments in object detection, mobile computing, action generation and human-computer interfacing to interpret the user's surroundings and present effective guidance directions. Our approach to direction generation uses a Partially Observable Markov Decision Process (POMDP) to track the system's state and output the optimal location to be investigated. This system includes an object detector and an audio-based guidance interface to provide a complete active search pipeline. The ActiVis system was evaluated in a set of experiments showing better performance than a simpler unguided case.}
}

@inproceedings{lincoln34596,
       booktitle = {14th International Conference on Computer Vision Theory and Applications (VISAPP)},
           title = {Active Object Search with a Mobile Device for People with Visual Impairments},
          author = {Jacobus Lock and Grzegorz Cielniak and Nicola Bellotto},
       publisher = {VISIGRAPP},
            year = {2019},
           pages = {476--485},
             doi = {10.5220/0007582304760485},
        keywords = {ARRAY(0x5568fbb92a20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34596/},
        abstract = {Modern smartphones can provide a multitude of services to assist people with visual impairments, and their cameras in particular can be useful for assisting with tasks, such as reading signs or searching for objects in unknown environments. Previous research has looked at ways to solve these problems by processing the camera's video feed, but very little work has been done in actively guiding the user towards specific points of interest, maximising the effectiveness of the underlying visual algorithms. In this paper, we propose a control algorithm based on a Markov Decision Process that uses a smartphone?s camera to generate real-time instructions to guide a user towards a target object. The solution is part of a more general active vision application for people with visual impairments. An initial implementation of the system on a smartphone was experimentally evaluated with participants with healthy eyesight to determine the performance of the control algorithm. The results show the effectiveness of our solution and its potential application to help people with visual impairments find objects in unknown environments.}
}

@inproceedings{lincoln39624,
       booktitle = {15th ESA Symposium on Advanced Space Technologies in Robotics and Automation},
           title = {A Self-Reconfigurable Undulating Grasper for Asteroid Mining},
          author = {Suzanna Lucarotti and Chakravarthini M. Saaj and Elie Allouis and Paolo Bianco},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39624/}
}

@article{lincoln36283,
           title = {Compatible natural gradient policy search},
          author = {J. Pajarinen and H.L. Thai and R. Akrour and J. Peters and Gerhard Neumann},
       publisher = {Springer},
            year = {2019},
             doi = {10.1007/s10994-019-05807-0},
         journal = {Machine Learning},
        keywords = {ARRAY(0x5568fba5eab0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36283/},
        abstract = {Trust-region methods have yielded state-of-the-art results in policy search. A common approach is to use KL-divergence to bound the region of trust resulting in a natural gradient policy update. We show that the natural gradient and trust region optimization are equivalent if we use the natural parameterization of a standard exponential policy distribution in combination with compatible value function approximation. Moreover, we show that standard natural gradient updates may reduce the entropy of the policy according to a wrong schedule leading to premature convergence. To control entropy reduction we introduce a
new policy search method called compatible policy search (COPOS) which bounds entropy loss. The experimental results show that COPOS yields state-of-the-art results in challenging continuous control tasks and in discrete partially observable tasks.}
}

@article{lincoln38400,
          volume = {11327},
          author = {A.R. Panisson and ?. Sarkadi and P. McBurney and Simon Parsons and R.H. Bordini},
            note = {cited By 0},
           title = {On the Formal Semantics of Theory of Mind in Agent Communication},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-17294-7{$_2$}},
           pages = {18--32},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38400/}
}

@misc{lincoln38397,
           title = {Sentiment-stance-specificity (SSS) dataset: Identifying support-based entailment among opinions},
          author = {P. Rajendran and D. Bollegala and Simon Parsons},
            year = {2019},
           pages = {619--626},
            note = {cited By 0},
         journal = {LREC 2018 - 11th International Conference on Language Resources and Evaluation},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38397/}
}

@article{lincoln38399,
          volume = {11327},
          author = {{\c S}. Sarkadi and A.R. Panisson and R.H. Bordini and P. McBurney and S. Parsons},
            note = {cited By 0},
           title = {Towards an Approach for Modelling Uncertain Theory of Mind in Multi-Agent Systems},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-17294-7{$_1$}},
           pages = {3--17},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38399/},
        abstract = {Applying Theory of Mind to multi-agent systems enables agents to model and reason about other agents? minds. Recent work shows that this ability could increase the performance of agents, making them more efficient than agents that lack this ability. However, modelling others agents? minds is a difficult task, given that it involves many factors of uncertainty, e.g., the uncertainty of the communication channel, the uncertainty of reading other agents correctly, and the uncertainty of trust in other agents. In this paper, we explore how agents acquire and update Theory of Mind under conditions of uncertainty. To represent uncertain Theory of Mind, we add probability estimation on a formal semantics model for agent communication based on the BDI architecture and agent communication languages.}
}

@article{lincoln38401,
          volume = {32},
          number = {4},
          author = {{\c S}. Sarkadi and A.R. Panisson and R.H. Bordini and P. McBurney and S. Parsons and M. Chapman},
            note = {cited By 0},
           title = {Modelling deception using theory of mind in multi-agent systems},
            year = {2019},
         journal = {AI Communications},
             doi = {10.3233/AIC-190615},
           pages = {287--302},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38401/},
        abstract = {Agreement, cooperation and trust would be straightforward if deception did not ever occur in communicative interactions. Humans have deceived one another since the species began. Do machines deceive one another or indeed humans? If they do, how may we detect this? To detect machine deception, arguably requires a model of how machines may deceive, and how such deception may be identified. Theory of Mind (ToM) provides the opportunity to create intelligent machines that are able to model the minds of other agents. The future implications of a machine that has the capability to understand other minds (human or artificial) and that also has the reasons and intentions to deceive others are dark from an ethical perspective. Being able to understand the dishonest and unethical behaviour of such machines is crucial to current research in AI. In this paper, we present a high-level approach for modelling machine deception using ToM under factors of uncertainty and we propose an implementation of this model in an Agent-Oriented Programming Language (AOPL). We show that the Multi-Agent Systems (MAS) paradigm can be used to integrate concepts from two major theories of deception, namely Information Manipulation Theory 2 (IMT2) and Interpersonal Deception Theory (IDT), and how to apply these concepts in order to build a model of computational deception that takes into account ToM. To show how agents use ToM in order to deceive, we define an epistemic agent mechanism using BDI-like architectures to analyse deceptive interactions between deceivers and their potential targets and we also explain the steps in which the model can be implemented in an AOPL. To the best of our knowledge, this work is one of the first attempts in AI that (i) uses ToM along with components of IMT2 and IDT in order to analyse deceptive interactions and (ii) implements such a model.}
}

@article{lincoln38398,
          volume = {11763},
          author = {I. Sassoon and N. K{\"o}kciyan and E. Sklar and Simon Parsons},
            note = {cited By 0},
           title = {Explainable argumentation for wellness consultation},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-30391-4{$_1$}{$_1$}},
           pages = {186--202},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38398/}
}

@article{lincoln38539,
          volume = {11763},
          author = {I. Sassoon and N. K{\"o}kciyan and Elizabeth Sklar and S. Parsons},
            note = {cited By 0},
           title = {Explainable argumentation for wellness consultation},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-30391-4},
           pages = {186--202},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38539/}
}

@inproceedings{lincoln39420,
       booktitle = {Towards Autonomous Robotic Systems Conference},
           title = {Collision-Free Optimal Trajectory Generator for a Controlled Floating Space Robot},
          author = {Asma Seddaoui and Chakravarthini M. Saaj and Steve Eckersley},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39420/}
}

@article{lincoln38537,
          volume = {11650},
          author = {D. Zhang and E. Schneider and Elizabeth Sklar},
            note = {cited By 0},
           title = {A cross-landscape evaluation of multi-robot team performance in static task-allocation domains},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-25332-5},
           pages = {261--272},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38537/}
}

@article{lincoln38538,
          volume = {11650},
          author = {Tsvetan Zhivkov and E. Schneider and Elizabeth Sklar},
            note = {cited By 0},
           title = {MRComm: Multi-robot communication testbed},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-25332-5},
           pages = {346--357},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38538/}
}

@article{lincoln37426,
          volume = {34},
          number = {6},
           month = {December},
          author = {F.J. Comin and C. Saaj and S.M. Mustaza and R. Saaj},
            note = {cited By 0},
           title = {Safe Testing of Electrical Diathermy Cutting Using a New Generation Soft Manipulator},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Transactions on Robotics},
             doi = {10.1109/TRO.2018.2861898},
           pages = {1659--1666},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37426/},
        abstract = {The first demonstration of a pneumatic soft continuum robot is integrated in series with a rigid robot arm, safely performing teleoperated diathermic tissue-cutting. The rigid arm autonomously maintains a safe tool contact force, while the soft arm manually follows the desired cutting path. Ex-vivo experimentation demonstrates submillimetric deviations from target paths.}
}

@inproceedings{lincoln34433,
       booktitle = {NeurIPS Workshop on Conversational AI},
           month = {December},
           title = {A Study on Dialogue Reward Prediction for Open-Ended Conversational Agents},
          author = {Heriberto Cuayahuitl and Seonghan Ryu and Donghyeon Lee and Jihie Kim},
       publisher = {arXiv},
            year = {2018},
        keywords = {ARRAY(0x5568fb686800)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34433/},
        abstract = {The amount of dialogue history to include in a conversational agent is often underestimated and/or set in an empirical and thus possibly naive way. This suggests that principled investigations into optimal context windows are urgently needed given that the amount of dialogue history and corresponding representations can play an important role in the overall performance of a conversational system. This paper studies the amount of history required by conversational agents for reliably predicting dialogue rewards. The task of dialogue reward prediction is chosen for investigating the effects of varying amounts of dialogue history and their impact on system performance. Experimental results using a dataset of 18K human-human dialogues report that lengthy  dialogue histories of at least 10 sentences are preferred (25 sentences being the best in our experiments) over short ones, and that lengthy histories are useful for training dialogue reward predictors with strong positive correlations between target dialogue rewards and predicted ones.}
}

@inproceedings{lincoln33104,
           month = {December},
          author = {Huatian Wang and Shigang Yue and Jigen Peng and Paul Baxter and Chun Zhang and Zhihua Wang},
       booktitle = {ICANN 2018},
           title = {A Model for Detection of Angular Velocity of Image Motion Based on the Temporal Tuning of the Drosophila},
       publisher = {Springer, Cham},
             doi = {https://doi.org/10.1007/978-3-030-01421-6\_4},
           pages = {37--46},
            year = {2018},
        keywords = {ARRAY(0x5568fbae64c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33104/},
        abstract = {We propose a new bio-plausible model based on the visual systems of Drosophila for estimating angular velocity of image motion in insects? eyes. The model implements both preferred direction motion enhancement and non-preferred direction motion suppression which is discovered in Drosophila?s visual neural circuits recently to give a stronger directional selectivity. In addition, the angular velocity detecting model (AVDM) produces a response largely independent of the spatial frequency in grating experiments which enables insects to estimate the flight speed in cluttered environments. This also coincides with the behaviour experiments of honeybee flying through tunnels with stripes of different spatial frequencies.}
}

@inproceedings{lincoln33846,
       booktitle = {IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS},
           month = {December},
           title = {Performance of a Visual Fixation Model in an Autonomous Micro Robot Inspired by Drosophila Physiology},
          author = {Qinbing Fu and Nicola Bellotto and Cheng Hu and Shigang Yue},
            year = {2018},
        keywords = {ARRAY(0x5568fbb928a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33846/},
        abstract = {In nature, lightweight and low-powered insects are ideal model systems to study motion perception strategies. Understanding the underlying characteristics and functionality of insects? visual systems is not only attractive to neural system modellers, but also critical in providing effective solutions to future robotics. This paper presents a novel modelling of dynamic vision system inspired by Drosophila physiology for mimicking fast motion tracking and a closed-loop behavioural response to ?xation. The proposed model was realised on embedded system in an autonomous micro robot which has limited computational resources. A monocular camera was applied as the only motion sensing modality. Systematic experiments including open-loop and closed-loop bio-robotic tests validated the proposed visual ?xation model: the robot showed motion tracking and ?xation behaviours similarly to insects; the image processing frequency can maintain 25 {$\sim$} 45Hz. Arena tests also demonstrated a successful following behaviour aroused by ?xation in navigation.}
}

@article{lincoln37427,
          volume = {152},
           month = {November},
          author = {W. Lewinger and F. Comin and M. Matthews and C. Saaj},
            note = {cited By 0},
           title = {Earth analogue testing and analysis of Martian duricrust properties},
            year = {2018},
         journal = {Acta Astronautica},
             doi = {10.1016/j.actaastro.2018.05.025},
           pages = {567--579},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37427/},
        abstract = {Previous and current Mars rover missions have noted a nearly ubiquitous presence of duricrusts on the planet surface. Duricrusts are thin, brittle layers of cemented regolith that cover the underlying terrain. In some cases, the duricrust hides safe or relatively safe underneath the top soil. However, as was observed by both Mars exploration rovers, Spirit and Opportunity, such crusts can also hide loose, untrafficable terrain, leading to Spirit becoming permanently incapacitated in 2009. Whilst several reports of the Martian surface have indicated the presence of duricrusts, none have been able to provide details on the physical properties of the material, which may indicate the level of safe traversability of duricrust terrains. This paper presents the findings of testing terrestrially-created duricrusts with simulated Martian soil properties, in order to determine the properties of such duricrusts and to discover what level of hazard that they may represent (e.g. can vehicles traverse the duricrust surface without penetration to lower sub-surface soils?). Combinations of elements that have been observed in the Martian soil were used as the basis for forming the laboratory-created duricrusts. Variations in duricrust thickness, water content, and the iron oxide compound were investigated. As was observed throughout the testing process, duricrusts behave in a rather brittle fashion and are easily destroyed by low surface pressures. This indicates that duricrusts are not safe for traversing and they present a definite hazard for travelling on the Martian landscape when utilising only visual terrain classification, as the surface appearance is not necessarily representative of what may be lying beneath.}
}

@article{lincoln43299,
          volume = {5},
           month = {November},
          author = {James O?Keeffe and Danesh Tarapore and Alan Millard and Jon Timmis},
           title = {Adaptive Online Fault Diagnosis in Autonomous Robot Swarms},
         journal = {Frontiers in Robotics and AI},
             doi = {10.3389/frobt.2018.00131},
           pages = {131},
            year = {2018},
        keywords = {ARRAY(0x5568fb9b8480)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43299/},
        abstract = {Previous work has shown that robot swarms are not always tolerant to the failure of individual robots, particularly those that have only partially failed and continue to contribute to collective behaviors. A case has been made for an active approach to fault tolerance in swarm robotic systems, whereby the swarm can identify and resolve faults that occur during operation. Existing approaches to active fault tolerance in swarms have so far omitted fault diagnosis, however we propose that diagnosis is a feature of active fault tolerance that is necessary if swarms are to obtain long-term autonomy. This paper presents a novel method for fault diagnosis that attempts to imitate some of the observed functions of natural immune system. The results of our simulated experiments show that our system is flexible, scalable, and improves swarm tolerance to various electro-mechanical faults in the cases examined.}
}

@article{lincoln46155,
          volume = {55},
           month = {November},
          author = {Giacomo Picardi and Cecilia Laschi and Marcello Calisti},
           title = {Model-based open loop control of a multigait legged underwater robot},
         journal = {Mechatronics},
             doi = {10.1016/j.mechatronics.2018.09.006},
           pages = {162--170},
            year = {2018},
        keywords = {ARRAY(0x5568fbbbd2d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46155/},
        abstract = {In this paper a model-based open loop control of SILVER, a multigait legged underwater vehicle for the benthic zone exploration, is presented. The contributions of underwater environment are taken into account by resorting to a recently introduced fundamental model of monopedal underwater hopping locomotion on which the tuning of a completely open loop control algorithm for dynamic gaits is based. The design of the robot and the control algorithm of each gait are presented along with experimental results which demonstrate on-spot static and dynamic rotation, and forward locomotion by crawling, walking and hopping. Moreover, for the first time the behavior of multi-legged underwater robots is grounded to the fundamental monopedal model. SILVER is the first underwater legged robot capable of performing dynamic self-stabilizing hopping gaits together with static gaits and precise foot placement. Thanks to its unique features the category of underwater legged robots has the potential to be a very versatile and valuable alternative to the existing technology for the exploration of the seabed.}
}

@inproceedings{lincoln42420,
       booktitle = {2018 IEEE Symposium Series on Computational Intelligence (SSCI)},
           month = {November},
           title = {Biological Goal Seeking},
          author = {E. P. Kerr and P.J. Vance and D. Kerr and S.A. Coleman and Gautham Das and T.M. McGinnity and D.P. Moyes and T. Delbruck},
            year = {2018},
             doi = {10.1109/SSCI.2018.8628696},
        keywords = {ARRAY(0x5568fb2da2e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42420/},
        abstract = {Obstacle avoidance is a critical aspect of control for a mobile robot when navigating towards a goal in an unfamiliar environment. Where traditional methods for obstacle avoidance depend heavily on path planning to reach a specific goal location whilst avoiding obstacles, the method proposed uses an adaption of a potential fields algorithm to successfully avoid obstacles whilst the robot is being guided to a non-specific goal location. Details of a generalised finite state machine based control algorithm that enable the robot to pursue a dynamic goal location, whilst avoiding obstacles and without the need for specific path planning, are presented. We have developed a novel potential fields algorithm for obstacle avoidance for use within Robot Operating Software (ROS) and made it available for download within the open source community. We evaluated the control algorithm in a high-speed predator-prey scenario in which the predator could successfully catch the moving prey whilst avoiding collision with all obstacles within the environment.}
}

@inproceedings{lincoln33089,
       booktitle = {21st IEEE International Conference on Intelligent Transportation Systems},
           month = {November},
           title = {Predicting pedestrian road-crossing assertiveness for autonomous vehicle control},
          author = {F Camara and O Giles and M Rothmuller and PH Rasmussen and A Vendelbo-Larsen and G Markkula and Y-M Lee and N Merat and Charles Fox},
       publisher = {IEEE},
            year = {2018},
        keywords = {ARRAY(0x5568fb67dbf8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33089/},
        abstract = {Autonomous vehicles (AVs) must interact with other
road users including pedestrians. Unlike passive environments,
pedestrians are active agents having their own utilities and
decisions, which must be inferred and predicted by AVs in order
to control interactions with them and navigation around them.
In particular, when a pedestrian wishes to cross the road in
front of the vehicle at an unmarked crossing, the pedestrian
and AV must compete for the space, which may be considered
as a game-theoretic interaction in which one agent must yield
to the other. To inform AV controllers in this setting, this study
collects and analyses data from real-world human road crossings
to determine what features of crossing behaviours are predictive
about the level of assertiveness of pedestrians and of the eventual
winner of the interactions. It presents the largest and most
detailed data set of its kind known to us, and new methods to
analyze and predict pedestrian-vehicle interactions based upon
it. Pedestrian-vehicle interactions are decomposed into sequences
of independent discrete events. We use probabilistic methods ?
regression and decision tree regression ? and sequence analysis
to analyze sets and sub-sequences of actions used by both
pedestrians and human drivers while crossing at an intersection,
to find common patterns of behaviour and to predict the winner
of each interaction. We report on the particular features found
to be predictive and which can thus be integrated into game-
theoretic AV controllers to inform real-time interactions.}
}

@article{lincoln34106,
          volume = {5},
          number = {6},
           month = {November},
          author = {Khaled Goher and Sulaiman Fadlallah},
           title = {PID, BFO-optimized PID, and PD-FLC control of a two-wheeled machine with two-direction handling mechanism: a comparative study},
       publisher = {SpringerOpen},
            year = {2018},
         journal = {Robotics and Biomimetics},
             doi = {10.1186/s40638-018-0089-3},
        keywords = {ARRAY(0x5568fbb4ddb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34106/},
        abstract = {In this paper; three control approaches are utilized in order to control the stability of a novel five-degrees-of-freedom two-wheeled robotic machine designed for industrial applications that demand a limited-space working environment. Proportional?integral?derivative (PID) control scheme, bacterial foraging optimization of PID control method, and fuzzy logic control method are applied to the wheeled machine to obtain the optimum control strategy that provides the best system stabilization performance. According to simulation results, considering multiple motion scenarios, the PID controller optimized by bacterial foraging optimization method outperformed the other two control methods in terms of minimum overshoot, rise time, and applied input forces.}
}

@article{lincoln31536,
          volume = {106},
           month = {October},
          author = {Qinbing Fu and Cheng Hu and Jigen Peng and Shigang Yue},
           title = {Shaping the collision selectivity in a looming sensitive neuron model with parallel ON and OFF pathways and spike frequency adaptation},
       publisher = {Elsevier for European Neural Network Society (ENNS)},
            year = {2018},
         journal = {Neural Networks},
             doi = {10.1016/j.neunet.2018.04.001},
           pages = {127--143},
        keywords = {ARRAY(0x5568fba96df0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31536/},
        abstract = {Shaping the collision selectivity in vision-based artificial collision-detecting systems is still an open challenge. This paper presents a novel neuron model of a locust looming detector, i.e. the lobula giant movement detector (LGMD1), in order to provide effective solutions to enhance the collision selectivity of looming objects over other visual challenges. We propose an approach to model the biologically plausible mechanisms of ON and OFF pathways and a biophysical mechanism of spike frequency adaptation (SFA) in the proposed LGMD1 visual neural network. The ON and OFF pathways can separate both dark and light looming features for parallel spatiotemporal computations. This works effectively on perceiving a potential collision from dark or light objects that approach; such a bio-plausible structure can also separate LGMD1's collision selectivity to its neighbouring looming detector -- the LGMD2.The SFA mechanism can enhance the LGMD1's collision selectivity to approaching objects rather than receding and translating stimuli, which is a significant improvement compared with similar LGMD1 neuron models. The proposed framework has been tested using off-line tests of synthetic and real-world stimuli, as well as on-line bio-robotic tests. The enhanced collision selectivity of the proposed model has been validated in systematic experiments. The computational simplicity and robustness of this work have also been verified by the bio-robotic tests, which demonstrates potential in building neuromorphic sensors for collision detection in both a fast and reliable manner.}
}

@inproceedings{lincoln34105,
       booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
           month = {October},
           title = {Cut to the Chase: A Context Zoom-in Network for Reading Comprehension},
          author = {Satish Indurthi and Seunghak Yu and Seohyun Back and Heriberto Cuayahuitl},
       publisher = {Association for Computational Linguistics},
            year = {2018},
        keywords = {ARRAY(0x5568fba4abd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34105/},
        abstract = {In recent years many deep neural networks have been proposed to solve Reading Comprehension (RC) tasks. Most of these models suffer from reasoning over long documents and do not trivially generalize to cases where the answer is not present as a span in a given document. We present a novel neural-based architecture that is capable of extracting relevant regions based on a given question-document pair and generating a well-formed answer. To show the effectiveness of our architecture, we conducted several experiments on the recently proposed and challenging RC dataset ?NarrativeQA?. The proposed architecture outperforms state-of-the-art results (Tay et al., 2018) by 12.62\% (ROUGE-L) relative improvement.}
}

@article{lincoln32558,
          volume = {3},
          number = {4},
           month = {October},
          author = {Li Sun and Zhi Yan and Anestis Zaganidis and Cheng Zhao and Tom Duckett},
           title = {Recurrent-OctoMap: Learning State-based Map Refinement for Long-Term Semantic Mapping with 3D-Lidar Data},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2856268},
           pages = {3749--3756},
        keywords = {ARRAY(0x5568fba804e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32558/},
        abstract = {This paper presents a novel semantic mapping approach, Recurrent-OctoMap, learned from long-term 3D
Lidar data. Most existing semantic mapping approaches focus on improving semantic understanding of single frames, rather than 3D refinement of semantic maps (i.e. fusing semantic observations). The most widely-used approach for 3D semantic map refinement is a Bayes update, which fuses the consecutive predictive probabilities following a Markov-Chain model. Instead, we propose a learning approach to fuse the semantic features, rather than simply fusing predictions from a classifier. In our approach, we represent and maintain our 3D map as an OctoMap, and model each cell as a recurrent neural network (RNN), to obtain a Recurrent-OctoMap. In this case, the semantic mapping process can be formulated as a sequenceto-sequence encoding-decoding problem. Moreover, in order to extend the duration of observations in our Recurrent-OctoMap, we developed a robust 3D localization and mapping system for successively mapping a dynamic environment using more than two weeks of data, and the system can be trained and deployed with arbitrary memory length. We validate our approach on the ETH long-term 3D Lidar dataset [1]. The experimental results show that our proposed approach outperforms the conventional ?Bayes update? approach.}
}

@article{lincoln32390,
          volume = {3},
          number = {4},
           month = {October},
          author = {Anestis Zaganidis and Li Sun and Tom Duckett and Grzegorz Cielniak},
           title = {Integrating Deep Semantic Segmentation Into 3-D Point Cloud Registration},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2848308},
           pages = {2942--2949},
        keywords = {ARRAY(0x5568fbba1948)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32390/},
        abstract = {Point cloud registration is the task of aligning 3D scans of the same environment captured from different poses. When semantic information is available for the points, it can be used as a prior in the search for correspondences to improve registration. Semantic-assisted Normal Distributions Transform (SE-NDT) is a new registration algorithm that reduces the complexity of the problem by using the semantic information to partition the point cloud into a set of normal distributions, which are then registered separately. In this paper we extend the NDT registration pipeline by using PointNet, a deep neural network for segmentation and classification of point clouds, to learn and predict per-point semantic labels. We also present the Iterative Closest Point (ICP) equivalent of the algorithm, a special case of Multichannel Generalized ICP. We evaluate the performance of SE-NDT against the state of the art in point cloud registration on the publicly available classification data set Semantic3d.net. We also test the trained classifier and algorithms on dynamic scenes, using a sequence from the public dataset KITTI. The experiments demonstrate the improvement of the registration in terms of robustness, precision and speed, across a range of initial registration errors, thanks to the inclusion of semantic information.}
}

@inproceedings{lincoln47571,
          volume = {11163},
           month = {October},
          author = {Zakaria Maamar and Khouloud Boukadi and Emir Ugljanin and Thar Baker and Muhammad Asim and Mohammed Al-Khafajiy and Djamal Benslimane and Hasna El Alaoui El Abdallaoui},
       booktitle = {Model and Data Engineering},
           title = {Thing Federation as a Service: Foundations and Demonstration},
       publisher = {Springer},
            year = {2018},
         journal = {Thing Federation as a Service: Foundations and Demonstration},
             doi = {10.1007/978-3-030-00856-7\_12},
           pages = {184--197},
        keywords = {ARRAY(0x5568fb6b8998)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47571/},
        abstract = {This paper presents the design and implementation guidelines of thing federation-as-a-service. The large and growing number of things compliant with the Internet-of-Things (IoT) principles need to be ?harnessed? so, that, things? collective over individual behaviors prevail. A federation gathers necessary things together according to the needs and requirements of the situation that this federation is tasked to handle. Two types of federations exist: planned whose things are all known at design-time and ad-hoc whose things are known after a competitive selection at run-time. In this paper, federations handle situations about emergency services that involve different stakeholders with different backgrounds raising the complexity of ensuring a successful delivery of these services. A system for patient emergency transfer following a tunnel closure is implemented demonstrating the technical doability of thing federation-as-a-service.}
}

@inproceedings{lincoln34847,
           month = {October},
          author = {Jiannan Zhao and Cheng Hu and Chun Zhang and Zhihua Wang and Shigang Yue},
       booktitle = {2018 International Joint Conference on Neural Networks (IJCNN)},
           title = {A Bio-inspired Collision Detector for Small Quadcopter},
       publisher = {IEEE},
             doi = {10.1109/IJCNN.2018.8489298},
           pages = {1--7},
            year = {2018},
        keywords = {ARRAY(0x5568fb9d0028)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34847/},
        abstract = {The sense and avoid capability enables insects to fly versatilely and robustly in dynamic and complex environment. Their biological principles are so practical and efficient that inspired we human imitating them in our flying machines. In this paper, we studied a novel bio-inspired collision detector and its application on a quadcopter. The detector is inspired from Lobula giant movement detector (LGMD) neurons in the locusts, and modeled into an STM32F407 Microcontroller Unit (MCU).
Compared to other collision detecting methods applied on quadcopters, we focused on enhancing the collision accuracy in a bio-inspired way that can considerably increase the computing efficiency during an obstacle detecting task even in complex and dynamic environment. We designed the quadcopter's responding operation to imminent  collisions and tested this bio-inspired system in an indoor arena. The observed results from the experiments demonstrated that the LGMD collision detector is feasible to work as a vision module for the quadcopter's collision avoidance task.}
}

@inproceedings{lincoln33782,
       booktitle = {9th International Gas Turbine Conference},
           month = {October},
           title = {Performance analysis of a twin-shaft gas turbine with fault in the variable stator guide vane system of the axial compressor},
          author = {Samuel Cruz-Manzo and Sepehr Maleki and Vili Panov and Festus Agbonzikilo and Yu Zhang and Anthony Latimer},
            year = {2018},
        keywords = {ARRAY(0x5568fba00dd8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33782/},
        abstract = {In this study, an analysis of the performance of a twin-shaft industrial gas turbine (IGT) with a fault in the mechanism of the compressor that changes the position of variable stator guide vanes (VSGVs) is carried out. Measured field data of a twin-shaft engine denoting a difference (offset) between the demanded inlet guide vane (IGV) angle and the measured IGV angle in the axial compressor have been considered for the analysis. A validated Simulink model which simulates the performance of the twin-shaft engine has been considered for the analysis of the fault in the VSGV system. The Simulink model architecture comprises an axial compressor module and considers an multi-stage compressor performance map at optimal conditions (new \& clean). The results demonstrate that it is possible to predict the physical parameters such as pressure and temperature measured across the different stations of the engine during the offset of the IGV angle. The effect of the IGV offset on the compressor performance is discussed as well. The change in compressor air flow and compressor efficiency at different IGV offset is discussed, as during a low power engine operation and fault within the VSGV system, the surge line may drift close to the compressor running operation line.}
}

@article{lincoln32371,
          volume = {3},
          number = {4},
           month = {October},
          author = {Petra Bosilj and Tom Duckett and Grzegorz Cielniak},
           title = {Analysis of morphology-based features for classification of crop and weeds in precision agriculture},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2848305},
           pages = {2950--2956},
        keywords = {ARRAY(0x5568fba6cea8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32371/},
        abstract = {Determining the types of vegetation present in an image is a core step in many precision agriculture tasks. In this paper, we focus on pixel-based approaches for classification of crops versus weeds, especially for complex cases involving overlapping plants and partial occlusion. We examine the benefits of multi-scale and content-driven morphology-based descriptors called Attribute Profiles. These are compared to state-of-the art keypoint descriptors with a fixed neighbourhood previously used in precision agriculture, namely Histograms of Oriented Gradients and Local Binary Patterns. The proposed classification technique is especially advantageous when coupled with morphology-based segmentation on a max-tree structure, as the same representation can be re-used for feature extraction. The robustness of the approach is demonstrated by an experimental evaluation on two datasets with different crop types. The proposed approach compared favourably to state-of-the-art approaches without an increase in computational complexity, while being able to provide descriptors at a higher resolution.}
}

@inproceedings{lincoln36200,
       booktitle = {IROS 2018 Workshop on Human/Robot in the Loop Machine Learning},
           month = {October},
           title = {From Evaluating to Teaching: Rewards and Challenges of Human Control for Learning Robots},
          author = {Emmanuel Senft and Severin Lemaignan and Paul Baxter and Tony Belpaeme},
       publisher = {Imperial College London},
            year = {2018},
        keywords = {ARRAY(0x5568fbb64318)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36200/},
        abstract = {Keeping a human in a robot learning cycle can provide many advantages to improve the learning process. However, most of these improvements are only available when the human teacher is in complete control of the robot?s behaviour, and not just providing feedback. This human control can make the learning process safer, allowing the robot to learn in high-stakes interaction scenarios especially social ones. Furthermore, it allows faster learning as the human guides the robot to the relevant parts of the state space and can provide additional information to the learner. This information can also enable the
learning algorithms to learn for wider world representations, thus increasing the generalisability of a deployed system. Additionally, learning from end users improves the precision of the final policy as it can be specifically tailored to many situations. Finally, this progressive teaching might create trust between the learner and the teacher, easing the deployment of the autonomous robot. However, with such control comes a range of challenges. Firstly, the rich communication between the robot and the teacher needs to be handled by an interface, which may require complex features. Secondly, the teacher needs to be embedded within the robot action selection cycle, imposing time constraints, which increases the cognitive load on the teacher. Finally, given a cycle of interaction between the robot and the teacher, any mistakes made by the teacher can be propagated to the robot?s policy. Nevertheless, we are are able to show that empowering the teacher with ways to control a robot?s behaviour has the potential to drastically improve both the learning process (allowing robots to learn in a wider range of environments) and the experience of the teacher.}
}

@inproceedings{lincoln32541,
       booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {October},
           title = {Multisensor Online Transfer Learning for 3D LiDAR-based Human Detection with a Mobile Robot},
          author = {Zhi Yan and Li Sun and Tom Duckett and Nicola Bellotto},
       publisher = {IEEE},
            year = {2018},
        keywords = {ARRAY(0x5568fbb448f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32541/},
        abstract = {Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new ?trajectory probability?. Our framework uses this probability to check whether new detections belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.}
}

@incollection{lincoln39233,
          volume = {140},
           month = {September},
          author = {Sofia Papadaki and Georgios Banias and Charisios Achillas and Dimitris Aidonis and Dimitris Folinas and Dionysis Bochtis and Stamatis Papangelou},
       booktitle = {Dynamics of Disasters},
           title = {A Humanitarian Logistics Case Study for the Intermediary Phase Accommodation Center for Refugees and Other Humanitarian Disaster Victims},
       publisher = {Springer},
            year = {2018},
             doi = {doi:10.1007/978-3-319-97442-2\_8},
           pages = {157--202},
        keywords = {ARRAY(0x5568fb96a860)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39233/},
        abstract = {The growing and uncontrollable stream of refugees from Middle East and North Africa has created considerable pressure to governments and societies all over Europe. To establish the theoretical framework, the concept of humanitarian logistics is briefly examined in this paper. Historical data from the nineteenth century onwards illuminates the fact that this influx is not a novelty in the European continent and the interpretation of statistical data highlights the characteristics and particularities of the current refugee wave, as well as the possible repercussions these could inflict both to hosting societies and to displaced populations. Finally, a review of European and national legislation and policies shows that measures taken so far are disjointed and that no complete but at the same time fair and humanitarian management strategy exists.

Within this context, the paper elaborates on the development of a compact accommodation center made of shipping containers, to function as one of the initial stages in adaptation before full social integration of the displaced populations. It aims at maximizing the respect for human rights and values while minimizing the impact on society and on the environment. Some of the humanitarian and ecological issues discussed are: integration of medical, educational, religious and social functions within the unit, optimal land utilization, renewable energy use, and waste management infrastructures. Creating added value for the ?raw? material (shipping containers) and prolonging the unit?s life span by enabling transformation and change of use, transportation and reuse, and finally end-of-life dismantlement and recycling also lie within the scope of the project.

The overall goal is not only to address the current needs stemming from the refugee crisis, but also to develop a project versatile enough to be adapted for implementation on further social groups in need of support. The paper?s results could serve as a useful tool for governments and organizations to better plan ahead and respond fast and efficiently not only in regard to the present humanitarian emergency, but also in any possible similar major disaster situation, including the potential consequences of climate change.}
}

@inproceedings{lincoln33422,
       booktitle = {The 27th International Conference on Artificial Neural Networks},
           month = {September},
           title = {A Feedback Neural Network for Small Target Motion Detection in Cluttered Backgrounds},
          author = {Hongxin Wang and Jigen Peng and Shigang Yue},
       publisher = {IEEE},
            year = {2018},
        keywords = {ARRAY(0x5568fbb47570)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33422/},
        abstract = {Small target motion detection is critical for insects to search for and track mates or prey which always appear as small dim speckles in the visual field. A class of specific neurons, called small target motion detectors (STMDs), has been characterized by exquisite sensitivity for small target motion. Understanding and analyzing visual pathway of STMD neurons are beneficial to design artificial visual systems for small target motion detection. Feedback loops have been widely identified in visual neural circuits and play an important role in target detection. However, if there exists a feedback loop in the STMD visual pathway or if a feedback loop could significantly improve the detection performance of STMD neurons, is unclear. In this paper, we propose a feedback neural network for small target motion detection against naturally cluttered backgrounds. In order to form a feedback loop, model output is temporally delayed and relayed to previous neural layer as feedback signal. Extensive experiments showed that the significant improvement of the proposed feedback neural network over the existing STMD-based models for small target motion detection.}
}

@incollection{lincoln34108,
       booktitle = {Robotics},
           month = {September},
           title = {System Identification and HSDBC-Optimized PID Control of a Portable Lower-Limb Rehabilitation Device},
          author = {Sulaiman Fadlallah and Khaled Goher},
       publisher = {World Scientfic},
            year = {2018},
        keywords = {ARRAY(0x5568fba93da0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34108/},
        abstract = {The present paper introduces a novel portable leg rehabilitation system (PLRS) that is developed to provide the user with the necessary rehabilitation exercises for both the knee and ankle in addition to the portability feature to overcome the hardships associated with both effort and cost of hospitals and rehabilitation clinics? steady sessions. Prior realizing the actual prototype, the proposed configuration was visualized using SolidWorks including its main components. Aiming to control the developed system, and given the fact that tuning controller parameters is not an easy task, Hybrid Spiral-Dynamics Bacteria-Chemotaxis (HSDBC) algorithm has been applied on the proposed control strategy in order to obtain a satisfactory performance. The obtained system performance was satisfactory in terms of desired elevation and settling time.}
}

@article{lincoln34138,
          volume = {18},
          number = {9},
           month = {September},
          author = {Cheng Zhao and Li Sun and Pulak Purkait and Tom Duckett and Rustam Stolkin},
           title = {Dense RGB-D Semantic Mapping with Pixel-Voxel Neural Network},
       publisher = {Multidisciplinary Digital Publishing Institute},
            year = {2018},
         journal = {Sensors},
             doi = {10.3390/s18093099},
           pages = {3099},
        keywords = {ARRAY(0x5568fb966bf8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34138/},
        abstract = {In this paper, a novel Pixel-Voxel network is proposed for dense 3D semantic mapping, which can perform dense 3D mapping while simultaneously recognizing and labelling the semantic category each point in the 3D map. In our approach, we fully leverage the advantages of different modalities. That is, the PixelNet can learn the high-level contextual information from 2D RGB images, and the VoxelNet can learn 3D geometrical shapes from the 3D point cloud. Unlike the existing architecture that fuses score maps from different modalities with equal weights, we propose a softmax weighted fusion stack that adaptively learns the varying contributions of PixelNet and VoxelNet and fuses the score maps according to their respective confidence levels. Our approach achieved competitive results on both the SUN RGB-D and NYU V2 benchmarks, while the runtime of the proposed system is boosted to around 13 Hz, enabling near-real-time performance using an i7 eight-cores PC with a single Titan X GPU.}
}

@inproceedings{lincoln31675,
           month = {September},
          author = {R. Pinsler and R. Akrour and T. Osa and J. Peters and G. Neumann},
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
           title = {Sample and feedback efficient hierarchical reinforcement learning from human preferences},
       publisher = {IEEE},
             doi = {10.1109/ICRA.2018.8460907},
           pages = {596--601},
            year = {2018},
        keywords = {ARRAY(0x5568fbb5c348)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31675/},
        abstract = {While reinforcement learning has led to promising results in robotics, defining an informative reward function can sometimes prove to be challenging. Prior work considered including the human in the loop to jointly learn the reward function and the optimal policy. Generating samples from a physical robot and requesting human feedback are both taxing efforts for which efficiency is critical. In contrast to prior work, in this paper we propose to learn reward functions from both the robot and the human perspectives in order to improve on both efficiency metrics. On one side, learning a reward function from the human perspective increases feedback efficiency by assuming that humans rank trajectories according to an outcome space of reduced dimensionaltiy. On the other side, learning a reward function from the robot perspective circumvents the need for learning a dynamics model while retaining the sample efficiency of model-based approaches. We provide an algorithm that incorporates bi-perspective reward learning into a general hierarchical reinforcement learning framework and demonstrate the merits of our approach on a toy task and a simulated robot grasping task.}
}

@article{lincoln31956,
           month = {September},
           title = {3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data},
          author = {Li Sun and Zhi Yan and Sergi Molina Mellado and Marc Hanheide and Tom Duckett},
       publisher = {IEEE},
            year = {2018},
             doi = {10.1109/icra.2018.8461228},
         journal = {International Conference on Robotics and Automation (ICRA) 2018},
        keywords = {ARRAY(0x5568fb9d0c70)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31956/},
        abstract = {This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service
robots. While most previously reported methods are based on learning of 2D positions in monocular camera images,
our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-PoseLSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.}
}

@article{lincoln31131,
          volume = {11},
          number = {3},
           month = {September},
          author = {Ayse Kucukyilmaz and Yiannis Demiris},
           title = {Learning shared control by demonstration for personalized wheelchair assistance},
       publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
            year = {2018},
         journal = {IEEE Transactions on Haptics},
             doi = {10.1109/TOH.2018.2804911},
           pages = {431--442},
        keywords = {ARRAY(0x5568fbb046c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31131/},
        abstract = {An emerging research problem in assistive robotics is the design of methodologies that allow robots to provide personalized assistance to users. For this purpose, we present a method to learn shared control policies from demonstrations offered by a human assistant. We train a Gaussian process (GP) regression model to continuously regulate the level of assistance between the user and the robot, given the user's previous and current actions and the state of the environment. The assistance policy is learned after only a single human demonstration, i.e. in one-shot. Our technique is evaluated in a one-of-a-kind experimental study, where the machine-learned shared control policy is compared to human assistance. Our analyses show that our technique is successful in emulating human shared control, by matching the location and amount of offered assistance on different trajectories. We observed that the effort requirement of the users were comparable between human-robot and human-human settings. Under the learned policy, the jerkiness of the user's joystick movements dropped significantly, despite a significant increase in the jerkiness of the robot assistant's commands. In terms of performance, even though the robotic assistance increased task completion time, the average distance to obstacles stayed in similar ranges to human assistance.}
}

@article{lincoln34496,
          volume = {18},
          number = {3},
           month = {September},
          author = {Wang-Su Jeon and Grzegorz Cielniak and Rhee Sang-Yong},
           title = {Semantic Segmentation Using Trade-Off and Internal Ensemble},
            year = {2018},
         journal = {International Journal of Fuzzy Logic and Intelligent Systems},
             doi = {10.5391/IJFIS.2018.18.3.196},
           pages = {196--203},
        keywords = {ARRAY(0x5568fba719f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34496/},
        abstract = {The computer vision consists of image classification, image segmentation, object detection, and tracking, etc. Among them, image segmentation is the most basic technique of the computer vision, which divides an image into foreground and background. This paper proposes an ensemble model using a concept of physical perception for image segmentation. Practically two connected models, the DeepLab and a modified VGG model, get feedback each other in the training process. On inference processing, we combine the results of two parallel models and execute an atrous spatial pyramid pooling (ASPP) and post-processing by using conditional random field (CRF). The proposed model shows better performance than the DeepLab in local area and about 1\% improvement on average on comparison of pixel-by-pixel.}
}

@article{lincoln32981,
          volume = {32},
          number = {18},
           month = {September},
          author = {T. Osa and J. Peters and Gerhard Neumann},
           title = {Hierarchical Reinforcement Learning of Multiple Grasping Strategies with Human Instructions},
       publisher = {Taylor \& Francis},
            year = {2018},
         journal = {Advanced Robotics},
             doi = {10.1080/01691864.2018.1509018},
           pages = {955--968},
        keywords = {ARRAY(0x5568fba7eb40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32981/},
        abstract = {Grasping is an essential component for robotic manipulation and has been investigated for decades. Prior work on grasping often assumes that a sufficient amount of training data is available for learning and planning robotic grasps. However, since constructing such an exhaustive training dataset is very challenging in practice, it is desirable that a robotic system can autonomously learn and improves its grasping strategy. In this paper, we address this problem using reinforcement learning. Although recent work has presented autonomous data collection through trial and error, such methods are often limited to a single grasp type, e.g., vertical pinch grasp. We present a hierarchical policy search approach for learning multiple grasping strategies. Our framework autonomously constructs a database of grasping motions and point clouds of objects to learn multiple grasping types autonomously. We formulate the problem of selecting the grasp location and grasp policy as a bandit problem, which can be interpreted as a variant of active learning. We applied our reinforcement learning to grasping both rigid and deformable objects. The experimental results show that our framework autonomously learns and improves its performance through trial and error and can grasp previously unseen objects with a high accuracy.}
}

@article{lincoln37443,
          volume = {15},
          number = {5},
           month = {August},
          author = {S.M. Mustaza and C Saaj and F.J. Comin and W.A. Albukhanajer and D. Mahdi and C. Lekakou},
            note = {cited By 1},
           title = {Stiffness Control for Soft Surgical Manipulators},
       publisher = {World Scientific},
            year = {2018},
         journal = {International Journal of Humanoid Robotics},
             doi = {10.1142/S0219843618500214},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37443/},
        abstract = {Tunable stiffness control is critical for undertaking surgical procedures using soft manipulators. However, active stiffness control in soft continuum manipulators is very challenging and has been rarely realized for real-time surgical applications. Low stiffness at the tip is much preferred for safe navigation of the robot in restricted spaces inside the human body. On the other hand, high stiffness at the tip is demanded for efficiently operating surgical instruments. In this paper, the manipulability and characteristics of a class of soft hyper-redundant manipulator, fabricated using Ecoflex-0050TM silicone, is discussed and a new methodology is introduced to actively tune the stiffness matrix, in real-time, for disturbance rejection and stiffness control. Experimental results are used to derive a more accurate description of the characteristics of the soft manipulator, capture the varying stiffness effects of the actuated arm and consequently offer a more accurate response using closed loop feedback control in real-time. The novel results presented in this paper advances the state-of-the-art of tunable stiffness control in soft continuum manipulators for real-time applications.}
}

@article{lincoln32842,
          volume = {10994},
           month = {August},
          author = {Cheng Hu and Qinbing Fu and Tian liu and Shigang Yue},
       booktitle = {Manoonpong P., Larsen J., Xiong X., Hallam J., Triesch J. (eds) From Animals to Animats 15. SAB 2018. Lecture Notes in Computer Science},
           title = {A Hybrid Visual-Model Based Robot Control Strategy for Micro Ground Robots},
       publisher = {Springer, Cham},
            year = {2018},
         journal = {SAB 2018: From Animals to Animats 15},
             doi = {10.1007/978-3-319-97628-0\_14},
           pages = {162--174},
        keywords = {ARRAY(0x5568fb9f9110)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32842/},
        abstract = {This paper proposed a hybrid vision-based robot control strategy for micro ground robots by mediating two vision models from mixed categories: a bio-inspired collision avoidance model and a segmentation based target following model. The implemented model coordination strategy is described as a probabilistic model using ?nite state machine (FSM) that allows the robot to switch behaviours adapting to the acquired visual information. Experiments demonstrated the stability and convergence of the embedded hybrid system by real robots, including the studying of collective behaviour by a swarm of such robots with environment mediation. This research enables micro robots to run visual models with more complexity. Moreover, it showed the possibility to realize aggregation behaviour on micro robots by utilizing vision as the only sensing modality from non-omnidirectional cameras.}
}

@article{lincoln32296,
          volume = {2018},
          number = {10965},
           month = {August},
          author = {Khaled Elgeneidy and Pengcheng Liu and Simon Pearson and Niels Lohse and Gerhard Neumann},
           title = {Printable Soft Grippers with Integrated Bend Sensing for Handling of Crops},
       publisher = {Springer},
            year = {2018},
         journal = {Towards Autonomous Robotic Systems (TAROS) Conference},
             doi = {10.1007/978-3-319-96728-8},
           pages = {479--480},
        keywords = {ARRAY(0x5568fba8c448)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32296/},
        abstract = {Handling delicate crops without damaging or bruising is a challenge facing the au-tomation of tasks within the agri-food sector, which encourages the utilization of soft grippers that are inherently safe and passively compliant. In this paper we present a brief overview of the development of a printable soft gripper integrated with printable bend sensors. The softness of the gripper fingers allows delicate crops to be grasped gently, while the bend sensors are calibrated to measure bending and detect contact. This way the soft gripper not only benefits from the passive compliance of its soft fingers, but also demonstrates a sensor-guided approach for improved grasp control.}
}

@article{lincoln32850,
          volume = {3},
          number = {4},
           month = {July},
          author = {Francesco Del Duchetto and Ayse Kucukyilmaz and Luca Iocchi and Marc Hanheide},
            note = {{\copyright} 2018 IEEE},
           title = {Don't Make the Same Mistakes Again and Again: Learning Local Recovery Policies for Navigation from Human Demonstrations},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2861080},
           pages = {4084--4091},
        keywords = {ARRAY(0x5568fbb94708)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32850/},
        abstract = {In this paper, we present a human-in-the-loop learning framework for mobile robots to generate effective local policies in order to recover from navigation failures in long-term autonomy. We present an analysis of failure and recovery cases derived from long-term autonomous operation of a mobile robot, and propose a two-layer learning framework that allows to detect and recover from such navigation failures. Employing a learning by demonstration (LbD) approach, our framework can incrementally learn to autonomously recover from situations it initially needs humans to help with. The learning framework allows for both real-time failure detection and regression using Gaussian processes (GPs). Our empirical results on two different failure scenarios indicate that given 40 failure state observations, the true positive rate of the failure detection model exceeds 90\%, ending with successful recovery actions in more than 90\% of all detected cases.}
}

@inproceedings{lincoln47570,
           month = {July},
          author = {Mohamed Sellami and Mohammed Al-Khafajiy and Yacine Atif and Emir Ugljanin and Noura Faci and Thar Baker and Zakaria Maamar},
       booktitle = {Proceedings of the 13th International Conference on Software Technologies},
           title = {Cognitive Computing Meets the Internet of Things},
       publisher = {13th International Conference on Software Technologies},
             doi = {doi:10.5220/0006877507750780},
           pages = {775--780},
            year = {2018},
        keywords = {ARRAY(0x5568fb9b8018)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47570/},
        abstract = {This paper discusses the blend of cognitive computing with the Internet-of-Things that should result into developing cognitive things. Today?s things are confined into a data-supplier role, which deprives them from being the technology of choice for smart applications development. Cognitive computing is about reasoning, learning, explaining, acting, etc. In this paper, cognitive things? features include functional and non-functional restrictions along with a 3 stage operation cycle that takes into account these restrictions during reasoning, adaptation, and learning. Some implementation details about cognitive things are included in this paper based on a water pipe case-study.}
}

@incollection{lincoln31671,
          volume = {10965},
           month = {July},
          author = {Qinbing Fu and Cheng Hu and Pengcheng Liu and Shigang Yue},
       booktitle = {M. Giuliani et al. (Eds.): TAROS 2018, LNAI},
           title = {Towards computational models of insect motion detectors for robot vision},
       publisher = {Springer International Publishing AG, part of Springer Nature 2018},
           pages = {465--467},
            year = {2018},
        keywords = {ARRAY(0x5568fbb70c90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31671/},
        abstract = {In this essay, we provide a brief survey of computational models of insect motion detectors, and bio-robotic solutions to build fast and reliable motion-sensing systems for robot vision. Vision is an important sensing modality for autonomous robots, since it can extract abundant useful features from visually cluttered and dynamic environments. Fast development of computer vision technology facilitates the modeling of dynamic vision systems for mobile robots.}
}

@inproceedings{lincoln31679,
       booktitle = {19th Towards Autonomous Robotic Systems (TAROS) Conference},
           month = {July},
           title = {Towards real-time robotic motion planning for grasping in cluttered and uncertain environments},
          author = {Pengcheng Liu and Khaled Elgeneidy and Simon Pearson and Nazmul Huda and Gerhard Neumann},
       publisher = {Springer},
            year = {2018},
        keywords = {ARRAY(0x5568fbb89b58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31679/},
        abstract = {Adaptation to unorganized, congested and uncertain environment is a desirable capability but challenging task in development of robotic motion planning algorithms for object grasping. We have to make a tradeoff between coping with the environmental complexities using computational expensive approaches, and enforcing practical manipulation and grasping in real-time. In this paper, we present a brief overview and research objectives towards real-time motion planning for grasping in cluttered and uncertain environments. We present feasible ways in approaching this goal, in which key challenges and plausible solutions are discussed.}
}

@article{lincoln43298,
           month = {July},
           title = {ARDebug: An Augmented Reality
Tool for Analysing and Debugging
Swarm Robotic Systems},
          author = {Alan Millard and Richard Redpath and Jewers Alistair M. and Arndt Charlotte and Joyce Russell and Hilder James A. and McDaid Liam J. and Halliday David M.},
            year = {2018},
             doi = {10.3389/frobt.2018.00087},
         journal = {Frontiers in robotics and AI},
        keywords = {ARRAY(0x5568fba6b8f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43298/},
        abstract = {Despite growing interest in collective robotics over the past few years, analysing and
debugging the behaviour of swarm robotic systems remains a challenge due to the lack
of appropriate tools. We present a solution to this problem{--}ARDebug: an open-source,
cross-platform, and modular tool that allows the user to visualise the internal state of a
robot swarm using graphical augmented reality techniques. In this paper we describe the
key features of the software, the hardware required to support it, its implementation, and
usage examples. ARDebug is specifically designed with adoption by other institutions in
mind, and aims to provide an extensible tool that other researchers can easily integrate
with their own experimental infrastructure.}
}

@incollection{lincoln31672,
          volume = {10965},
           month = {July},
          author = {Cheng Hu and Qinbing Fu and Shigang Yue},
       booktitle = {Giuliani M., Assaf T., Giannaccini M. (eds) Towards Autonomous Robotic Systems. TAROS 2018. Lecture Notes in Computer Science},
          editor = {Manuel Giuliani and Tareq Assaf and Maria Elena Giannaccini},
           title = {Colias IV: The Affordable Micro Robot Platform with Bio-inspired Vision},
       publisher = {Springer},
            year = {2018},
             doi = {10.1007/978-3-319-96728-8\_17},
        keywords = {ARRAY(0x5568fb6d4fa0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31672/},
        abstract = {Vision is one of the most important sensing modalities for robots and has been realized on mostly large platforms. However for micro robots which are commonly utilized in swarm robotic studies, the visual ability is seldom applied or with only limited functions and resolution, due to the challenging requirements on the computation power and high data volume to deal with. This research has proposed the low-cost micro ground robot Colias IV, which is particularly designed to meet the requirements to allow embedded vision based tasks onboard, such as bio-inspired collision detection neural networks. Numerous of successful approaches have demonstrated that the proposed micro robot Colias IV to be a feasible platform for introducing visual based algorithms into swarm robotics.}
}

@inproceedings{lincoln40822,
           month = {July},
          author = {Philip J. Vance and Gautham Das and Sonya A. Coleman and Dermot Kerr and Emmett P. Kerr and Thomas M. McGinnity},
       booktitle = {2018 International Joint Conference on Neural Networks (IJCNN)},
           title = {Investigation into Sub-Receptive Fields of Retinal Ganglion Cells with Natural Images},
       publisher = {IEEE},
             doi = {10.1109/IJCNN.2018.8489324},
           pages = {1--8},
            year = {2018},
        keywords = {ARRAY(0x5568fba6b0f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40822/},
        abstract = {Determining the receptive field of a retinal ganglion cell is critically important when formulating a computational model that maps the relationship between the stimulus and response. This process is traditionally undertaken using reverse correlation to estimate the receptive field. By stimulating the retina with artificial stimuli, such as alternating checkerboards, bars or gratings and recording the neural response it is possible to estimate the cell?s receptive field by analysing the stimuli that produced the response. Artificial stimuli such as white noise is known to not stimulate the full range of the cell?s responses. By using natural image stimuli, it is possible to estimate the receptive field and obtain a resulting model that more accurately mimics the cells? responses to natural stimuli. This paper extends on previous work to seek further improvements in estimating a ganglion cell?s receptive field by considering that the receptive field can be divided into subunits. It is thought that these subunits may relate to receptive fields which are associated with bipolar retinal cells. The findings of this preliminary study show that by using subunits to define the receptive field we achieve a significant improvement over existing approaches when deriving computational models of the cell?s response.}
}

@inproceedings{lincoln31779,
       booktitle = {IEEE International Engineering in Medicine and Biology Conference},
           month = {July},
           title = {Thermal camera based physiological monitoring with an assistive robot},
          author = {Serhan Cosar and Zhi Yan and Feng Zhao and Tryphon Lambrou and Shigang Yue and Nicola Bellotto},
       publisher = {IEEE},
            year = {2018},
        keywords = {ARRAY(0x5568fb9c1450)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31779/},
        abstract = {This paper presents a physiological monitoring system for assistive robots using a thermal camera. It is based on the detection of subtle changes in temperature observed on different parts of the face. First, we segment and estimate these face regions on thermal images. Then, by applying Fourier analysis on temperature data, we estimate respiration and heartbeat rate. This physiological monitoring system has been integrated in an assistive robot for elderly people at home, as part of the ENRICHME project. Its performance has been evaluated on a new thermal dataset for physiological monitoring, which is made publicly available for research purposes.}
}

@inproceedings{lincoln46151,
       booktitle = {2018 IEEE International Conference on Soft Robotics (RoboSoft)},
           month = {July},
           title = {Underwater soft jet propulsion based on a hoberman mechanism},
          author = {Saverio Iacoponi and Giacomo Picardi and Mrudul Chellapurath and Marcello Calisti and Laschi Cecilia},
            year = {2018},
           pages = {449--454},
             doi = {10.1109/ROBOSOFT.2018.8405367},
        keywords = {ARRAY(0x5568fb67b3e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46151/},
        abstract = {This paper presents the results of single pulsation tests aimed to evaluate the performance of a Hoberman sphere mechanism as an underwater jet propulsor. The tests were carried out in a fish tank and the position of the robot was visually tracked to estimate the speed and the contraction kinematic. Results suggest that, due to the great volume variation allowed by the Hoberman sphere, this system can reach similar performances in term of speed with respect to previous solutions, while it can improve the generated thrust.}
}

@article{lincoln32172,
          volume = {3},
          number = {4},
           month = {July},
          author = {Jaime Pulido Fentanes and Iain Gould and Tom Duckett and Simon Pearson and Grzegorz Cielniak},
           title = {3D Soil Compaction Mapping through Kriging-based Exploration with a Mobile Robot},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2849567},
           pages = {3066 --3072},
        keywords = {ARRAY(0x5568fbb58c30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32172/},
        abstract = {This paper presents an automated method for creating spatial maps of soil condition with an outdoor mobile robot. Effective soil mapping on farms can enhance yields, reduce inputs and help protect the environment. Traditionally, data are collected manually at an arbitrary set of locations, then soil maps are constructed offline using kriging, a form of Gaussian process regression. This process is laborious and costly, limiting the quality and resolution of the resulting information. 
Instead, we propose to use an outdoor mobile robot for automatic collection of soil condition data, building soil maps online and also adapting the robot's exploration strategy on-the-fly based on the current quality of the map. We show how using kriging variance as a reward function for robotic exploration allows for both more efficient data collection and better soil models. This work presents the theoretical foundations for our proposal and an experimental comparison of exploration strategies using soil compaction data from a field generated with a mobile robot.}
}

@incollection{lincoln33007,
           month = {July},
          author = {Xuelong Sun and Michael Mangan and Shigang Yue},
            note = {This publication can be purchased online at https://www.springer.com/us/book/9783319959719},
       booktitle = {Biomimetic and Biohybrid Systems},
           title = {An Analysis of a Ring Attractor Model for Cue Integration},
       publisher = {Springer},
            year = {2018},
             doi = {https://doi.org/10.1007/978-3-319-95972-6\_49},
           pages = {459--470},
        keywords = {ARRAY(0x5568fba20c50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33007/},
        abstract = {Animals and robots must constantly combine multiple streams of noisy information from their senses to guide their actions. Recently, it has been proposed that animals may combine cues optimally using a ring attractor neural network architecture inspired by the head direction system of rats augmented with a dynamic re-weighting mechanism. In this work we report that an older and simpler ring attractor network architecture, requiring no re-weighting property combines cues according to their certainty for moderate cue conflicts but converges on the most certain cue for larger conflicts. These results are consistent with observations in animal experiments that show sub-optimal cue integration and switching from cue integration to cue selection strategies. This work therefore demonstrates an alternative architecture for those seeking neural correlates of sensory integration in animals. In addition, performance is shown robust to noise and miniaturization and thus provides an efficient solution for artificial systems.}
}

@article{lincoln47563,
          volume = {1},
          number = {1},
           month = {July},
          author = {Bandar Aldawsari and Thar Baker and Muhammad Asim and Zakaria Maamar and Dhiya Al-Jumeily and Mohammed Al-Khafajiy},
           title = {A Survey of Resource Management Challenges in Multi-cloud Environment: Taxonomy and Empirical Analysis},
       publisher = {Azerbaijan State Oil and Industry University},
            year = {2018},
         journal = {Azerbaijan Journal of High Performance Computing},
             doi = {doi:10.32010/26166127.2018.1.1.51.65},
           pages = {51--65},
        keywords = {ARRAY(0x5568fbb7b498)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47563/},
        abstract = {Cloud computing has seen a great deal of interest by researchers and  industrial  firms  since  its  first  coined.  Different  perspectives and  research  problems,  such  as  energy  efficiency,  security  and threats, to name but a few, have been dealt with and addressed from cloud computing perspective. However, cloud computing environment still encounters a major challenge of how to allocate and  manage  computational  resources  efficiently.  Furthermore, due to the different architectures and cloud computing networks and models used (i.e., federated clouds, VM migrations, cloud brokerage), the complexity of resource management in the cloud has been increased dramatically. Cloud providers and service consumers have the cloud brokers working as the intermediaries between them, and the confusion among the cloud computing parties (consumers, brokers, data centres and service providers) on who is responsible for managing the request of cloud resources is a key issue. In a traditional scenario, upon renting the various cloud resources from the providers, the cloud brokers engage in subletting and managing these resources to the service consumers. However, providers? usually deal with many brokers, and vice versa, and any dispute of any kind between the providers and the brokers will lead to service unavailability, in which  the  consumer  is  the  only  victim.  Therefore,  managing  cloud resources and services still needs a lot of attention and effort. This paper expresses the survey on the systems of the cloud brokerage resource management issues in multi-cloud environments.}
}

@book{lincoln34555,
           month = {June},
           title = {Green Supply Chain Management},
          author = {Charisios Achillas and Dionysis Bochtis and Dimitrios Aidonis and Dimitris Folinas},
       publisher = {Routledge},
            year = {2018},
        keywords = {ARRAY(0x5568fb9b9b08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34555/},
        abstract = {Today, one of the top priorities of an organization?s modern corporate strategy is to portray itself as socially responsible and environmentally sustainable. As a focal point of sustainability initiatives, green supply chain management has emerged as a key strategy that can provide competitive advantages with significant parallel gains for company profitability. In designing a green supply chain, the intent is the adoption of comprehensive and cross-business sustainability principles, from the product conception stage to the end-of-life stage. In this context, green initiatives relate to tangible and intangible corporate benefits. Sustainability reports from numerous companies reveal that greening their supply chains has helped reduce operating cost, thus boosting effectiveness and efficiency while increasing sustainability of the business.

Green Supply Chain Management provides a strategic overview of sustainable supply chain management, shedding light on the theoretical background and key principles of the topic. Specifically, this book covers various thematic areas including benefits and impact of green supply chain management; enablers and barriers on supply chain operations; inbound and outbound logistics considerations; and production, packaging and reverse logistics under the notion of "greening". The ultimate aim of this textbook is to highlight the challenges in the implementation of green supply chain management in modern companies and to provide a roadmap for decision-making in real-life cases.

Combining chapter summaries and discussion questions, this book provides an accessible and student-friendly introduction to green supply change management and will be of great interest to students, scholars and practitioners in the fields of sustainable business and supply chain management.}
}

@article{lincoln31634,
          volume = {98},
           month = {June},
          author = {Petra Bosilj and Tom Duckett and Grzegorz Cielniak},
           title = {Connected attribute morphology for unified vegetation segmentation and classification in precision agriculture},
       publisher = {Elsevier},
            year = {2018},
         journal = {Computers in Industry},
             doi = {10.1016/j.compind.2018.02.003},
           pages = {226--240},
        keywords = {ARRAY(0x5568fbb72c00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31634/},
        abstract = {Discriminating value crops from weeds is an important task in precision agriculture. In this paper, we propose a novel image processing pipeline based on attribute morphology for both the segmentation and classification tasks. The commonly used approaches for vegetation segmentation often rely on thresholding techniques which reach their decisions globally. By contrast, the proposed method works with connected components obtained by image threshold decomposition, which are naturally nested in a hierarchical structure called the max-tree, and various attributes calculated from these regions. Image segmentation is performed by attribute filtering, preserving or discarding the regions based on their attribute value and allowing for the decision to be reached locally. This segmentation method naturally selects a collection of foreground regions rather than pixels, and the same data structure used for segmentation can be further reused to provide the features for classification, which is realised in our experiments by a support vector machine (SVM). We apply our methods to normalised difference vegetation index (NDVI) images, and demonstrate the performance of the pipeline on a dataset collected by the authors in an onion field, as well as a publicly available dataset for sugar beets. The results show that the proposed segmentation approach can segment the fine details of plant regions locally, in contrast to the state-of-the-art thresholding methods, while providing discriminative features which enable efficient and competitive classification rates for crop/weed discrimination.}
}

@article{lincoln41511,
          volume = {170},
           month = {June},
          author = {Junfeng Gao and David Nuyttens and Peter Lootens and Yong He and Jan Pieters},
           title = {Recognising weeds in a maize crop using a random forest machine-learning algorithm and near-infrared snapshot mosaic hyperspectral imagery},
       publisher = {Elsevier},
            year = {2018},
         journal = {Biosystems Engineering},
             doi = {10.1016/j.biosystemseng.2018.03.006},
           pages = {39--50},
        keywords = {ARRAY(0x5568fb674e68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41511/},
        abstract = {This study explores the potential of a novel hyperspectral snapshot mosaic camera forweed and maize classification. The image processing, feature engineering and machinelearning techniques were discussed when developing an optimal classification model forthe three kinds of weeds and maize. A total set of 185 spectral features includingreflectance and vegetation index features was constructed. Subsequently, the principalcomponent analysis was used to reduce the redundancy of the constructed features, andthe first 5 principal components, explaining over 95\% variance ratio, were kept for furtheranalysis. Furthermore, random forests as one of machine learning techniques were builtfor developing the classifier with three different combinations of features. Accuracy-oriented feature reduction was performed when choosing the optimal number of fea-tures for building the classification model. Moreover, hyperparameter tuning wasexplored for the optimal selection of random forest model. The results showed that theoptimal random forest model with 30 important spectral features can achieve a meancorrect classification rate of 1.0, 0.789, 0.691 and 0.752 forZea mays,Convolvulus arvensis,RumexandCirsium arvense, respectively. The McNemar test showed an overall betterperformance of the optimal random forest model at the 0.05 significance level comparedto the k-nearest neighbours (KNN) model.}
}

@inproceedings{lincoln42421,
       booktitle = {4th International Conference on Event-Based Control, Communication and Signal Processing},
           month = {June},
           title = {PRED18: Dataset and Further Experiments with DAVIS Event Camera in Predator-Prey Robot Chasing},
          author = {Diederik Paul Moyes and Daniel Neil and Federico Corradi and Emmett Kerr and Philip Vance and Gautham Das and Sonya A. Coleman and Thomas M. McGinnity and Dermot Kerr and Tobi Delbruck},
            year = {2018},
        keywords = {ARRAY(0x5568fba87e70)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42421/},
        abstract = {Machine vision systems using convolutional neural networks (CNNs) for robotic applications are increasingly being developed. Conventional vision CNNs are driven by camera frames at constant sample rate, thus achieving a fixed latency and power consumption tradeoff. This paper describes further work on the first experiments of a closed-loop robotic system integrating a CNN together with a Dynamic and Active Pixel Vision Sensor (DAVIS) in a predator/prey scenario. The DAVIS, mounted on the predator Summit XL robot, produces frames at a fixed 15 Hz frame-rate and Dynamic Vision Sensor (DVS) histograms containing 5k ON and OFF events at a variable frame-rate ranging from 15-500 Hz depending on the robot speeds. In contrast to conventional frame-based systems, the latency and processing cost depends on the rate of change of the image. The CNN is trained offline on the 1.25h labeled dataset to recognize the position and size of the prey robot, in the field of view of the predator. During inference, combining the ten output classes of the CNN allows extracting the analog position vector of the prey relative to the predator with a mean 8.7\% error in angular estimation. The system is compatible with conventional deep learning technology, but achieves a variable latency-power tradeoff that adapts automatically to the dynamics. Finally, investigations on the robustness of the algorithm, a human performance comparison and a deconvolution analysis are also explored.}
}

@inproceedings{lincoln47569,
           month = {June},
          author = {Mohammed Al-Khafajiy and Lee Webster and Thar Baker and Atif Waraich},
       booktitle = {Proceedings of the 2nd International Conference on Future Networks and Distributed Systems},
           title = {Towards fog driven IoT healthcare: challenges and framework of fog computing in healthcare},
       publisher = {ACM},
             doi = {10.1145/3231053.3231062},
           pages = {1--7},
            year = {2018},
        keywords = {ARRAY(0x5568fbb5ce28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47569/},
        abstract = {As we are within the era of the internet of things (IoT) its increasing integration to our everyday lives means that the devices involved produce massive amounts of data every second from billions of devices. The current approach used to handle this data is cloud computing. However because of its requirement of data centres this can become infeasible for the processing of data from IoT due to distance between these IoT smart objects (e.g., sensors) and the data centre. If this data holds any importance to minimal delay then the travel time between the end device and the clouds data centre could affect the relevance of that data. Therefore, to deal with these issues a new network paradigm placed closer to the IoT end devices is introduced called "Fog computing" to help address these challenges. If introduced effectively then fog computing can lead to the improvements in the quality of service (QoS) offered to systems that require the processing of delay sensitive data like healthcare systems that could benefit from the quick processing of data from sensors to allow the monitoring of patients. This paper has a main focus on healthcare systems. An architecture containing three layers; things (i.e., sensors), fog nodes and a cloud data centre is proposed alongside a framework incorporating this architecture. This framework offers collaboration among fog nodes with optimal management of resources and job allocation, which is able to achieve a high QoS (i.e., low latency) within the scenario of a healthcare system.}
}

@inproceedings{lincoln31363,
       booktitle = {14th International Conference on Precision Agriculture},
           month = {June},
           title = {Rumex and Urtica detection in grassland by UAV},
          author = {Adam Binch and Nigel Cooke and Charles Fox},
       publisher = {14th International Conference on Precision Agriculture},
            year = {2018},
        keywords = {ARRAY(0x5568fba5f038)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31363/},
        abstract = {. Previous work (Binch \& Fox, 2017) used autonomous ground robotic platforms to successfully detect Urtica (nettle) and Rumex (dock) weeds in grassland, to improve farm productivity and the environment through precision herbicide spraying. It assumed that ground robots swathe entire fields to both detect and spray weeds, but this is a slow process as the slow ground platform must drive over every square meter of the field even where there are no weeds. The present study examines a complimentary approach, using unmanned aerial vehicles (UAVs) to perform faster detections, in order to inform slower ground robots of weed location and direct them to spray them from the ground. In a controlled study, it finds that the existing state-of-the-art (Binch \& Fox, 2017) ground detection algorithm based on local binary patterns and support vector machines is easily re-usable from a UAV with 4K camera despite large differences in camera type, distance, perspective and motion, without retraining. The algorithm achieves 83-95\% accuracy on ground platform data with 1-3 independent views, and improves to 90\% from single views on aerial data. However this is only attainable at low altitudes up to 8 feet, speeds below 0.3m/s, and a vertical view angle, suggesting that autonomous or manual UAV swathing is required to cover fields, rather than use of a single high-altitude photograph. This demonstrates for the first time that combined aerial detection with ground spraying system is feasible for Rumex and Urtica in grassland, using UAVs to replace the swathing and detection of weeds then dispatching ground platforms to spray them at the detection sites (as spraying by UAV is illegal in EU countries). This reduces total time requires to spray as the UAV performs the survey stage faster than a ground platform.}
}

@techreport{lincoln32517,
           month = {June},
            type = {Other},
           title = {Agricultural Robotics: The Future of Robotic Agriculture},
          author = {Tom Duckett and Simon Pearson and Simon Blackmore and Bruce Grieve and Wen-Hua Chen and Grzegorz Cielniak and Jason Cleaversmith and Jian Dai and Steve Davis and Charles Fox and Pal From and Ioannis Georgilas and Richie Gill and Iain Gould and Marc Hanheide and Fumiya Iida and Lyudmila Mihalyova and Samia Nefti-Meziani and Gerhard Neumann and Paolo Paoletti and Tony Pridmore and Dave Ross and Melvyn Smith and Martin Stoelen and Mark Swainson and Sam Wane and Peter Wilson and Isobel Wright and Guang-Zhong Yang},
       publisher = {UK-RAS Network White Papers},
            year = {2018},
     institution = {UK-RAS Network White Papers},
        keywords = {ARRAY(0x5568fbaea030)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32517/},
        abstract = {Agri-Food is the largest manufacturing sector in the UK. It supports a food chain that generates over {\pounds}108bn p.a., with 3.9m employees in a truly international industry and exports {\pounds}20bn of UK manufactured goods. However, the global food chain is under pressure from population growth, climate change, political pressures affecting migration, population drift from rural to urban regions and the demographics of an aging global population. These challenges are recognised in the UK Industrial Strategy white paper and backed by significant investment via a Wave 2 Industrial Challenge Fund Investment ("Transforming Food Production: from Farm to Fork"). Robotics and Autonomous Systems (RAS) and associated digital technologies are now seen as enablers of this critical food chain transformation. To meet these challenges, this white paper reviews the state of the art in the application of RAS in Agri-Food production and explores research and innovation needs to ensure these technologies reach their full potential and deliver the necessary impacts in the Agri-Food sector.}
}

@misc{lincoln33091,
           month = {June},
           title = {Radio 4 interview, Farming Today, on agri-robotics},
          author = {Charles Fox},
       publisher = {BBC Radio 4},
            year = {2018},
         journal = {Farming Today},
        keywords = {ARRAY(0x5568fb677ca0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33091/},
        abstract = {Interview on Radio4 Farming today about the future of agricultural robotics.}
}

@inproceedings{lincoln40820,
          volume = {172},
           month = {June},
          author = {Monish Koshy and S. Sreevishnu and Anjai Krishnan and Gautham Das},
       booktitle = {International Conference on Design, Analysis, Manufacturing and Simulation (ICDAMS)},
           title = {Kinematic Design, Analysis and Simulation of a Hybrid Robot with Terrain and Aerial Locomotion Capability},
       publisher = {EDP Sciences},
            year = {2018},
         journal = {MATEC Web of Conferences},
             doi = {10.1051/matecconf/201817203008},
           pages = {03008},
        keywords = {ARRAY(0x5568fbafc980)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40820/},
        abstract = {Having only one type of locomotion mechanism limits the stability and locomotion capability of a mobile robot on irregular terrain surfaces. One of the possible solution to this is combining more than one locomotion mechanisms in the robot. In this paper, robotic platform composed of a quadruped module for terrain locomotion and quadrotor module for aerial locomotion is introduced. This design is inspired by the way which birds are using their wings and legs for stability in slopped and uneven surfaces. The main idea is to combine the two systems in such a way that the strengths of both subsystems are used, and the weakness of the either systems are covered. The ability of the robot to reach the target position quickly and to avoid large terrestrial obstacles by flying expands its application in various areas of search and rescue. The same platform can be used for detailed 3D mapping and aerial mapping which are very helpful in rescue operations. In particular, this paper presents kinematic design, analysis and simulation of such a robotic system. Simulation and verification of results are done using MATLAB.}
}

@inproceedings{lincoln40821,
          volume = {172},
           month = {June},
          author = {Monish Koshy and S. Sreevishnu and Anjai Krishnan and Gautham Das},
       booktitle = {International Conference on Design, Analysis, Manufacturing and Simulation (ICDAMS)},
           title = {Mechanical Design and Analysis of Hybrid Mobile Robot with Aerial and Terrain Locomotion Capability},
       publisher = {EDP Sciences},
            year = {2018},
         journal = {MATEC Web of Conferences},
             doi = {10.1051/matecconf/201817203007},
           pages = {03007},
        keywords = {ARRAY(0x5568fba0de98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40821/},
        abstract = {Although different locomotion mechanisms are available, the use of only one locomotion system in a mobile robot restricts its application scenarios. Hybrid locomotion improves the maneuverability and flexibility of a robot. This paper introduces a hybrid locomotion mobile robot, a combination of quadruped and quadrotor system. The robot has a unique expediency to fly to remote places, then walk to perform close range operations in the field. The prime intention is to use the quadrotor to tackle large objects by flying over it. The four legs provide easy movements in uneven terrain. Thus, this robot can be used in erratic and dynamic environments where stability, maneuverability and flexibility are required. This system can be used as first responders in search and rescue missions, where it responds before human responders gets to the site and get the entire information of the area in detail (like spotting trapped ones, getting detailed 3D mapping etc.). This platform offers unique capabilities suited for search and rescue, disaster zone assistance and surveillances. This paper elucidates the mechanical design and analysis of a hybrid locomotion robot. The solid model of the robot was made using CATIA and further analysis like static analysis, computational fluid dynamics analysis and drop test analysis were performed in ANSYS.}
}

@inproceedings{lincoln32484,
       booktitle = {Proceedings of the 15th International Conference on Intelligent Autonomous Systems},
           month = {June},
           title = {Filtration analysis of pedestrian-vehicle interactions for autonomous vehicle control},
          author = {Fanta Camara and Charles Fox},
       publisher = {15th International Conference on Intelligent Autonomous Systems},
            year = {2018},
        keywords = {ARRAY(0x5568fbaf21a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32484/},
        abstract = {Abstract. Interacting with humans remains a challenge for autonomous
vehicles (AVs). When a pedestrian wishes to cross the road in front of the
vehicle at an unmarked crossing, the pedestrian and AV must compete
for the space, which may be considered as a game-theoretic interaction in
which one agent must yield to the other. To inform development of new
real-time AV controllers in this setting, this study collects and analy-
ses detailed, manually-annotated, temporal data from real-world human
road crossings as they interact with manual drive vehicles. It studies the
temporal orderings (filtrations) in which features are revealed to the ve-
hicle and their informativeness over time. It presents a new framework
suggesting how optimal stopping controllers may then use such data to
enable an AV to decide when to act (by speeding up, slowing down, or
otherwise signalling intent to the pedestrian) or alternatively, to continue
at its current speed in order to gather additional information from new
features, including signals from that pedestrian, before acting itself.}
}

@article{lincoln43297,
           month = {June},
           title = {The Need for Combining Implicit and
Explicit Communication in
Cooperative Robotic Systems},
          author = {Naomi Gildert and Alan Millard and Andrew Pomfret and Jon Timmis},
            year = {2018},
             doi = {10.3389/frobt.2018.00065},
         journal = {Frontiers in Robotics and AI},
        keywords = {ARRAY(0x5568fb968158)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43297/},
        abstract = {As the number of robots used in warehouses and manufacturing increases, so too does
the need for robots to be able to manipulate objects, not only independently, but also
in collaboration with humans and other robots. Our ability to effectively coordinate our
actions with fellow humans encompasses several behaviours that are collectively referred
to as joint action, and has inspired advances in human-robot interaction by leveraging
our natural ability to interpret implicit cues. However, our capacity to efficiently coordinate
on object manipulation tasks remains an advantageous process that is yet to be fully
exploited in robotic applications. Humans achieve this form of coordination by combining
implicit communication (where information is inferred) and explicit communication (direct
communication through an established channel) in varying degrees according to the task
at hand. Although these two forms of communication have previously been implemented
in robotic systems, no system exists that integrates the two in a task-dependent adaptive
manner. In this paper, we review existing work on joint action in human-robot interaction,
and analyse the state-of-the-art in robot-robot interaction that could act as a foundation
for future cooperative object manipulation approaches. We identify key mechanisms that
must be developed in order for robots to collaborate more effectively, with other robots
and humans, on object manipulation tasks in shared autonomy spaces.}
}

@article{lincoln32874,
          volume = {140},
          number = {6},
           month = {June},
          author = {Pal From and Lars Grimstad and Marc Hanheide and Simon Pearson and Grzegorz Cielniak},
           title = {RASberry - Robotic and Autonomous Systems for Berry Production},
       publisher = {ASME},
            year = {2018},
         journal = {Mechanical Engineering Magazine Select Articles},
             doi = {10.1115/1.2018-JUN-6},
        keywords = {ARRAY(0x5568fbb91f28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32874/},
        abstract = {The soft fruit industry is facing unprecedented challenges due to its reliance of manual labour. We are presenting a newly launched robotics initiative which will help to address the issues faced by the industry and enable automation of the main processes involved in soft fruit production. The RASberry project (Robotics and Autonomous Systems for Berry Production) aims to develop autonomous fleets of robots for horticultural industry. To achieve this goal, the project will bridge several current technological gaps including the development of a mobile platform suitable for the strawberry fields, software components for fleet management, in-field navigation and mapping, long-term operation, and safe human-robot collaboration.
In this paper, we provide a general overview of the project, describe the main system components, highlight interesting challenges from a control point of view and then present three specific applications of the robotic fleets in soft fruit production. The applications demonstrate how robotic fleets can benefit the soft fruit industry by significantly decreasing production costs, addressing labour shortages and being the first step towards fully autonomous robotic systems for agriculture.}
}

@unpublished{lincoln39627,
       booktitle = {Amazing Technology Symposium},
           month = {June},
           title = {Design of a bendable and steerable robotic uterine elevator},
          author = {Chakravarthini M. Saaj and Seri Mustaza and Kavitha Madhuri and Simon Butler-Manuel},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39627/}
}

@article{lincoln32403,
          volume = {8},
          number = {4},
           month = {June},
          author = {Andrew Schofield and Iain Gilchrist and Marina Bloj and Ales Leonardis and Nicola Bellotto},
           title = {Understanding images in biological and computer vision},
       publisher = {The Royal Society},
            year = {2018},
         journal = {Interface Focus},
             doi = {10.1098/rsfs.2018.0027},
           pages = {1--3},
        keywords = {ARRAY(0x5568fbadaf18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32403/},
        abstract = {This issue of Interface Focus is a collection of papers arising out of a Royal Society Discussion meeting entitled ?Understanding images in biological and computer vision? held at Carlton Terrace on the 19th and 20th February, 2018. There is a strong tradition of inter-disciplinarity in the study of visual perception and visual cognition. Many of the great natural scientists including Newton [1], Young [2] and Maxwell (see [3]) were intrigued by the relationship between light, surfaces and perceived colour considering both physical and perceptual processes. Brewster [4] invented both the lenticular stereoscope and the binocular camera but also studied the perception of shape-from-shading. More recently, Marr's [5] description of visual perception as an information processing problem led to great advances in our understanding of both biological and computer vision: both the computer vision and biological vision communities have a Marr medal. The recent successes of deep neural networks in classifying the images that we see and the fMRI images that reveal the activity in our brains during the act of seeing are both intriguing. The links between machine vision systems and biology may at sometimes be weak but the similarity of some of the operations is nonetheless striking [6]. This two-day meeting brought together researchers from the fields of biological and computer vision, robotics, neuroscience, computer science and psychology to discuss the most recent developments in the field. The meeting was divided into four themes: vision for action, visual appearance, vision for recognition and machine learning.}
}

@unpublished{lincoln39626,
       booktitle = {14th International Symposium on Artificial Intelligence, Robotics and Automation in Space (i-SAIRAS 2018),},
           month = {June},
           title = {H{\ensuremath{\alpha}} Controller for a Free-flying Robotic Spacecraft},
          author = {Asma Seddaoui and Chakravarthini Mini Saaj},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39626/}
}

@article{lincoln41512,
          volume = {67},
           month = {May},
          author = {Junfeng Gao and wenzhi Liao and David Nuyttens and Peter Lootens and J{\"u}rgen Vangeyte and Aleksandra Pi{\v z}urica and Yong He and Jan G. Pieters},
           title = {Fusion of pixel and object-based features for weed mapping using unmanned aerial vehicle imagery},
       publisher = {Elsevier},
            year = {2018},
         journal = {International Journal of Applied Earth Observation and Geoinformation},
             doi = {10.1016/j.jag.2017.12.012},
           pages = {43--53},
        keywords = {ARRAY(0x5568fba33b30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41512/},
        abstract = {The developments in the use of unmanned aerial vehicles (UAVs) and advanced imaging sensors provide new opportunities for ultra-high resolution (e.g., less than a 10 cm ground sampling distance (GSD)) crop field monitoring and mapping in precision agriculture applications. In this study, we developed a strategy for inter- and intra-row weed detection in early season maize fields from aerial visual imagery. More specifically, the Hough transform algorithm (HT) was applied to the orthomosaicked images for inter-row weed detection. A semi-automatic Object-Based Image Analysis (OBIA) procedure was developed with Random Forests (RF) combined with feature selection techniques to classify soil, weeds and maize. Furthermore, the two binary weed masks generated from HT and OBIA were fused for accurate binary weed image. The developed RF classifier was evaluated by 5-fold cross validation, and it obtained an overall accuracy of 0.945, and Kappa value of 0.912. Finally, the relationship of detected weeds and their ground truth densities was quantified by a fitted linear model with a coefficient of determination of 0.895 and a root mean square error of 0.026. Besides, the importance of input features was evaluated, and it was found that the ratio of vegetation length and width was the most significant feature for the classification model. Overall, our approach can yield a satisfactory weed map, and we expect that the obtained accurate and timely weed map from UAV imagery will be applicable to realize site-specific weed management (SSWM) in early season crop fields for reducing spraying non-selective herbicides and costs.}
}

@inproceedings{lincoln32170,
       booktitle = {IEEE International Conference on Robotics and Automation, Workshop on Robotic Vision and Action in Agriculture},
           month = {May},
           title = {Discrete Event Simulations for Scalability Analysis of Robotic In-Field Logistics in Agriculture ? A Case Study},
          author = {Gautham Das and Grzegorz Cielniak and Pal From and Marc Hanheide},
            year = {2018},
        keywords = {ARRAY(0x5568fbaaeab0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32170/},
        abstract = {Agriculture lends itself to automation due to its labour-intensive processes and the strain posed on workers in the domain. This paper presents a discrete event simulation (DES) framework allowing to rapidly assess different processes and layouts for in-field logistics operations employing a fleet of autonomous transportation robots supporting soft-fruit pickers. The proposed framework can help to answer pressing questions regarding the economic viability and scalability of such fleet operations, which we illustrate and discuss in the context of a specific case study considering strawberry picking operations. In particular, this paper looks into the effect of a robotic fleet in scenarios with different transportation requirements, as well as on the effect of allocation algorithms, all without requiring resource demanding field trials. The presented framework demonstrates a great potential for future development and optimisation of the efficient robotic fleet operations in agriculture.}
}

@inproceedings{lincoln32171,
       booktitle = {ICRA 2018 Workshop on Robotic Vision and Action in Agriculture},
           month = {May},
           title = {Soil Compaction Mapping Through Robot Exploration: A Study into Kriging Parameters},
          author = {Jaime Pulido Fentanes and Iain Gould and Tom Duckett and Simon Pearson and Grzegorz Cielniak},
       publisher = {IEEE},
            year = {2018},
        keywords = {ARRAY(0x5568fb9f08c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32171/},
        abstract = {Soil condition mapping is a manual, laborious and costly process which requires soil measurements to be taken at fixed, pre-defined locations, limiting the quality of the resulting information maps. For these reasons, we propose the use of an outdoor mobile robot equipped with an actuated soil probe for automatic mapping of soil condition, allowing for both, more efficient data collection and better soil models. The robot is building soil models on-line using standard geo-statistical methods such as kriging, and is using the quality of the model to drive the exploration. In this work, we take a closer look at the kriging process itself and how its parameters affect the exploration outcome. For this purpose, we employ soil compaction datasets collected from two real fields of varying characteristics and analyse how the parameters vary between fields and how they change during the exploration process. We particularly focus on the stability of the kriging parameters, their evolution over the exploration process and influence on the resulting soil maps.}
}

@inproceedings{lincoln31674,
       booktitle = {IEEE International Conference on Robotics and Automation},
           month = {May},
           title = {Learning robust policies for object manipulation with robot swarms},
          author = {G. H. W. Gebhardt and K. Daun and M. Schnaubelt and G. Neumann},
            year = {2018},
        keywords = {ARRAY(0x5568fb9ecfe8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31674/},
        abstract = {Swarm robotics investigates how a large population of robots with simple actuation and limited sensors can collectively solve complex tasks. One particular interesting application with robot swarms is autonomous object assembly.
Such tasks have been solved successfully with robot swarms that are controlled by a human operator using a light source.
In this paper, we present a method to solve such assembly tasks autonomously based on policy search methods. We split the assembly process in two subtasks: generating a high-level assembly plan and learning a low-level object movement policy.  The assembly policy plans the trajectories for each object and the object movement policy controls the trajectory execution.  Learning the object movement policy is challenging as it depends on the complex state of the swarm which consists of an individual state for each agent. To approach this problem, we introduce a representation of the swarm which is based on Hilbert space embeddings of distributions. This representation is invariant to the number of agents in the swarm as well as to the allocation of an agent to its position in the swarm.  These invariances make the learned policy robust to changes in the swarm and also reduce the search space for the policy search method significantly. We show that the resulting system is able to solve assembly tasks with varying object shapes in multiple simulation scenarios and evaluate the robustness of our representation to changes in the swarm size. Furthermore, we demonstrate that the policies learned in simulation are robust enough to be transferred to real robots.}
}

@inproceedings{lincoln30920,
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           month = {May},
           title = {Robust learning of object assembly tasks with an invariant representation of robot swarms},
          author = {G. H. W. Gebhardt and K. Daun and M. Schnaubelt and G. Neumann},
            year = {2018},
        keywords = {ARRAY(0x5568fba448e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30920/},
        abstract = {{--} Swarm robotics investigates how a large population of robots with simple actuation and limited sensors can collectively solve complex tasks. One particular interesting application with robot swarms is autonomous object assembly. Such tasks have been solved successfully with robot swarms that are controlled by a human operator using a light source. In this paper, we present a method to solve such assembly tasks autonomously based on policy search methods. We split the assembly process in two subtasks: generating a high-level assembly plan and learning a low-level object movement policy. The assembly policy plans the trajectories for each object and the object movement policy controls the trajectory execution.
Learning the object movement policy is challenging as it depends on the complex state of the swarm which consists of an individual state for each agent. To approach this problem, we introduce a representation of the swarm which is based on Hilbert space embeddings of distributions. This representation is invariant to the number of agents in the swarm as well as to the allocation of an agent to its position in the swarm.  These invariances make the learned policy robust to changes in the swarm and also reduce the search space for the policy search method significantly. We show that the resulting system is able to solve assembly tasks with varying object shapes in multiple simulation scenarios and evaluate the robustness of our representation to changes in the swarm size. Furthermore, we demonstrate that the policies learned in simulation are robust enough to be transferred to real robots.}
}

@inproceedings{lincoln31686,
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           month = {May},
           title = {Learning coupled forward-inverse models with combined prediction errors},
          author = {D. Koert and G. Maeda and G. Neumann and J. Peters},
            year = {2018},
        keywords = {ARRAY(0x5568fbaa0978)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31686/},
        abstract = {Challenging tasks in unstructured environments require robots to learn complex models. Given a large amount of information, learning multiple simple models can offer an efficient alternative to a monolithic complex network. Training multiple models{--}that is, learning their parameters and their responsibilities{--}has been shown to be prohibitively hard as optimization is prone to local minima. To efficiently learn multiple models for different contexts, we thus develop a new algorithm based on expectation maximization (EM). In contrast to comparable concepts, this algorithm trains multiple modules of paired forward-inverse models by using the prediction errors of both forward and inverse models simultaneously.  In particular, we show that our method yields a substantial improvement over only considering the errors of the forward models on tasks where the inverse space contains multiple solutions}
}

@incollection{lincoln30916,
           month = {May},
          author = {Nicola Bellotto and Serhan Cosar and Zhi Yan},
       booktitle = {Encyclopedia of Robotics},
          editor = {M. H. Ang and O. Khatib and B. Siciliano},
           title = {Human detection and tracking},
       publisher = {Springer},
             doi = {10.1007/978-3-642-41610-1\_34-1},
            year = {2018},
        keywords = {ARRAY(0x5568fbbb4468)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30916/},
        abstract = {In robotics, detecting and tracking moving objects is key to implementing useful and safe robot behaviours. Identifying which of the detected objects are humans is particularly important for domestic and public environments.
Typically the robot is required to collect environmental data of the surrounding area using its on-board sensors, estimating where humans are and where they are going to. Moreover, robots should detect and track humans accurately and as early as possible in order to have enough time to react accordingly}
}

@article{lincoln32026,
           month = {May},
          author = {Subhajit Basu and Adekemi Omotubora and Charles Fox},
           title = {Legal framework for small autonomous agricultural robots},
       publisher = {Springer},
         journal = {AI and Society},
             doi = {10.1007/s00146-018-0846-4},
           pages = {1--22},
            year = {2018},
        keywords = {ARRAY(0x5568fb4a5358)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32026/},
        abstract = {Legal structures may form barriers to, or enablers of, adoption of precision agriculture management with small autonomous
agricultural robots. This article develops a conceptual regulatory framework for small autonomous agricultural robots, from
a practical, self-contained engineering guide perspective, sufficient to get working research and commercial agricultural
roboticists quickly and easily up and running within the law. The article examines the liability framework, or rather lack of
it, for agricultural robotics in EU, and their transpositions to UK law, as a case study illustrating general international legal
concepts and issues. It examines how the law may provide mitigating effects on the liability regime, and how contracts can
be developed between agents within it to enable smooth operation. It covers other legal aspects of operation such as the use
of shared communications resources and privacy in the reuse of robot-collected data. Where there are some grey areas in
current law, it argues that new proposals could be developed to reform these to promote further innovation and investment
in agricultural robots}
}

@article{lincoln40819,
          volume = {29},
          number = {5},
           month = {May},
          author = {Philip J. Vance and Gautham Das and Dermot Kerr and Sonya A. Coleman and T. Martin McGinnity and Tim Gollisch and Jian K. Liu},
           title = {Bioinspired Approach to Modeling Retinal Ganglion Cells Using System Identification Techniques},
            year = {2018},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
             doi = {10.1109/TNNLS.2017.2690139},
           pages = {1796--1808},
        keywords = {ARRAY(0x5568fbba0ef8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40819/},
        abstract = {The processing capabilities of biological vision systems are still vastly superior to artificial vision, even though this has been an active area of research for over half a century. Current artificial vision techniques integrate many insights from biology yet they remain far-off the capabilities of animals and humans in terms of speed, power, and performance. A key aspect to modeling the human visual system is the ability to accurately model the behavior and computation within the retina. In particular, we focus on modeling the retinal ganglion cells (RGCs) as they convey the accumulated data of real world images as action potentials onto the visual cortex via the optic nerve. Computational models that approximate the processing that occurs within RGCs can be derived by quantitatively fitting the sets of physiological data using an input?output analysis where the input is a known stimulus and the output is neuronal recordings. Currently, these input?output responses are modeled using computational combinations of linear and nonlinear models that are generally complex and lack any relevance to the underlying biophysics. In this paper, we illustrate how system identification techniques, which take inspiration from biological systems, can accurately model retinal ganglion cell behavior, and are a viable alternative to traditional linear?nonlinear approaches.}
}

@inproceedings{lincoln32195,
           month = {May},
          author = {Andrey Postnikov and Argyrios Zolotas and Chris Bingham and Ibrahim Saleh and Corneliu Arsene and Simon Pearson and Ronald Bickerton},
       booktitle = {2017 European Modelling Symposium (EMS)},
           title = {Modelling of Thermostatically Controlled Loads to Analyse the Potential of Delivering FFR DSR with a Large Network of Compressor Packs},
       publisher = {IEEE},
             doi = {doi:10.1109/EMS.2017.37},
           pages = {163--167},
            year = {2018},
        keywords = {ARRAY(0x5568fbb54d08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32195/},
        abstract = {This paper presents preliminary work from a current study on large refrigeration pack network. In particular, the simulation model of a typical refrigeration system with a single pack of 6 compressor units operating as fixed volume displacement machines is presented, and the potential of delivering static FFR with a large population of such packs is studied. Tuning of the model is performed using experimental data collected at the Refrigeration Research Centre in Riseholme, Lincoln. The purpose of modelling is to monitor the essential dynamics of what resembles a typical supermarket convenience-type store and to measure the capacity of a massive refrigeration network to hold off a considerable amount of load in response to FFR DSR event. This study focuses on investigation of the aggregated response of 150 packs (approx. 1 MW capacity) with refrigeration cases on hysteresis and modulation control. The presented model captures interconnected dynamics (refrigerant flow in the system linked to temperature control and the system's refrigerant demand and to compressors' power consumption). Type of refrigerant used for simulation is R407F. Refrigerant properties such as specific enthalpy, pressure and temperature at different state points are computed on each time step of simulation with REFPROP.}
}

@unpublished{lincoln39628,
       booktitle = {Amazing Technology Symposium},
           month = {May},
           title = {Control of a soft robot for minimally invasive surgery},
          author = {Chakravarthini M. Saaj and Seri Mustaza},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39628/}
}

@article{lincoln31010,
          volume = {49},
          number = {4},
           month = {April},
          author = {Daqi Liu and Shigang Yue},
           title = {Event-driven continuous STDP learning with deep structure for visual pattern recognition},
       publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
            year = {2018},
         journal = {IEEE Transactions on Cybernetics},
             doi = {10.1109/tcyb.2018.2801476},
           pages = {1377--1390},
        keywords = {ARRAY(0x5568fbb8bfb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31010/},
        abstract = {Human beings can achieve reliable and fast visual pattern recognition with limited time and learning samples. Underlying this capability, ventral stream plays an important role in object representation and form recognition. Modeling the ventral steam may shed light on further understanding the visual brain in humans and building artificial vision systems for pattern recognition. The current methods to model the mechanism of ventral stream are far from exhibiting fast, continuous and event-driven learning like the human brain. To create a visual system similar to ventral stream in human with fast learning capability, in this study, we propose a new spiking neural system with an event-driven continuous spike timing dependent plasticity (STDP) learning method using specific spiking timing sequences. Two novel continuous input mechanisms have been used to obtain the continuous input spiking pattern sequence. With the event-driven STDP learning rule, the proposed learning procedure will be activated if the neuron receive one pre- or post-synaptic spike event. The experimental results on MNIST database show that the proposed method outperforms all other methods in fast learning scenarios and most of the current models in exhaustive learning experiments.}
}

@book{lincoln33090,
           month = {April},
           title = {Data Science for Transport},
          author = {Charles Fox},
         address = {Germany},
       publisher = {Springer},
            year = {2018},
          series = {Springer Texts in Earth Science, Geography and Environment},
        keywords = {ARRAY(0x5568fbb9cfb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33090/},
        abstract = {The quantity, diversity and availability of transport data is increasing rapidly, requiring new skills in the management and interrogation of data and databases. Recent years have seen a new wave of 'big data', 'Data Science', and 'smart cities' changing the world, with the Harvard Business Review describing Data Science as the "sexiest job of the 21st century". Transportation professionals and researchers need to be able to use data and databases in order to establish quantitative, empirical facts, and to validate and challenge their mathematical models, whose axioms have traditionally often been assumed rather than rigorously tested against data. This book takes a highly practical approach to learning about Data Science tools and their application to investigating transport issues. The focus is principally on practical, professional work with real data and tools, including business and ethical issues.}
}

@inproceedings{lincoln33421,
       booktitle = {2017 Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)},
           month = {April},
           title = {An Improved LPTC Neural Model for Background Motion Direction Estimation},
          author = {Hongxin Wang and Jigen Peng and Shigang Yue},
       publisher = {IEEE},
            year = {2018},
             doi = {10.1109/DEVLRN.2017.8329786},
        keywords = {ARRAY(0x5568fb95db90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33421/},
        abstract = {A class of specialized neurons, called lobula plate tangential cells (LPTCs) has been shown to respond strongly to wide-field motion. The classic model, elementary motion detector (EMD) and its improved model, two-quadrant detector (TQD) have been proposed to simulate LPTCs. Although EMD and TQD can percept background motion, their outputs are so cluttered that it is difficult to discriminate actual motion direction of the background. In this paper, we propose a max operation mechanism to model a newly-found transmedullary neuron Tm9 whose physiological properties do not map onto EMD and TQD. This proposed max operation mechanism is able to improve the detection performance of TQD in cluttered background by filtering out irrelevant motion signals. We will demonstrate the functionality of this proposed mechanism in wide-field motion perception.}
}

@article{lincoln30386,
          volume = {50},
           month = {April},
          author = {Khaled Elgeneidy and Niels Lohse and Michael Jackson},
           title = {Bending angle prediction and control of soft pneumatic actuators with embedded flex sensors: a data-driven approach},
       publisher = {Elsevier for International Federation of Automatic Control (IFAC)},
            year = {2018},
         journal = {Mechatronics},
             doi = {10.1016/j.mechatronics.2017.10.005},
           pages = {234--247},
        keywords = {ARRAY(0x5568fb9bc4f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30386/},
        abstract = {In this paper, a purely data-driven modelling approach is presented for predicting and controlling the free bending angle response of a typical soft pneumatic actuator (SPA), embedded with a resistive flex sensor. An experimental setup was constructed to test the SPA at different input pressure values and orientations, while recording the resulting feedback from the embedded flex sensor and on-board pressure sensor. A calibrated high speed camera captures image frames during the actuation, which are then analysed using an image processing program to calculate the actual bending angle and synchronise it with the recorded sensory feedback. Empirical models were derived based on the generated experimental data using two common data-driven modelling techniques; regression analysis and artificial neural networks. Both techniques were validated using a new dataset at untrained operating conditions to evaluate their prediction accuracy. Furthermore, the derived empirical model was used as part of a closed-loop PID controller to estimate and control the bending angle of the tested SPA based on the real-time sensory feedback generated. The tuned PID controller allowed the bending SPA to accurately follow stepped and sinusoidal reference signals, even in the presence of pressure leaks in the pneumatic supply. This work demonstrates how purely data-driven models can be effectively used in controlling the bending of SPAs under different operating conditions, avoiding the need for complex analytical modelling and material characterisation. Ultimately, the aim is to create more controllable soft grippers based on such SPAs with embedded sensing capabilities, to be used in applications requiring both a ?soft touch? as well as a more controllable object manipulation.}
}

@unpublished{lincoln39629,
       booktitle = {8th Annual British and Irish Association of Robotic Gynaecological Surgeons},
           month = {April},
           title = {Gynaecological Endoscopic Uterine Elevator},
          author = {Chakravarthini M. Saaj and Seri Mustaza and Kavitha Madhuri and Simon Butler-Manuel},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39629/}
}

@article{lincoln38544,
          volume = {94},
           month = {March},
          author = {Andrea Cohen and Simon Parsons and Elizabeth Sklar and Peter McBurney},
            note = {cited By 1},
           title = {A characterization of types of support between structured arguments and their relationship with support in abstract argumentation},
       publisher = {Elsevier},
            year = {2018},
         journal = {International Journal of Approximate Reasoning},
             doi = {10.1016/j.ijar.2017.12.008},
           pages = {76--104},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38544/},
        abstract = {Argumentation is an important approach in artificial intelligence and multiagent systems, providing a basis for single agents to make rational decisions, and for groups of agents to reach agreements, as well as a mechanism to underpin a wide range of agent interactions. In such work, a crucial role is played by the notion of attack between arguments, and the notion of attack is well-studied. There is, for example, a range of different approaches to identifying which of a set of arguments should be accepted given the attacks between them. Less well studied is the notion of support between arguments, yet the idea that one argument may support another is very intuitive and seems particularly relevant in the area of decision-making where decision options may have multiple arguments for and against them. In the last decade, the study of support in argumentation has regained attention among researchers, but most approaches address support in the context of abstract argumentation where the elements from which arguments are composed are ignored. In contrast, this paper studies the notion of support between arguments in the context of structured argumentation systems where the elements from which arguments are composed play a crucial role. Different forms of support are presented, each of which takes into account the structure of arguments; and the relationships between these forms of support are studied. Then, the paper investigates whether there is a correspondence between the structured and abstract forms of support, and determines whether the abstract formalisms may be instantiated using concrete forms of support in terms of structured arguments. The conclusion is that support in structured argumentation does not mesh well with support in abstract argumentation, and this suggests that more work is required to develop forms of support in abstract argumentation that model what happens in structured argumentation.}
}

@article{lincoln34519,
          volume = {101},
           month = {March},
          author = {Amir Ghalamzan Esfahani and Matteo Ragaglia and  },
           title = {Robot learning from demonstrations: Emulation learning in environments with moving obstacles},
       publisher = {Elsevier},
            year = {2018},
         journal = {Robotics and autonomous systems},
             doi = {10.1016/j.robot.2017.12.001},
           pages = {45--56},
        keywords = {ARRAY(0x5568fbbbac50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34519/},
        abstract = {In this paper, we present an approach to the problem of Robot Learning from Demonstration (RLfD) in a dynamic environment, i.e. an environment whose state changes throughout the course of performing a task. RLfD mostly has been successfully exploited only in non-varying environments to reduce the programming time and cost, e.g. fixed manufacturing workspaces. Non-conventional production lines necessitate Human?Robot Collaboration (HRC) implying robots and humans must work in shared workspaces. In such conditions, the robot needs to avoid colliding with the objects that are moved by humans in the workspace. Therefore, not only is the robot: (i) required to learn a task model from demonstrations; but also, (ii) must learn a control policy to avoid a stationary obstacle. Furthermore, (iii) it needs to build a control policy from demonstration to avoid moving obstacles. Here, we present an incremental approach to RLfD addressing all these three problems. We demonstrate the effectiveness of the proposed RLfD approach, by a series of pick-and-place experiments by an ABB YuMi robot. The experimental results show that a person can work in a workspace shared with a robot where the robot successfully avoids colliding with him.}
}

@article{lincoln34759,
          volume = {10},
          number = {1},
           month = {March},
          author = {Ronghua Shang and Bingqi Du and Kaiyun Dai and Licheng Jiao and Amir Ghalamzan Esfahani and Rustam Stolkin and   and  },
           title = {Quantum-Inspired Immune Clonal Algorithm for solving large-scale capacitated arc routing problems},
       publisher = {Springer},
            year = {2018},
         journal = {Memetic Computing},
             doi = {10.1007/s12293-017-0224-7},
           pages = {81--102},
        keywords = {ARRAY(0x5568fbb7b1b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34759/},
        abstract = {In this paper, we present an approach to Large-Scale CARP called Quantum-Inspired Immune Clonal Algorithm (QICA-CARP). This algorithm combines the feature of an artificial immune system and quantum computation ground on the qubit and the quantum superposition. We call an antibody of population quantum bit encoding, in QICA-CARP. For this encoding, to control the population with a high probability evolution towards a good schema we use the information on the current optimal antibody. The mutation strategy of quantum rotation gate accelerates the convergence of the original clone operator. Moreover, quantum crossover operator enhances the exchange of information and increases the diversity of the population. Furthermore, it avoids falling into local optimum. We also use the repair operator to amend the infeasible solutions to ensure the diversity of solutions. This makes QICA-CARP approximating the optimal solution. We demonstrate the effectiveness of our approach by a set of experiments and by Comparing the results of our approach with ones obtained with the RDG-MAENS and RAM using different test sets. Experimental results show that QICA-CARP outperforms other algorithms in terms of convergence rate and the quality of the obtained solutions. Especially, QICA-CARP converges to a better lower bound at a faster rate illustrating that it is suitable for solving large-scale CARP.}
}

@article{lincoln27883,
          volume = {42},
          number = {3},
           month = {March},
          author = {Alexandros Paraschos and Christian Daniel and Jan Peters and Gerhard Neumann},
           title = {Using probabilistic movement primitives in robotics},
       publisher = {Springer Verlag},
            year = {2018},
         journal = {Autonomous Robots},
             doi = {10.1007/s10514-017-9648-7},
           pages = {529--551},
        keywords = {ARRAY(0x5568fb67f7b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27883/},
        abstract = {Movement Primitives are a well-established paradigm for modular movement representation and generation. They provide a data-driven representation of movements and support generalization to novel situations, temporal modulation, sequencing of primitives and controllers for executing the primitive on physical systems. However, while many MP frameworks exhibit some of these properties, there is a need for a unified framework that implements all of them in a principled way. In this paper, we show that this goal can be achieved by using a probabilistic representation. Our approach models trajectory distributions learned from stochastic movements. Probabilistic operations, such as conditioning can be used to achieve generalization to novel situations or to combine and blend movements in a principled way. We derive a stochastic feedback controller that reproduces the encoded variability of the
movement and the coupling of the degrees of freedom of the robot. We evaluate and compare our approach on several simulated and real robot scenarios.}
}

@article{lincoln32297,
          volume = {27},
          number = {5},
           month = {March},
          author = {Jianglong Guo and Khaled Elgeneidy and C Xiang and Niels Lohse and Laura Justham and Jonathan Rossiter},
           title = {Soft pneumatic grippers embedded with stretchable electroadhesion},
       publisher = {IOP Publishing},
            year = {2018},
         journal = {Smart Materials and Structures},
             doi = {10.1088/1361-665X/aab579},
           pages = {055006},
        keywords = {ARRAY(0x5568fb6706a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32297/},
        abstract = {Current soft pneumatic grippers cannot robustly grasp flat materials and flexible objects on curved surfaces without distorting them. Current electroadhesive grippers, on the other hand, are difficult to actively deform to complex shapes to pick up free-form surfaces or objects. An easy-to-implement PneuEA gripper is proposed by the integration of an electroadhesive gripper and a two-fingered soft pneumatic gripper. The electroadhesive gripper was fabricated by segmenting a soft conductive silicon sheet into a two-part electrode design and embedding it in a soft dielectric elastomer. The two-fingered soft pneumatic gripper was manufactured using a standard soft lithography approach. This novel integration has combined the benefits of both the electroadhesive and soft pneumatic grippers. As a result, the proposed PneuEA gripper was not only able to pick-and-place flat and flexible materials such as a porous cloth but also delicate objects such as a light bulb. By combining two soft touch sensors with the electroadhesive, an intelligent and shape-adaptive PneuEA material handling system has been developed. This work is expected to widen the applications of both soft gripper and electroadhesion technologies.}
}

@article{lincoln31687,
          volume = {7},
          number = {1-2},
           month = {March},
          author = {Takayuki Osa and Joni Pajarinen and Gerhard Neumann and J. Andrew Bagnell and Pieter Abbeel and Jan Peters},
           title = {An algorithmic perspective on imitation learning},
       publisher = {Now publishers},
            year = {2018},
         journal = {Foundations and Trends in Robotics},
             doi = {10.1561/2300000053},
           pages = {1--179},
        keywords = {ARRAY(0x5568fba66388)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31687/},
        abstract = {As robots and other intelligent agents move from simple environments and problems to more complex, unstructured settings, manually programming their behavior has become increasingly challenging and expensive. Often, it is easier for a teacher to demonstrate a desired behavior rather than attempt to manually engineer it. This process of learning from demonstrations, and the study of algorithms to do so, is called imitation learning. This work provides an introduction to imitation learning. It covers the underlying assumptions, approaches, and how they relate; the rich set of algorithms developed to tackle the problem; and advice on effective tools and implementation. We intend this paper to serve two audiences. First, we want to familiarize machine learning experts with the challenges of imitation learning, particularly those arising in robotics, and the interesting theoretical and practical distinctions between it and more familiar frameworks like statistical supervised learning theory and reinforcement learning. Second, we want to give roboticists and experts in applied artificial intelligence a broader appreciation for the frameworks and tools available for imitation learning. We pay particular attention to the intimate connection between imitation learning approaches and those of structured prediction Daum{\'e} III et al. [2009]. To structure this discussion, we categorize imitation learning techniques based on the following key criteria which drive algorithmic decisions:

1) The structure of the policy space. Is the learned policy a time-index trajectory (trajectory learning), a mapping from observations to actions (so called behavioral cloning [Bain and Sammut, 1996]), or the result of a complex optimization or planning problem at each execution as is common in inverse optimal control methods [Kalman, 1964, Moylan and Anderson, 1973].

2) The information available during training and testing. In particular, is the learning algorithm privy to the full state that the teacher possess? Is the learner able to interact with the teacher and gather corrections or more data? Does the learner have a (typically a priori) model of the system with which it interacts? Does the learner have access to the reward (cost) function that the teacher is attempting to optimize?

3) The notion of success. Different algorithmic approaches provide varying guarantees on the resulting learned behavior. These guarantees range from weaker (e.g., measuring disagreement with the agent?s decision) to stronger (e.g., providing guarantees on the performance of the learner with respect to a true cost function, either known or unknown). We organize our work by paying particular attention to distinction (1): dividing imitation learning into directly replicating desired behavior (sometimes called behavioral cloning) and learning the hidden objectives of the desired behavior from demonstrations (called inverse optimal control or inverse reinforcement learning [Russell, 1998]). In the latter case, behavior arises as the result of an optimization problem solved for each new instance that the learner faces. In addition to method analysis, we discuss the design decisions a practitioner must make when selecting an imitation learning approach. Moreover, application examples{--}such as robots that play table tennis [Kober and Peters, 2009], programs that play the game of Go [Silver et al., 2016], and systems that understand natural language [Wen et al., 2015]{--} illustrate the properties and motivations behind different forms of imitation learning. We conclude by presenting a set of open questions and point towards possible future research directions for machine learning.}
}

@inproceedings{lincoln31959,
       booktitle = {R4L @ HRI2018},
           month = {March},
           title = {Robots in the classroom: Learning to be a Good Tutor},
          author = {Emmanuel Senft and Severin Lemaignan and Madeleine Bartlett and Paul Baxter and Tony Belpaeme},
            year = {2018},
        keywords = {ARRAY(0x5568fb686740)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31959/},
        abstract = {To broaden the adoption and be more inclusive, robotic tutors need to tailor their
behaviours to their audience. Traditional approaches, such as Bayesian Knowledge
Tracing, try to adapt the content of lessons or the difficulty of tasks to the current
estimated knowledge of the student. However, these variations only happen in a limited
domain, predefined in advance, and are not able to tackle unexpected variation in a
student's behaviours. We argue that robot adaptation needs to go beyond variations in
preprogrammed behaviours and that robots should in effect learn online how to become
better tutors. A study is currently being carried out to evaluate how human supervision
can teach a robot to support child learning during an educational game using one
implementation of this approach.}
}

@inproceedings{lincoln31204,
       booktitle = {The 13th Annual ACM/IEEE International Conference on Human Robot Interaction},
           month = {March},
           title = {Studying table-top manipulation tasks: a robust framework for object tracking in collaboration},
          author = {Peter Lightbody and Paul Baxter and Marc Hanheide},
       publisher = {ACM/IEEE},
            year = {2018},
             doi = {10.1145/3173386.3177045},
        keywords = {ARRAY(0x5568fbb4afe8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31204/},
        abstract = {Table-top object manipulation is a well-established test bed on which to study both basic foundations of general human-robot interaction and more specific collaborative tasks. A prerequisite, both for studies and for actual collaborative or assistive tasks, is the robust perception of any objects involved. This paper presents a real-time capable and ROS-integrated approach, bringing together state-of-the-art detection and tracking algorithms, integrating perceptual cues from multiple cameras and solving detection, sensor fusion and tracking in one framework. The highly scalable framework was tested in a HRI use-case scenario with 25 objects being reliably tracked under significant temporary occlusions. The use-case demonstrates the suitability of the approach when working with multiple objects in small table-top environments and highlights the versatility and range of analysis available with this framework.}
}

@article{lincoln31137,
          volume = {11},
          number = {2},
           month = {February},
          author = {Ibrahim Saleh and Andrey Postnikov and Corneliu Arsene and Argyrios Zolotas and Chris Bingham and Ronald Bickerton and Simon Pearson},
           title = {Impact of demand side response on a commercial retail refrigeration system},
       publisher = {MDPI},
            year = {2018},
         journal = {Energies},
             doi = {10.3390/en11020371},
           pages = {371},
        keywords = {ARRAY(0x5568fbb58cc0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31137/},
        abstract = {The UK National Grid has placed increased emphasis on the development of Demand Side Response (DSR) tariff mechanisms to manage load at peak times. Refrigeration systems, along with HVAC, are estimated to consume 14\% of the UK?s electricity and could have a significant role for DSR application. However, characterized by relatively low individual electrical loads and massive asset numbers, multiple low power refrigerators need aggregation for inclusion in these tariffs. In this paper, the impact of the Demand Side Response (DSR) control mechanisms on food retailing refrigeration systems is investigated. The experiments are conducted in a test-rig built to resemble a typical small supermarket store. The paper demonstrates how the temperature and pressure profiles of the system, the active power and the drawn current of the compressors are affected following a rapid shut down and subsequent return to normal operation as a response to a DSR event. Moreover, risks and challenges associated with primary and secondary Firm Frequency Response (FFR) mechanisms, where the load is rapidly shed at high speed in response to changes in grid frequency, is considered. For instance, measurements are included that show a significant increase in peak inrush currents of approx. 30\% when the system returns to normal operation at the end of a DSR event. Consideration of how high inrush currents after a DSR event can produce voltage fluctuations of the supply and we assess risks to the local power supply system.}
}

@article{lincoln34757,
          volume = {142},
           month = {January},
          author = {Ronghua Shang and Yijing Yuan and Licheng Jiao and Yang Meng and Amir Ghalamzan Esfahani},
           title = {A self-paced learning algorithm for change detection in synthetic aperture radar images},
       publisher = {Elsevier},
            year = {2018},
         journal = {Signal Processing},
             doi = {10.1016/j.sigpro.2017.07.023},
           pages = {375--387},
        keywords = {ARRAY(0x5568fb70e4c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34757/},
        abstract = {Detecting changed regions between two given synthetic aperture radar images is very important to monitor the change of landscapes, change of ecosystem and so on. This can be formulated as a classification problem and addressed by learning a classifier, traditional machine learning classification methods very easily stick to local optima which can be caused by noises of data. Hence, we propose an unsupervised algorithm aiming at constructing a classifier based on self-paced learning. Self-paced learning is a recently developed supervised learning approach and
has been proven to be capable to overcome effectively this shortcoming. After applying a pre-classification to the difference image, we uniformly select samples using the initial result. Then, self-paced learning is utilized to train a classifier. Finally, a filter is used based on spatial contextual information to further smooth the classification result. In order to demonstrate the efficiency of the proposed algorithm, we apply our proposed algorithm on five real synthetic aperture radar images datasets. The results obtained by our algorithm are compared with five other state-of-the-art algorithms, which demonstrates that our algorithm outperforms those state-of-the-art algorithms in terms of accuracy and robustness.}
}

@article{lincoln30806,
          volume = {10},
          number = {1},
           month = {January},
          author = {George Petropoulos and Prashant Srivastava and Maria Piles and Simon Pearson},
            note = {This article belongs to the Special Issue Precision Agriculture Technologies for a Sustainable Future: Current Trends and Perspectives},
           title = {Earth observation-based operational estimation of soil moisture and evapotranspiration for agricultural crops in support of sustainable water management},
       publisher = {MDPI},
            year = {2018},
         journal = {Sustainability},
             doi = {10.3390/su10010181},
           pages = {181},
        keywords = {ARRAY(0x5568fba27a58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30806/},
        abstract = {Global information on the spatio-temporal variation of parameters driving the Earth?s terrestrial water and energy cycles, such as evapotranspiration (ET) rates and surface soil moisture (SSM), is of key significance. The water and energy cycles underpin global food and water security and need to be fully understood as the climate changes. In the last few decades, Earth Observation (EO) technology has played an increasingly important role in determining both ET and SSM. This paper reviews the state of the art in the use specifically of operational EO of both ET and SSM estimates. We discuss the key technical and operational considerations to derive accurate estimates of those parameters from space. The review suggests significant progress has been made in the recent years in retrieving ET and SSM operationally; yet, further work is required to optimize parameter accuracy and to improve the operational capability of services developed using EO data. Emerging applications on which ET/SSM operational products may be included in the context specifically in relation to agriculture are also highlighted; the operational use of those operational products in such applications remains to be seen.}
}

@inproceedings{lincoln44713,
           month = {January},
          author = {Helen Harman and Keshav Chintamani and Pieter Simoens},
       booktitle = {2017 IEEE International Symposium on Robotics and Intelligent Sensors (IRIS)},
           title = {Architecture for incorporating Internet-of-Things sensors and actuators into robot task planning in dynamic environments},
       publisher = {IEEE},
             doi = {10.1109/IRIS.2017.8250091},
           pages = {13--18},
            year = {2018},
        keywords = {ARRAY(0x5568fbbaa0d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44713/},
        abstract = {Robots are being deployed in a wide range of smart environments that are equipped with sensors and actuators. These devices can provide valuable information beyond the perception range of a robot's on-board sensors, or provide additional actuators that can complement the robot's actuation abilities. Traditional robot task planners do not take these additional sensor and actuators abilities into account. This paper introduces an enhanced robotic planning framework which improves robots' ability to operate in dynamically changing environments. To keep planning time short, the amount of knowledge in the planner's world model is minimized.}
}

@inproceedings{lincoln31168,
       booktitle = {Global Power and Propulsion Forum},
           month = {January},
           title = {Performance analysis and prediction of compressor fouling condition for a twin-shaft engine},
          author = {Sepehr Maleki and Samuel Cruz-Manzo and Chris Bingham and Vili Panov},
       publisher = {Global Power and Propulsion Society},
            year = {2018},
        keywords = {ARRAY(0x5568fbb67db0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31168/},
        abstract = {Performance of a twin-shaft Industrial Gas Turbine (IGT) at fouling condition is simulated via a gas turbine model based
on fundamental thermodynamics. Measurements across the engine during compressor fouling conditions were considered to validate the outcomes. By implementing correlation coefficients in the compressor model, the performance of the IGT during compressor fouling conditions is predicted. The change in the compressor air flow and the compressor efficiency during fouling conditions is estimated. The results show that the reduction of air flow rate is the dominating parameter in loss of generated power under fouled conditions. The model can provide an insight into the effect of compressor fouling conditions on IGT performance.}
}

@inproceedings{lincoln33098,
       booktitle = {Transportation Research Board},
           month = {January},
           title = {Models of human decision-making as tools for estimating and optimising impacts of vehicle automation},
          author = {G Markkula and R Romano and R Madigan and Charles Fox and O Giles and N Merat},
       publisher = {Transportatio n Research Record},
            year = {2018},
        keywords = {ARRAY(0x5568fb9b7a18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33098/},
        abstract = {With the development of increasingly automated vehicles (AVs) comes the increasingly difficult challenge of comprehensively validating these for acceptable, and ideally beneficial, impacts on the transport system. There is a growing consensus that virtual testing, where simulated AVs are deployed in simulated traffic, will be key for cost-effective testing and optimisation. The least mature model components in such simulations are those generating the behaviour of human agents in or around the AVs. In this paper, human models and virtual testing applications are presented for two example scenarios: (i) a human pedestrian deciding whether to cross a street in front of an approaching automated vehicle, with or without external human-machine interface elements, and (ii) an AV handing over control to a human driver in a critical rear-end situation. These scenarios have received much recent research attention, yet simulation-ready human behaviour models are lacking. They are discussed here in the context of existing models of perceptual decision-making, situational awareness, and traffic interactions. It is argued that the human behaviour in question might be usefully conceptualised as a number of interrelated decision processes, not all of which are necessarily directly associated with externally observable behaviour. The results show that models based on this type of framework can reproduce qualitative patterns of behaviour reported in the literature for the two addressed scenarios, and it is demonstrated how computer simulations based on the models, once these have been properly validated, could allow prediction and optimisation of  the AV.}
}

@article{lincoln32457,
          volume = {19},
          number = {14},
          author = {R. Akrour and A. Abdolmaleki and H. Abdulsamad and J. Peters and Gerhard Neumann},
           title = {Model-Free Trajectory-based Policy Optimization with Monotonic Improvement},
       publisher = {Journal of Machine Learning Research},
         journal = {Journal of Machine Learning Research (JMLR)},
           pages = {1--25},
            year = {2018},
        keywords = {ARRAY(0x5568fba36530)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32457/},
        abstract = {Many of the recent trajectory optimization algorithms alternate between linear approximation
of the system dynamics around the mean trajectory and conservative policy update.
One way of constraining the policy change is by bounding the Kullback-Leibler (KL)
divergence between successive policies. These approaches already demonstrated great experimental
success in challenging problems such as end-to-end control of physical systems.
However, these approaches lack any improvement guarantee as the linear approximation of
the system dynamics can introduce a bias in the policy update and prevent convergence
to the optimal policy. In this article, we propose a new model-free trajectory-based policy
optimization algorithm with guaranteed monotonic improvement. The algorithm backpropagates
a local, quadratic and time-dependent Q-Function learned from trajectory data
instead of a model of the system dynamics. Our policy update ensures exact KL-constraint
satisfaction without simplifying assumptions on the system dynamics. We experimentally
demonstrate on highly non-linear control tasks the improvement in performance of our algorithm
in comparison to approaches linearizing the system dynamics. In order to show the
monotonic improvement of our algorithm, we additionally conduct a theoretical analysis of
our policy update scheme to derive a lower bound of the change in policy return between
successive iterations.}
}

@inproceedings{lincoln32456,
       booktitle = {Proceedings of the International Conference on Machine Learning},
           title = {Efficient Gradient-Free Variational Inference using Policy Search},
          author = {O. Arenz and M. Zhong and Gerhard Neumann},
            year = {2018},
        keywords = {ARRAY(0x5568fba7e210)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32456/},
        abstract = {Inference from complex distributions is a common problem in machine learning needed for many Bayesian methods. We propose an efficient, gradient-free method for learning general GMM approximations of multimodal distributions based on recent insights from stochastic search methods. Our method establishes information-geometric trust regions to ensure efficient exploration of the sampling space and stability of the GMM updates, allowing for efficient estimation of multi-variate Gaussian variational distributions. For GMMs, we apply a variational lower bound to decompose the learning objective into sub-problems given by learning the individual mixture components and the coefficients. The number of mixture components is adapted online in order to allow for arbitrary exact approximations. We demonstrate on several domains that we can learn significantly better approximations than competing variational inference methods and that the quality of samples drawn from our approximations is on par with samples created by state-of-the-art MCMC samplers that require significantly more computational resources.}
}

@article{lincoln33871,
          volume = {80},
           title = {Efficient Gradient-Free Variational Inference using Policy Search},
          author = {Oleg Arenz and Gerhard Neumann and Mingjun Zhong},
       publisher = {Proceedings of Machine Learning Research},
            year = {2018},
           pages = {234--243},
         journal = {Proceedings of the 35th International Conference on Machine Learning},
        keywords = {ARRAY(0x5568fba28700)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33871/},
        abstract = {Inference from complex distributions is a common problem in machine learning needed for many Bayesian methods. We propose an efficient, gradient-free method for learning general GMM approximations of multimodal distributions based on recent insights from stochastic search methods. Our method establishes information-geometric trust regions to ensure efficient exploration of the sampling space and stability of the GMM updates, allowing for efficient estimation of multi-variate Gaussian variational distributions. For GMMs, we apply a variational lower bound to decompose the learning objective into sub-problems given by learning the individual mixture components and the coefficients. The number of mixture components is adapted online in order to allow for arbitrary exact approximations. We demonstrate on several domains that we can learn significantly better approximations than competing variational inference methods and that the quality of samples drawn from our approximations is on par with samples created by state-of-the-art MCMC samplers that require significantly more computational resources.}
}

@inproceedings{lincoln33320,
       booktitle = {Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction - HRI '18},
           title = {Safe Human-Robot Interaction in Agriculture},
          author = {Paul Baxter and Grzegorz Cielniak and Marc Hanheide and Pal From},
       publisher = {ACM},
            year = {2018},
           pages = {59--60},
             doi = {doi:10.1145/3173386.3177072},
        keywords = {ARRAY(0x5568fbaf2158)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33320/},
        abstract = {Robots in agricultural contexts are finding increased numbers of applications with respect to (partial) automation for increased productivity. However, this presents complex technical problems to be overcome, which are magnified when these robots are intended to work side-by-side with human workers. In this contribution we present an exploratory pilot study to characterise interactions between a robot performing an in-field transportation task and human fruit pickers. Partly an effort to inform the development of a fully autonomous system, the emphasis is on involving the key stakeholders (i.e. the pickers themselves) in the process so as to maximise the potential impact of such an application.}
}

@inproceedings{lincoln33321,
       booktitle = {Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction - HRI '18},
           title = {Robots Providing Cognitive Assistance in Shared Workspaces},
          author = {Paul Baxter and Peter Lightbody and Marc Hanheide},
       publisher = {ACM},
            year = {2018},
           pages = {57--58},
             doi = {doi:10.1145/3173386.3177070},
        keywords = {ARRAY(0x5568fb969f60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33321/},
        abstract = {Human-Robot Collaboration is an area of particular current interest, with the attempt to make robots more generally useful in contexts where they work side-by-side with humans. Currently, efforts typically focus on the sensory and motor aspects of the task on the part of the robot to enable them to function safely and effectively given an assigned task. In the present contribution, we rather focus on the cognitive faculties of the human worker by attempting to incorporate known (from psychology) properties of human cognition. In a proof-of-concept study, we demonstrate how applying characteristics of human categorical perception to the type of robot assistance impacts on task performance and experience of the participants. This lays the foundation for further developments in cognitive assistance and collaboration in side-by-side working for humans and robots.}
}

@book{lincoln39216,
       booktitle = {Operations Management in Agriculture},
           title = {Operations Management in Agriculture},
          author = {Dionysis Bochtis and Claus Aage Gr{\o}n S{\o}rensen and Dimitrios Kateris},
       publisher = {Elsevier},
            year = {2018},
             doi = {doi:10.1016/C2015-0-06290-6},
        keywords = {ARRAY(0x5568fb6d1790)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39216/},
        abstract = {Operations Management in Agriculture bridges the knowledge gap on operations management for agricultural machinery. It complements traditional topics (cost of using and choosing machinery) with advanced engineering approaches recently applied in agricultural machinery management (area coverage planning and sequential scheduling). The book covers new technologies in bio-production systems (robotics, IoT) and environmental compliance by employing a systems engineering perspective with focuses on sub-systems, including advanced optimization, supply chain systems, sustainability, autonomous vehicles and IT-driven decision-making. It will be a valuable resource for students studying decision-making and those working to improve the efficiency, effectiveness and sustainability of production through machinery choice.}
}

@inproceedings{lincoln33565,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2018) Workshops},
           title = {Towards pedestrian-AV interaction: method for elucidating pedestrian preferences},
          author = {Fanta Camara and Serhan Cosar and Nicola Bellotto and Natasha Merat and Charles Fox},
            year = {2018},
        keywords = {ARRAY(0x5568fbb67888)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33565/},
        abstract = {Autonomous vehicle navigation around human pedestrians remains a challenge due to the potential for complex interactions and feedback loops between the agents. As a small step towards better understanding of these interactions, this Methods Paper presents a new empirical protocol based on tracking real humans in a controlled lab environment, which is able to make inferences about the human?s preferences for interaction (how they trade off the cost of their time against the cost of a collision). Knowledge of such preferences if collected in more realistic environments could then be used by future AVs to predict and control for pedestrian behaviour. This study is intended as a work-in-progress report on methods working towards real-time and less controlled experiments, demonstrating successful use of several key components required by such systems, but in its more controlled setting. This suggests that these components could be extended to more realistic situations and results in an ongoing research programme.}
}

@inproceedings{lincoln33126,
       booktitle = {The 21st IEEE International Conference on Intelligent Transportation Systems},
           title = {Predicting pedestrian road-crossing assertiveness for autonomous vehicle control},
          author = {Fanta Camara and O Giles and R Madigan and M Rothmueller and P Holm Rasmussen and SA Vendelbo-Larsen and G Markkula and YM Lee and L Garach and N Merat and CW Fox},
       publisher = {IEEE Xplore},
            year = {2018},
        keywords = {ARRAY(0x5568fba1b298)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33126/},
        abstract = {Autonomous vehicles (AVs) must interact with other road users including pedestrians. Unlike passive environments, pedestrians are active agents having their own utilities and decisions, which must be inferred and predicted by AVs in order to control interactions with them and navigation around them. In particular, when a pedestrian wishes to cross the road in front of the vehicle at an unmarked crossing, the pedestrian and AV must compete for the space, which may be considered as a game-theoretic interaction in which one agent must yield to the other. To inform AV controllers in this setting, this study collects and analyses data from real-world human road crossings to determine what features of crossing behaviours are predictive about the level of assertiveness of pedestrians and of the eventual winner of the interactions. It presents the largest and most detailed data set of its kind known to us, and new methods to analyze and predict pedestrian-vehicle interactions based upon it. Pedestrian-vehicle interactions are decomposed into sequences of independent discrete events. We use probabilistic methods ?logistic regression and decision tree regression ? and sequence analysis to analyze sets and sub-sequences of actions used by both pedestrians and human drivers while crossing at an intersection, to find common patterns of behaviour and to predict the winner of each interaction. We report on the particular features found to be predictive and which can thus be integrated into game-theoretic AV controllers to inform real-time interactions.}
}

@inproceedings{lincoln33564,
       booktitle = {15th International Conference on Intelligent Autonomous Systems (IAS-15) workshops},
           title = {Filtration analysis of pedestrian-vehicle interactions for autonomous vehicles control},
          author = {Fanta Camara and Oscar Giles and Ruth Madigan and Markus Rothm{\"u}ller and Pernille Holm Rasmussen and Signe Alexandra Vendelbo-Larsen and Gustav Markkula and Yee Mun Lee and Laura Garach and Natasha Merat and Charles Fox},
            year = {2018},
        keywords = {ARRAY(0x5568fba05570)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33564/},
        abstract = {Interacting with humans remains a challenge for autonomous
vehicles (AVs). When a pedestrian wishes to cross the road in front of the
vehicle at an unmarked crossing, the pedestrian and AV must compete
for the space, which may be considered as a game-theoretic interaction in
which one agent must yield to the other. To inform development of new
real-time AV controllers in this setting, this study collects and analy-
ses detailed, manually-annotated, temporal data from real-world human
road crossings as they interact with manual drive vehicles. It studies the
temporal orderings (filtrations) in which features are revealed to the ve-
hicle and their informativeness over time. It presents a new framework
suggesting how optimal stopping controllers may then use such data to
enable an AV to decide when to act (by speeding up, slowing down, or
otherwise signalling intent to the pedestrian) or alternatively, to continue
at its current speed in order to gather additional information from new
features, including signals from that pedestrian, before acting itself.}
}

@inproceedings{lincoln32028,
       booktitle = {Proc. Measuring Behaviour 2018: International Conference on Methods and Techniques in Behavioral Research},
           title = {Empirical game theory of pedestrian interaction for autonomous vehicles},
          author = {Fanta Camara and Richard A. Romano and Gustav Markkula and Ruth Madigan and Natasha Merat and Charles W. Fox},
            year = {2018},
         journal = {Proceedings of Measuring Behavior 2018.},
        keywords = {ARRAY(0x5568fbb514c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32028/},
        abstract = {Autonomous vehicles (AV?s) are appearing on roads, based on standard robotic mapping and
navigation algorithms. However their ability to interact with other road-users is much less well understood. If
AVs are programmed to stop every time another road user obstructs them, then other road users simply learn that
they can take priority at every interaction, and the AV will make little or no progress. This issue is especially
important in the case of a pedestrian crossing the road in front of the AV. The present methods paper expands the
sequential chicken model introduced in (Fox et al., 2018), using empirical data to measure behavior of humans in
a controlled plus-maze experiment, and showing how such data can be used to infer parameters of the model via
a Gaussian Process. This providing a more realistic, empirical understanding of the human factors intelligence
required by future autonomous vehicles.}
}

@inproceedings{lincoln33029,
       booktitle = {Turbomachinery Technical Conference and Exposition},
           title = {ANALYSIS OF PERFORMANCE OF A TWIN-SHAFT GAS TURBINE DURING HOT-END DAMAGE IN THE GAS GENERATOR TURBINE},
          author = {Samuel Cruz-Manzo and Sepehr Maleki and Vili Panov and Festus Agbonzikilo and Yu Zhang},
       publisher = {ASME},
            year = {2018},
        keywords = {ARRAY(0x5568fbb7edb0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33029/},
        abstract = {In this study, an analysis of the performance of a twin-shaft industrial gas turbine (IGT) during hot-end damage in the gas generator turbine (GGT) at high-power operation has been carried out using a validated Simulink IGT model. The Simulink model is based on fundamental thermodynamics and allows the implementation of correlation coefficients in the GGT module to predict the performance of the IGT system during a hot-end GGT damage incident. Measured field data from a twin-shaft IGT operated as a power generation unit denoting a reduction in performance due to hot-end GGT damage are considered for the analysis. Four hot-end GGT damage incidents across a range of measured field data have been identified and considered for the analysis. The results show that the Simulink model can predict the change of physical parameters (pressure, temperature) across the IGT system for each GGT damage incident. Hot-end damage increases the flow capacity and reduces the efficiency of the GGT.  Future work will validate the dynamic change of flow capacity and efficiency during different GGT damage incidents.}
}

@article{lincoln33938,
           title = {Towards an automated masking process: A model-based approach},
          author = {Khaled Elgeneidy and Ali Al-Yacoub and Zahid Usman and Niels Lohsa and Michael jackson and Iain Wright},
       publisher = {Sage},
            year = {2018},
             doi = {10.1177/0954405418810058},
            note = {The final published version of this article can be found online at http://www.uk.sagepub.com/journals/Journal202016/},
         journal = {Journal of Engineering Manufacture},
        keywords = {ARRAY(0x5568fba0dc28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33938/},
        abstract = {The masking of aircraft engine parts, such as turbine blades, is a major bottleneck for the aerospace industry. The process is often carried out manually in multiple stages of coating and curing, which requires extensive time and introduces variations in the masking quality. This article investigates the automation of the masking process utilising the well-established time?pressure dispensing process for controlled maskant dispensing and a robotic manipulator for accurate part handling. A mathematical model for the time?pressure dispensing process was derived, extending previous models from the literature by incorporating the robot velocity for controlled masking line width. An experiment was designed, based on the theoretical analysis of the dispensing process, to derive an empirical model from the generated data that incorporate the losses that are otherwise difficult to model mathematically. The model was validated under new input conditions to demonstrate the feasibility of the proposed approach and the masking accuracy using the derived model.}
}

@article{lincoln32562,
           title = {Directly Printable Flexible Strain Sensors for Bending and Contact Feedback of Soft Actuators},
          author = {Khaled Elgeneidy and Gerhard Neumann and Michael Jackson and Niels Lohse},
       publisher = {Frontiers Media},
            year = {2018},
             doi = {10.3389/frobt.2018.00002},
         journal = {Front. Robot. AI},
        keywords = {ARRAY(0x5568fb9bdcd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32562/},
        abstract = {This paper presents a fully printable sensorized bending actuator that can be calibrated to provide reliable bending feedback and simple contact detection. A soft bending actuator following a pleated morphology, as well as a flexible resistive strain sensor, were directly 3D printed using easily accessible FDM printer hardware with a dual-extrusion tool head. The flexible sensor was directly welded to the bending actuator?s body and systematically tested to characterize and evaluate its response under variable input pressure. A signal conditioning circuit was developed to enhance the quality of the sensory feedback, and flexible conductive threads were used for wiring. The sensorized actuator?s response was then calibrated using a vision system to convert the sensory readings to real bending angle values. The empirical relationship was derived using linear regression and validated at untrained input conditions to evaluate its accuracy. Furthermore, the sensorized actuator was tested in a constrained setup that prevents bending, to evaluate the potential of using the same sensor for simple contact detection by comparing the constrained and free-bending responses at the same input pressures. The results of this work demonstrated how a dual-extrusion FDM printing process can be tuned to directly print highly customizable flexible strain sensors that were able to provide reliable bending feedback and basic contact detection. The addition of such sensing capability to bending actuators enhances their functionality and reliability for applications such as controlled soft grasping, flexible wearables, and haptic devices.}
}

@inproceedings{lincoln32544,
       booktitle = {IROS 2018},
           title = {Contact Detection and Object Size Estimation using a Modular Soft Gripper with Embedded Flex Sensors},
          author = {Khaled Elgeneidy and Gerhard Neumann and Simon Pearson and Michael Jackson and Niels Lohse},
            year = {2018},
         journal = {IROS 2018},
        keywords = {ARRAY(0x5568fbb80d50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32544/},
        abstract = {Soft-grippers can grasp delicate and deformable objects without bruise or damage as the gripper can adapt to the object?s shape. However, the contact forces are still hard to regulate due to missing contact feedback of such grippers. In this paper, a modular soft gripper design is presented utilizing interchangeable soft pneumatic actuators with embedded flex sensors as fingers of the gripper. The fingers can be assembled in different configurations using 3D printed connectors. The paper investigates the potential of utilizing the simple sensory feedback from the flex sensors to make additional meaningful inferences regarding the contact state and grasped object size. We study the effect of the grasped object size and contact type on the combined feedback from the embedded flex sensors of all fingers. Our results show that a simple linear relationship exists between the grasped object size and the final flex sensor reading at fixed input conditions, despite the variation in object weight and contact type. Additionally, by simply monitoring the time series response from the flex sensor, contact can be detected by comparing the response to the known free-bending response at the same input conditions. Furthermore, by utilizing the measured internal pressure supplied to the soft fingers, it is possible to distinguish between power and pinch grasps, as the nature of the contact affects the rate of change in the flex sensor readings against the internal pressure.}
}

@inproceedings{lincoln38402,
           title = {The CONSULT system: Demonstration},
          author = {K. Essers and M. Chapman and N. Kokciyan and I. Sassoon and T. Porat and P. Balatsoukas and P. Young and M. Ashworth and V. Curcin and S. Modgil and Simon Parsons and Elizabeth Sklar},
            year = {2018},
           pages = {385--386},
             doi = {10.1145/3284432.3287170},
            note = {cited By 0},
         journal = {HAI 2018 - Proceedings of the 6th International Conference on Human-Agent Interaction},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38402/}
}

@inproceedings{lincoln38543,
           title = {The CONSULT system: Demonstration},
          author = {K. Essers and M. Chapman and N. Kokciyan and I. Sassoon and T. Porat and P. Balatsoukas and P. Young and M. Ashworth and V. Curcin and S. Modgil and Simon Parsons and Elizabeth Sklar},
            year = {2018},
           pages = {385--386},
             doi = {10.1145/3284432.3287170},
            note = {cited By 0},
         journal = {HAI 2018 - Proceedings of the 6th International Conference on Human-Agent Interaction},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38543/}
}

@inproceedings{lincoln38542,
           title = {Assessing the POSTURE prototype: A late-breaking report on patient views},
          author = {K. Essers and R. Rogers and J. Sturt and Elizabeth Sklar and E. Black},
            year = {2018},
           pages = {344--346},
             doi = {10.1145/3284432.3287181},
            note = {cited By 0},
         journal = {HAI 2018 - Proceedings of the 6th International Conference on Human-Agent Interaction},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38542/}
}

@inproceedings{lincoln32029,
       booktitle = {Proc. 4th International Conference on Vehicle Technology and Intelligent Transport Systems (VEHITS)},
           title = {When should the chicken cross the road?: Game theory for autonomous vehicle-human interactions},
          author = {Charles Fox and F. Camara and G. Markkula and R. Romano and R. Madigan and N. Merat},
            year = {2018},
        keywords = {ARRAY(0x5568fbaf8d50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32029/},
        abstract = {Autonomous vehicle control is well understood for local- [15], good approximations exist such as particle ?ltering,
ization, mapping and planning in un-reactive environ- which make use of large compute power to draw samples
ments, but the human factors of complex interactions near solutions.
stood [16], and despite its exact solution being NP-hard
with other road users are not yet developed.
Route planning in non-interactive envi-
ronments also has well known tractable solutions such as
This po-
the A-star algorithm. Given a route, localizing and con-
sition paper presents an initial model for negotiation be-
trol to follow that route then becomes a similar task to
tween an autonomous vehicle and another vehicle at an
that performed by the 1959 General Motors Firebird-III
unsigned intersections or (equivalently) with a pedestrian
self-driving car [1], which used electromagnetic sensing
at an unsigned road-crossing (jaywalking), using discrete
to follow a wire built into the road.
Such path follow-
sequential game theory. The model is intended as a ba- ing, using wires or SLAM, can then be augmented with
sic framework for more realistic and data-driven future simple safety logic to stop the vehicle if any obstacle is
extensions. The model shows that when only vehicle po- in its way, as detected by any range sensor.
sition is used to signal intent, the optimal behaviors for open source systems for this level of `self-driving' are now
both agents must include a non-zero probability of al- widely available [6].
lowing a collision to occur.
In contrast,
This suggests extensions to
problems that these vehicles will face
around interacting with other road users are much harder
reduce this probability in future, such as other forms of
both to formulate and solve. Autonomous vehicles do not
signaling and control. Unlike most Game Theory appli-
just have to deal with inanimate objects, sensors, and
cations in Economics, active vehicle control requires real-
maps.
time selection from multiple equilibria with no history,
They have to deal with other agents, currently
human drivers and pedestrians and eventually other au-
and we present and argue for a novel solution concept,
meta-strategy convergence , suited to this task.}
}

@article{lincoln33158,
          volume = {3},
          number = {4},
          author = {Roberto Pinillos Herrero and Jaime Pulido Fentanes and Marc Hanheide},
            note = {The final published version of this article can be accessed online at https://ieeexplore.ieee.org/document/8411093/},
           title = {Getting to Know Your Robot Customers: Automated Analysis of User Identity and Demographics for Robots in the Wild},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {doi:10.1109/LRA.2018.2856264},
           pages = {3733--3740},
        keywords = {ARRAY(0x5568fbb8df70)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33158/},
        abstract = {Long-term studies with autonomous robots ?in the wild? (deployed in real-world human-inhabited environments) are among the most laborious and resource-intensive endeavours in human-robot interaction. Even if a robot system itself is robust and well-working, the analysis of the vast amounts of user data one aims to collect and analyze poses a significant challenge. This letter proposes an automated processing pipeline, using state-of-the-art computer vision technology to estimate demographic factors from users? faces and reidentify them to establish usage patterns. It overcomes the problem of explicitly recruiting participants and having them fill questionnaires about their demographic background and allows one to study completely unsolicited and nonprimed interactions over long periods of time. This letter offers a comprehensive assessment of the performance of the automated analysis with data from 68 days of continuous deployment of a robot in a care home and also presents a set of findings obtained through the analysis, underpinning the viability of the approach.
Index}
}

@inproceedings{lincoln32460,
       booktitle = {International Conference for Swarm Intelligence (ANTS)},
           title = {Exploiting Local Communication Protocols for Learning Complex Swarm Behaviors with Deep Reinforcement Learning},
          author = {Max Huttenrauch and Adrian Sosic and Gerhard Neumann},
       publisher = {Springer International Publishing},
            year = {2018},
        keywords = {ARRAY(0x5568fbb90420)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32460/},
        abstract = {Swarm systems constitute a challenging problem for reinforcement learning (RL) as the algorithm needs to learn decentralized control policies that can cope with limited local sensing and communication abilities of the agents. While it is often difficult to directly define the behavior of the agents, simple communication protocols can be defined more easily using prior knowledge about the given task. In this paper, we propose a number of simple communication protocols that can be exploited by deep reinforcement learning to find decentralized control policies in a multi-robot swarm environment. The protocols are based on histograms that encode the local neighborhood relations of the gents
and can also transmit task-specific information, such as the shortest distance and direction to a desired target. In our framework, we use an adaptation of Trust Region Policy Optimization to learn complex collaborative tasks, such as formation building and building a communication link. We evaluate our findings in a simulated 2D-physics environment, and compare the implications of different communication protocols.}
}

@inproceedings{lincoln38541,
           title = {HAI 2018 Chairs? Welcome},
          author = {M. Imai and Elizabeth Sklar and T.J. Norman and T. Komatsu},
            year = {2018},
           pages = {III},
            note = {cited By 0},
         journal = {HAI 2018 - Proceedings of the 6th International Conference on Human-Agent Interaction},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38541/}
}

@incollection{lincoln38408,
          volume = {305},
          author = {N. Kokciyan and I. Sassoon and A.P. Young and S. Modgil and S. Parsons},
          series = {Frontiers in Artificial Intelligence and Applications},
            note = {cited By 0},
       booktitle = {Computational Models of Argument},
           title = {Reasoning with metalevel argumentation frameworks in aspartix},
       publisher = {IOS Press},
            year = {2018},
         journal = {Frontiers in Artificial Intelligence and Applications},
             doi = {10.3233/978-1-61499-906-5-463},
           pages = {463--464},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38408/},
        abstract = {In this demo paper, we propose an encoding for Metalevel Argumentation Frameworks
(MAFs) to be used in Aspartix, an Answer Set Programming (ASP) approach to find
the justified arguments of an AF [2]. MAFs provide a uniform encoding of object level
Dung Frameworks and extensions thereof that include values, preferences and attacks
on attacks (EAFs). The justification status of arguments in the object level AF can then
be evaluated and explained through evaluation of the arguments in the MAF. The demo
includes multiple examples from the literature to show the applicability of our proposed
encoding for translating various object level AFs to the uniform language of MAFs.}
}

@article{lincoln34133,
          volume = {3},
          number = {4},
          author = {Lars Kunze and Nick Hawes and Tom Duckett and Marc Hanheide},
           title = {Introduction to the Special Issue on AI for Long-Term Autonomy},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2870466},
           pages = {4431--4434},
        keywords = {ARRAY(0x5568fba8f850)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34133/},
        abstract = {The papers in this special section focus on the use of artificial intelligence (AI) for long term autonomy. Autonomous systems have a long history in the fields of AI and robotics. However, only through recent advances in technology has it been possible to create autonomous systems capable of operating in long-term, real-world scenarios. Examples include autonomous robots that operate outdoors on land, in air, water, and space; and indoors in offices, care homes, and factories. Designing, developing, and maintaining intelligent autonomous systems that operate in real-world environments over long periods of time, i.e. weeks, months, or years, poses many challenges. This special issue focuses on such challenges and on ways to overcome them using methods from AI. Long-term autonomy can be viewed as both a challenge and an opportunity. The challenge of long-term autonomy requires system designers to ensure that an autonomous system can continue operating successfully according to its real-world application demands in unstructured and semi-structured environments. This means addressing issues related to hardware and software robustness (e.g., gluing in screws and profiling for memory leaks), as well as ensuring that all modules and functions of the system can deal with the variation in the environment and tasks that is expected to occur over its operating time.}
}

@article{lincoln32829,
          volume = {3},
          number = {4},
          author = {Lars Kunze and Nick Hawes and Tom Duckett and Marc Hanheide and Tomas Krajnik},
           title = {Artificial Intelligence for Long-Term Robot Autonomy: A Survey},
       publisher = {IEEE},
            year = {2018},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2018.2860628},
           pages = {4023--4030},
        keywords = {ARRAY(0x5568fba48bb0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32829/},
        abstract = {Autonomous systems will play an essential role in many applications across diverse domains including space, marine, air, field, road, and service robotics. They will assist us in our daily routines and perform dangerous, dirty and dull tasks. However, enabling robotic systems to perform autonomously in complex, real-world scenarios over extended time periods (i.e. weeks, months, or years) poses many challenges. Some of these have been investigated by sub-disciplines of Artificial Intelligence (AI) including navigation \& mapping, perception, knowledge representation \& reasoning, planning, interaction, and learning. The different sub-disciplines have developed techniques that, when re-integrated within an autonomous system, can enable robots to operate effectively in complex, long-term scenarios. In this paper, we survey and discuss AI techniques as ?enablers? for long-term robot autonomy, current progress in integrating these techniques within long-running robotic systems, and the future challenges and opportunities for AI in long-term autonomy.}
}

@inproceedings{lincoln39622,
          volume = {152},
          author = {William Lewinger and Francisco Comin and Marcus Matthews and Chakravarthini Saaj},
       booktitle = {14th Symposium on Advanced Space Technologies in Robotics and Automation},
           title = {Earth analogue testing and analysis of Martian duricrust properties},
       publisher = {Elsevier},
            year = {2018},
         journal = {Acta Astronautica},
             doi = {10.1016/j.actaastro.2018.05.025},
           pages = {567--579},
        keywords = {ARRAY(0x5568fbbaa018)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39622/},
        abstract = {Previous and current Mars rover missions have noted a nearly ubiquitous presence of duricrusts on the planet surface. Duricrusts are thin, brittle layers of cemented regolith that cover the underlying terrain. In some cases, the duricrust hides safe or relatively safe underneath the top soil. However, as was observed by both Mars exploration rovers, Spirit and Opportunity, such crusts can also hide loose, untrafficable terrain, leading to Spirit becoming permanently incapacitated in 2009. Whilst several reports of the Martian surface have indicated the presence of duricrusts, none have been able to provide details on the physical properties of the material, which may indicate the level of safe traversability of duricrust terrains. This paper presents the findings of testing terrestrially-created duricrusts with simulated Martian soil properties, in order to determine the properties of such duricrusts and to discover what level of hazard that they may represent (e.g. can vehicles traverse the duricrust surface without penetration to lower sub-surface soils?). Combinations of elements that have been observed in the Martian soil were used as the basis for forming the laboratory-created duricrusts. Variations in duricrust thickness, water content, and the iron oxide compound were investigated. As was observed throughout the testing process, duricrusts behave in a rather brittle fashion and are easily destroyed by low surface pressures. This indicates that duricrusts are not safe for traversing and they present a definite hazard for travelling on the Martian landscape when utilising only visual terrain classification, as the surface appearance is not necessarily representative of what may be lying beneath.}
}

@article{lincoln38404,
          volume = {10767},
          author = {Z. Li and A. Cohen and Simon Parsons},
            note = {cited By 0},
           title = {Two forms of minimality in ASPIC+},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-01713-2{$_1$}{$_5$}},
           pages = {203--218},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38404/}
}

@article{lincoln38405,
          volume = {10757},
          author = {Z. Li and N. Oren and S. Parsons},
            note = {cited By 0},
           title = {On the links between argumentation-based reasoning and nonmonotonic reasoning},
       publisher = {Springer},
            year = {2018},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-75553-3\_5},
           pages = {67--85},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38405/},
        abstract = {In this paper we investigate the links between instantiated argumentation systems and the axioms for non-monotonic reasoning described in [15] with the aim of characterising the nature of argument based reasoning. In doing so, we consider two possible interpretations of the consequence relation, and describe which axioms are met by   ASPIC+  under each of these interpretations. We then consider the links between these axioms and the rationality postulates. Our results indicate that argument based reasoning as characterised by   ASPIC+  is{--}according to the axioms of [15]{--}non-cumulative and non-monotonic, and therefore weaker than the weakest non-monotonic reasoning systems considered in [15]. This weakness underpins   ASPIC+ ?s success in modelling other reasoning systems. We conclude by considering the relationship between   ASPIC+  and other weak logical systems.}
}

@article{lincoln33015,
          volume = {18},
          number = {8},
          author = {Konstantinos Liakos and Patrizia Busato and Dimitrios Moshou and Simon Pearson and Dionysis Bochtis},
            note = {This is an open access article distributed under the Creative Commons Attribution License which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. (CC BY 4.0).},
           title = {Machine Learning in Agriculture: A Review},
       publisher = {MDPI},
            year = {2018},
         journal = {Sensors},
             doi = {10.3390/s18082674},
           pages = {2674},
        keywords = {ARRAY(0x5568fbb6c3f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33015/},
        abstract = {Machine learning has emerged with big data technologies and high-performance computing to create new opportunities for data intensive science in the multi-disciplinary agri-technologies domain. In this paper, we present a comprehensive review of research dedicated to applications of machine learning in agricultural production systems. The works analyzed were categorized in (a) crop management, including applications on yield prediction, disease detection, weed detection crop quality, and species recognition; (b) livestock management, including applications on animal welfare and livestock production; (c) water management; and (d) soil management. The filtering and classification of the presented articles demonstrate how agriculture will benefit from machine learning technologies. By applying machine learning to sensor data, farm management systems are evolving into real time artificial intelligence enabled programs that provide rich recommendations and insights for farmer decision support and action}
}

@inproceedings{lincoln32540,
       booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           title = {Energy-efficient design and control of a vibro-driven robot},
          author = {Pengcheng Liu and Gerhard Neumann and Qinbing Fu and Simon Pearson and Hongnian Yu},
       publisher = {IEEE},
            year = {2018},
        keywords = {ARRAY(0x5568fbbaaa50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32540/},
        abstract = {Vibro-driven robotic (VDR) systems use stick-slip motions for locomotion. Due to the underactuated nature of the system, efficient design and control are still open problems. We present a new energy preserving design based on a spring-augmented pendulum. We indirectly control the friction-induced stick-slip motions by exploiting the passive dynamics in order to achieve an improvement in overall travelling distance and energy efficacy. Both collocated and non-collocated constraint conditions are elaborately analysed and considered to obtain a desired trajectory generation profile. For tracking control, we develop a partial feedback controller which for the pendulum which counteracts the dynamic contributions from the platform. Comparative simulation studies show the effectiveness and intriguing performance of the proposed approach, while its feasibility is experimentally verified through a physical robot. Our robot is to the best of our knowledge the first nonlinear-motion prototype in literature towards the VDR systems.}
}

@inproceedings{lincoln33448,
       booktitle = {TAROS},
           title = {Modelling and Predicting Rhythmic Flow Patterns in Dynamic Environments},
          author = {Sergi Molina Mellado and Grzegorz Cielniak and Tom{\'a}{\v s} Krajn{\'i}k and Tom Duckett},
            year = {2018},
           pages = {135--146},
        keywords = {ARRAY(0x5568fbbb1ca8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33448/},
        abstract = {We present a time-dependent probabilistic map able to model and predict flow patterns of people in indoor environments. The proposed representation models the likelihood of motion direction on a grid-based map by a set of harmonic functions, which efficiently capture long-term (minutes to weeks) variations of crowd movements over time. The evaluation, performed on data from two real environments, shows that the proposed model enables prediction of human movement patterns in the future. Potential applications include human-aware motion planning, improving the efficiency and safety of robot navigation.}
}

@misc{lincoln32454,
          volume = {7},
          number = {1-2},
          author = {Takayuki Osa and Joni Pajarinen and Gerhard Neumann and J. Andrew Bagnell and Pieter Abbeel and Jan Peters},
           title = {An Algorithmic Perspective on Imitation Learning},
       publisher = {Now Publishers},
            year = {2018},
         journal = {Foundations and Trends in Robotics},
             doi = {10.1561/2300000053},
           pages = {1--179},
        keywords = {ARRAY(0x5568fba8c4a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32454/},
        abstract = {As robots and other intelligent agents move from simple environments and problems to more complex, unstructured settings, manually programming their behavior has become increasingly challenging and expensive. Often, it is easier for a teacher to demonstrate a desired behavior rather than attempt to manually engineer it. This process of learning from demonstrations, and the study of algorithms to do so, is called imitation learning. This work provides an introduction to imitation learning. It covers the underlying assumptions, approaches, and how they relate; the rich set of algorithms developed to tackle the problem; and advice on effective tools and implementation. We intend this paper to serve two audiences. First, we want to familiarize machine learning experts with the challenges of imitation learning, particularly those arising in robotics, and the interesting theoretical and practical distinctions between it and more familiar frameworks like statistical supervised learning theory and reinforcement learning. Second, we want to give roboticists and experts in applied artificial intelligence a broader appreciation for the frameworks and tools available for imitation learning. We pay particular attention to the intimate connection between imitation learning approaches and those of structured prediction Daum{\'e} III et al. [2009]. To structure this discussion, we categorize imitation learning techniques based on the following key criteria which drive algorithmic decisions:

1) The structure of the policy space. Is the learned policy a time-index trajectory (trajectory learning), a mapping from observations to actions (so called behavioral cloning [Bain and Sammut, 1996]), or the result of a complex optimization or planning problem at each execution as is common in inverse optimal control methods [Kalman, 1964, Moylan and Anderson, 1973].

2) The information available during training and testing. In particular, is the learning algorithm privy to the full state that the teacher possess? Is the learner able to interact with the teacher and gather corrections or more data? Does the learner have a (typically a priori) model of the system with which it interacts? Does the learner have access to the reward (cost) function that the teacher is attempting to optimize?

3) The notion of success. Different algorithmic approaches provide varying guarantees on the resulting learned behavior. These guarantees range from weaker (e.g., measuring disagreement with the agent?s decision) to stronger (e.g., providing guarantees on the performance of the learner with respect to a true cost function, either known or unknown). We organize our work by paying particular attention to distinction (1): dividing imitation learning into directly replicating desired behavior (sometimes called behavioral cloning) and learning the hidden objectives of the desired behavior from demonstrations (called inverse optimal control or inverse reinforcement learning [Russell, 1998]). In the latter case, behavior arises as the result of an optimization problem solved for each new instance that the learner faces. In addition to method analysis, we discuss the design decisions a practitioner must make when selecting an imitation learning approach. Moreover, application examples{--}such as robots that play table tennis [Kober and Peters, 2009], programs that play the game of Go [Silver et al., 2016], and systems that understand natural language [Wen et al., 2015]{--} illustrate the properties and motivations behind different forms of imitation learning. We conclude by presenting a set of open questions and point towards possible future research directions for machine learning.}
}

@article{lincoln38406,
          volume = {305},
          author = {A.R. Panisson and Simon Parsons and P. McBurney and R.H. Bordini},
            note = {cited By 0},
           title = {Choosing appropriate arguments from trustworthy sources},
         journal = {Frontiers in Artificial Intelligence and Applications},
             doi = {10.3233/978-1-61499-906-5-345},
           pages = {345--352},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38406/}
}

@inproceedings{lincoln38409,
          volume = {2154},
           title = {Lies, bullshit, and deception in agent-oriented programming languages},
          author = {A.R. Panisson and S. Sarkadi and P. McBurney and Simon Parsons and R.H. Bordini},
            year = {2018},
           pages = {50--61},
            note = {cited By 2},
         journal = {CEUR Workshop Proceedings},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38409/}
}

@unpublished{lincoln34265,
            type = {Project Report},
           title = {Internet of Food Things Network Plus: IoFT Launch Event},
          author = {Simon Pearson and Steve Brewer and Jill Duarte},
         address = {Lincoln, UK},
       publisher = {University of Lincoln},
            year = {2018},
     institution = {University of Lincoln},
        keywords = {ARRAY(0x5568fbb97a68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34265/},
        abstract = {The Internet of Food Things Network Plus (IoFT+) launched at the IET Global Engineering Hub in London on 21 September 2018 with a gathering of experts from industry, government and academia. 

In a series of keynote talks and discussions they opened a three-year investigation into how artificial intelligence, data analytics and emerging digital technologies can improve the safety, security and efficiency of the UK food supply chain.}
}

@article{lincoln38545,
          volume = {10767},
          author = {J. Raphael and Elizabeth Sklar},
            note = {cited By 0},
           title = {Towards dynamic coalition formation for intelligent traffic management},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-01713-2},
           pages = {400--414},
            year = {2018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38545/}
}

@inproceedings{lincoln32931,
       booktitle = {International Conference on Energy Engineering and Smart Grids},
           title = {Aggregated power profile of a large network of refrigeration compressors following FFR DSR events},
          author = {Ibrahim Saleh and Andrey Postnikov and Chris Bingham and Ronald Bickerton and Argyrios Zolotas and Simon Pearson},
       publisher = {ESG2018},
            year = {2018},
        keywords = {ARRAY(0x5568fbada2a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32931/},
        abstract = {Refrigeration systems and HVAC are estimated to consume approximately 14\% of the UK?s electricity and could make a significant contribution towards the application of DSR. In this paper, active power profiles of single and multi-pack refrigeration systems responding DSR events are experimentally investigated. Further, a large population of 300 packs (approx. 1.5 MW capacity) is simulated to investigate the potential of delivering DSR using a network of refrigeration compressors, in common with commercial retail refrigeration systems. Two scenarios of responding to DSR are adopted for the studies viz. with and without applying a suction pressure offset after an initial 30 second shut-down of the compressors. The experiments are conducted at the Refrigeration Research Centre at University of Lincoln. Simulations of the active power profile for the compressors following triggered DSR events are realized based on a previously reported model of the thermodynamic properties of the refrigeration system. A Simulink model of a three phase power supply system is used to determine the impact of compressor operation on the power system performance, and in particular, on the line voltage of the local power supply system. The authors demonstrate how the active power and the drawn current of the multi-pack refrigeration system are affected following a rapid shut down and subsequent return to operation. Specifically, it is shown that there is a significant increase in power consumption post DSR, approximately two times higher than during normal operation, particularly when many packs of compressors are synchronized post DSR event, which can have a significant effect on the line voltage of the power supply.}
}

@inproceedings{lincoln38540,
           title = {Explanation through argumentation},
          author = {Elizabeth Sklar and M.Q. Azhar},
            year = {2018},
           pages = {277--285},
             doi = {10.1145/3284432.3284473},
            note = {cited By 0},
         journal = {HAI 2018 - Proceedings of the 6th International Conference on Human-Agent Interaction},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38540/}
}

@incollection{lincoln38407,
          volume = {305},
          author = {A.P. Young and N. Kokciyan and I. Sassoon and S. Modgil and S. Parsons},
          series = {Frontiers in Artificial Intelligence and Applications},
            note = {cited By 1},
       booktitle = {Computational Models of Argument},
           title = {Instantiating metalevel argumentation frameworks},
       publisher = {IOS Press},
            year = {2018},
         journal = {Frontiers in Artificial Intelligence and Applications},
             doi = {10.3233/978-1-61499-906-5-97},
           pages = {97--108},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38407/},
        abstract = {We directly instantiate metalevel argumentation frameworks (MAFs) to enable argumentation-based reasoning about information relevant to various applications. The advantage of this is that information that typically cannot be incorporated via the instantiation of object-level argumentation frameworks can now be incorporated, in particular information referencing (1) preferences over arguments, (2) the rationale for attacks, and (3) the dialectical effect of critical questions that shifts the burden of proof when posed. We achieve this by using a variant of ASPIC+ and a higher-order typed language that can reference object-level formulae and arguments. We illustrate these representational advantages with a running example from clinical decision support.}
}

@article{lincoln37397,
          volume = {33},
          number = {6},
           month = {December},
          author = {F.J. Comin and C. M. Saaj},
            note = {cited By 0},
           title = {Models for slip estimation and soft terrain characterization with multilegged wheel-legs},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Transactions on Robotics},
             doi = {10.1109/TRO.2017.2723904},
           pages = {1438--1452},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37397/},
        abstract = {Successful operation of off-road mobile robots faces the challenge of mobility hazards posed by soft, deformable terrain, e.g., sand traps. The slip caused by these hazards has a significant impact on tractive efficiency, leading to complete immobilization in extreme circumstances. This paper addresses the interaction between dry frictional soil and the multilegged wheel-leg concept, with the aim of exploiting its enhanced mobility for safe, in situ terrain sensing. The influence of multiple legs and different foot designs on wheel-leg-soil interaction is analyzed by incorporating these aspects to an existing terradynamics model. In addition, new theoretical models are proposed and experimentally validated to relate wheel-leg slip to both motor torque and stick-slip vibrations. These models, which are capable of estimating wheel-leg slip from purely proprioceptive sensors, are then applied in combination with detected wheel-leg sinkage to successfully characterize the load bearing and shear strength properties of different types of deformable soil. The main contribution of this paper enables nongeometric hazard detection based on detected wheel-leg slip and sinkage.}
}

@article{lincoln33057,
          volume = {4},
          number = {1},
           month = {December},
          author = {Khaled Goher and Abdullah Almeshal and Saad Agouri and Ahmed Nasir and Osman Tokhi and Mohamed Alenizi and Talal Alzanki and Sulaiman Fadlallah},
            note = {This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.},
           title = {Hybrid spiral-dynamic bacteria-chemotaxis algorithm with application to control two-wheeled machines},
       publisher = {Springer},
            year = {2017},
         journal = {Robotics and Biomimetics},
             doi = {10.1186/s40638-017-0059-1},
           pages = {3},
        keywords = {ARRAY(0x5568f9c50260)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33057/},
        abstract = {This paper presents the implementation of the hybrid spiral-dynamic bacteria-chemotaxis (HSDBC) approach to control two different configurations of a two-wheeled vehicle. The HSDBC is a combination of bacterial chemotaxis used in bacterial forging algorithm (BFA) and the spiral-dynamic algorithm (SDA). BFA provides a good exploration strategy due to the chemotaxis approach. However, it endures an oscillation problem near the end of the search process when using a large step size. Conversely; for a small step size, it affords better exploitation and accuracy with slower convergence. SDA provides better stability when approaching an optimum point and has faster convergence speed. This may cause the search agents to get trapped into local optima which results in low accurate solution. HSDBC exploits the chemotactic strategy of BFA and fitness accuracy and convergence speed of SDA so as to overcome the problems associated with both the SDA and BFA algorithms alone. The HSDBC thus developed is evaluated in optimizing the performance and energy consumption of two highly nonlinear platforms, namely single and double inverted pendulum-like vehicles with an extended rod. Comparative results with BFA and SDA show that the proposed algorithm is able to result in better performance of the highly nonlinear systems.}
}

@article{lincoln27022,
          volume = {18},
          number = {12},
           month = {December},
          author = {Dongdong Wang and Xinwen Hou and Jiawei Xu and Shigang Yue and Cheng-Lin Liu},
           title = {Traffic sign detection using a cascade method with fast feature extraction and saliency test},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Transactions on Intelligent Transportation Systems},
             doi = {10.1109/tits.2017.2682181},
           pages = {3290--3302},
        keywords = {ARRAY(0x5568fbba4e88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27022/},
        abstract = {Automatic traffic sign detection is challenging due to the complexity of scene images, and fast detection is required in real applications such as driver assistance systems. In this paper, we propose a fast traffic sign detection method based on a cascade method with saliency test and neighboring scale awareness. In the cascade method, feature maps of several channels are extracted efficiently using approximation techniques. Sliding windows are pruned hierarchically using coarse-to-fine classifiers and the correlation between neighboring scales. The cascade system has only one free parameter, while the multiple thresholds are selected by a data-driven approach. To further increase speed, we also use a novel saliency test based on mid-level features to pre-prune background windows. Experiments on two public traffic sign data sets show that the proposed method achieves competing performance and runs 27 times as fast as most of the state-of-the-art methods.}
}

@article{lincoln28284,
          volume = {42},
          number = {4},
           month = {December},
          author = {Nina Dethlefs and Maarten Milders and Heriberto Cuay{\'a}huitl and Turkey Al-Salkini and Lorraine Douglas},
           title = {A natural language-based presentation of cognitive stimulation to people with dementia in assistive technology: a pilot study},
       publisher = {Taylor \& Francis: STM},
            year = {2017},
         journal = {Informatics for Health and Social Care},
             doi = {10.1080/17538157.2016.1255627},
           pages = {349--360},
        keywords = {ARRAY(0x5568fbb9d138)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28284/},
        abstract = {Currently, an estimated 36 million people worldwide are affected by Alzheimer?s disease or related dementias. In the absence of a cure, non-pharmacological interventions, such as cognitive stimulation, which slow down the rate of deterioration can benefit people with dementia and their caregivers. Such interventions have shown to improve well-being and slow down the rate of cognitive decline. It has further been shown that cognitive stimulation in interaction with a computer is as effective as with a human. However, the need to operate a computer often represents a difficulty for the elderly and stands in the way of widespread adoption. A possible solution to this obstacle is to provide a spoken natural language interface that allows people with dementia to interact with the cognitive stimulation software in the same way as they would interact with a human caregiver. This makes the assistive technology accessible to users regardless of their technical skills and provides a fully intuitive user experience. This article describes a pilot study that evaluated the feasibility of computer-based cognitive stimulation through a spoken natural language interface. Prototype software was evaluated with 23 users, including healthy elderly people and people with dementia. Feedback was overwhelmingly positive.}
}

@inproceedings{lincoln37349,
          volume = {694},
           month = {December},
          author = {Maria Teresa Lazaro and G. Grisetti and Luca Iocchi and Jaime Pulido Fentanes and Marc Hanheide},
       booktitle = {Iberian Robotics conference},
           title = {A Lightweight Navigation System for Mobile Robots},
             doi = {10.1007/978-3-319-70836-2\_25},
           pages = {295--306},
            year = {2017},
        keywords = {ARRAY(0x5568fbbae318)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37349/},
        abstract = {{\copyright} Springer International Publishing AG 2018. In this paper, we describe a navigation system requiring very few computational resources, but still providing performance comparable with commonly used tools in the ROS universe. This lightweight navigation system is thus suitable for robots with low computational resources and provides interfaces for both ROS and NAOqi middlewares. We have successfully evaluated the software on different robots and in different situations, including SoftBank Pepper robot for RoboCup@Home SSPL competitions and on small home-made robots for RoboCup@Home Education workshops. The developed software is well documented and easy to understand. It is released open-source and as Debian package to facilitate ease of use, in particular for the young researchers participating in robotic competitions and for educational activities.}
}

@inproceedings{lincoln29946,
       booktitle = {UK-RAS Conference on Robotics and Autonomous Systems},
           month = {December},
           title = {Active human detection with a mobile robot},
          author = {Mohamed Heshmat and Manuel Fernandez-Carmona and Zhi Yan and Nicola Bellotto},
            year = {2017},
        keywords = {ARRAY(0x5568fbb893f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29946/},
        abstract = {The problem of active human detection with a mobile robot equipped with an RGB-D camera is considered in this work. Traditional human detection algorithms for indoor mobile robots face several challenges, including occlusions due to cluttered dynamic environments, changing backgrounds, and large variety of human movements. Active human detection aims to improve classic detection systems by actively selecting new and potentially better observation points of the person. In this preliminary work, we present a system that actively guides a mobile robot towards high-confidence human detections, including initial simulation tests that highlight pros and cons of the proposed approach.}
}

@inproceedings{lincoln31053,
       booktitle = {UK-RAS Network Conference},
           month = {December},
           title = {Modelling and predicting rhythmic flow patterns in dynamic environments},
          author = {Sergi Molina Mellado and Grzegorz Cielniak and Tomas Krajnik and Tom Duckett},
            year = {2017},
        keywords = {ARRAY(0x5568fbafcf38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31053/},
        abstract = {In this paper, we introduce a time-dependent probabilistic map able to model and predict future flow patterns of people in indoor environments. The proposed representation models the likelihood of motion direction by a set of harmonic functions, which efficiently capture long-term (hours to months) variations of crowd movements over time, so from a robotics perspective, this model could be useful to add the predicted human behaviour into the control loop to influence the actions of the robot. Our approach is evaluated with data collected from a real environment and initial qualitative results are presented.}
}

@inproceedings{lincoln31547,
       booktitle = {UK-RAS Conference on Robotics and Autonomous Systems},
           month = {December},
           title = {Navigation testing for continuous integration in robotics},
          author = {Jaime Pulido Fentanes and Christian Dondrup and Marc Hanheide},
       publisher = {UK-RAS Conference on Robotics and Autonomous Systems (RAS 2017)},
            year = {2017},
        keywords = {ARRAY(0x5568fb9f4a90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31547/},
        abstract = {Robots working in real-world applications need to be robust and reliable. However, ensuring robust software in an academic development environment with dozens of developers poses a significant challenge. This work presents a testing framework, successfully employed in a large-scale integrated robotics project, based on continuous integration and the fork-and-pull model of software development, implementing automated system regression testing for robot navigation. It presents a framework suitable for both regression testing and also providing processes for parameter optimisation and benchmarking.}
}

@incollection{lincoln28879,
           month = {December},
          author = {Qinbing Fu and Shigang Yue},
            note = {{\copyright} 2017 IEEE},
       booktitle = {2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)},
           title = {Mimicking fly motion tracking and fixation behaviors with a hybrid visual neural network},
       publisher = {IEEE},
           pages = {1636--1641},
            year = {2017},
        keywords = {ARRAY(0x5568fb6d58b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28879/},
        abstract = {How do animals, e.g. insects, detect meaningful visual motion cues involving directional and locational information of moving objects in visual clutter accurately and efficiently? This open question has been very attractive for decades. In this paper, with respect to latest biological research progress made on motion detection circuitry, we conduct a novel hybrid visual neural network, combining the functionality of two bio-plausible, namely motion and position pathways explored in fly visual system, for mimicking the tracking and fixation behaviors. This modeling study extends a former direction selective neurons model to the higher level of behavior. The motivated algorithms can be used to guide a system that extracts location information on moving objects in a scene regardless of background clutter, using entirely low-level visual processing. We tested it against translational movements in synthetic and real-world scenes. The results demonstrated the following contributions: (1) Compared to conventional computer vision techniques, it turns out the computational simplicity of this model may benefit the utility in small robots for real time fixating. (2) The hybrid neural network structure fulfills the characteristics of a putative signal tuning map in physiology. (3) It also satisfies with a profound implication proposed by biologists: visual fixation behaviors could be simply tuned via only the position pathway; nevertheless, the motion-detecting pathway enhances the tracking precision.}
}

@article{lincoln29511,
          volume = {13},
          number = {2},
           month = {December},
          author = {Claire Keeble and Peter Adam Thwaites and Stuart Barber and Graham Richard Law and Paul David Baxter},
           title = {Adaptation of chain event graphs for use with case-Control studies in epidemiology},
       publisher = {De Gruyter},
            year = {2017},
         journal = {The International Journal of Biostatistics},
             doi = {10.1515/ijb-2016-0073},
        keywords = {ARRAY(0x5568fbb9c0f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29511/},
        abstract = {Case-control studies are used in epidemiology to try to uncover the causes of diseases, but are a retrospective study design known to suffer from non-participation and recall bias, which may explain their decreased popularity in recent years. Traditional analyses report usually only the odds ratio for given exposures and the binary disease status. Chain event graphs are a graphical representation of a statistical model derived from event trees which have been developed in artificial intelligence and statistics, and only recently introduced to the epidemiology literature. They are a modern Bayesian technique which enable prior knowledge to be incorporated into the data analysis using the agglomerative hierarchical clustering algorithm, used to form a suitable chain event graph. Additionally, they can account for missing data and be used to explore missingness mechanisms. Here we adapt the chain event graph framework to suit scenarios often encountered in case-control studies, to strengthen this study design which is time and financially efficient. We demonstrate eight adaptations to the graphs, which consist of two suitable for full case-control study analysis, four which can be used in interim analyses to explore biases, and two which aim to improve the ease and accuracy of analyses. The adaptations are illustrated with complete, reproducible, fully-interpreted examples, including the event tree and chain event graph. Chain event graphs are used here for the first time to summarise non-participation, data collection techniques, data reliability, and disease severity in case-control studies. We demonstrate how these features of a case-control study can be incorporated into the analysis to provide further insight, which can help to identify potential biases and lead to more accurate study results.}
}

@article{lincoln26734,
          volume = {36},
          number = {13-14},
           month = {December},
          author = {Guilherme Maeda and Marco Ewerton and Gerhard Neumann and Rudolf Lioutikov and Jan Peters},
           title = {Phase estimation for fast action recognition and trajectory generation in human?robot collaboration},
       publisher = {SAGE},
            year = {2017},
         journal = {The International Journal of Robotics Research},
             doi = {10.1177/0278364917693927},
           pages = {1579--1594},
        keywords = {ARRAY(0x5568fbb85930)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26734/},
        abstract = {This paper proposes a method to achieve fast and fluid human?robot interaction by estimating the progress of the movement of the human. The method allows the progress, also referred to as the phase of the movement, to be estimated even when observations of the human are partial and occluded; a problem typically found when using motion capture systems in cluttered environments. By leveraging on the framework of Interaction Probabilistic Movement Primitives, phase estimation makes it possible to classify the human action, and to generate a corresponding robot trajectory before the human finishes his/her movement. The method is therefore suited for semi-autonomous robots acting as assistants and coworkers. Since observations may be sparse, our method is based on computing the probability of different phase candidates to find the phase that best aligns the Interaction Probabilistic Movement Primitives with the current observations. The method is fundamentally different from approaches based on Dynamic Time Warping that must rely on a consistent stream of measurements at runtime. The resulting framework can achieve phase estimation, action recognition and robot trajectory coordination using a single probabilistic representation. We evaluated the method using a seven-degree-of-freedom lightweight robot arm equipped with a five-finger hand in single and multi-task collaborative experiments. We compare the accuracy achieved by phase estimation with our previous method based on dynamic time warping.}
}

@article{lincoln30636,
          volume = {18},
          number = {136},
           month = {December},
          author = {Christian Wirth and Riad Akrour and Gerhard Neumann and Johannes F{\"u}rnkranz},
           title = {A survey of preference-based reinforcement learning methods},
       publisher = {Journal of Machine Learning Research / Massachusetts Institute of Technology Press (MIT Press) / Microtome},
            year = {2017},
         journal = {Journal of Machine Learning Research},
           pages = {1--46},
        keywords = {ARRAY(0x5568fbb024f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30636/},
        abstract = {Reinforcement learning (RL) techniques optimize the accumulated long-term reward of a suitably chosen reward function. However, designing such a reward function often requires a lot of task- specific prior knowledge. The designer needs to consider different objectives that do not only influence the learned behavior but also the learning progress. To alleviate these issues, preference-based reinforcement learning algorithms (PbRL) have been proposed that can directly learn from an expert's preferences instead of a hand-designed numeric reward. PbRL has gained traction in recent years due to its ability to resolve the reward shaping problem, its ability to learn from non numeric rewards and the possibility to reduce the dependence on expert knowledge. We provide a unified framework for PbRL that describes the task formally and points out the different design principles that affect the evaluation task for the human as well as the computational complexity. The design principles include the type of feedback that is assumed, the representation that is learned to capture the preferences, the optimization problem that has to be solved as well as how the exploration/exploitation problem is tackled. Furthermore, we point out shortcomings of current algorithms, propose open research questions and briefly survey practical tasks that have been solved using PbRL.}
}

@article{lincoln24936,
          volume = {28},
          number = {11},
           month = {November},
          author = {Bin Hu and Shigang Yue and Zhuhong Zhang},
           title = {A rotational motion perception neural network based on asymmetric spatiotemporal visual information processing},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
             doi = {10.1109/TNNLS.2016.2592969},
           pages = {2803--2821},
        keywords = {ARRAY(0x5568fbb6d978)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24936/},
        abstract = {All complex motion patterns can be decomposed into several elements, including translation, expansion/contraction, and rotational motion. In biological vision systems, scientists have found that specific types of visual neurons have specific preferences to each of the three motion elements. There are computational models on translation and expansion/contraction perceptions; however, little has been done in the past to create computational models for rotational motion perception. To fill this gap, we proposed a neural network that utilizes a specific spatiotemporal arrangement of asymmetric lateral inhibited direction selective neural networks (DSNNs) for rotational motion perception. The proposed neural network consists of two parts-presynaptic and postsynaptic parts. In the presynaptic part, there are a number of lateral inhibited DSNNs to extract directional visual cues. In the postsynaptic part, similar to the arrangement of the directional columns in the cerebral cortex, these direction selective neurons are arranged in a cyclic order to perceive rotational motion cues. In the postsynaptic network, the delayed excitation from each direction selective neuron is multiplied by the gathered excitation from this neuron and its unilateral counterparts depending on which rotation, clockwise (cw) or counter-cw (ccw), to perceive. Systematic experiments under various conditions and settings have been carried out and validated the robustness and reliability of the proposed neural network in detecting cw or ccw rotational motion. This research is a critical step further toward dynamic visual information processing.}
}

@article{lincoln46152,
          volume = {13},
          number = {1},
           month = {November},
          author = {Marcello Calisti and Cecilia Laschi},
           title = {Morphological and control criteria for self-stable underwater hopping},
            year = {2017},
         journal = {Bioinspiration \& Biomimetics},
             doi = {10.1088/1748-3190/aa90f6},
           pages = {016001},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46152/},
        abstract = {This paper presents the self-stabilisation features of a hopping gait during underwater legged locomotion. We used a bio-inspired fundamental model of this gait, the underwater spring-loaded inverted pendulum model, to numerically derive quantitative (dimension of the basin of attraction, Floquet multipliers, mean horizontal speed) and qualitative (shape of the basin) features which characterise the self-stability of the system. Furthermore, we compared the results obtained with a terrestrial self-stable running model (i.e. the spring-loaded inverted pendulum with swing-leg retraction) to highlight the role of water-related components in relation to dynamic legged locomotion. The analysis revealed fundamental morphological and actuation parameters that could be used to design self-stabilising underwater hopping machines, as well as elucidating their role with respect to stability and speed. Underwater hopping is a simple and reliable locomotion, as it does not require complex control feedback to reject significant disturbances. Thanks to its high self-stabilising property, underwater hopping appears to be a reliable alternative locomotion for underwater robots}
}

@incollection{lincoln39232,
           month = {November},
          author = {Claus G. S{\o}rensen and Efthymios Rodias and Dionysis Bochtis},
       booktitle = {Precision Agriculture: Technology and Economic Perspectives},
           title = {Auto-Steering and Controlled Traffic Farming ? Route Planning and Economics},
       publisher = {Springer},
             doi = {doi:10.1007/978-3-319-68715-5\_6},
           pages = {129--145},
            year = {2017},
        keywords = {ARRAY(0x5568fba44448)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39232/},
        abstract = {Agriculture nowadays includes automation systems that contribute significantly to many levels of the food production process. Such systems include GPS based systems like auto-steering and Controlled Traffic Farming (CTF). These systems have led to many innovations in agricultural field area coverage design. Integrating these advancements, two different route planning designs, a traditional and an optimised one, are outlined and explained in this chapter. Four different machinery scenarios were tested in four fields each, and the main aim was to compare the two different route planning systems under economic criteria and identify the best operational route coverage design criterion. The results show that there are significant reductions in operational costs varying from 9 to 20\%, depending on the specific machinery and field configurations. Such results show the considerable potential of advanced route planning designs and further optimization measures. They indicate the need for research efforts that quantify the operational and economic benefits by optimising field coverage designs in the headlands, turnings or obstacles avoidance according to the actual configuration to minimize the non-working activities and, as a consequence, the overall operational cost.}
}

@inproceedings{lincoln29060,
       booktitle = {IEEE RAS International Conference on Humanoid Robots},
           month = {November},
           title = {Deep reinforcement learning for conversational robots playing games},
          author = {Heriberto Cuayahuitl},
       publisher = {IEEE},
            year = {2017},
        keywords = {ARRAY(0x5568fb9f9470)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29060/},
        abstract = {Deep reinforcement learning for interactive multimodal robots is attractive for endowing machines with trainable skill acquisition. But this form of learning still represents several challenges. The challenge that we focus in this paper is effective policy learning. To address that, in this paper we compare the Deep Q-Networks (DQN) method against a variant that aims for stronger decisions than the original method by avoiding decisions with the lowest negative rewards. We evaluated our baseline and proposed algorithms in agents playing the game of Noughts and Crosses with two grid sizes (3x3 and 5x5). Experimental results show evidence that our proposed method can lead to more effective policies than the baseline DQN method, which can be used for training interactive social robots.}
}

@article{lincoln26599,
          volume = {186},
          number = {10},
           month = {November},
          author = {C. Keeble and P. A. Thwaites and P. D. Baxter and S. Barber and R. C. Parslow and G. R. Law},
           title = {Learning Through Chain Event Graphs: The Role of Maternal Factors in Childhood Type 1 Diabetes},
       publisher = {Oxford University Press},
            year = {2017},
         journal = {American Journal of Epidemiology},
             doi = {10.1093/aje/kwx171},
           pages = {1204--1208},
        keywords = {ARRAY(0x5568fbb9c210)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26599/},
        abstract = {Chain event graphs (CEGs) are a graphical representation of a statistical model derived from event trees. They have previously been applied to cohort studies but not to case-control studies. In this paper, we apply the CEG framework to a Yorkshire, United Kingdom, case-control study of childhood type 1 diabetes (1993?1994) in order to examine 4 exposure variables associated with the mother, 3 of which are fully observed (her school-leaving-age, amniocenteses during pregnancy, and delivery type) and 1 with missing values (her rhesus factor), while incorporating previous type 1 diabetes knowledge. We conclude that the unknown rhesus factor values were likely to be missing not at random and were mainly rhesus-positive. The mother?s school-leaving-age and rhesus factor were not associated with the diabetes status of the child, whereas having at least 1 amniocentesis procedure and, to a lesser extent, birth by cesarean delivery were associated; the combination of both procedures further increased the probability of diabetes. This application of CEGs to case-control data allows for the inclusion of missing data and prior knowledge, while investigating associations in the data. Communication of the analysis with the clinical expert is more straightforward than with traditional modeling, and this approach can be applied retrospectively or when assumptions for traditional analyses are not held.}
}

@inproceedings{lincoln30193,
           month = {November},
          author = {Emmanuel Senft and Severin Lemaignan and Paul Baxter and Tony Belpaeme},
       booktitle = {4th AAAI FSS on Artificial Intelligence for Social Human-Robot Interaction (AI-HRI)},
         address = {Arlington, Virginia, U.S.A.},
           title = {Toward supervised reinforcement learning with partial states for social HRI},
       publisher = {AAAI Press},
           pages = {109--113},
            year = {2017},
        keywords = {ARRAY(0x5568fbb75108)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30193/},
        abstract = {Social interacting is a complex task for which machine learning holds particular promise. However, as no sufficiently accurate simulator of human interactions exists today, the learning of social interaction strategies has to happen online in the real world. Actions executed by the robot impact on humans, and as such have to be carefully selected, making it impossible to rely on random exploration. Additionally, no clear reward function exists for social interactions. This implies that traditional approaches used for Reinforcement Learning cannot be directly applied for learning how to interact with the social world. As such we argue that robots will profit from human expertise and guidance to learn social interactions. However, as the quantity of input a human can provide is limited, new methods have to be designed to use human input more efficiently. In this paper we describe a setup in which we combine a framework called Supervised Progressively Autonomous Robot Competencies (SPARC), which allows safer online learning with Reinforcement Learning, with the use of partial states rather than full states to accelerate generalisation and obtain a usable action policy more quickly.}
}

@article{lincoln27782,
          volume = {34},
          number = {8},
           month = {November},
          author = {Keerthy Kusumam and Tomas Krajnik and Simon Pearson and Tom Duckett and Grzegorz Cielniak},
           title = {3D-vision based detection, localization, and sizing of broccoli heads in the field},
       publisher = {Wiley Periodicals, Inc.},
            year = {2017},
         journal = {Journal of Field Robotics},
             doi = {10.1002/rob.21726},
           pages = {1505--1518},
        keywords = {ARRAY(0x5568fb67e288)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27782/},
        abstract = {This paper describes a 3D vision system for robotic harvesting of broccoli using low-cost RGB-D sensors, which was developed and evaluated using sensory data collected under real-world field conditions in both the UK and Spain. The presented method addresses the tasks of detecting mature broccoli heads in the field and providing their 3D locations relative to the vehicle. The paper evaluates different 3D features, machine learning, and temporal filtering methods for detection of broccoli heads. Our experiments show that a combination of Viewpoint Feature Histograms, Support Vector Machine classifier, and a temporal filter to track the detected heads results in a system that detects broccoli heads with high precision. We also show that the temporal filtering can be used to generate a 3D map of the broccoli head positions in the field. Additionally, we present methods for automatically estimating the size of the broccoli heads, to determine when a head is ready for harvest. All of the methods were evaluated using ground-truth data from both the UK and Spain, which we also make available to the research community for subsequent algorithm development and result comparison. Cross-validation of the system trained on the UK dataset on the Spanish dataset, and vice versa, indicated good generalization capabilities of the system, confirming the strong potential of low-cost 3D imaging for commercial broccoli harvesting.}
}

@article{lincoln26857,
          volume = {99},
           month = {November},
          author = {Emmanuel Senft and Paul Baxter and James Kennedy and Severin Lemaignan and Tony Belpaeme},
           title = {Supervised autonomy for online learning in human-robot interaction},
       publisher = {Elsevier / North Holland for International Association for Pattern Recognition},
            year = {2017},
         journal = {Pattern Recognition Letters},
             doi = {10.1016/j.patrec.2017.03.015},
           pages = {77--86},
        keywords = {ARRAY(0x5568fba0d328)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26857/},
        abstract = {When a robot is learning it needs to explore its environment and how its environment responds on its
actions. When the environment is large and there are a large number of possible actions the robot can
take, this exploration phase can take prohibitively long. However, exploration can often be optimised
by letting a human expert guide the robot during its learning. Interactive machine learning, in which a
human user interactively guides the robot as it learns, has been shown to be an effective way to teach a
robot. It requires an intuitive control mechanism to allow the human expert to provide feedback on
the robot?s progress. This paper presents a novel method which combines Reinforcement Learning
and Supervised Progressively Autonomous Robot Competencies (SPARC). By allowing the user to
fully control the robot and by treating rewards as implicit, SPARC aims to learn an action policy
while maintaining human supervisory oversight of the robot?s behaviour. This method is evaluated and
compared to Interactive Reinforcement Learning in a robot teaching task. Qualitative and quantitative
results indicate that SPARC allows for safer and faster learning by the robot, whilst not placing a high
workload on the human teacher.}
}

@unpublished{lincoln39630,
       booktitle = {29th Conference of the International Society for Medical Innovation and Technology},
           month = {November},
           title = {From concept to design: A new flexible robotic uterine elevator},
          author = {Chakravarthini M. Saaj and Seri Mustaza and Kavitha Madhuri},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39630/}
}

@article{lincoln39222,
          volume = {9},
          number = {11},
           month = {October},
          author = {Efthymios Rodias and Remigio Berruto and Patrizia Busato and Dionysis Bochtis and Claus S{\o}rensen and Kun Zhou},
           title = {Energy Savings from Optimised In-Field Route Planning for Agricultural Machinery},
            year = {2017},
         journal = {Sustainability},
             doi = {10.3390/su9111956},
           pages = {1956},
        keywords = {ARRAY(0x5568fba801b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39222/},
        abstract = {Various types of sensors technologies, such as machine vision and global positioning system (GPS) have been implemented in navigation of agricultural vehicles. Automated navigation systems have proved the potential for the execution of optimised route plans for field area coverage. This paper presents an assessment of the reduction of the energy requirements derived from the implementation of optimised field area coverage planning. The assessment regards the analysis of the energy requirements and the comparison between the non-optimised and optimised plans for field area coverage in the whole sequence of operations required in two different cropping systems: Miscanthus and Switchgrass production. An algorithmic approach for the simulation of the executed field operations by following both non-optimised and optimised field-work patterns was developed. As a result, the corresponding time requirements were estimated as the basis of the subsequent energy cost analysis. Based on the results, the optimised routes reduce the fuel energy consumption up to 8\%, the embodied energy consumption up to 7\%, and the total energy consumption from 3\% up to 8\%}
}

@inproceedings{lincoln46159,
       booktitle = {OCEANS 2017 - Aberdeen},
           month = {October},
           title = {A rotating polarizing filter approach for image enhancement},
          author = {Marcello Calisti and Gaetano Carbonara and Cecilia Laschi},
            year = {2017},
           pages = {1--4},
             doi = {10.1109/OCEANSE.2017.8084722},
        keywords = {ARRAY(0x5568fbba0f88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46159/},
        abstract = {This paper presents a polarization-based enhancing system consisting of a rotating polarizing filter and an image fusion algorithm. A prototype was developed and tested in different light conditions, from early morning to late afternoon, and recordings of underwater scenes were taken in a sea stretch of the Mediterranean sea. Several images within the polarization range of 0? to 180? were used in an image fusion algorithm to obtain a restored image. With respect to common image quality measure metrics, our approach has similar performance of previous systems. Conversely to current solutions, our approach benefits from the light selection properties of polarizing filters, without assumptions on the polarization angle, meanwhile it provides a generic implementation which could be easily adapted to existing cameras.}
}

@article{lincoln25279,
          volume = {9},
          number = {3},
           month = {September},
          author = {Cheng Hu and Farshad Arvin and Caihua Xiong and Shigang Yue},
           title = {A bio-inspired embedded vision system for autonomous micro-robots: the LGMD case},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Transactions on Cognitive and Developmental Systems},
             doi = {10.1109/TCDS.2016.2574624},
           pages = {241--254},
        keywords = {ARRAY(0x5568fbb54f60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25279/},
        abstract = {In this paper, we present a new bio-inspired vision system embedded for micro-robots. The vision system takes inspiration from locusts in detecting fast approaching objects. Neurophysiological research suggested that locusts use a wide-field visual neuron called lobula giant movement detector (LGMD) to respond to imminent collisions. In this work, we present the implementation of the selected neuron model by a low-cost ARM processor as part of a composite vision module. As the first embedded LGMD vision module fits to a micro-robot, the developed system performs all image acquisition and processing independently. The vision module is placed on top of a microrobot to initiate obstacle avoidance behaviour autonomously. Both simulation and real-world experiments were carried out to test the reliability and robustness of the vision system. The results of the experiments with different scenarios demonstrated the potential of the bio-inspired vision system as a low-cost embedded module for autonomous robots.}
}

@inproceedings{lincoln27675,
       booktitle = {IEEE/RSJ International Conference on Itelligent Robots and Systems (IROS)},
           month = {September},
           title = {Online learning for human classification in 3D LiDAR-based tracking},
          author = {Zhi Yan and Tom Duckett and Nicola Bellotto},
       publisher = {IEEE},
            year = {2017},
             doi = {10.1109/IROS.2017.8202247},
        keywords = {ARRAY(0x5568fbb49820)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27675/},
        abstract = {Human detection and tracking is one of the most important aspects to be considered in service robotics, as the robot often shares its workspace and interacts closely with humans. This paper presents an online learning framework for human classification in 3D LiDAR scans, taking advantage of robust multi-target tracking to avoid the need for data annotation by a human expert. The system learns iteratively by retraining a classifier online with the samples collected by the robot over time. A novel aspect of our approach is that errors in training data can be corrected using the information provided by the 3D LiDAR-based tracking. In order to do this, an efficient 3D cluster detector of potential human targets has been implemented. We evaluate the framework using a new 3D LiDAR dataset of people moving in a large indoor public space, which is made available to the research community. The experiments analyse the real-time performance of the cluster detector and show that our online-trained human classifier matches and in some cases outperforms its offline version.}
}

@inproceedings{lincoln28481,
       booktitle = {International Conference on Intelligent Robots and Systems (IROS)},
           month = {September},
           title = {Semantic-assisted 3D Normal Distributions Transform for scan registration in environments with limited structure},
          author = {Anestis Zaganidis and Martin Magnusson and Tom Duckett and Grzegorz Cielniak},
       publisher = {IEEE/RSJ},
            year = {2017},
        keywords = {ARRAY(0x5568fbab58e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28481/},
        abstract = {Point cloud registration is a core problem of many robotic applications, including simultaneous localization and mapping. The Normal Distributions Transform (NDT) is a method that fits a number of Gaussian distributions to the data points, and then uses this transform as an approximation of the real data, registering a relatively small number of distributions as opposed to the full point cloud. This approach contributes to NDT?s registration robustness and speed but leaves room for improvement in environments of limited structure. 
To address this limitation we propose a method for the introduction of semantic information extracted from the point clouds into the registration process. The paper presents a large scale experimental evaluation of the algorithm against NDT on two publicly available benchmark data sets. For the purpose of this test a measure of smoothness is used for the semantic partitioning of the point clouds. The results indicate that the proposed method improves the accuracy, robustness and speed of NDT registration, especially in unstructured environments, making NDT suitable for a wider range of applications.}
}

@article{lincoln27834,
           month = {September},
          author = {Qinbing Fu and Cheng Hu and Tian liu and Shigang Yue},
            note = {{\copyright} 2017 IEEE},
       booktitle = {2017 IEEE/RSJ International Conference on Intelligent Robots and Systems},
           title = {Collision selective LGMDs neuron models research benefits from a vision-based autonomous micro robot},
       publisher = {IEEE},
            year = {2017},
         journal = {2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
             doi = {10.1109/IROS.2017.8206254},
           pages = {3996--4002},
        keywords = {ARRAY(0x5568fbb37818)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27834/},
        abstract = {The developments of robotics inform research across a broad range of disciplines. In this paper, we will study and compare two collision selective neuron models via a vision-based autonomous micro robot. In the locusts' visual brain, two Lobula Giant Movement Detectors (LGMDs), i.e. LGMD1 and LGMD2, have been identified as looming sensitive neurons responding to rapidly expanding objects, yet with different collision selectivity. Both neurons have been built for perceiving potential collisions in an efficient and reliable manner; a few modeling works have also demonstrated their effectiveness for robotic implementations. In this research, for the first time, we set up binocular neuronal models, combining the functionalities of LGMD1 and LGMD2 neurons, in the visual modality of a ground mobile robot. The results of systematic on-line experiments demonstrated three contributions: (1) The arena tests involving multiple robots verified the robustness and efficiency of a reactive motion control strategy via integrating a bilateral pair of LGMD1 and LGMD2 models for collision detection in dynamic scenarios. (2) We pinpointed the different collision selectivity between LGMD1 and LGMD2 neuron models fulfilling corresponded biological research results. (3) The low-cost robot may also shed lights on similar bio-inspired embedded vision systems and swarm robotics applications.}
}

@inproceedings{lincoln28257,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {September},
           title = {Hybrid control trajectory optimization under uncertainty},
          author = {J. Pajarinen and V. Kyrki and M. Koval and S Srinivasa and J. Peters and G. Neumann},
            year = {2017},
        keywords = {ARRAY(0x5568fbad80b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28257/},
        abstract = {Trajectory optimization is a fundamental problem in robotics. While optimization of continuous control trajectories is well developed, many applications require both discrete and continuous, i.e. hybrid controls. Finding an optimal sequence of hybrid controls is challenging due to the exponential explosion of discrete control combinations. Our method, based on Differential Dynamic Programming (DDP), circumvents this problem by incorporating discrete actions inside DDP: we first optimize continuous mixtures of discrete actions, and, subsequently force the mixtures into fully discrete actions. Moreover, we show how our approach can be extended to partially observable Markov decision processes (POMDPs) for trajectory planning under uncertainty. We validate the approach in a car driving problem where the robot has to switch discrete gears and in a box pushing application where the robot can switch the side of the box to push. The pose and the friction parameters of the pushed box are initially unknown and only indirectly observable.}
}

@article{lincoln33039,
          volume = {4},
          number = {5},
           month = {September},
          author = {Khaled Goher and Nazanin Mansouri and Fadlallah Sulaiman},
            note = {This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.},
           title = {Assessment of personal care and medical robots from older adults? perspective},
       publisher = {Springer},
            year = {2017},
         journal = {Robotics and Biomimetics},
             doi = {10.1186/s40638-017-0061-7},
        keywords = {ARRAY(0x5568fba6da00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33039/},
        abstract = {Demographic reports indicate that population of older adults is growing significantly over the world and in particular in developed nations. Consequently, there are a noticeable number of demands for certain services such as health-care systems and assistive medical robots and devices. In today?s world, different types of robots play substantial roles specifically in medical sector to facilitate human life, especially older adults. Assistive medical robots and devices are created in various designs to fulfill specific needs of older adults. Though medical robots are utilized widely by senior citizens, it is dramatic to find out into what extent assistive robots satisfy their needs and expectations. This paper reviews various assessments of assistive medical robots from older adults? perspectives with the purpose of identifying senior citizen?s needs, expectations, and preferences. On the other hand, these kinds of assessments inform robot designers, developers, and programmers to come up with robots fulfilling elderly?s needs while improving their life quality.}
}

@inproceedings{lincoln31052,
       booktitle = {Student Conference on Planning in Artificial Intelligence and Robotics (PAIR)},
           month = {September},
           title = {Spatiotemporal models for motion planning in human populated environments},
          author = {Tomas Vintr and Sergi Molina Mellado and Grzegorz Cielniak and Tom Duckett and Tomas Krajnik},
       publisher = {Czech Technical University in Prague, Faculty of Electrical Engineering},
            year = {2017},
        keywords = {ARRAY(0x5568fb67bc40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31052/},
        abstract = {In this paper we present an effective spatio-temporal model for motion planning computed using a novel representation known as the temporary warp space-hypertime continuum. Such a model is suitable for robots that are expected to be helpful to humans in their natural environments. This method allows to capture natural periodicities of human behavior by adding additional time dimensions. The model created thus represents the temporal structure of the human habits within a given space and can be analyzed using regular analytical methods. We visualize the results on a real-world dataset using heatmaps.}
}

@article{lincoln40526,
          volume = {24},
          number = {3},
           month = {September},
          author = {Nick Hawes and Christopher Burbridge and Ferdian Jovan and Lars Kunze and Bruno Lacerda and Lenka Mudrova and Jay Young and Jeremy Wyatt and Denise Hebesberger and Tobias Kortner and Rares Ambrus and Nils Bore and John Folkesson and Patric Jensfelt and Lucas Beyer and Alexander Hermans and Bastian Leibe and Aitor Aldoma and Thomas Faulhammer and Michael Zillich and Markus Vincze and Eris Chinellato and Muhannad Al-Omari and Paul Duckworth and Yiannis Gatsoulis and David C. Hogg and Anthony G. Cohn and Christian Dondrup and Jaime Pulido Fentanes and Tomas Krajnik and Joao M. Santos and Tom Duckett and Marc Hanheide},
           title = {The STRANDS Project: Long-Term Autonomy in Everyday Environments},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Robotics \& Automation Magazine},
             doi = {10.1109/MRA.2016.2636359},
           pages = {146--156},
        keywords = {ARRAY(0x5568fb6709a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40526/},
        abstract = {Thanks to the efforts of the robotics and autonomous systems community, the myriad applications and capacities of robots are ever increasing. There is increasing demand from end users for autonomous service robots that can operate in real environments for extended periods. In the Spatiotemporal Representations and Activities for Cognitive Control in Long-Term Scenarios (STRANDS) project (http://strandsproject.eu), we are tackling this demand head-on by integrating state-of-the-art artificial intelligence and robotics research into mobile service robots and deploying these systems for long-term installations in security and care environments. Our robots have been operational for a combined duration of 104 days over four deployments, autonomously performing end-user-defined tasks and traversing 116 km in the process. In this article, we describe the approach we used to enable long-term autonomous operation in everyday environments and how our robots are able to use their long run times to improve their own performance.}
}

@article{lincoln29678,
          volume = {17},
          number = {3},
           month = {September},
          author = {Peter Lightbody and Marc Hanheide and Tomas Krajnik},
            note = {Copyright is held by the authors. This work is based on an earlier work: SAC?17 Proceedings of the 2017 ACM Symposium on Applied Computing, Copyright 2017 ACM 978-1-4503-4486-9. http://dx.doi.org/10. 1145/3019612.3019709},
           title = {An efficient visual fiducial localisation system},
       publisher = {ACM},
            year = {2017},
         journal = {Applied Computing Review},
             doi = {10.1145/3161534.3161537},
           pages = {28--37},
        keywords = {ARRAY(0x5568fba2a820)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29678/},
        abstract = {With use cases that range from external localisation of single robots or robotic swarms to self-localisation in marker-augmented environments and simplifying perception by tagging objects in a robot's surrounding, fiducial markers have a wide field of application in the robotic world.
We propose a new family of circular markers which allow for both computationally efficient detection, tracking and identification and full 6D position estimation.
At the core of the proposed approach lies the separation of the detection and identification steps, with the former using computationally efficient circular marker detection and the latter utilising an open-ended `necklace encoding', allowing scalability to a large number of individual markers.
While the proposed algorithm achieves similar accuracy to other state-of-the-art methods, its experimental evaluation in realistic conditions demonstrates that it can detect markers from larger distances while being up to two orders of magnitude faster than other state-of-the-art fiducial marker detection methods. In addition, the entire system is available as an open-source package at {$\backslash$}url\{https://github.com/LCAS/whycon\}.}
}

@inproceedings{lincoln43301,
           month = {September},
           title = {The Pi-puck extension board:
a Raspberry Pi interface for the e-puck robot platform},
          author = {Alan Millard and Russel Joyce and James A. Hilder and Cristian Fleseriu and Leonard Newbrook and Wei Li and Liam J. McDaid and Halliday David M.},
       publisher = {IEEE},
            year = {2017},
             doi = {10.1109/IROS.2017.8202233},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43301/},
        abstract = {This paper presents the Pi-puck extension board ? an interface between the e-puck robot platform and a Raspberry Pi single-board computer that enhances the processing power, memory capacity, and networking capabilities of the robot at a low cost. It allows high-level control algorithms, wireless communication, and computationally expensive operations such as real-time image processing to be handled by a Raspberry Pi, while the e-puck?s microcontroller deals with low-level motor control and sensor interfacing. Although two similar extension boards for the e-puck robot platform already exist, they are now out-dated and expensive in comparison. Our open-source hardware design and supporting software infrastructure offer an inexpensive upgrade to the e-puck robot, transforming it into the Pi-puck ? a modern and flexible new platform for mobile robotics research.}
}

@article{lincoln26196,
          volume = {33},
          number = {4},
           month = {August},
          author = {Tomas Krajnik and Jaime Pulido Fentanes and Joao Santos and Tom Duckett},
           title = {FreMEn: Frequency map enhancement for long-term mobile robot autonomy in changing environments},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Transactions on Robotics},
             doi = {10.1109/TRO.2017.2665664},
           pages = {964--977},
        keywords = {ARRAY(0x5568fbb7b0c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26196/},
        abstract = {We present a new approach to long-term mobile robot mapping in dynamic indoor environments. Unlike traditional world models that are tailored to represent static scenes, our approach explicitly models environmental dynamics. We assume that some of the hidden processes that influence the dynamic environment states are periodic and model the uncertainty of the estimated state variables by their frequency spectra. The spectral model can represent arbitrary timescales of environment dynamics with low memory requirements. Transformation of the spectral model to the time domain allows for the prediction of the future environment states, which improves the robot's long-term performance in dynamic environments. Experiments performed over time periods of months to years demonstrate that the approach can efficiently represent large numbers of observations and reliably predict future environment states. The experiments indicate that the model's predictive capabilities improve mobile robot localisation and navigation in changing environments.}
}

@article{lincoln28020,
          volume = {18},
          number = {73},
           month = {August},
          author = {Herke van Hoof and Gerhard Neumann and Jan Peters},
           title = {Non-parametric policy search with limited information loss},
       publisher = {Journal of Machine Learning Research},
            year = {2017},
         journal = {Journal of Machine Learning Research},
           pages = {1--46},
        keywords = {ARRAY(0x5568fbba6468)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28020/},
        abstract = {Learning complex control policies from non-linear and redundant sensory input is an important challenge for reinforcement learning algorithms. Non-parametric methods that approximate values functions or transition models can address this problem, by adapting to the complexity of the dataset. Yet, many current non-parametric approaches rely on
unstable greedy maximization of approximate value functions, which might lead to poor convergence or oscillations in the policy update. A more robust policy update can be obtained by limiting the information loss between successive state-action distributions. In this paper, we develop a policy search algorithm with policy updates that are both robust and non-parametric. Our method can learn non-parametric control policies for infinite horizon continuous Markov decision processes with non-linear and redundant sensory representations. We investigate how we can use approximations of the kernel function to reduce the time requirements of the demanding non-parametric computations. In our experiments, we show the strong performance of the proposed method, and how it can be approximated efficiently. Finally, we show that our algorithm can learn a real-robot underpowered swing-up task directly from image data.}
}

@inproceedings{lincoln27676,
       booktitle = {International Conference of the Speech Communication Association (INTERSPEECH)},
           month = {August},
           title = {Deep reinforcement learning of dialogue policies with less weight updates},
          author = {Heriberto Cuayahuitl and Seunghak Yu},
            year = {2017},
        keywords = {ARRAY(0x5568fb9b9c28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27676/},
        abstract = {Deep reinforcement learning dialogue systems are attractive because they can jointly learn their feature representations and policies without manual feature engineering. But its application is challenging due to slow learning. We propose a two-stage method for accelerating the induction of single or multi-domain dialogue policies. While the first stage reduces the amount of weight updates over time, the second stage uses very limited minibatches (of as much as two learning experiences) sampled from experience replay memories. The former frequently updates the weights of the neural nets at early stages of training, and decreases the amount of updates as training progresses by performing updates during exploration and by skipping updates during exploitation. The learning process is thus accelerated
through less weight updates in both stages. An empirical evaluation in three domains (restaurants, hotels and tv guide) confirms that the proposed method trains policies 5 times faster than a baseline without the proposed method. Our findings are useful for training larger-scale neural-based spoken dialogue systems.}
}

@inproceedings{lincoln28141,
       booktitle = {International Joint Conference on Artificial Intelligence (IJCAI)},
           month = {August},
           title = {Contextual CMA-ES},
          author = {A. Abdolmaleki and B. Price and N. Lau and P. Reis and G. Neumann},
            year = {2017},
        keywords = {ARRAY(0x5568fb9b96b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28141/},
        abstract = {Many stochastic search algorithms are designed to optimize a fixed objective function to learn a task, i.e., if the objective function changes slightly, for example, due to a change in the situation or context of the task, relearning is required to adapt to the new context. For instance, if we want to learn a kicking movement for a soccer robot, we have to relearn the movement for different ball locations. Such relearning is undesired as it is highly inefficient and many applications require a fast adaptation to a new context/situation. Therefore, we investigate contextual stochastic search algorithms
that can learn multiple, similar tasks simultaneously. Current contextual stochastic search methods are based on policy search algorithms and suffer from premature convergence and the need for parameter tuning. In this paper, we extend the well known CMA-ES algorithm to the contextual setting and illustrate its performance on several contextual
tasks. Our new algorithm, called contextual CMAES, leverages from contextual learning while it preserves all the features of standard CMA-ES such as stability, avoidance of premature convergence, step size control and a minimal amount of parameter tuning.}
}

@article{lincoln32031,
          volume = {140},
           month = {August},
          author = {Adam Binch and Charles Fox},
           title = {Controlled comparison of machine vision algorithms for Rumex and Urtica detection in grassland},
       publisher = {Elsevier},
            year = {2017},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2017.05.018},
           pages = {123--138},
        keywords = {ARRAY(0x5568fbb66f10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32031/},
        abstract = {Automated robotic weeding of grassland will improve the productivity of dairy and sheep farms
7 while helping to conserve their environments. Previous studies have reported results of machine
8 vision methods to separate grass from grassland weeds but each use their own datasets and
9 report only performance of their own algorithm, making it impossible to compare them. A
10 definitive, large-scale independent study is presented of all major known grassland weed detec-
11 tion methods evaluated on a new standardised data set under a wider range of environment
12 conditions. This allows for a fair, unbiased, independent and statistically significant comparison
13 of these and future methods for the first time. We test features including linear binary pat-
14 terns, BRISK, Fourier and Watershed; and classifiers including support vector machines, linear
15 discriminants, nearest neighbour, and meta-classifier combinations. The most accurate method
16 is found to use linear binary patterns together with a support vector machine}
}

@inproceedings{lincoln27902,
       booktitle = {International Conference on Machine Learning (ICML)},
           month = {August},
           title = {Local Bayesian optimization of motor skills},
          author = {R. Akrour and D. Sorokin and J. Peters and G. Neumann},
            year = {2017},
        keywords = {ARRAY(0x5568fbaa8420)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27902/},
        abstract = {Bayesian optimization is renowned for its sample
efficiency but its application to higher dimensional
tasks is impeded by its focus on global
optimization. To scale to higher dimensional
problems, we leverage the sample efficiency of
Bayesian optimization in a local context. The
optimization of the acquisition function is restricted
to the vicinity of a Gaussian search distribution
which is moved towards high value areas
of the objective. The proposed informationtheoretic
update of the search distribution results
in a Bayesian interpretation of local stochastic
search: the search distribution encodes prior
knowledge on the optimum?s location and is
weighted at each iteration by the likelihood of
this location?s optimality. We demonstrate the
effectiveness of our algorithm on several benchmark
objective functions as well as a continuous
robotic task in which an informative prior is obtained
by imitation learning.}
}

@article{lincoln26922,
          volume = {249},
           month = {August},
          author = {Daqi Liu and Shigang Yue},
           title = {Fast unsupervised learning for visual pattern recognition using spike timing dependent plasticity},
       publisher = {Elsevier},
            year = {2017},
         journal = {Neurocomputing},
             doi = {10.1016/j.neucom.2017.04.003},
           pages = {212--224},
        keywords = {ARRAY(0x5568fb9cc2a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26922/},
        abstract = {Real-time learning needs algorithms operating in a fast speed comparable to human or animal, however this is a huge challenge in processing visual inputs. Research shows a biological brain can process complicated real-life recognition scenarios at milliseconds scale. Inspired by biological system, in this paper, we proposed a novel real-time learning method by combing the spike timing-based feed-forward spiking neural network (SNN) and the fast unsupervised spike timing dependent plasticity learning method with dynamic post-synaptic thresholds. Fast cross-validated experiments using MNIST database showed the high e?ciency of the proposed method at an acceptable accuracy.}
}

@inproceedings{lincoln40823,
           month = {August},
          author = {Anu B. Titus and Thejas Narayanan and Gautham Das},
       booktitle = {2017 IEEE International Conference on Smart Technologies and Management for Computing, Communication, Controls, Energy and Materials (ICSTM)},
           title = {Vision system for coconut farm cable robot},
       publisher = {IEEE},
             doi = {10.1109/ICSTM.2017.8089201},
           pages = {443--450},
            year = {2017},
        keywords = {ARRAY(0x5568fbba4d38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40823/},
        abstract = {In many countries, robots and automation techniques are being introduced in agriculture farms to reduce the human labour and to improve the yield. However, such technological initiatives are still lacking in India, although it is the leading producer of many vegetables and fruits, for example, coconuts. Some of the activities carried out in a coconut farm that requires human labor are coconut dehusking, loading and unloading of coconuts. Automating these activities in a coconut farm would require a robotic system to pick and transport coconuts, for which the primary need would be to detect coconuts in those environments under natural lighting conditions. Towards this, the work in this paper tests for the applicability of three most used computer vision based object detection approaches namely, Local Binary Pattern (LBP) cascade, Histogram of Oriented Gradients (HOG) cascade and Haar - like cascade in coconut detection. This vision system would enable any field robot to automate the tasks in coconut farms without human assistance. A comparative analysis using confusion matrix is carried on these three approaches. It is observed that Haar-like features provided comparably better results among all the three features, in terms of hit rate and precision.}
}

@inproceedings{lincoln44700,
       booktitle = {2017 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)},
           month = {July},
           title = {A one-class Clustering technique for Novelty Detection and Isolation in sensor networks},
          author = {Sepehr Maleki and Chris Bingham},
            year = {2017},
           pages = {1--6},
             doi = {10.1109/CIVEMSA.2017.7995292},
        keywords = {ARRAY(0x5568fb67c060)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44700/},
        abstract = {A new Cluster-based methodology for real-time Novelty Detection and Isolation (NDI) in sensor networks, is presented. The proposed algorithm enables uniform clustering across time-frames to indicate the presence of a ?healthy? network. In the event of novelty, the associated sensor is seen to be clustered in a non-uniform manner with respect other sensors in the network, thereby facilitating fault isolation. Moreover, a statistical approach is proposed to determine a noise tolerance level for reducing false alarms. Performance of the proposed algorithm is examined using datasets obtained from a number of industrial case studies, and the significance for fault detection for such systems is demonstrated. Specifically, it is shown that through a correct selection of the noise tolerance level, an emerging failure is successfully isolated in presence of other abrupt changes that visually might be perceived as indication of a failure.}
}

@article{lincoln35378,
           month = {July},
          author = {Ashiqur Rahman and Amr Ahmed and Shigang Yue},
       booktitle = {The 2017 International Conference of Data Mining and Knowledge Engineering},
           title = {Classification of Tongue - Glossitis Abnormality},
       publisher = {International Association of Engineers (IAENG)},
         journal = {Lecture Notes in Engineering and Computer Science: Proceedings of The World Congress on Engineering},
           pages = {1--4},
            year = {2017},
        keywords = {ARRAY(0x5568fbb85828)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35378/},
        abstract = {Glossitis abnormality is a tongue abnormality affecting patients suffering from Diabetes Mellitus (DM). The novelty of the proposed approach is attributed to utilising visual signs that appear on the tongue due to Glossitis abnormality caused by the high blood sugar level in the human body. The clinical test for the blood sugar level is inconvenient for some patients in rural and poor areas where medical services are minimal or may not be available at all.

This paper presents an approach to classifying a tongue abnormality related to Diabetes Mellitus (DM) following Western Medicine. To screen and monitor human organ effectively, the proposed computer-aided model predicts and classifies abnormality appears on the tongue or tongue surface using visual signs caused by the Glossitis abnormality. The visual signs extracted following a coherent diagnosis procedure complying with Western Medicine (WM) in practice.  The experimental result has shown a promising accuracy of 95.8\% for the Glossitis abnormality by applying Random Forest classifier on the extracted visual signs from 572 tongue samples of 166 patients.}
}

@inproceedings{lincoln53889,
       booktitle = {TAROS 2017: Towards Autonomous Robotic Systems},
           month = {July},
           title = {Towards automated strawberry harvesting: Identifying the picking point},
          author = {Zhuoling Huang and Sam Wane and Simon Parsons},
            year = {2017},
             doi = {10.1007/978-3-319-64107-2 18},
        keywords = {ARRAY(0x5568fbb89c60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53889/},
        abstract = {With the decline of rural populations across the globe, much hope is vested in the use of robots in agriculture as a means to sustain food production. This is particularly relevant for high-value crops, such as strawberries, where harvesting is currently very labour-intensive. As part of a larger project to build a robot that is capable of harvesting strawberries, we have studied the identification of the picking point of strawberries {--} the point that a robot hand should grasp the strawberry {--} from images of strawberries. We present a novel approach to identify the picking point and evaluate this approach.}
}

@inproceedings{lincoln37437,
          volume = {10454},
           month = {July},
          author = {C. Lekakou and S.M. Mustaza and T. Crisp and Y. Elsayed and Mini Saaj},
            note = {cited By 1},
       booktitle = {Annual Conference Towards Autonomous Robotic Systems},
           title = {A material-based model for the simulation and control of soft robot actuator},
       publisher = {Springer},
            year = {2017},
         journal = {Proc. 18th Towards Autonomous Robotics Systems Conference},
             doi = {10.1007/978-3-319-64107-2\_45},
           pages = {557--569},
        keywords = {ARRAY(0x5568fba4f8e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37437/},
        abstract = {An innovative material-based model is described for a three-pneumatic channel, soft robot actuator and implemented in simulations and control. Two types of material models are investigated: a soft, hyperelastic material model and a novel visco-hyperelastic material model are presented and evaluated in simulations of one-channel operation. The advanced visco-hyperelastic model is further demonstrated in control under multi-channel actuation. Finally, a soft linear elastic material model was used in finite element analysis of the soft three-pneumatic channel actuator within SOFA, moving inside a pipe and interacting with its rigid wall or with a soft hemispherical object attached to that wall. A collision model was used for these interactions and the simulations yielded ?virtual haptic? 3d-force profiles at monitored nodes at the free- and fixed-end of the actuator.}
}

@inproceedings{lincoln27056,
       booktitle = {The Genetic and Evolutionary Computation Conference (GECCO 2017)},
           month = {July},
           title = {Deriving and improving CMA-ES with Information geometric trust regions},
          author = {Abbas Abdolmaleki and Bob Price and Nuno Lau and Luis Paulo Reis and Gerhard Neumann},
            year = {2017},
        keywords = {ARRAY(0x5568fba14928)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27056/},
        abstract = {CMA-ES is one of the most popular stochastic search algorithms.
It performs favourably in many tasks without the need of extensive
parameter tuning. The algorithm has many beneficial properties,
including automatic step-size adaptation, efficient covariance updates
that incorporates the current samples as well as the evolution
path and its invariance properties. Its update rules are composed
of well established heuristics where the theoretical foundations of
some of these rules are also well understood. In this paper we
will fully derive all CMA-ES update rules within the framework of
expectation-maximisation-based stochastic search algorithms using
information-geometric trust regions. We show that the use of the trust
region results in similar updates to CMA-ES for the mean and the
covariance matrix while it allows for the derivation of an improved
update rule for the step-size. Our new algorithm, Trust-Region Covariance
Matrix Adaptation Evolution Strategy (TR-CMA-ES) is
fully derived from first order optimization principles and performs
favourably in compare to standard CMA-ES algorithm.}
}

@article{lincoln27901,
          volume = {PP},
          number = {99},
           month = {July},
          author = {Alexandros Paraschos and Rudolf Lioutikov and Jan Peters and Gerhard Neumann},
       booktitle = {, Proceedings of the International Conference on Intelligent Robot Systems, and IEEE Robotics and Automation Letters (RA-L)},
           title = {Probabilistic prioritization of movement primitives},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2017.2725440},
        keywords = {ARRAY(0x5568fb9f0638)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27901/},
        abstract = {Movement prioritization is a common approach
to combine controllers of different tasks for redundant robots,
where each task is assigned a priority. The priorities of the
tasks are often hand-tuned or the result of an optimization,
but seldomly learned from data. This paper combines Bayesian
task prioritization with probabilistic movement primitives to
prioritize full motion sequences that are learned from demonstrations.
Probabilistic movement primitives (ProMPs) can
encode distributions of movements over full motion sequences
and provide control laws to exactly follow these distributions.
The probabilistic formulation allows for a natural application of
Bayesian task prioritization. We extend the ProMP controllers
with an additional feedback component that accounts inaccuracies
in following the distribution and allows for a more
robust prioritization of primitives. We demonstrate how the
task priorities can be obtained from imitation learning and
how different primitives can be combined to solve even unseen
task-combinations. Due to the prioritization, our approach can
efficiently learn a combination of tasks without requiring individual
models per task combination. Further, our approach can
adapt an existing primitive library by prioritizing additional
controllers, for example, for implementing obstacle avoidance.
Hence, the need of retraining the whole library is avoided in
many cases. We evaluate our approach on reaching movements
under constraints with redundant simulated planar robots and
two physical robot platforms, the humanoid robot ?iCub? and
a KUKA LWR robot arm.}
}

@inproceedings{lincoln26622,
       booktitle = {International Joint Conference on Neural Networks (IJCNN)},
           month = {July},
           title = {Scaling up deep reinforcement learning for multi-domain dialogue systems},
          author = {Heriberto Cuayahuitl and Seunghak Yu and Ashley Williamson and Jacob Carse},
       publisher = {IEEE},
            year = {2017},
             doi = {10.1109/IJCNN.2017.7966275},
        keywords = {ARRAY(0x5568fba96790)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26622/},
        abstract = {Standard deep reinforcement learning methods such as Deep Q-Networks (DQN) for multiple tasks (domains) face scalability problems due to large search spaces. This paper proposes a three-stage method for multi-domain dialogue policy learning{--}termed NDQN, and applies it to an information-seeking spoken dialogue system in the domains of restaurants and hotels. In this method, the first stage does multi-policy learning via a network of DQN agents; the second makes use of compact state representations by compressing raw inputs; and the third stage applies a pre-training phase for bootstraping the behaviour of agents in the network. Experimental results comparing DQN
(baseline) versus NDQN (proposed) using simulations report that the proposed method exhibits better scalability and is
promising for optimising the behaviour of multi-domain dialogue systems. An additional evaluation reports that the NDQN agents outperformed a K-Nearest Neighbour baseline in task success and dialogue length, yielding more efficient and successful dialogues.}
}

@article{lincoln28021,
          volume = {36},
          number = {8},
           month = {July},
          author = {Rudolf Lioutikov and Gerhard Neumann and Guilherme Maeda and Jan Peters},
           title = {Learning movement primitive libraries through probabilistic segmentation},
       publisher = {SAGE},
            year = {2017},
         journal = {International Journal of Robotics Research (IJRR)},
             doi = {10.1177/0278364917713116},
           pages = {879--894},
        keywords = {ARRAY(0x5568fba85c50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28021/},
        abstract = {Movement primitives are a well established approach for encoding and executing movements. While the primitives
themselves have been extensively researched, the concept of movement primitive libraries has not received similar
attention. Libraries of movement primitives represent the skill set of an agent. Primitives can be queried and sequenced
in order to solve specific tasks. The goal of this work is to segment unlabeled demonstrations into a representative
set of primitives. Our proposed method differs from current approaches by taking advantage of the often neglected,
mutual dependencies between the segments contained in the demonstrations and the primitives to be encoded. By
exploiting this mutual dependency, we show that we can improve both the segmentation and the movement primitive
library. Based on probabilistic inference our novel approach segments the demonstrations while learning a probabilistic
representation of movement primitives. We demonstrate our method on two real robot applications. First, the robot
segments sequences of different letters into a library, explaining the observed trajectories. Second, the robot segments
demonstrations of a chair assembly task into a movement primitive library. The library is subsequently used to assemble the chair in an order not present in the demonstrations.}
}

@inproceedings{lincoln31513,
       booktitle = {IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications},
           month = {June},
           title = {A one-class clustering technique for novelty detection and Isolation in sensor networks},
          author = {Sepehr Maleki and Chris Bingham},
       publisher = {IEEE},
            year = {2017},
        keywords = {ARRAY(0x5568fba6cde8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31513/},
        abstract = {A new Cluster-based methodology for real-time Novelty Detection and Isolation (NDI) in sensor networks, is presented. The proposed algorithm enables uniform clustering across time-frames to indicate the presence of a ?healthy? network. In the event of novelty, the associated sensor is seen to be clustered in a non-uniform manner with respect other sensors in the network, thereby facilitating fault isolation. Moreover, a statistical approach is proposed to determine a noise tolerance level for reducing false alarms. Performance of the proposed algorithm is examined using datasets obtained from a number of industrial case studies, and the significance for fault detection for such systems is demonstrated. Specifically, it is shown that through a correct selection of the noise tolerance level, an emerging failure is successfully isolated in presence of other abrupt changes that visually might be perceived as indication of a failure.}
}

@inproceedings{lincoln27055,
       booktitle = {Proceedings of the International Conference on Automated Planning and Scheduling (ICAPS)},
           month = {June},
           title = {State-regularized policy search for linearized dynamical systems},
          author = {Hany Abdulsamad and Oleg Arenz and Jan Peters and Gerhard Neumann},
            year = {2017},
        keywords = {ARRAY(0x5568fbbc8270)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27055/},
        abstract = {Trajectory-Centric Reinforcement Learning and Trajectory
Optimization methods optimize a sequence of feedbackcontrollers
by taking advantage of local approximations of
model dynamics and cost functions. Stability of the policy update
is a major issue for these methods, rendering them hard
to apply for highly nonlinear systems. Recent approaches
combine classical Stochastic Optimal Control methods with
information-theoretic bounds to control the step-size of the
policy update and could even be used to train nonlinear deep
control policies. These methods bound the relative entropy
between the new and the old policy to ensure a stable policy
update. However, despite the bound in policy space, the
state distributions of two consecutive policies can still differ
significantly, rendering the used local approximate models invalid.
To alleviate this issue we propose enforcing a relative
entropy constraint not only on the policy update, but also on
the update of the state distribution, around which the dynamics
and cost are being approximated. We present a derivation
of the closed-form policy update and show that our approach
outperforms related methods on two nonlinear and highly dynamic
simulated systems.}
}

@article{lincoln39221,
          volume = {10},
          number = {7},
           month = {June},
          author = {Efthymios Rodias and Remigio Berruto and Dionysis Bochtis and Patrizia Busato and Alessandro Sopegno},
           title = {A Computational Tool for Comparative Energy Cost Analysis of Multiple-Crop Production Systems},
            year = {2017},
         journal = {Energies},
             doi = {10.3390/en10070831},
           pages = {831},
        keywords = {ARRAY(0x5568fb9ed3f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39221/},
        abstract = {Various crops can be considered as potential bioenergy and biofuel production feedstocks. The selection of the crops to be cultivated for that purpose is based on several factors. For an objective comparison between different crops, a common framework is required to assess their economic or energetic performance. In this paper, a computational tool for the energy cost evaluation of multiple-crop production systems is presented. All the in-field and transport operations are considered, providing a detailed analysis of the energy requirements of the components that contribute to the overall energy consumption. A demonstration scenario is also described. The scenario is based on three selected energy crops, namely Miscanthus, Arundo donax and Switchgrass. The tool can be used as a decision support system for the evaluation of different agronomical practices (such as fertilization and agrochemicals application), machinery systems, and management practices that can be applied in each one of the individual crops within the production system}
}

@inproceedings{lincoln28054,
       booktitle = {2017 IEEE International Conference on Prognostics and Health Management (ICPHM)},
           month = {June},
           title = {Performance analysis of a twin shaft Industrial Gas Turbine at fouling conditions},
          author = {Samuel Cruz-Manzo and Sepehr Maleki and Yu Zhang and Vili Panov and Anthony Latimer},
            year = {2017},
        keywords = {ARRAY(0x5568fb67ff90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28054/},
        abstract = {In this study, the performance of a twin-shaft Industrial Gas Turbine (IGT) at fouling conditions is simulated through a Simulink model based on fundamental thermodynamics. Engine measurements across a twin-shaft IGT system during compressor fouling conditions were considered to validate this study. By implementing correlation coefficients in the compressor model, it is possible to predict the performance of the IGT system during compressor fouling conditions. The change of compressor air flow and the compressor efficiency in the twin-shaft IGT during fouling conditions is estimated. The results show that the reduction of air flow rate is the dominating parameter in the decrease of power generation in an IGT under fouled conditions. The model can provide an insight into the effect of compressor fouling conditions on system IGT performance.}
}

@article{lincoln18592,
          volume = {247},
           month = {June},
          author = {Marc Hanheide and Moritz G{\"o}belbecker and Graham S. Horn and Andrzej Pronobis and Kristoffer Sj{\"o}{\"o} and Alper Aydemir and Patric Jensfelt and Charles Gretton and Richard Dearden and Miroslav Janicek and Hendrik Zender and Geert-Jan Kruijff and Nick Hawes and Jeremy L. Wyatt},
           title = {Robot task planning and explanation in open and uncertain worlds},
       publisher = {Elsevier},
            year = {2017},
         journal = {Artificial Intelligence},
             doi = {10.1016/j.artint.2015.08.008},
           pages = {119--150},
        keywords = {ARRAY(0x5568fb680038)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/18592/},
        abstract = {A long-standing goal of AI is to enable robots to plan in the face of uncertain and incomplete information, and to handle task failure intelligently. This paper shows how to achieve this. There are two central ideas. The first idea is to organize the robot's knowledge into three layers: instance knowledge at the bottom, commonsense knowledge above that, and diagnostic knowledge on top. Knowledge in a layer above can be used to modify knowledge in the layer(s) below. The second idea is that the robot should represent not just how its actions change the world, but also what it knows or believes. There are two types of knowledge effects the robot's actions can have: epistemic effects (I believe X because I saw it) and assumptions (I'll assume X to be true). By combining the knowledge layers with the models of knowledge effects, we can simultaneously solve several problems in robotics: (i) task planning and execution under uncertainty; (ii) task planning and execution in open worlds; (iii) explaining task failure; (iv) verifying those explanations. The paper describes how the ideas are implemented in a three-layer architecture on a mobile robot platform. The robot implementation was evaluated in five different experiments on object search, mapping, and room categorization.}
}

@article{lincoln25774,
          volume = {247},
           month = {June},
          author = {A. Kupcsik and M. P. Deisenroth and J. Peters and A. P. Loh and P. Vadakkepat and G. Neumann},
           title = {Model-based contextual policy search for data-efficient generalization of robot skills},
       publisher = {Elsevier},
            year = {2017},
         journal = {Artificial Intelligence},
             doi = {10.1016/j.artint.2014.11.005},
           pages = {415--439},
        keywords = {ARRAY(0x5568fbb54f90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25774/},
        abstract = {In robotics, lower-level controllers are typically used to make the robot solve a specific task in a fixed context. For example, the lower-level controller can encode a hitting movement while the context defines the target coordinates to hit. However, in many learning problems the context may change between task executions. To adapt the policy to a new context, we utilize a hierarchical approach by learning an upper-level policy that generalizes the lower-level controllers to new contexts. A common approach to learn such upper-level policies is to use policy search. However, the majority of current contextual policy search approaches are model-free and require a high number of interactions with the robot and its environment. Model-based approaches are known to significantly reduce the amount of robot experiments, however, current model-based techniques cannot be applied straightforwardly to the problem of learning contextual upper-level policies. They rely on specific parametrizations of the policy and the reward function, which are often unrealistic in the contextual policy search formulation. In this paper, we propose a novel model-based contextual policy search algorithm that is able to generalize lower-level controllers, and is data-efficient. Our approach is based on learned probabilistic forward models and information theoretic policy search. Unlike current algorithms, our method does not require any assumption on the parametrization of the policy or the reward function. We show on complex simulated robotic tasks and in a real robot experiment that the proposed learning framework speeds up the learning process by up to two orders of magnitude in comparison to existing methods, while learning high quality policies.}
}

@inproceedings{lincoln39636,
       booktitle = {25th International Congress of the European Association of Endoscopic Surgeons},
           month = {June},
           title = {Gynaecological ENdoscopic uTerine eLEvatoR (GENTLER)},
          author = {S. Mustaza and C.M. Saaj},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39636/}
}

@article{lincoln46161,
          volume = {14},
          number = {130},
           month = {May},
          author = {M. Calisti and G. Picardi and C. Laschi},
           title = {Fundamentals of soft robot locomotion},
            year = {2017},
         journal = {Journal of The Royal Society Interface},
             doi = {10.1098/rsif.2017.0101},
           pages = {20170101},
        keywords = {ARRAY(0x5568fbb4e3a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46161/},
        abstract = {Soft robotics and its related technologies enable robot abilities in several robotics domains including, but not exclusively related to, manipulation, manufacturing, human?robot interaction and locomotion. Although field applications have emerged for soft manipulation and human?robot interaction, mobile soft robots appear to remain in the research stage, involving the somehow conflictual goals of having a deformable body and exerting forces on the environment to achieve locomotion. This paper aims to provide a reference guide for researchers approaching mobile soft robotics, to describe the underlying principles of soft robot locomotion with its pros and cons, and to envisage applications and further developments for mobile soft robotics.}
}

@article{lincoln38546,
          volume = {69},
           month = {May},
          author = {S. Zhang and E. Grave and Elizabeth Sklar and N. Elhadad},
            note = {cited By 10},
           title = {Longitudinal analysis of discussion topics in an online breast cancer community using convolutional neural networks},
            year = {2017},
         journal = {Journal of Biomedical Informatics},
             doi = {10.1016/j.jbi.2017.03.012},
           pages = {1--9},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38546/}
}

@article{lincoln27582,
          volume = {12},
          number = {5},
           month = {May},
          author = {Paul Baxter and Emily Ashurst and Robin Read and James Kennedy and Tony Belpaeme},
           title = {Robot education peers in a situated primary school study: personalisation promotes child learning},
       publisher = {Public Library of Science},
            year = {2017},
         journal = {PLoS One},
             doi = {10.1371/journal.pone.0178126},
           pages = {e0178126},
        keywords = {ARRAY(0x5568fbb617b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27582/},
        abstract = {The benefit of social robots to support child learning in an educational context over an extended period of time is evaluated. Specifically, the effect of personalisation and adaptation of robot social behaviour is assessed. Two autonomous robots were embedded within two matched classrooms of a primary school for a continuous two week period without experimenter supervision to act as learning companions for the children for familiar and novel subjects. Results suggest that while children in both personalised and non-personalised conditions learned, there was increased child learning of a novel subject exhibited when interacting with a robot that personalised its behaviours, with indications that this benefit extended to other class-based performance. Additional evidence was obtained suggesting that there is increased acceptance of the personalised robot peer over a non-personalised version. These results provide the first evidence in support of peer-robot behavioural personalisation having a positive influence on learning when embedded in a learning environment for an extended period of time.}
}

@inproceedings{lincoln26619,
       booktitle = {The 2017 International Joint Conference on Neural Networks (IJCNN 2017)},
           month = {May},
           title = {Modeling direction selective visual neural network with ON and OFF pathways for extracting motion cues from cluttered background},
          author = {Qinbing Fu and Shigang Yue},
            year = {2017},
        keywords = {ARRAY(0x5568fbab5990)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26619/},
        abstract = {The nature endows animals robustvision systems for extracting and recognizing differentmotion cues, detectingpredators, chasing preys/mates in dynamic and cluttered environments. Direction selective neurons (DSNs), with preference to certain orientation visual stimulus, have been found in both vertebrates and invertebrates for decades. In thispaper, with respectto recent biological research progress in motion-detecting circuitry, we propose a novel way to model DSNs for recognizing movements on four cardinal directions. It is based on an architecture of ON and OFF visual pathways underlies a theory of splitting motion signals into parallel channels, encoding brightness increments and decrements separately. To enhance the edge selectivity and speed response to moving objects, we put forth a bio-plausible spatial-temporal network structure with multiple connections of same polarity ON/OFF cells. Each pair-wised combination is ?ltered with dynamic delay depending on sampling distance. The proposed vision system was challenged against image streams from both synthetic and cluttered real physical scenarios. The results demonstrated three major contributions: ?rst, the neural network ful?lled the characteristics of a postulated physiological map of conveying visual information through different neuropile layers; second, the DSNs model can extract useful directional motion cues from cluttered background robustly and timely, which hits at potential of quick implementation in visionbased micro mobile robots; moreover, it also represents better speed response compared to a state-of-the-art elementary motion detector.}
}

@inproceedings{lincoln28089,
           month = {May},
          author = {Gregor H. W. Gebhardt and Kevin Daun and Marius Schnaubelt and Alexander Hendrich and Daniel Kauth and Gerhard Neumann},
            note = {Extended abstract},
       booktitle = {Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems (AAMAS 17)},
           title = {Learning to assemble objects with a robot swarm},
       publisher = {international foundation for autonomous agents and multiagent systems},
           pages = {1547--1549},
            year = {2017},
        keywords = {ARRAY(0x5568fba49510)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28089/},
        abstract = {Large populations of simple robots can solve complex tasks, but controlling them is still a challenging problem, due to limited communication and computation power. In order to assemble objects, have shown that a human controller can solve such a task. Instead, we investigate how to learn the assembly of multiple objects with a single central controller. We propose splitting the assembly process in two sub-tasks -- generating a top-level assembly policy and learning an object movement policy. The assembly policy plans the trajectories for each object and the object movement policy controls the trajectory execution.The resulting system is able to solve assembly tasks with varying object shapes being assembled as shown in multiple simulation scenarios.}
}

@article{lincoln33056,
           month = {May},
          author = {Khaled Goher and Sulaiman Fadlallah},
            note = {The final published version of this article is available online at http://dynamicsystems.asmedigitalcollection.asme.org/article.aspx?articleid=2599257},
           title = {Design, Modelling and Control of a Portable Leg Rehabilitation System},
       publisher = {American Society of Mechanical Engineers},
         journal = {ASME Journal of Dynamic Systems, Measurement and Control},
             doi = {10.1115/1.4035815},
            year = {2017},
        keywords = {ARRAY(0x5568fbb90258)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33056/},
        abstract = {In this work, a novel design of a portable leg rehabilitation system (PLRS) is presented. The main purpose of this paper is to provide a portable system, which allows patients with lower limb disabilities to perform leg and foot rehabilitation exercises anywhere without any embarrassment compared to other devices that lack the portability feature.  The model of the system is identified by inverse kinematics and dynamics analysis. In kinematics analysis, the pattern of motion of both leg and foot holders for different modes of operation has been investigated.  The system is modeled by applying Lagrangian dynamics approach. The mathematical model derived considers calf and foot masses and moment of inertias as important parameters. Therefore, a gait analysis study is conducted to calculate the required parameters to simulate the model.  PD controller and PID controller are applied to the model and compared. The PID controller optimized by Hybrid Spiral-Dynamics Bacteria-Chemotaxis (HSDBC) algorithm provides the best response with a reasonable settling time and minimum overshot. The robustness of the HSDBC-PID controller is tested by applying disturbance force with various amplitudes. A setup is built for the system experimental validation where the system mathematical model is compare with the estimated model using System Identification Toolbox. A significant difference is observed between both models when applying the obtained HSDBC-PID controller for the mathematical model. The results of this experiment are used to update the controller parameters of the HSDBC-optimized PID.}
}

@article{lincoln27519,
          volume = {8},
          number = {1},
           month = {May},
          author = {Pablo G. Esteban and Paul Baxter and Tony Belpaeme and Erik Billing and Haibin Cai and Hoang-Long Cao and Mark Coeckelbergh and Cristina Costescu and Daniel David and Albert De Beir and Yinfeng Fang and Zhaojie Ju and James Kennedy and Honghai Liu and Alexandre Mazel and Amit Pandey and Kathleen Richardson and Emmanue Senft and Serge Thill and Greet Van de Perre and Bram Vanderborght and David Vernon and Hui Yu and Tom Ziemke},
           title = {How to build a supervised autonomous system for robot-enhanced therapy for children with autism spectrum disorder},
       publisher = {Springer/Versita with DeGruyter},
            year = {2017},
         journal = {Paladyn, Journal of Behavioral Robotics},
             doi = {10.1515/pjbr-2017-0002},
        keywords = {ARRAY(0x5568fb9ba1e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27519/},
        abstract = {Robot-Assisted Therapy (RAT) has successfully been used to improve social skills in children with autism spectrum disorders (ASD) through remote control of the robot in so-called Wizard of Oz (WoZ) paradigms.However, there is a need to increase the autonomy of the robot both to lighten the burden on human therapists (who have to remain in control and, importantly, supervise the robot) and to provide a consistent therapeutic experience. This paper seeks to provide insight into increasing the autonomy level of social robots in therapy to move beyond WoZ. With the final aim of improved human-human social interaction for the children, this multidisciplinary research seeks to facilitate the use of social robots as tools in clinical situations by addressing the challenge of increasing robot autonomy.We introduce the clinical framework in which the developments are tested, alongside initial data obtained from patients in a first phase of the project using a WoZ set-up mimicking the targeted supervised-autonomy behaviour. We further describe the implemented system architecture capable of providing the robot with supervised autonomy.}
}

@article{lincoln39220,
          volume = {9},
          number = {5},
           month = {May},
          author = {Patrizia Busato and Alessandro Sopegno and Remigio Berruto and Dionysis Bochtis and Angela Calvo},
           title = {A Web-Based Tool for Energy Balance Estimation in Multiple-Crops Production Systems},
            year = {2017},
         journal = {Sustainability},
             doi = {10.3390/su9050789},
           pages = {789},
        keywords = {ARRAY(0x5568fba4af60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39220/},
        abstract = {Biomass production systems include multiple-crops rotations, various machinery systems, diversified operational practices and several dispersed fields located in a range of distances between the various facilities (e.g., storage and processing facilities). These factors diversify the energy and cost requirements of the system. To that effect, assessment tools dedicated a single-crop production based on average standards cannot provide an insight evaluation of a specific production system, e.g., for a whole farm in terms of energy and cost requirements. This paper is the continuation of previous work, which presents a web-based tool for cost estimation of biomass production and transportation of multiple-crop production. In the present work, the tool is extended to additionally provide the energy balance of the examined systems. The energy input includes the whole supply chain of the biomass, namely crop cultivation, harvesting, handling of biomass and transportation to the processing facilities. A case study involving a real crop production system that feeds a biogas plant of 200 kW was selected for the demonstration of the tool?s applicability. The output of the tool provides a series of indexes dedicated to the energy input and balance. The presented tool can be used for the comparison of the performance, in terms of energy requirements, between various crops, fields, operations practices, and operations systems providing support for decisions on the biomass production system design (e.g., allocation of crops to fields) and operations management (e.g., machinery system selection).}
}

@article{lincoln28034,
          volume = {91},
           month = {May},
          author = {Tom Duckett and Adriana Tapus and Nicola Bellotto},
           title = {Editorial to special issue on the Seventh European Conference on Mobile Robots (ECMR?15)},
       publisher = {Elsevier},
            year = {2017},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2016.12.011},
           pages = {348},
        keywords = {ARRAY(0x5568fbaf9170)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28034/},
        abstract = {This Special Issue is based on a selection of the best papers presented at the Seventh European Conference on Mobile Robots (ECMR?15), September 2nd?4th, 2015, in Lincoln, UK.}
}

@inproceedings{lincoln26737,
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           month = {May},
           title = {Layered direct policy search for learning hierarchical skills},
          author = {F. End and R. Akrour and J. Peters and G. Neumann},
            year = {2017},
        keywords = {ARRAY(0x5568fbb80258)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26737/},
        abstract = {Solutions to real world robotic tasks often require
complex behaviors in high dimensional continuous state and
action spaces. Reinforcement Learning (RL) is aimed at learning
such behaviors but often fails for lack of scalability. To
address this issue, Hierarchical RL (HRL) algorithms leverage
hierarchical policies to exploit the structure of a task. However,
many HRL algorithms rely on task specific knowledge such
as a set of predefined sub-policies or sub-goals. In this paper
we propose a new HRL algorithm based on information
theoretic principles to autonomously uncover a diverse set
of sub-policies and their activation policies. Moreover, the
learning process mirrors the policys structure and is thus also
hierarchical, consisting of a set of independent optimization
problems. The hierarchical structure of the learning process
allows us to control the learning rate of the sub-policies and
the gating individually and add specific information theoretic
constraints to each layer to ensure the diversification of the subpolicies.
We evaluate our algorithm on two high dimensional
continuous tasks and experimentally demonstrate its ability to
autonomously discover a rich set of sub-policies.}
}

@inproceedings{lincoln26738,
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
           month = {May},
           title = {A learning-based shared control architecture for interactive task execution},
          author = {F. B. Farraj and T. Osa and N. Pedemonte and J. Peters and G. Neumann and P. R. Giordano},
       publisher = {IEEE},
            year = {2017},
        keywords = {ARRAY(0x5568fba0ac50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26738/},
        abstract = {Shared control is a key technology for various
robotic applications in which a robotic system and a human
operator are meant to collaborate efficiently. In order to achieve
efficient task execution in shared control, it is essential to
predict the desired behavior for a given situation or context
to simplify the control task for the human operator. To do this
prediction, we use Learning from Demonstration (LfD), which is
a popular approach for transferring human skills to robots. We
encode the demonstrated behavior as trajectory distributions
and generalize the learned distributions to new situations. The
goal of this paper is to present a shared control framework
that uses learned expert distributions to gain more autonomy.
Our approach controls the balance between the controller?s
autonomy and the human preference based on the distributions
of the demonstrated trajectories. Moreover, the learned
distributions are autonomously refined from collaborative task
executions, resulting in a master-slave system with increasing
autonomy that requires less user input with an increasing
number of task executions. We experimentally validated that
our shared control approach enables efficient task executions.
Moreover, the conducted experiments demonstrated that the
developed system improves its performances through interactive
task executions with our shared control.}
}

@inproceedings{lincoln26736,
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           month = {May},
           title = {Empowered skills},
          author = {A. Gabriel and R. Akrour and J. Peters and G. Neumann},
            year = {2017},
        keywords = {ARRAY(0x5568fb6d6060)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26736/},
        abstract = {Robot Reinforcement Learning (RL) algorithms
return a policy that maximizes a global cumulative reward
signal but typically do not create diverse behaviors. Hence, the
policy will typically only capture a single solution of a task.
However, many motor tasks have a large variety of solutions
and the knowledge about these solutions can have several
advantages. For example, in an adversarial setting such as
robot table tennis, the lack of diversity renders the behavior
predictable and hence easy to counter for the opponent. In an
interactive setting such as learning from human feedback, an
emphasis on diversity gives the human more opportunity for
guiding the robot and to avoid the latter to be stuck in local
optima of the task. In order to increase diversity of the learned
behaviors, we leverage prior work on intrinsic motivation and
empowerment. We derive a new intrinsic motivation signal by
enriching the description of a task with an outcome space,
representing interesting aspects of a sensorimotor stream. For
example, in table tennis, the outcome space could be given
by the return position and return ball speed. The intrinsic
motivation is now given by the diversity of future outcomes,
a concept also known as empowerment. We derive a new
policy search algorithm that maximizes a trade-off between
the extrinsic reward and this intrinsic motivation criterion.
Experiments on a planar reaching task and simulated robot
table tennis demonstrate that our algorithm can learn a diverse
set of behaviors within the area of interest of the tasks.}
}

@inproceedings{lincoln29190,
          volume = {2017-A},
           month = {April},
          author = {X Zheng and F. Lv and F. Zhao and S. Yue and C. Zhang and Z. Wang and F. Li and H. Jiang and Z. Wang},
            note = {Conference Code:129634},
       booktitle = {38th Annual Custom Integrated Circuits Conference, CICC 2017},
           title = {A 10 GHz 56 fsrms-integrated-jitter and -247 dB FOM ring-VCO based injection-locked clock multiplier with a continuous frequency-tracking loop in 65 nm CMOS},
       publisher = {Institute of Electrical and Electronics Engineers Inc.},
            year = {2017},
             doi = {10.1109/CICC.2017.7993597},
        keywords = {ARRAY(0x5568fbab26d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29190/},
        abstract = {This paper presents a low jitter ring-VCO based injection-locked clock multiplier (RILCM) with a phase-shift detection based hybrid frequency tracking loop (FTL). A full-swing pseudo-differential delay cell (FS-PDDC) is proposed to lower the device noise to phase noise conversion. To obtain high operation speed, high detection accuracy, and low output disturbance, a compact timing-adjusted phase detector (TPD) tightly combining with a well-matched charge pump (CP) is designed. Additionally, a lock-loss detection and lock recovery (LLD-LR) scheme is devised to equip the RILCM with a similar lock-acquisition ability to conventional PLL, thus excluding the initial frequency setup aid and preventing potential lock loss. Implemented in 65 nm CMOS, the RILCM occupies an active area of 0.07 mm2 and consumes 59.4 mW at 10 GHz. The measured results show that it achieves 56.1 fs rms-jitter and -57.13 dBc spur level. The calculated figure-of-merit (FOM) is -247.3 dB, which is better than previous RILCMs and even comparable to those large-area LC-ILCMs. {\^A}{\copyright} 2017 IEEE.}
}

@article{lincoln27043,
           month = {April},
          author = {James Kennedy and Paul Baxter and Tony Belpaeme},
            note = {THIS ARTICLE IS PART OF THE RESEARCH TOPIC
Affective and Social Signals for HRI},
           title = {The impact of robot tutor nonverbal social behavior on child learning},
       publisher = {Frontiers Media},
         journal = {Frontiers in ICT},
             doi = {10.3389/fict.2017.00006},
            year = {2017},
        keywords = {ARRAY(0x5568fba9b488)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27043/},
        abstract = {Several studies have indicated that interacting with social robots in educational contexts may lead to a greater learning than interactions with computers or virtual agents. As such, an increasing amount of social human?robot interaction research is being conducted in the learning domain, particularly with children. However, it is unclear precisely what social behavior a robot should employ in such interactions. Inspiration can be taken from human?human studies; this often leads to an assumption that the more social behavior an agent utilizes, the better the learning outcome will be. We apply a nonverbal behavior metric to a series of studies in which children are taught how to identify prime numbers by a robot with various behavioral manipulations. We find a trend, which generally agrees with the pedagogy literature, but also that overt nonverbal behavior does not account for all learning differences. We discuss the impact of novelty, child expectations, and responses to social cues to further the understanding of the relationship between robot social behavior and learning. We suggest that the combination of nonverbal behavior and social cue congruency is necessary to facilitate learning.}
}

@article{lincoln37428,
          volume = {34},
          number = {3},
           month = {April},
          author = {F.J. Comin and W.A. Lewinger and C. Saaj and M.C. Matthews},
            note = {cited By 3},
           title = {Trafficability Assessment of Deformable Terrain through Hybrid Wheel-Leg Sinkage Detection},
       publisher = {Wiley},
            year = {2017},
         journal = {Journal of Field Robotics},
             doi = {10.1002/rob.21645},
           pages = {451--476},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37428/},
        abstract = {Off?road ground mobile robots are widely used in diverse applications, both in terrestrial and planetary environments. They provide an efficient alternative, with lower risk and cost, to explore or to transport materials through hazardous or challenging terrain. However, nongeometric hazards that cannot be detected remotely pose a serious threat to the mobility of such robots. A prominent example of the negative effects these hazards can have is found on planetary rover exploration missions. They can cause a serious degradation of mission performance at best and complete immobilization and mission failure at worst. To tackle this issue, the work presented in this paper investigates the novel application of an existing enhanced?mobility locomotion concept, a hybrid wheel?leg equipped by a lightweight micro?rover, for in situ characterization of deformable terrain and online detection of nongeometric hazards. This is achieved by combining an improved vision?based approach and a new ranging?based approach to wheel?leg sinkage detection. In addition, the paper proposes an empirical model, and a parametric generalization, to predict terrain trafficability based on wheel?leg sinkage and a well?established semiempirical terramechanics model. The robustness and accuracy of the sinkage detection methods implemented are tested in a variety of conditions, both in the laboratory and in the field, using a single wheel?leg test bed. The sinkage?trafficability model is developed based on experimental data using this test bed and then validated onboard a fully mobile robot through experimentation on a range of dry frictional soils that covers a wide spectrum of macroscopic physical characteristics.}
}

@inproceedings{lincoln26621,
       booktitle = {15th Conference of the European chapter of the Association for Computational Linguistics},
           month = {April},
           title = {Evaluating persuasion strategies and deep reinforcement learning methods for negotiation dialogue agents},
          author = {Simon Keizer and Markus Guhe and Heriberto Cuayahuitl and Ioannis Efstathiou and Klaus-Peter Engelbrecht and Mihai Dobre and Alex Lascarides and Oliver Lemon},
       publisher = {ACL},
            year = {2017},
        keywords = {ARRAY(0x5568fbb94168)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26621/},
        abstract = {In this paper we present a comparative evaluation of various negotiation strategies within an online version of the game ?Settlers of Catan?. The comparison is based on human subjects playing games against artificial game-playing
agents (?bots?) which implement different negotiation dialogue strategies, using a chat dialogue interface to negotiate trades. Our results suggest that a negotiation strategy that uses persuasion, as well as a strategy that is trained from data using Deep Reinforcement Learning, both lead to an improved win rate against humans, compared to previous rule-based and supervised learning baseline dialogue negotiators.}
}

@inproceedings{lincoln25828,
           month = {April},
          author = {Peter Lightbody and Marc Hanheide and Tomas Krajnik},
       booktitle = {32nd ACM Symposium on Applied Computing},
           title = {A versatile high-performance visual fiducial marker detection system with scalable identity encoding},
       publisher = {Association for Computing Machinery},
             doi = {10.1145/3019612.3019709},
           pages = {1--7},
            year = {2017},
        keywords = {ARRAY(0x5568fbbc86f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25828/},
        abstract = {Fiducial markers have a wide field of applications in robotics, ranging from external localisation of single robots or robotic swarms, over self-localisation in marker-augmented environments, to simplifying perception by tagging objects in a robot?s surrounding. We propose a new family of circular markers allowing for a computationally efficient detection, identification and full 3D position estimation. A key concept of our system is the separation of the detection and identification steps, where the first step is based on a computationally efficient circular marker detection, and the identification step is based on an open-ended ?Necklace code?, which allows for a theoretically infinite number of individually identifiable markers. The experimental evaluation of the system on a real robot indicates that while the proposed algorithm achieves similar accuracy to other state-of-the-art methods, it is faster by two orders of magnitude and it can detect markers from longer distances.}
}

@article{lincoln23128,
          volume = {27},
          number = {2},
           month = {March},
          author = {Oscar Martinez Mozos and Virginia Sandulescu and Sally Andrews and David Ellis and Nicola Bellotto and Radu Dobrescu and Jose Manuel Ferrandez},
           title = {Stress detection using wearable physiological and sociometric sensors},
       publisher = {World Scientific Publishing},
            year = {2017},
         journal = {International Journal of Neural Systems},
             doi = {10.1142/S0129065716500416},
           pages = {1650041},
        keywords = {ARRAY(0x5568fbaede68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23128/},
        abstract = {Stress remains a significant social problem for individuals in modern societies. This paper presents a machine learning approach for the automatic detection of stress of people in a social situation by combining two sensor systems that capture physiological and social responses. We compare the performance using different classifiers including support vector machine, AdaBoost, and k-nearest neighbour. Our experimental results show that by combining the measurements from both sensor systems, we could accurately discriminate between stressful and neutral situations during a controlled Trier social stress test (TSST). Moreover, this paper assesses the discriminative ability of each sensor modality individually and considers their suitability for real time stress detection. Finally, we present an study of the most discriminative features for stress detection.}
}

@inproceedings{lincoln25362,
       booktitle = {Wellbeing AI: From Machine Learning to Subjectivity Oriented Computing (AAAI 2017 Spring Symposium)},
           month = {March},
           title = {ENRICHME integration of ambient intelligence and robotics for AAL},
          author = {Nicola Bellotto and Manuel Fernandez-Carmona and Serhan Cosar},
       publisher = {AAAI},
            year = {2017},
        keywords = {ARRAY(0x5568fbb904b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25362/},
        abstract = {Technological advances and affordability of recent smart sensors, as well as the consolidation of common software platforms for the integration of the latter and robotic sensors, are enabling the creation of complex active and assisted living environments for improving the quality of life of the elderly and the less able people. One such example is the integrated system developed by the European project ENRICHME, the aim of which is to monitor and prolong the independent living of old people affected by mild cognitive impairments with a combination of smart-home, robotics and web technologies. This paper presents in particular the design and technological solutions adopted to integrate, process and store the information provided by a set of fixed smart sensors and mobile robot sensors in a domestic scenario, including presence and contact detectors, environmental sensors, and RFID-tagged objects, for long-term user monitoring and}
}

@inproceedings{lincoln25413,
       booktitle = {AAAI 2017 Spring Symposium - Designing the User Experience of Machine Learning Systems},
           month = {March},
           title = {Portable navigations system with adaptive multimodal interface for the blind},
          author = {Jacobus Lock and Grzegorz Cielniak and Nicola Bellotto},
       publisher = {AAAI},
            year = {2017},
        keywords = {ARRAY(0x5568fbae9688)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25413/},
        abstract = {Recent advances in mobile technology have the potential to radically change the quality of tools available for people with sensory impairments, in particular the blind. Nowadays almost every smart-phone and tablet is equipped with high resolutions cameras, which are typically used for photos and videos, communication purposes, games and virtual reality applications. Very little has been proposed to exploit these sensors for user localisation and navigation instead. To this end, the ?Active Vision with Human-in-the-Loop for the Visually Impaired? (ActiVis) project aims to develop a novel electronic travel aid to tackle the ?last 10 yards problem? and enable the autonomous navigation of blind users in unknown environments, ultimately enhancing or replacing existing solutions, such as guide dogs and white canes. This paper describes some of the key project?s challenges, in particular with respect to the design of the user interface that translate visual information from the camera to guiding instructions for the blind person, taking into account limitations due to the visual impairment and proposing a multimodal interface that embeds human-machine co-adaptation.}
}

@article{lincoln33059,
           month = {March},
          author = {Khaled Goher and Sulaiman Fadlallah},
            note = {This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.},
           title = {Bacterial foraging-optimized PID control of a two-wheeled machine with a two-directional handling mechanism},
       publisher = {Springer},
         journal = {Robotics and Biomimetics},
             doi = {10.1186/s40638-017-0057-3},
            year = {2017},
        keywords = {ARRAY(0x5568fba22028)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33059/},
        abstract = {This paper presents the performance of utilizing a bacterial foraging optimization algorithm on a PID control scheme for controlling a five DOF two-wheeled robotic machine with two-directional handling mechanism. The system under investigation provides solutions for industrial robotic applications that require a limited-space working environment. The system nonlinear mathematical model, derived using Lagrangian modelling approach, is simulated in MATLAB/Simulink? environment. Bacterial foraging-optimized PID control with decoupled nature is designed and implemented. Various working scenarios with multiple initial conditions are used to test the robustness and the system performance. Simulation results revealed the effectiveness of the bacterial foraging-optimized PID control method in improving the system performance compared to the PID control scheme.}
}

@article{lincoln27044,
          volume = {17},
          number = {3},
           month = {March},
          author = {Maha Salem and Astrid Weiss and Paul Baxter},
           title = {New frontiers in human-robot interaction [special section on interdisciplinary human-centred approaches]},
       publisher = {John Benjamins Publishers},
            year = {2017},
         journal = {Interaction Studies},
             doi = {10.1075/is.17.3.05sal},
           pages = {405--407},
        keywords = {ARRAY(0x5568fba00e20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27044/},
        abstract = {-}
}

@article{lincoln33040,
          volume = {22},
          number = {6},
           month = {March},
          author = {Khaled Goher and Kong Chenhui and Sulaiman Fadlallah and Abdullah Al Shabibi and Nabeel Al Rawahi},
           title = {Transient dynamic impact suppression of a Baja chassis using frontal and rear shock absorbers},
       publisher = {Taylor and Francis},
            year = {2017},
         journal = {International Journal of Crashworthiness  ?},
             doi = {10.1080/13588265.2017.1301081},
           pages = {676--688},
        keywords = {ARRAY(0x5568fbaa8510)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33040/},
        abstract = {This paper investigates the behaviour of impact loading on a Baja vehicle chassis with frontal and rear shock absorbers, using transient dynamic analysis under different assumptions of contact conditions. Using a Baja car, a transient dynamic impact is performed in ANSYS Workbench 14.0, where the maximum deformation, stress and strains are calculated over duration of the particular impact. The mathematical model of the chassis is derived based on Kelvin model in order to design the best parameters of stiffness and damping coefficient in shock absorbers to minimise the deformation of the frame with the same impact. To study the effects of shock absorber under loading on a vehicle chassis, multiple finite element simulations are performed with different methodologies. Each methodology uses a different assumption on loading and boundary conditions, which leads to different results.}
}

@inproceedings{lincoln25866,
           month = {March},
          author = {Marc Hanheide and Denise Hebesberger and Tomas Krajnik},
       booktitle = {Int. Conf. on Human-Robot Interaction (HRI)},
         address = {Vienna},
           title = {The when, where, and how: an adaptive robotic info-terminal for care home residents ? a long-term study},
       publisher = {ACM},
             doi = {10.1145/2909824.3020228},
            year = {2017},
        keywords = {ARRAY(0x5568fbb04ff0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25866/},
        abstract = {Adapting to users' intentions is a key requirement for autonomous robots in general, and in care settings in particular. In this paper, a comprehensive long-term study of a mobile robot providing information services to residents, visitors, and staff of a care home is presented with a focus on adapting to the when and where the robot should be offering its services to best accommodate the users' needs. Rather than providing a fixed schedule, the presented system takes the opportunity of long-term deployment to explore the space of possibilities of interaction while concurrently exploiting the model learned to provide better services. But in order to provide effective services to users in a care home, not only then when and where are relevant, but also the way how the information is provided and accessed. Hence, also the usability of the deployed system is studied specifically, in order to provide a most comprehensive overall assessment of a robotic info-terminal implementation in a care setting. Our results back our hypotheses, (i) that learning a spatiotemporal model of users' intentions improves efficiency and usefulness of the system, and (ii) that the specific information sought after is indeed dependent on the location the info-terminal is offered.}
}

@inproceedings{lincoln30192,
           month = {March},
          author = {Emmanuel Senft and Severin Lemaignan and Paul E. Baxter and Tony Belpaeme},
       booktitle = {ACM/IEEE International Conference on Human-Robot Interaction - HRI '17},
         address = {Vienna, Austria},
           title = {Leveraging human inputs in interactive machine learning for human robot interaction},
             doi = {10.1145/3029798.3038385},
           pages = {281--282},
            year = {2017},
        keywords = {ARRAY(0x5568fbb71f40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30192/},
        abstract = {A key challenge of HRI is allowing robots to be adaptable, especially as robots are expected to penetrate society at large and to interact in unexpected environments with non- technical users. One way of providing this adaptability is to use Interactive Machine Learning, i.e. having a human supervisor included in the learning process who can steer the action selection and the learning in the desired direction. We ran a study exploring how people use numeric rewards to evaluate a robot's behaviour and guide its learning. From the results we derive a number of challenges when design- ing learning robots: what kind of input should the human provide? How should the robot communicate its state or its intention? And how can the teaching process by made easier for human supervisors?}
}

@inproceedings{lincoln25867,
       booktitle = {Proc ACM/IEEE Int. Conf. on Human-Robot Interaction (HRI) Late Breaking Reports},
           month = {March},
           title = {Patterns of use: how older adults with progressed dementia interact with a robot},
          author = {Denise Hebesberger and Christian Dondrup and Christoph Gisinger and Marc Hanheide},
         address = {Vienna},
       publisher = {ACM/IEEE},
            year = {2017},
        keywords = {ARRAY(0x5568fba429d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25867/},
        abstract = {Older adults represent a new user group of robots that are deployed in their private homes or in care facilities. In the presented study tangible aspects of older adults' interaction with an autonomous robot were focused. The robot was deployed as a companion in physical therapy for older adults with progressed dementia. Interaction was possible via a mounted touch screen. The menu was structured in a single layer and icons were big and with strong contrast. Employing a detailed observation protocol, interaction frequencies and contexts were assessed. Thereby, it was found that most of the interaction was encouraged by the therapists and that two out of 12 older adults with progressed dementia showed self-inducted interactions.}
}

@article{lincoln25744,
          volume = {41},
          number = {3},
           month = {March},
          author = {G. J. Maeda and G. Neumann and M. Ewerton and R. Lioutikov and O. Kroemer and J. Peters},
            note = {Special Issue on Assistive and Rehabilitation Robotics},
           title = {Probabilistic movement primitives for coordination of multiple human?robot collaborative tasks},
       publisher = {Springer},
            year = {2017},
         journal = {Autonomous Robots},
             doi = {10.1007/s10514-016-9556-2},
           pages = {593--612},
        keywords = {ARRAY(0x5568fb67dc40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25744/},
        abstract = {This paper proposes an interaction learning method for collaborative and assistive robots based on movement primitives. The method allows for both action recognition and human?robot movement coordination. It uses imitation learning to construct a mixture model of human?robot interaction primitives. This probabilistic model allows the assistive trajectory of the robot to be inferred from human observations. The method is scalable in relation to the number of tasks and can learn nonlinear correlations between the trajectories that describe the human?robot interaction. We evaluated the method experimentally with a lightweight robot arm in a variety of assistive scenarios, including the coordinated handover of a bottle to a human, and the collaborative assembly of a toolbox. Potential applications of the method are personal caregiver robots, control of intelligent prosthetic devices, and robot coworkers in factories.}
}

@article{lincoln25239,
          volume = {88},
           month = {February},
          author = {Tomas Krajnik and Pablo Cristoforis and Keerthy Kusumam and Peer Neubert and Tom Duckett},
           title = {Image features for visual teach-and-repeat navigation in changing environments},
       publisher = {Elsevier},
            year = {2017},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2016.11.011},
           pages = {127--141},
        keywords = {ARRAY(0x5568fba93d28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25239/},
        abstract = {We present an evaluation of standard image features in the context of long-term visual teach-and-repeat navigation of mobile robots, where the environment exhibits significant changes in appearance caused by seasonal weather variations and daily illumination changes. We argue that for long-term autonomous navigation, the viewpoint-, scale- and rotation- invariance of the standard feature extractors is less important than their robustness to the mid- and long-term environment appearance changes. Therefore, we focus our evaluation on the robustness of image registration to variable lighting and naturally-occurring seasonal changes. We combine detection and description components of different image extractors and evaluate their performance on five datasets collected by mobile vehicles in three different outdoor environments over the course of one year. Moreover, we propose a trainable feature descriptor based on a combination of evolutionary algorithms and Binary Robust Independent Elementary Features, which we call GRIEF (Generated BRIEF). In terms of robustness to seasonal changes, the most promising results were achieved by the SpG/CNN and the STAR/GRIEF feature, which was slightly less robust, but faster to calculate.}
}

@article{lincoln25412,
          volume = {88},
           month = {February},
          author = {Jo{\~a}o Machado Santos and Tom{\'a}{\v s} Krajn{\'i}k and Tom Duckett},
           title = {Spatio-temporal exploration strategies for long-term autonomy of mobile robots},
       publisher = {Elsevier},
            year = {2017},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2016.11.016},
           pages = {116--126},
        keywords = {ARRAY(0x5568fbbb1288)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25412/},
        abstract = {We present a study of spatio-temporal environment representations and exploration strategies for long-term deployment of mobile robots in real-world, dynamic environments. We propose a new concept for life-long mobile robot spatio-temporal exploration that aims at building, updating and maintaining the environment model during the long-term deployment. The addition of the temporal dimension to the explored space makes the exploration task a never-ending data-gathering process, which we address by application of information-theoretic exploration techniques to world representations that model the uncertainty of environment states as probabilistic functions of time. We evaluate the performance of different exploration strategies and temporal models on real-world data gathered over the course of several months. The combination of dynamic environment representations with information-gain exploration principles allows to create and maintain up-to-date models of continuously changing environments, enabling efficient and self-improving long-term operation of mobile robots.}
}

@inproceedings{lincoln25360,
       booktitle = {VISAPP - International Conference on Computer Vision Theory and Applications},
           month = {February},
           title = {Volume-based human re-identification with RGB-D cameras},
          author = {Serhan Cosar and Claudio Coppola and Nicola Bellotto},
            year = {2017},
        keywords = {ARRAY(0x5568fbab5de0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25360/},
        abstract = {This paper presents an RGB-D based human re-identification approach using novel biometrics features from the body's volume. Existing work based on RGB images or skeleton features have some limitations for real-world robotic applications, most notably in dealing with occlusions and orientation of the user. Here, we propose novel features that allow performing re-identification when the person is facing side/backward or the person is partially occluded. The proposed approach has been tested for various scenarios including different views, occlusion and the public BIWI RGBD-ID dataset.}
}

@inproceedings{lincoln25361,
           month = {February},
          author = {Daniele Liciotti and Tom Duckett and Nicola Bellotto and Emanuele Frontoni and Primo Zingaretti},
       booktitle = {ICPRAM - 6th International Conference on Pattern Recognition Applications and Methods},
           title = {HMM-based activity recognition with a ceiling RGB-D camera},
       publisher = {Science and Technology Publications},
             doi = {10.5220/0006202305670574},
           pages = {567--574},
            year = {2017},
        keywords = {ARRAY(0x5568fbb8e7f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25361/},
        abstract = {Automated recognition of Activities of Daily Living allows to identify possible health problems and apply corrective strategies in Ambient Assisted Living (AAL). Activities of Daily Living analysis can provide very useful information for elder care and long-term care services. This paper presents an automated RGB-D video analysis system that recognises human ADLs activities, related to classical daily actions. The main goal is to predict the probability of an analysed subject action. Thus, the abnormal behaviour can be detected. The activity detection and recognition is performed using an affordable RGB-D camera. Human activities, despite their unstructured nature, tend to have a natural hierarchical structure; for instance, generally making a coffee involves a three-step process of turning on the coffee machine, putting sugar in cup and opening the fridge for milk. Action sequence recognition is then handled using a discriminative Hidden Markov Model (HMM). RADiaL, a dataset with RGB-D images and 3D position of each person for training as well as evaluating the HMM, has been built and made publicly available.}
}

@article{lincoln39217,
          volume = {18},
          number = {3},
           month = {February},
          author = {Xanthoula Eirini Pantazi and Dimitrios Moshou and Roberto Oberti and Jon West and Abdul Mounem Mouazen and Dionysis Bochtis},
           title = {Detection of biotic and abiotic stresses in crops by using hierarchical self organizing classifiers},
            year = {2017},
         journal = {Precision Agriculture},
             doi = {doi:10.1007/s11119-017-9507-8},
           pages = {383--393},
        keywords = {ARRAY(0x5568fb9f9a40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39217/},
        abstract = {Hyperspectral signatures can provide abundant information regarding health status of crops; however it is difficult to discriminate between biotic and abiotic stress. In this study, the case of simultaneous occurrence of yellow rust disease symptoms and nitrogen stress was investigated by using hyperspectral features from a ground based hyperspectral imaging system. Hyperspectral images of healthy and diseased plant canopies were taken at Rothamsted Research, UK by a Specim V10 spectrograph. Five wavebands of 20 nm width were utilized for accurate identification of each of the stress and healthy plant conditions. The technique that was developed used a hybrid classification scheme consisting of hierarchical self organizing classifiers. Three different architectures were considered: counter-propagation artificial neural networks, supervised Kohonen networks (SKNs) and XY-fusion. A total of 12 120 spectra were collected. From these 3 062 (25.3\%) were used for testing. The results of biotic and abiotic stress identification appear to be promising, reaching more than 95\% for all three architectures. The proposed approach aimed at sensor based detection of diseased and stressed plants so that can be treated site specifically contributing to a more effective and precise application of fertilizers and fungicides according to specific plant?s needs.}
}

@inproceedings{lincoln33062,
           month = {February},
          author = {Khaled Goher and Amur Al Yahmadi},
       booktitle = {IEEE-EMBS Conference on Biomedical Engineering and Sciences},
           title = {Kinematic Analysis of the Sit-to-Stand Mechanism of a Reconfigurable Wheelchair},
       publisher = {IEEE},
             doi = {10.1109/iecbes.2016.7843558},
           pages = {788--791},
            year = {2017},
        keywords = {ARRAY(0x5568fbbb7758)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33062/},
        abstract = {In this paper; the authors presents kinematics analysis of a sit to stand mechanism of a reconfigurable wheelchair. A reconfigurable wheelchair is a device designed and built for the purpose of rehabilitation and self-assistance for a disabled 25 kg child. In addition to the sit-to-stand facility; the developed wheelchair has two additional features: upper body laying by adjusting the back seat and knee and ankle exercising mechanism. This flexible configuration will allow the user to use the wheelchair as a mobility device as well as for rehabilitation purposes without need any external support.  The mechanism is identified and a position analysis for the transform between sit to stand posture is obtained. MATLAB software is used to simulate the pattern of motion of both the input link and the follower. Proceeding in the investigation, velocity and acceleration analyses are derived for the reconfigurable wheelchair. Based on the previous analysis, the linear velocity and acceleration equations of the moving links are obtained.}
}

@inproceedings{lincoln26739,
       booktitle = {Thirty-First AAAI Conference on Artificial Intelligence},
           month = {February},
           title = {The kernel Kalman rule: efficient nonparametric inference with recursive least squares},
          author = {G. H. W. Gebhardt and A. Kupcsik and G. Neumann},
       publisher = {AAAI},
            year = {2017},
        keywords = {ARRAY(0x5568fbb07fa0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26739/},
        abstract = {Nonparametric inference techniques provide promising tools
for probabilistic reasoning in high-dimensional nonlinear systems.
Most of these techniques embed distributions into reproducing
kernel Hilbert spaces (RKHS) and rely on the kernel
Bayes? rule (KBR) to manipulate the embeddings. However,
the computational demands of the KBR scale poorly
with the number of samples and the KBR often suffers from
numerical instabilities. In this paper, we present the kernel
Kalman rule (KKR) as an alternative to the KBR. The derivation
of the KKR is based on recursive least squares, inspired
by the derivation of the Kalman innovation update. We apply
the KKR to filtering tasks where we use RKHS embeddings
to represent the belief state, resulting in the kernel Kalman filter
(KKF). We show on a nonlinear state estimation task with
high dimensional observations that our approach provides a
significantly improved estimation accuracy while the computational
demands are significantly decreased.}
}

@inproceedings{lincoln26740,
       booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
           month = {February},
           title = {Policy search with high-dimensional context variables},
          author = {V. Tangkaratt and H. van Hoof and S. Parisi and G. Neumann and J. Peters and M. Sugiyama},
       publisher = {Association for the Advancement of Artificial Intelligence},
            year = {2017},
        keywords = {ARRAY(0x5568fbabd5a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26740/},
        abstract = {Direct contextual policy search methods learn to improve policy
parameters and simultaneously generalize these parameters
to different context or task variables. However, learning
from high-dimensional context variables, such as camera images,
is still a prominent problem in many real-world tasks.
A naive application of unsupervised dimensionality reduction
methods to the context variables, such as principal component
analysis, is insufficient as task-relevant input may be ignored.
In this paper, we propose a contextual policy search method in
the model-based relative entropy stochastic search framework
with integrated dimensionality reduction. We learn a model of
the reward that is locally quadratic in both the policy parameters
and the context variables. Furthermore, we perform supervised
linear dimensionality reduction on the context variables
by nuclear norm regularization. The experimental results
show that the proposed method outperforms naive dimensionality
reduction via principal component analysis and
a state-of-the-art contextual policy search method.}
}

@article{lincoln25963,
          volume = {5},
           month = {February},
          author = {Jiawei Xu and Shigang Yue and Federica Menchinelli and Kun Guo},
           title = {What has been missed for predicting human attention in viewing driving clips?},
       publisher = {PeerJ},
            year = {2017},
         journal = {PeerJ},
             doi = {10.7717/peerj.2946},
           pages = {e2946},
        keywords = {ARRAY(0x5568fba20320)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25963/},
        abstract = {Recent research progress on the topic of human visual attention allocation in scene perception and its simulation is based mainly on studies with static images. However, natural vision requires us to extract visual information that constantly changes due to egocentric movements or dynamics of the world. It is unclear to what extent spatio-temporal regularity, an inherent regularity in dynamic vision, affects human gaze distribution and saliency computation in visual attention models. In this free-viewing eye-tracking study we manipulated the spatio-temporal regularity of traffic videos by presenting them in normal video sequence, reversed video sequence, normal frame sequence, and randomised frame sequence. The recorded human gaze allocation was then used as the ?ground truth? to examine the predictive ability of a number of state-of-the-art visual attention models. The analysis revealed high inter-observer agreement across individual human observers, but all the tested attention models performed significantly worse than humans. The inferior predictability of the models was evident from indistinguishable gaze prediction irrespective of stimuli presentation sequence, and weak central fixation bias. Our findings suggest that a realistic visual attention model for the processing of dynamic scenes should incorporate human visual sensitivity with spatio-temporal regularity and central fixation bias.}
}

@article{lincoln26731,
          volume = {2},
          number = {2},
           month = {January},
          author = {Takayuki Osa and Amir M. Ghalamzan Esfahani and Rustam Stolkin and Rudolf Lioutikov and Jan Peters and Gerhard Neumann},
           title = {Guiding trajectory optimization by demonstrated distributions},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Robotics and Automation Letters (RA-L)},
             doi = {10.1109/LRA.2017.2653850},
           pages = {819--826},
        keywords = {ARRAY(0x5568fbb8e060)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26731/},
        abstract = {Trajectory optimization is an essential tool for motion
planning under multiple constraints of robotic manipulators.
Optimization-based methods can explicitly optimize a trajectory
by leveraging prior knowledge of the system and have been used
in various applications such as collision avoidance. However, these
methods often require a hand-coded cost function in order to
achieve the desired behavior. Specifying such cost function for
a complex desired behavior, e.g., disentangling a rope, is a nontrivial
task that is often even infeasible. Learning from demonstration
(LfD) methods offer an alternative way to program robot
motion. LfD methods are less dependent on analytical models
and instead learn the behavior of experts implicitly from the
demonstrated trajectories. However, the problem of adapting the
demonstrations to new situations, e.g., avoiding newly introduced
obstacles, has not been fully investigated in the literature. In this
paper, we present a motion planning framework that combines
the advantages of optimization-based and demonstration-based
methods. We learn a distribution of trajectories demonstrated by
human experts and use it to guide the trajectory optimization
process. The resulting trajectory maintains the demonstrated
behaviors, which are essential to performing the task successfully,
while adapting the trajectory to avoid obstacles. In simulated
experiments and with a real robotic system, we verify that our
approach optimizes the trajectory to avoid obstacles and encodes
the demonstrated behavior in the resulting trajectory}
}

@inproceedings{lincoln25919,
       booktitle = {1st Global Power and Propulsion Forum 2017},
           month = {January},
           title = {Model-based compensation of sensor failure in industrial gas turbine},
          author = {Vili Panov and Sepehr Maleki},
       publisher = {Global Power and Propulsion Society},
            year = {2017},
        keywords = {ARRAY(0x5568fba0a2f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25919/},
        abstract = {This study investigates application of analytical sensor
redundancy to improve reliability of gas turbine control
system. Analytical redundancy, which uses a reference
engine model to provide redundant estimates of a measured
engine variables, has been utilized as a basis for the proposed
sensor fault detection and accommodation method.
Model-based compensation of measurement fault is
usually resolved by introducing virtual engine sensors, which
are obtained via accurate engine modelling. In this paper, a
real-time dynamic gas turbine engine model is used in order
to generate the redundant virtual measurements. The engine
model accuracy directly determines the validity of the modelbased
approach for sensor fault diagnosis, and hence a model
with auto-tuning capability is deployed as a reference for the
gas turbine.
The proposed fault detection technique examines the
residuals between the redundant channels. Once the
discrepancy between the virtual and the sensor measurement
exceeds the prescribed tolerance levels, the sensor fault
diagnosis determines the state of the switching logic in the
dual lane control configuration. The deployed logic is also
used for reconfiguration of the auto-tuning process. When a
sensor fault occurs, the estimation process is affected, and
hence the tuning process must be adjusted to account for this
deficiency.
Single and multiple sensor failures are simulated during
the gas turbine transient manoeuvre to assess capability of
the proposed model-based detection and accommodation
method. Hard (large in-range) and soft sensor failures (small
in-range or drift) are injected during the numerical simulation
and results are presented.}
}

@article{lincoln24215,
          volume = {9},
          number = {1},
           month = {January},
          author = {James Kennedy and Paul Baxter and Tony Belpaeme},
           title = {Nonverbal immediacy as a characterisation of social behaviour for human-robot interaction},
       publisher = {Springer},
            year = {2017},
         journal = {International Journal of Social Robotics},
             doi = {10.1007/s12369-016-0378-3},
           pages = {109--128},
        keywords = {ARRAY(0x5568fbb72258)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24215/},
        abstract = {An increasing amount of research has started
to explore the impact of robot social behaviour on the
outcome of a goal for a human interaction partner, such
as cognitive learning gains. However, it remains unclear
from what principles the social behaviour for such robots
should be derived. Human models are often used, but
in this paper an alternative approach is proposed. First,
the concept of nonverbal immediacy from the communication
literature is introduced, with a focus on how it
can provide a characterisation of social behaviour, and
the subsequent outcomes of such behaviour. A literature
review is conducted to explore the impact on learning
of the social cues which form the nonverbal immediacy
measure. This leads to the production of a series
of guidelines for social robot behaviour. The resulting
behaviour is evaluated in a more general context, where
both children and adults judge the immediacy of humans
and robots in a similar manner, and their recall of
a short story is tested. Children recall more of the story
when the robot is more immediate, which demonstrates
an e?ffect predicted by the literature. This study provides
validation for the application of nonverbal immediacy
to child-robot interaction. It is proposed that nonverbal
immediacy measures could be used as a means of
characterising robot social behaviour for human-robot
interaction.}
}

@article{lincoln38410,
          volume = {50},
          number = {12},
          author = {N. Ajmeri and C.-W. Hang and S. Parsons and M.P. Singh},
            note = {cited By 1},
           title = {Aragorn: Eliciting and Maintaining Secure Service Policies},
       publisher = {IEEE},
            year = {2017},
         journal = {Computer},
             doi = {10.1109/MC.2017.4451210},
           pages = {50--58},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38410/},
        abstract = {Services are configured via policies that capture expected behaviors, but stakeholder requirements can change, making policy errors a surprisingly common occurrence. Aragorn applies formal argumentation to produce policies that balance stakeholder concerns.}
}

@article{lincoln38547,
          volume = {36},
          number = {5-7},
          author = {M.Q. Azhar and Elizabeth Sklar},
            note = {cited By 1},
           title = {A study measuring the impact of shared decision making in a human-robot team},
            year = {2017},
         journal = {International Journal of Robotics Research},
             doi = {10.1177/0278364917710540},
           pages = {461--482},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38547/}
}

@inproceedings{lincoln27647,
       booktitle = {IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},
           title = {Automatic detection of human interactions from RGB-D data for social activity classification},
          author = {Claudio Coppola and Serhan Cosar and Diego Faria and Nicola Bellotto},
       publisher = {IEEE},
            year = {2017},
             doi = {10.1109/ROMAN.2017.8172405},
        keywords = {ARRAY(0x5568fb9cc228)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27647/},
        abstract = {We present a system for the temporal detection of social interactions. Many of the works until now have succeeded in recognising activities from clipped videos in datasets, but for robotic applications, it is important to be able to move to more realistic data. For this reason, it is important to be able to detect temporally the intervals of time in which humans are performing an individual activity or a social one. Recognition of the human activities is a key feature for analysing the human behaviour. In particular, recognition of social activities could be useful to trigger human-robot interactions or to detect situations of potential danger. Based on that, this research has three goals: (1) define a new set of descriptors able to represent the phenomena; (2) develop a computational model able to discern the intervals in which a pair of people are interacting or performing individual activities; (3) provide a public dataset with RGB-D videos where social interactions and individual activities happen in a continuous stream. Results show that using the proposed approach allows to reach a good performance in the temporal segmentation of social activities.}
}

@inproceedings{lincoln28779,
       booktitle = {IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)},
           title = {Entropy-based abnormal activity detection fusing RGB-D and domotic sensors},
          author = {Manuel Fernandez-Carmona and Serhan Cosar and Claudio Coppola and Nicola Bellotto},
       publisher = {IEEE},
            year = {2017},
             doi = {10.1109/MFI.2017.8170405},
        keywords = {ARRAY(0x5568fbaa2858)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28779/},
        abstract = {The automatic detection of anomalies in Active and Assisted Living (AAL) environments is important for monitoring the wellbeing and safety of the elderly at home. The integration of smart domotic sensors (e.g. presence detectors) with those ones equipping modern mobile robots (e.g. RGBD camera) provides new opportunities for addressing this challenge. In this paper, we propose a novel solution to combine local activity levels detected by a single RGBD camera with the global activity perceived by a network of domotic sensors. Our approach relies on a new method for computing such a global activity using various presence detectors, based on the concept of entropy from information theory. This entropy effectively shows how active a particular room or environment?s area is. The solution includes also a new application of Hybrid Markov Logic Networks (HMLNs) to merge different information sources for local and global anomaly detection. The system has been tested with RGBD data and a comprehensive domotic dataset containing data entries from 37 different domotic sensors (presence, temperature, light, energy consumption, door contact), which is made publicly available. The experimental results show the effectiveness of our approach and the potential for complex anomaly detection in AAL settings.}
}

@article{lincoln38412,
          volume = {10454},
          author = {Z. Huang and S. Wane and Simon Parsons},
            note = {cited By 3},
           title = {Towards automated strawberry harvesting: Identifying the picking point},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-64107-2{$_1$}{$_8$}},
           pages = {222--236},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38412/}
}

@article{lincoln32866,
          volume = {4},
          number = {1},
          author = {Nazanin Mansouri and Khaled Goher and Seyed Ebrahim Hosseini},
            note = {{\copyright} The Author(s) 2017},
           title = {Ethical framework of assistive devices: review and reflection},
       publisher = {Springer},
            year = {2017},
         journal = {Robotics and Biomimetics},
             doi = {10.1186/s40638-017-0074-2},
        keywords = {ARRAY(0x5568fba72400)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32866/},
        abstract = {The population of ageing is growing significantly over the world, and there is an emerging demand for better healthcare services and more care centres. Innovations of Information and Communication Technology has resulted in development of various types of assistive robots to fulfil elderly?s needs and independency, whilst carrying out daily routine tasks. This makes it vital to have a clear understanding of elderly?s needs and expectations from assistive robots. This paper addresses current ethical issues to understand elderly?s prime needs. Also, we consider other general ethics with the purpose of applying these theories to form a proper ethics framework. In the ethics framework, the ethical concerns of senior citizens will be prioritized to satisfy elderly?s needs and also to diminish related expenses to healthcare services.}
}

@article{lincoln38411,
          volume = {271},
          author = {J. Niu and S. Parsons},
            note = {cited By 0},
           title = {A genetic algorithmic approach to automated auction mechanism design},
       publisher = {Springer},
            year = {2017},
         journal = {Lecture Notes in Business Information Processing},
             doi = {10.1007/978-3-319-54229-4\_9},
           pages = {127--142},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38411/},
        abstract = {In this paper, we present a genetic algorithmic approach to automated auction mechanism design in the context of cat games. This is a follow-up to one piece of our prior work in the domain, the reinforcement learning-based grey-box approach [14]. Our experiments show that given the same search space the grey-box approach is able to produce better auction mechanisms than the genetic algorithmic approach. The comparison can also shed light on the design and evaluation of similar search solutions to other domain problems.}
}

@article{lincoln38548,
          number = {978331},
          author = {J. Raphael and Elizabeth Sklar and S. Maskell},
            note = {cited By 1},
           title = {An intersection-centric auction-based traffic signal control framework},
         journal = {Understanding Complex Systems},
             doi = {10.1007/978-3-319-46331-5\_6},
           pages = {121--142},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38548/}
}

@inproceedings{lincoln39635,
       booktitle = {14th Symposium on Advanced Space Technologies in Robotics and Automation,},
           title = {Robust Traction Control and Path Planning Algorithms for Planetary Micro-rover Swarms},
          author = {C.M. Saaj and H. Ibrahim},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39635/}
}

@article{lincoln38549,
          volume = {10454},
          author = {E. Schneider and Elizabeth Sklar and S. Parsons},
            note = {cited By 2},
           title = {Mechanism selection for multi-robot task allocation},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-64107-2},
           pages = {421--435},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38549/}
}

@article{lincoln38413,
          volume = {10454},
          author = {E. Schneider and Elizabeth Sklar and Simon Parsons},
            note = {cited By 2},
           title = {Mechanism selection for multi-robot task allocation},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-64107-2{$_3$}{$_3$}},
           pages = {421--435},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38413/}
}

@unpublished{lincoln39634,
       booktitle = {14th Symposium on Advanced Space Technologies in Robotics and Automation},
           title = {Optimised collision-free trajectory and controller design for robotic manipulators},
          author = { Seddaoui and C. M Saaj},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39634/}
}

@inproceedings{lincoln29189,
          volume = {2017-A},
          author = {X. Zheng and C. Zhang and F. Lv and F. Zhao and S. Yue and Z. Wang and F. Li and H. Jiang and Z. Wang},
            note = {Conference Code:129634},
       booktitle = {38th Annual Custom Integrated Circuits Conference, CICC 2017},
           title = {A 4-40 Gb/s PAM4 transmitter with output linearity optimization in 65 nm CMOS},
       publisher = {Institute of Electrical and Electronics Engineers Inc.},
             doi = {10.1109/CICC.2017.7993640},
            year = {2017},
        keywords = {ARRAY(0x5568fb9e1170)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29189/},
        abstract = {This paper presents a 4-40 Gb/s current mode PAM4 transmitter with an optimized eye linearity. By embedding an additional mixed combiner and an extra current source into the output driver and developing a coherent scaled-replica based bias generator, the channel-length modulation caused tail-current variations for both DC and AC coupling modes can be effectively compensated. Implemented in 65 nm CMOS, the transmitter occupies an area of 1.02 mm2 and consumes 102 mW at 40 Gb/s. After applying the proposed linearity optimization, the measured eye linearity can be optimized from 1.28 to 1.01 with a single-end swing of 480 mV in AC coupling mode. {\^A}{\copyright} 2017 IEEE.}
}

@article{lincoln38550,
          volume = {10454},
          author = {Tsvetan Zhivkov and Elizabeth Sklar and E. Schneider},
            note = {cited By 2},
           title = {Measuring the effects of communication quality on multi-robot team performance},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-64107-2},
           pages = {408--420},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38550/}
}

@article{lincoln33058,
          volume = {3},
           month = {December},
          author = {Khaled Goher},
            note = {This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.},
           title = {A two-wheeled machine with a handling mechanism in two different directions},
       publisher = {Springer},
            year = {2016},
         journal = {Robotics and Biomimetics},
             doi = {10.1186/s40638-016-0049-8},
           pages = {17},
        keywords = {ARRAY(0x5568fbb08498)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33058/},
        abstract = {Despite the fact that there are various configurations of self-balanced two-wheeled machines (TWMs), the workspace of such systems is restricted by their current configurations and designs. In this work, the dynamic analysis of a novel configuration of TWMs is introduced that enables handling a payload attached to the intermediate body (IB) in two mutually perpendicular directions. This configuration will enlarge the workspace of the vehicle and increase its flexibility in material handling, objects assembly and similar industrial and service robot applications. The proposed configuration gains advantages of the design of serial arms while occupying a minimum space which is unique feature of TWMs. The proposed machine has five degrees of freedoms (DOFs) that can be useful for industrial applications such as pick and place, material handling and packaging. This machine will provide an advantage over other TWMs in terms of the wider workspace and the increased flexibility in service and industrial applications. Furthermore, the proposed design will add additional challenge of controlling the system to compensate for the change of the location of the COM due to performing tasks of handling in multiple directions.}
}

@article{lincoln38414,
          volume = {78},
          number = {3-4},
           month = {December},
          author = {P. Shakarian and G.I. Simari and G. Moores and D. Paulo and Simon Parsons and M.A. Falappa and A. Aleali},
            note = {cited By 7},
           title = {Belief revision in structured probabilistic argumentation: Model and application to cyber security},
            year = {2016},
         journal = {Annals of Mathematics and Artificial Intelligence},
             doi = {10.1007/s10472-015-9483-5},
           pages = {259--301},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38414/}
}

@inproceedings{lincoln25937,
          volume = {abs/16},
           month = {December},
          author = {Heriberto Cuayahuitl and Guillaume Couly and Clement Olalainty},
       booktitle = {NIPS Workshop on Deep Reinforcement Learning},
           title = {Training an interactive humanoid robot using multimodal deep reinforcement learning},
       publisher = {arXiv},
         journal = {CoRR},
            year = {2016},
        keywords = {ARRAY(0x5568fbaedbf8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25937/},
        abstract = {Training robots to perceive, act and communicate using multiple modalities still represents a challenging problem, particularly if robots are expected to learn efficiently from small sets of example interactions. We describe a learning approach as a step in this direction, where we teach a humanoid robot how to play the game of noughts and crosses. Given that multiple multimodal skills can be trained to play this game, we focus our attention to training the robot to perceive the game, and to interact in this game. Our multimodal deep reinforcement learning agent perceives multimodal features and exhibits verbal and non-verbal actions while playing. Experimental results using simulations show that the robot can learn to win or draw up to 98\% of the games. A pilot test of the proposed multimodal system for the targeted game---integrating speech, vision and gestures---reports that reasonable and fluent interactions can be achieved using the proposed approach.}
}

@inproceedings{lincoln30191,
           month = {December},
          author = {Paul Baxter},
       booktitle = {Proceedings of the EUCognition Meeting (European Association for Cognitive Systems) "Cognitive Robot Architectures"},
         address = {Vienna, Austria},
           title = {Solve memory to solve cognition},
       publisher = {CEUR Workshop Proceedings},
           pages = {58--59},
            year = {2016},
        keywords = {ARRAY(0x5568fb9e3790)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30191/},
        abstract = {The foundations of cognition and cognitive behaviour are consistently proposed to be built upon the capability to predict (at various levels of abstraction). For autonomous cognitive agents, this implicitly assumes a foundational role for memory, as a mechanism by which prior experience can be brought to bear in the service of present and future behaviour. In this contribution, this idea is extended to propose that an active process of memory provides the substrate for cognitive processing, particularly when considering it as fundamentally associative and from a developmental perspective. It is in this context that the claim is made that in order to solve the question of cognition, the role and function of memory must be fully resolved.}
}

@inproceedings{lincoln30194,
       booktitle = {Future of Interactive Learning Machines Workshop at NIPS'16},
           month = {December},
           title = {SPARC: an efficient way to combine reinforcement learning and supervised autonomy},
          author = {Emmanuel Senft and Severin Lemaignan and Paul E. Baxter and Tony Belpaeme and   and  },
         address = {Los Angeles, USA},
       publisher = {?},
            year = {2016},
        keywords = {ARRAY(0x5568fbb62438)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30194/},
        abstract = {Shortcomings of reinforcement learning for robot control include the sparsity of the environmental reward function, the high number of trials required before reaching an efficient action policy and the reliance on exploration to gather information about the environment, potentially resulting in undesired actions. These limits can be overcome by adding a human in the loop to provide additional information during the learning phase. In this paper, we propose a novel way to combine human inputs and reinforcement by following the Supervised Progressively Autonomous Robot Competencies (SPARC) approach. We compare this method to the principles of Interactive Reinforcement Learning as proposed by Thomaz and Breazeal. Results from a study involving 40 participants show that using SPARC increases the performance of the learning, reduces the time and number of inputs required for teaching and faces fewer errors during the learning process. These results support the use of SPARC as an efficient method to teach a robot to interact with humans.}
}

@inproceedings{lincoln25935,
          volume = {abs/16},
           month = {December},
          author = {Heriberto Cuayahuitl and Seunghak Yu and Ashley Williamson and Jacob Carse},
       booktitle = {NIPS Workshop on Deep Reinforcement Learning},
           title = {Deep reinforcement learning for multi-domain dialogue systems},
       publisher = {arXiv},
         journal = {CoRR},
            year = {2016},
        keywords = {ARRAY(0x5568fba22940)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25935/},
        abstract = {Standard deep reinforcement learning methods such as Deep Q-Networks (DQN) for multiple tasks (domains) face scalability problems. We propose a method for multi-domain dialogue policy learning---termed NDQN, and apply it to an information-seeking spoken dialogue system in the domains of restaurants and hotels. Experimental results comparing DQN (baseline) versus NDQN (proposed) using simulations report that our proposed method exhibits better scalability and is promising for optimising the behaviour of multi-domain dialogue systems.}
}

@inproceedings{lincoln30195,
       booktitle = {Workshop on Robots for Learning at RoMAN 2016},
           month = {November},
           title = {The Effect of Repeating Tasks on Performance Levels in Mediated Child-Robot Interactions},
          author = {Paul Baxter and James Kennedy and Emily Ashurst and Tony Belpaeme},
         address = {New York, USA},
            year = {2016},
        keywords = {ARRAY(0x5568fb674610)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30195/},
        abstract = {That ?practice makes perfect? is a powerful heuristic for improving performance through repetition. This is widely used in educational contexts, and as such it provides a potentially useful feature for application to child-robot educational interactions. While this effect may intuitively appear to be present, we here describe data to provide evidence in support of this supposition. Conducting a descriptive analysis of data from a wider study, we specifically examine the effect on child performance of repeating a previously performed collaborative task with a peer robot (i.e. not an expert agent), if initial performance is low. The results generally indicate a positive effect on performance through repetition, and a number of other correlation effects that highlight the role of individual differences. This outcome provides evidence for the variable utility of repetition between individuals, but also indicates that this is driven by the individual, which can nevertheless result in performance improvements even in the context of peer-peer interactions with relatively sparse feedback.}
}

@inproceedings{lincoln30196,
       booktitle = {Workshop on Long-Term Child-Robot Interaction at RoMAN 2016},
           month = {November},
           title = {Towards ``Machine-Learnable'' Child-Robot Interactions: the PInSoRo Dataset},
          author = {Severin Lemaignan and James Kennedy and Paul Baxter and Tony Belpaeme},
         address = {New York, USA},
            year = {2016},
        keywords = {ARRAY(0x5568fb9e7ca0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30196/},
        abstract = {Child-robot interactions are increasingly being explored in domains which require longer-term application, such as healthcare and education. In order for a robot to behave in an appropriate manner over longer timescales, its behaviours should be coterminous with that of the interacting children. Generating such sustained and engaging social behaviours is an on-going research challenge, and we argue here that the recent progress of deep machine learning opens new perspectives that the HRI community should embrace. As an initial step in that direction, we propose the creation of a large open dataset of child-robot social interactions. We detail our proposed methodology for data acquisition: children interact with a robot puppeted by an expert adult during a range of playful face-to- face social tasks. By doing so, we seek to capture a rich set of human-like behaviours occurring in natural social interactions, that are explicitly mapped to the robot's embodiment and affordances.}
}

@inproceedings{lincoln25579,
           month = {November},
          author = {Ernest Gyebi and Marc Hanheide and Grzegorz Cielniak},
       booktitle = {Edurobotics 2016},
           title = {The effectiveness of integrating educational robotic activities into higher education Computer Science curricula: a case study in a developing country},
       publisher = {Springer},
             doi = {10.1007/978-3-319-55553-9\_6},
           pages = {73--87},
            year = {2016},
        keywords = {ARRAY(0x5568fb9be3c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25579/},
        abstract = {In this paper, we present a case study to investigate the effects of educational robotics on a formal undergraduate Computer Science education in a developing country. The key contributions of this paper include a longitudinal study design, spanning the whole duration of one taught course, and its focus on continually assessing the effectiveness and the impact of robotic-based exercises. The study assessed the  students' motivation, engagement and level of understanding in learning general computer programming. The survey results indicate that there are benefits which can be gained from such activities and educational robotics is a promising tool in developing engaging study curricula. We hope that our experience from this study together with the free materials and data available for download will be beneficial to other practitioners working with educational robotics in different parts of the world.}
}

@article{lincoln33060,
           month = {November},
          author = {Khaled Goher},
            note = {{\copyright} 2016 The Author(s). This open access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license},
           title = {A reconfigurable wheelchair for mobility and rehabilitation: Design and development},
       publisher = {Cogent},
         journal = {Cogent Engineering},
             doi = {10.1080/23311916.2016.1261502},
            year = {2016},
        keywords = {ARRAY(0x5568fba1b448)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33060/},
        abstract = {This paper presents the design and development of a prototype of a reconfigurable wheelchair for rehabilitation and self-assistance to fit the size of a seven years old child (average 35 kg weight). Though the developed prototype is developed at this stage to fit a child, it can be resized, after considering variations in weight and size, to fit an older adult. The developed prototype has a mechanism that enables the user to transform from sit-to-stand (STS) posture and vice versa. With the help of the developed wheelchair, the user will also be able to adjust the posture of his upper body using an adjustable back support using two linear actuators. This configuration will allow the user to use the wheelchair as a mobility device as well as for rehabilitation purposes without the need of external support. The availability of STS and back adjustment mechanisms will allow the user to do regular exercising which will enhance blood circulation as sitting for long periods inflates lower limbs disability. The proposed configuration will help in enhancing the functional capabilities of end-users allowing for increased independence and ultimately quality of life.}
}

@article{lincoln27915,
          volume = {130},
           month = {November},
          author = {Alessandro Sopegno and Angela Calvo and Remigio Berruto and Patrizia Busato and Dionysis Bochtis},
           title = {A web mobile application for agricultural machinery cost analysis},
       publisher = {Elsevier},
            year = {2016},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2016.08.017},
           pages = {158--168},
        keywords = {ARRAY(0x5568fba883f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27915/},
        abstract = {Machinery cost is the major cost item in farm businesses in highly mechanized production systems. Moreover, in the last years, high power machines, advanced technologies, higher cost for spare parts and repairing, and fuel consumption contributed to an even more higher increase of the machinery costs. Many engineering and economic methodological approaches have been implemented to calculate machinery use and cost, but they are almost confined in scientific and technical documentations making it difficult for a farmer to apply these approaches for deciding on buying, leasing, or sharing agricultural machinery.

Information and communications technology (ICT) has an increasingly important role on business processes and provides a powerful foundation to address many daily problems. Today users want to be connected to useful information in real time. To that effect, the aim of this work was to develop an easy-to-use mobile application, called ?AMACA? (Agricultural Machine App Cost Analysis) for determining the machinery cost in different field operations and making it available via a web mobile application using a cross-platform approach. The customer-driven Quality Function Deployment [QFD] approach was implemented in order to link the user expectations with the design characteristics of the app. The AMACA app is free, readily available, and does not require any installation on the end user?s device. It is a cross-platform application meaning that it operates on any device through a web interface and is supported by various browsers. The user can make subsequent calculations by varying the input parameters (fuel price, interest rate, field capacity, tractor power, etc.) and compare the results in a sensitivity analysis basis. AMACA app can support the decisions on whether to purchase a new equipment/tractor (strategic level), the use of own machinery or to hire a service, and also to select the economical appropriate cultivation system (tactical level).}
}

@article{lincoln23534,
          volume = {28},
          number = {11},
           month = {October},
          author = {Bin Hu and Shigang Yue and Zhuhong Zhang},
           title = {A rotational motion perception neural network base on asymmetric spatiotemporal visual information processing},
       publisher = {IEEE},
            year = {2016},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
             doi = {10.1109/TNNLS.2016.2592969},
           pages = {2803--2821},
        keywords = {ARRAY(0x5568fba5c740)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23534/},
        abstract = {All complex motion patterns can be decomposed into several elements, including translation, expansion/contraction and rotational motion. In biological vision systems, scientists have found specific types of visual neurons have specific preferences to each of the three motion elements. There are computational models on translation and expansion/contraction perception, however, little has been done in the past to create computational models for rotation motion perception. To fill this gap, we proposed a neural network which utilizes a specific spatiotemporal arrangement of asymmetric lateral inhibited directional selective neural networks for rotational motion perception. The proposed neural network consists of two parts - presynaptic and postsynaptic parts. In the presynaptic part, there are a number of lateral inhibited directional selective neural networks to extract directional visual cues. In the postsynaptic part, similar to the arrangement of the directional columns in the cerebral cortex, these directional selective neurons are arranged in a cyclic order to perceive rotational motion cues. In the postsynaptic network, the delayed excitation from each directional selective neuron is multiplied by the gathered excitation from this neuron and its unilateral counterparts depending on which rotation, clockwise or counterclockwise, to perceive. Systematic experiments under various conditions and settings have been carried out and validated the robustness and reliability of the proposed neural network in detecting clockwise or counterclockwise rotational motion. This research is a critical step further towards dynamic visual information processing.}
}

@inproceedings{lincoln25738,
          volume = {2016-N},
           month = {October},
          author = {A. Abdolmaleki and N. Lau and L.P. Reis and G. Neumann},
       booktitle = {Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ International Conference on},
           title = {Non-parametric contextual stochastic search},
            year = {2016},
         journal = {IEEE International Conference on Intelligent Robots and Systems},
             doi = {10.1109/IROS.2016.7759411},
           pages = {2643--2648},
        keywords = {ARRAY(0x5568fba87798)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25738/},
        abstract = {Stochastic search algorithms are black-box optimizer of an objective function. They have recently gained a lot of attention in operations research, machine learning and policy search of robot motor skills due to their ease of use and their generality. Yet, many stochastic search algorithms require relearning if the task or objective function changes slightly to adapt the solution to the new situation or the new context. In this paper, we consider the contextual stochastic search setup. Here, we want to find multiple good parameter vectors for multiple related tasks, where each task is described by a continuous context vector. Hence, the objective function might change slightly for each parameter vector evaluation of a task or context. Contextual algorithms have been investigated in the field of policy search, however, the search distribution typically uses a parametric model that is linear in the some hand-defined context features. Finding good context features is a challenging task, and hence, non-parametric methods are often preferred over their parametric counter-parts. In this paper, we propose a non-parametric contextual stochastic search algorithm that can learn a non-parametric search distribution for multiple tasks simultaneously. In difference to existing methods, our method can also learn a context dependent covariance matrix that guides the exploration of the search process. We illustrate its performance on several non-linear contextual tasks.}
}

@inproceedings{lincoln25737,
          volume = {2016-N},
           month = {October},
          author = {O. Arenz and H. Abdulsamad and G. Neumann},
       booktitle = {Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ International Conference on},
           title = {Optimal control and inverse optimal control by distribution matching},
            year = {2016},
         journal = {IEEE International Conference on Intelligent Robots and Systems},
             doi = {10.1109/IROS.2016.7759596},
           pages = {4046--4053},
        keywords = {ARRAY(0x5568fb712470)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25737/},
        abstract = {Optimal control is a powerful approach to achieve optimal behavior. However, it typically requires a manual specification of a cost function which often contains several objectives, such as reaching goal positions at different time steps or energy efficiency. Manually trading-off these objectives is often difficult and requires a high engineering effort. In this paper, we present a new approach to specify optimal behavior. We directly specify the desired behavior by a distribution over future states or features of the states. For example, the experimenter could choose to reach certain mean positions with given accuracy/variance at specified time steps. Our approach also unifies optimal control and inverse optimal control in one framework. Given a desired state distribution, we estimate a cost function such that the optimal controller matches the desired distribution. If the desired distribution is estimated from expert demonstrations, our approach performs inverse optimal control. We evaluate our approach on several optimal and inverse optimal control tasks on non-linear systems using incremental linearizations similar to differential dynamic programming approaches.}
}

@inproceedings{lincoln23425,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {October},
           title = {Social activity recognition based on probabilistic merging of skeleton features with proximity priors from RGB-D data},
          author = {Claudio Coppola and Diego Faria and Urbano Nunes and Nicola Bellotto},
       publisher = {IEEE},
            year = {2016},
        keywords = {ARRAY(0x5568fbb38358)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23425/},
        abstract = {Social activity based on body motion is a key feature for non-verbal and physical behavior defined as function for communicative signal and social interaction between individuals. Social activity recognition is important to study human-human communication and also human-robot interaction. Based on that, this research has threefold goals: (1) recognition of social behavior (e.g. human-human interaction) using a probabilistic approach that merges spatio-temporal features from individual bodies and social features from the relationship between two individuals; (2) learn priors based on physical proximity between individuals during an interaction using proxemics theory to feed a probabilistic ensemble of classifiers; and (3) provide a public dataset with RGB-D data
of social daily activities including risk situations useful to test approaches for assisted living, since this type of dataset is still missing. Results show that using a modified dynamic Bayesian mixture model designed to merge features with different semantics and also with proximity priors, the proposed framework can correctly recognize social activities in different situations, e.g. using data from one or two individuals.}
}

@inproceedings{lincoln24087,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {October},
           title = {Can you pick a broccoli? 3D-vision based detection and localisation of broccoli heads in the field},
          author = {Keerthy Kusumam and Tomas Krajnik and Simon Pearson and Grzegorz Cielniak and Tom Duckett},
       publisher = {IEEE},
            year = {2016},
        keywords = {ARRAY(0x5568fb6725e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24087/},
        abstract = {This paper presents a 3D vision system for robotic harvesting of broccoli using low-cost RGB-D sensors. The presented method addresses the tasks of detecting mature broccoli heads in the field and providing their 3D locations relative to the vehicle. The paper evaluates different 3D features, machine learning and temporal filtering methods for detection of broccoli heads. Our experiments show that a combination of Viewpoint Feature Histograms, Support Vector Machine classifier and a temporal filter to track the detected heads results in a system that detects broccoli heads with 95.2\% precision. We also show that the temporal filtering can be used to generate a 3D map of the broccoli head positions in the field.}
}

@inproceedings{lincoln24852,
       booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {October},
           title = {Towards automated system and experiment reproduction in robotics},
          author = {Florian Lier and Marc Hanheide and Lorenzo Natale and Simon Schulz and Jonathan Weisz and Sven Wachsmuth and Sebastian Wrede},
            year = {2016},
        keywords = {ARRAY(0x5568fb9c4d28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24852/},
        abstract = {Even though research on autonomous robots and
human-robot interaction accomplished great progress in recent
years, and reusable soft- and hardware components are
available, many of the reported findings are only hardly
reproducible by fellow scientists. Usually, reproducibility is
impeded because required information, such as the specification
of software versions and their configuration, required data sets,
and experiment protocols are not mentioned or referenced
in most publications. In order to address these issues, we
recently introduced an integrated tool chain and its underlying
development process to facilitate reproducibility in robotics.
In this contribution we instantiate the complete tool chain in
a unique user study in order to assess its applicability and
usability. To this end, we chose three different robotic systems
from independent institutions and modeled them in our tool
chain, including three exemplary experiments. Subsequently,
we asked twelve researchers to reproduce one of the formerly
unknown systems and the associated experiment. We show that
all twelve scientists were able to replicate a formerly unknown
robotics experiment using our tool chain.}
}

@inproceedings{lincoln24088,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots ans Systems (IROS)},
           month = {October},
           title = {Persistent localization and life-long mapping in changing environments using the frequency map enhancement},
          author = {Jaime Pulido Fentanes and Tomas Krajnik and Marc Hanheide and Tom Duckett},
       publisher = {IEEE},
            year = {2016},
             doi = {10.1109/IROS.2016.7759671},
        keywords = {ARRAY(0x5568fba66208)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24088/},
        abstract = {We present a lifelong mapping and localisation system for long-term autonomous operation of mobile robots in changing environments.
The core of the system is a spatio-temporal occupancy grid that explicitly represents the persistence and periodicity of the individual cells and can predict the probability of their occupancy in the future.
During navigation, our robot builds temporally local maps and integrates then into the global spatio-temporal grid. Through re-observation of the same locations, the spatio-temporal grid learns the long-term environment dynamics and gains the ability to predict the future environment states. This predictive ability allows to generate time-specific 2d maps  used by the robot's localisation and planning modules. By analysing data from a long-term deployment of the robot in a human-populated environment, we show that the proposed  representation improves localisation accuracy and the efficiency of path planning. We also show how to integrate the method into the ROS navigation stack for use by other roboticists.}
}

@inproceedings{lincoln24589,
       booktitle = {2016 International Conference on Indoor Positioning and Indoor Navigation (IPIN), 4-7 October 2016, Alcal{\'a} de Henares, Spain},
           month = {October},
           title = {Indoor positioning of shoppers using a network of bluetooth low energy beacons},
          author = {Patrick Dickinson and Olivier Szymanezyk and Grzegorz Cielniak and Mike Mannion},
       publisher = {IEEE Xplore},
            year = {2016},
        keywords = {ARRAY(0x5568fba4b680)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24589/},
        abstract = {In this paper we present our work on the indoor positioning of users (shoppers), using a network of Bluetooth Low Energy (BLE) beacons deployed in a large wholesale shopping store. Our objective is to accurately determine which product sections a user is adjacent to while traversing the store, using RSSI readings from multiple beacons, measured asynchronously on a standard commercial mobile device. We further wish to leverage the store layout (which imposes natural constraints on the movement of users) and the physical configuration of the beacon network, to produce a robust and efficient solution. We start by describing our application context and hardware configuration, and proceed to introduce our node-graph model of user location. We then describe our experimental work which begins with an investigation of signal characteristics along and across aisles. We propose three methods of localization, using a ?nearest-beacon? approach as a base-line; exponentially averaged weighted range estimates; and a particle-filter method based on the RSSI attenuation model and Gaussian-noise. Our results demonstrate that the particle filter method significantly out-performs the others. Scalability also makes this method ideal for applications run on mobile devices with more limited computational capabilities}
}

@article{lincoln46193,
          volume = {2016},
           month = {September},
          author = {Marcello Calisti and Cecilia Laschi},
       booktitle = {Advances in Cooperative Robotics: Proceedings of the 19th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2016},
           title = {From Octopus vulgaris to underwater hopping robots: Bio-inspired path toward design and control of soft robots},
         journal = {Advances in Cooperative Robotics},
             doi = {10.1142/9789813149137\_0088},
            year = {2016},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46193/},
        abstract = {{\copyright}2016, World Scientific Publishing Co. Pte Ltd. All rights reserved. In this paper we present an octopus-inspired approach to the design and control of soft robots locomotion. We used the biological model as a reference to draw the conceptual design of our soft robots, and we showed how actuation strategy and mechanical design are properly coupled, in the animal as well in our robots, to simplify the control of locomotion. Finally, building upon our bioinspired solutions, we tried to exploit the water environment and the morphing soft body to increase behavioral diversity and locomotion stability of our soft vehicles.}
}

@article{lincoln25739,
          volume = {104},
          number = {2-3},
           month = {September},
          author = {C. Daniel and H. van Hoof and J. Peters and G. Neumann},
           title = {Probabilistic inference for determining options in reinforcement learning},
       publisher = {Springer},
            year = {2016},
         journal = {Machine Learning},
             doi = {10.1007/s10994-016-5580-x},
           pages = {337--357},
        keywords = {ARRAY(0x5568fbb4a7c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25739/},
        abstract = {Tasks that require many sequential decisions or complex solutions are hard to solve using conventional reinforcement learning algorithms. Based on the semi Markov decision process setting (SMDP) and the option framework, we propose a model which aims to alleviate these concerns. Instead of learning a single monolithic policy, the agent learns a set of simpler sub-policies as well as the initiation and termination probabilities for each of those sub-policies. While existing option learning algorithms frequently require manual specification of components such as the sub-policies, we present an algorithm which infers all relevant components of the option framework from data. Furthermore, the proposed approach is based on parametric option representations and works well in combination with current policy search methods, which are particularly well suited for continuous real-world tasks. We present results on SMDPs with discrete as well as continuous state-action spaces. The results show that the presented algorithm can combine simple sub-policies to solve complex tasks and can improve learning performance on simpler tasks.}
}

@article{lincoln46165,
          volume = {3},
           month = {September},
          author = {Marcello Calisti and Matteo Cianchetti and Mariangela Manti and Francesco Corucci and Cecilia Laschi},
           title = {Contest-Driven Soft-Robotics Boost: The RoboSoft Grand Challenge},
         journal = {Frontiers in Robotics and AI},
             doi = {10.3389/frobt.2016.00055},
           pages = {55},
            year = {2016},
        keywords = {ARRAY(0x5568fbb972d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46165/},
        abstract = {This paper reports the design process, the implementation, and the results of a novel robotic contest addressing soft robots, named RoboSoft Grand Challenge. Application-oriented tasks were proposed in three different scenarios where soft robotics is particularly lively: manipulation, terrestrial, and underwater locomotion. Starting from about 60 expressions of interest submitted by international teams distributed across the world, 19 robots were eventually selected to participate in the challenge in two of the initially proposed scenarios, i.e., manipulation and terrestrial locomotion. Results highlight both the effectiveness and limitations of state of the art soft robots with respect to the selected tasks. The paper will also focus on some of the advantages and disadvantages of contests as technology-steering mechanisms, including what we called ?reductionist design,? a phenomenon in which simplistic solutions are devised to purposely tackle the proposed tasks, possibly hindering more general and desired technological advancements.}
}

@incollection{lincoln46157,
          volume = {17},
           month = {September},
          author = {Marcello Calisti},
       booktitle = {Soft Robotics: Trends, Applications and Challenges},
           title = {Soft Robotics in Underwater Legged Locomotion: From Octopus?Inspired Solutions to Running Robots},
       publisher = {Springer},
            year = {2016},
             doi = {10.1007/978-3-319-46460-2\_5},
           pages = {31--36},
        keywords = {ARRAY(0x5568fb6d4a48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46157/},
        abstract = {This chapter reports on the conceptual design of an octopus-inspired robot. The investigation started from slow speed gaits, such as the crawling locomotion of octopuses, and was followed by faster gaits such as bipedal walking and hopping. Results envisage that this novel locomotion can be exploited to increase the mobility of underwater robots in the benthic realm.}
}

@inproceedings{lincoln24941,
       booktitle = {27th British Machine Vision Conference},
           month = {September},
           title = {Bio-inspired collision detector with enhanced selectivity for ground robotic vision system},
          author = {Qinbing Fu and Shigang Yue and Cheng Hu},
            year = {2016},
        keywords = {ARRAY(0x5568fbb77c90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24941/},
        abstract = {There are many ways of building collision-detecting systems. In this paper, we propose a novel collision selective visual neural network inspired by LGMD2 neurons in the juvenile locusts. Such collision-sensitive neuron matures early in the ?rst-aged or even hatching locusts, and is only selective to detect looming dark objects against bright background in depth, represents swooping predators, a situation which is similar to ground robots or vehicles. However, little has been done on modeling LGMD2, let alone its potential applications in robotics and other vision-based areas. Compared to other collision detectors, our major contributions are ?rst, enhancing the collision selectivity in a bio-inspired way, via constructing a computing ef?cient visual sensor, and realizing the revealed speci?c characteristic sofLGMD2. Second, we applied the neural network to help rearrange path navigation of an autonomous ground miniature robot in an arena. We also examined its neural properties through systematic experiments challenged against image streams from a visual sensor of the micro-robot.}
}

@inproceedings{lincoln23189,
       booktitle = {IEEE International Conference on Intelligent Environments},
           month = {September},
           title = {On-line inference comparison with Markov Logic Network engines for activity recognition in AAL environments},
          author = {Manuel Fernandez-Carmona and Nicola Bellotto},
       publisher = {IEEE},
            year = {2016},
        keywords = {ARRAY(0x5568fb9d0760)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23189/},
        abstract = {We address possible solutions for a practical application of Markov Logic Networks to online activity recognition, based on domotic sensors, to be used for monitoring elderly with mild cognitive impairments. Our system has to provide responsive information about user activities throughout the day, so different inference engines are tested. We use an abstraction layer to gather information from commercial domotic sensors.  Sensor events are stored using a non-relational database. Using this database, evidences are built to query a logic network about current activities. Markov Logic Networks are able to deal with uncertainty while keeping a structured knowledge. This makes them a suitable tool for ambient sensors based inference. However, in their previous application, inferences are usually made offline. Time is a relevant constrain in our system and hence logic networks are designed here accordingly. We compare in this work different engines to model a Markov Logic Network suitable for such circumstances. Results show some insights about how to design a low latency logic network and which kind of solutions should be avoided.}
}

@inproceedings{lincoln23298,
       booktitle = {International Workshop on Intelligent Environments Supporting Healthcare and Well-being (WISHWell)},
           month = {September},
           title = {RFID-based Object Localisation with a Mobile Robot to Assist the Elderly with Mild Cognitive Impairments},
          author = {George Broughton and Tomas Krajnik and Manuel Fernandez-carmona and Grzegorz Cielniak and Nicola Bellotto},
            year = {2016},
        keywords = {ARRAY(0x5568fba0aa88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23298/},
        abstract = {Mild Cognitive Impairments (MCI) disrupt the quality of life and reduce the independence of many elderly at home. People with MCI can increasingly become forgetful, hence solutions to help them ?finding lost objects are useful. This paper presents a framework for mobile robots to localise objects in a domestic environment using Radio Frequency Identification (RFID) technology. In particular, it describes the development of a new library for interacting with RFID readers, readily available for the Robot Operating System (ROS), and introduces some methods for its application to RFID-based object localisation with a single antenna. The framework adopts occupancy grids to create a probabilistic representations of tags location in the environment. A robot traversing the environment can then make use of this framework to keep an internal record of where objects were last spotted, and where they are most likely to be at any given point in time. Some preliminary results are presented, together with directions for future research.}
}

@book{lincoln33063,
           month = {September},
           title = {Assistive Robotic and ethical Norms: State of the Art Survey},
          author = {Nazanin Mansouri and Khaled Goher},
       publisher = {World Scientific},
            year = {2016},
            note = {The final version of this article can be purchased online at https://www.worldscientific.com/doi/abs/10.1142/9789813149137\_0073},
        keywords = {ARRAY(0x5568fbb97318)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33063/},
        abstract = {Over the past decades, autonomous robots have embedded themselves into human lives in various forms. Although there have been limited number of research studies in this discipline, yet the results of scholars? studies reveal that humans especially older adults and people with disabilities have benefited from the use of robots in their daily lives. Over the next decades, number of elderly will be growing; therefore, there will be a high demand for assistive robots to enhance mobility and promote independence. The topic to what extend assistive robots should be empowered in daily life is of great concern in robotic discipline. Robot ethics have a dominant role in forming norms for design, use, disposal, and deployment of assistive robots. This paper reviews design ethics of assistive and autonomous medical robot for elderly and disabled.}
}

@incollection{lincoln27950,
           month = {September},
          author = {Xuqiang Zheng and Chun Zhang and Fangxu Lv and Feng Zhao and Shigang Yue and Ziqiang Wang and Fule Li and Zhihua Wang},
            note = {{\copyright}2016 IEEE},
       booktitle = {ESSCIRC Conference 2016: 42nd European Solid-State Circuits Conference},
           title = {A 5-50 Gb/s quarter rate transmitter with a 4-tap multiple-MUX based FFE in 65 nm CMOS},
       publisher = {IEEE},
            year = {2016},
             doi = {10.1109/ESSCIRC.2016.7598303},
           pages = {305--308},
        keywords = {ARRAY(0x5568fb686998)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27950/},
        abstract = {This paper presents a 5-50 Gb/s quarter-rate transmitter with a 4-tap feed-forward equalization (FFE) based on multiple-multiplexer (MUX). A bandwidth enhanced 4:1 MUX with the capability of eliminating charge-sharing effect is proposed to increase the maximum operating speed. To produce the quarter-rate parallel data streams with appropriate delays, a compact latch array associated with an interleaved-retiming technique is designed. Implemented in 65 nm CMOS technology, the transmitter occupying an area of 0.6 mm2 achieves a maximum data rate of 50 Gb/s with an energy efficiency of 3.1 pJ/bit.}
}

@article{lincoln25745,
          volume = {83},
          number = {3},
           month = {September},
          author = {Abbas Abdolmaleki and Nuno Lau and Luis Paulo Reis and Jan Peters and Gerhard Neumann},
           title = {Contextual policy search for linear and nonlinear generalization of a humanoid walking controller},
       publisher = {Springer},
            year = {2016},
         journal = {Journal of Intelligent and Robotic Systems: Theory and Applications},
             doi = {10.1007/s10846-016-0347-y},
           pages = {393--408},
        keywords = {ARRAY(0x5568fb9d8aa8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25745/},
        abstract = {We investigate learning of flexible robot locomotion controllers, i.e., the controllers should be applicable for multiple contexts, for example different walking speeds, various slopes of the terrain or other physical properties of the robot. In our experiments, contexts are desired walking linear speed of the gait. Current approaches for learning control parameters of biped locomotion controllers are typically only applicable for a single context. They can be used for a particular context, for example to learn a gait with highest speed, lowest energy consumption or a combination of both. The question of our research is, how can we obtain a flexible walking controller that controls the robot (near) optimally for many different contexts? We achieve the desired flexibility of the controller by applying the recently developed contextual relative entropy policy search(REPS) method which generalizes the robot walking controller for different contexts, where a context is described by a real valued vector. In this paper we also extend the contextual REPS algorithm to learn a non-linear policy instead of a linear policy over the contexts which call it RBF-REPS as it uses Radial Basis Functions. In order to validate our method, we perform three simulation experiments including a walking experiment using a simulated NAO humanoid robot. The robot learns a policy to choose the controller parameters for a continuous set of forward walking speeds.}
}

@article{lincoln25371,
          volume = {63},
          number = {9},
           month = {September},
          author = {Xuqiang Zheng and Zhijun Wang and Fule Li and Feng Zhao and Shigang Yue and Chun Zhang and Zhihua Wang},
           title = {A 14-bit 250 MS/s IF sampling pipelined ADC in 180 nm CMOS process},
       publisher = {IEEE},
            year = {2016},
         journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
             doi = {10.1109/TCSI.2016.2580703},
           pages = {1381--1392},
        keywords = {ARRAY(0x5568fbb6d048)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25371/},
        abstract = {This paper presents a 14-bit 250 MS/s ADC fabricated
in a 180 nm CMOS process, which aims at optimizing its
linearity, operating speed, and power efficiency. The implemented
ADC employs an improved SHA with parasitic optimized bootstrapped
switches to achieve high sampling linearity over a wide
input frequency range. It also explores a dedicated foreground
calibration to correct the capacitor mismatches and the gain
error of residue amplifier, where a novel configuration scheme
with little cost for analog front-end is developed. Moreover, a
partial non-overlapping clock scheme associated with a highspeed
reference buffer and fast comparators is proposed to
maximize the residue settling time. The implemented ADC is
measured under different input frequencies with a sampling rate
of 250 MS/s and it consumes 300 mW from a 1.8 V supply. For 30
MHz input, the measured SFDR and SNDR of the ADC is 94.7
dB and 68.5 dB, which can remain over 84.3 dB and 65.4 dB for
up to 400 MHz. The measured DNL and INL after calibration
are optimized to 0.15 LSB and 1.00 LSB, respectively, while the
Walden FOM at Nyquist frequency is 0.57 pJ/step.}
}

@inproceedings{lincoln23297,
       booktitle = {European Conference  on Artificial Intelligence (ECAI)},
           month = {August},
           title = {Learning temporal context for activity recognition},
          author = {Claudio Coppola and Tomas Krajnik and Tom Duckett and Nicola Bellotto},
       publisher = {IOS Press},
            year = {2016},
           pages = {107--115},
        keywords = {ARRAY(0x5568fb966ca0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23297/},
        abstract = {We investigate how incremental learning of long-term human activity patterns improves the accuracy of activity classification over time. Rather than trying to improve the classification methods themselves, we assume that they can take into account prior probabilities of activities occurring at a particular time. We use the classification results to build temporal models that can provide these priors to the classifiers. As our system gradually learns about typical patterns of human activities, the accuracy of activity classification improves, which results in even more accurate priors. Two datasets collected over several months containing hand-annotated activity in residential and office environments were chosen to evaluate the approach. Several types of temporal models were evaluated for each of these datasets. The results indicate that incremental learning of daily routines leads to a significant improvement in activity classification.}
}

@inproceedings{lincoln27957,
           month = {August},
          author = {Christian Dondrup and Marc Hanheide},
       booktitle = {2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},
           title = {Qualitative constraints for human-aware robot navigation using Velocity Costmaps},
       publisher = {IEEE},
             doi = {10.1109/ROMAN.2016.7745177},
           pages = {586--592},
            year = {2016},
        keywords = {ARRAY(0x5568fb67b448)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27957/},
        abstract = {In this work, we propose the combination of a state-of-the-art sampling-based local planner with so-called Velocity Costmaps to achieve human-aware robot navigation. Instead of introducing humans as ?special obstacles? into the representation of the environment, we restrict the sample space of a ?Dynamic Window Approach? local planner to only allow trajectories based on a qualitative description of the future unfolding of the encounter. To achieve this, we use a Bayesian temporal model based on a Qualitative Trajectory Calculus to represent the mutual navigation intent of human and robot, and translate these descriptors into sample space constraints for trajectory generation. We show how to learn these models from demonstration and evaluate our approach against standard Gaussian cost models in simulation and in real-world using a non-holonomic mobile robot. Our experiments show that our approach exceeds the performance and safety of the Gaussian models in pass-by and path crossing situations.}
}

@inproceedings{lincoln27949,
       booktitle = {2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
           month = {August},
           title = {An algorithm for accurate needle orientation},
          author = {Yifan Yang and Amr Ahmed and Shigang Yue and Xiang Xie and Hong Chen and Zhihua Wang},
            year = {2016},
           pages = {5095--5098},
             doi = {10.1109/EMBC.2016.7591873},
        keywords = {ARRAY(0x5568fbbbd4b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27949/},
        abstract = {For the early diagnosis and treatment, a needle insertion for biopsy and treatment is a common and important means. To solve the low accuracy and high probability of repeat surgery in traditional surgical procedures, a computer-assisted system is an effective solution. In such a system, how to acquire the accurate orientation of the surgical needle is one of the most important factors. This paper proposes a ?Center Point Method? for needle axis extraction with high accuracy. The method makes full use of edge points from two sides of the needle in image and creates center points through which an accurate axis is extracted. Experiments show that the proposed method improves needle orientation accuracy by approximately 70\% compared to related work in binocular stereovision system.}
}

@article{lincoln22203,
          volume = {28},
          number = {5},
           month = {August},
          author = {Danijel Sko{\v c}aj and Alen Vre{\v c}ko and Marko Mahni{\v c} and Miroslav Jan{\'i}{\v c}ek and Geert-Jan M Kruijff and Marc Hanheide and Nick Hawes and Jeremy L Wyatt and Thomas Keller and Kai Zhou and Michael Zillich and Matej Kristan},
           title = {An integrated system for interactive continuous learning of categorical knowledge},
       publisher = {Taylor \& Francis: STM, Behavioural Science and Public Health Titles},
            year = {2016},
         journal = {Journal of Experimental \& Theoretical Artificial Intelligence},
             doi = {10.1080/0952813X.2015.1132268},
           pages = {823--848},
        keywords = {ARRAY(0x5568fbb99270)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22203/},
        abstract = {This article presents an integrated robot system capable of interactive learning in dialogue with a human. Such a system needs to have several competencies and must be able to process different types of representations. In this article, we describe a collection of mechanisms that enable integration of heterogeneous competencies in a principled way. Central to our design is the creation of beliefs from visual and linguistic information, and the use of these beliefs for planning system behaviour to satisfy internal drives. The system is able to detect gaps in its knowledge and to plan and execute actions that provide information needed to fill these gaps. We propose a hierarchy of mechanisms which are capable of engaging in different kinds of learning interactions, e.g. those initiated by a tutor or by the system itself. We present the theory these mechanisms are build upon and an instantiation of this theory in the form of an integrated robot system. We demonstrate the operation of the system in the case of learning conceptual models of objects and their visual properties.}
}

@inproceedings{lincoln27956,
       booktitle = {2016 International Joint Conference on Neural Networks (IJCNN)},
           month = {July},
           title = {Bio-inspired small target motion detector with a new lateral inhibition mechanism},
          author = {Hongxin Wang and Jigen Peng and Shigang Yue},
            year = {2016},
           pages = {4751--4758},
             doi = {10.1109/IJCNN.2016.7727824},
        keywords = {ARRAY(0x5568fba4f828)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27956/},
        abstract = {In nature, it is an important task for animals to detect small targets which move within cluttered background. In recent years, biologists have found that a class of neurons in the lobula complex, called STMDs (small target motion detectors) which have extreme selectivity for small targets moving within visual clutter. At the same time, some researchers assert that lateral inhibition plays an important role in discriminating the motion of the target from the motion of the background, even account for many features of the tuning of higher order visual neurons. Inspired by the finding that complete lateral inhibition can only be seen when the motion of the central region is identical to the motion of the peripheral region, we propose a new lateral inhibition mechanism combined with motion velocity and direction to improve the performance of ESTMD model (elementary small target motion detector). In this paper, we will elaborate on the biological plausibility and functionality of this new lateral inhibition mechanism in small target motion detection.}
}

@inproceedings{lincoln27954,
       booktitle = {2016 International Joint Conference on Neural Networks (IJCNN)},
           month = {July},
           title = {Visual pattern recognition using unsupervised spike timing dependent plasticity learning},
          author = {Daqi Liu and Shigang Yue},
            year = {2016},
           pages = {285--292},
             doi = {10.1109/IJCNN.2016.7727210},
        keywords = {ARRAY(0x5568fbaf8a38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27954/},
        abstract = {Neuroscience study shows mammalian brain only use millisecond scale time window to process complicated real-life recognition scenarios. However, such speed cannot be achieved by traditional rate-based spiking neural network (SNN). Compared with spiking rate, the specific spiking timing (also called spiking pattern) may convey much more information. In this paper, by using modified rank order coding scheme, the generated absolute analog features have been encoded into the first spike wave with specific spatiotemporal structural information. An intuitive yet powerful feed-forward spiking neural network framework has been proposed, along with its own unsupervised spike-timing-dependent plasticity (STDP) learning rule with dynamic post-synaptic potential threshold. Compared with other state-of-art spiking algorithms, the proposed method uses biologically plausible STDP learning method to learn the selectivity while the dynamic post-synaptic potential threshold guarantees no training sample will be ignored during the learning procedure. Furthermore, unlike the complicated frameworks used in those state-of-art spiking algorithms, the proposed intuitive spiking neural network is not time-consuming and quite capable of on-line learning. A satisfactory experimental result has been achieved on classic MNIST handwritten character database.}
}

@inproceedings{lincoln27955,
           month = {July},
          author = {Guopeng Zhang and Chun Zhang and Shigang Yue},
       booktitle = {2016 International Joint Conference on Neural Networks (IJCNN)},
           title = {LGMD and DSNs neural networks integration for collision predication},
       publisher = {IEEE},
             doi = {10.1109/IJCNN.2016.7727330},
           pages = {1174--1179},
            year = {2016},
        keywords = {ARRAY(0x5568fbadae28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27955/},
        abstract = {An ability to predict collisions is essential for current vehicles and autonomous robots. In this paper, an integrated collision predication system is proposed based on neural subsystems inspired from Lobula giant movement detector (LGMD) and directional selective neurons (DSNs) which focus on different part of the visual field separately. The two type of neurons found in the visual pathways of insects respond most strongly to moving objects with preferred motion patterns, i.e., the LGMD prefers looming stimuli and DSNs prefer specific lateral movements. We fuse the extracted information by each type of neurons to make final decision. By dividing the whole field of view into four regions for each subsystem to process, the proposed approaches can detect hazardous situations that had been difficult for single subsystem only. Our experiments show that the integrated system works in most of the hazardous scenarios.}
}

@inproceedings{lincoln25679,
           month = {July},
          author = {A. Abdolmaleki and N. Lau and L. Paulo Reis and G. Neumann},
       booktitle = {Genetic and Evolutionary Computation Conference GECCO 2016},
           title = {Contextual stochastic search},
       publisher = {ACM},
             doi = {10.1145/2908961.2909012},
           pages = {29--30},
            year = {2016},
        keywords = {ARRAY(0x5568fbbbd3b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25679/},
        abstract = {Stochastic search algorithms have recently also gained a lot of attention in operations research, machine learning and policy search of robot motor skills due to their ease of use and their generality. Yet, many stochastic search algorithms require relearning if the task changes slightly to adapt the solution to the new situation or the new context. Therefore we consider the contextual stochastic search setup. Here, we want to find good parameter vectors for multiple related tasks, where each task is described by a continuous context vector. Hence, the objective might change slightly for each parameter vector evaluation. In this research, we investigate the contextual stochastic search algorithms that can learn from multiple tasks simultaneously.}
}

@inproceedings{lincoln22704,
       booktitle = {15th International Conference on Computers Helping People with Special Needs (ICCHP 2016)},
           month = {July},
           title = {EnrichMe: a robotic solution for independence and active aging of elderly people with MCI},
          author = {Claudia Salatino and Valerio Gower and Meftah Ghrissi and Adriana Tapus and K Wieczorowska-Tobis and A Suwalska and Paolo Barattini and Roberto Rosso and Giulia Munaro and Nicola Bellotto and Herjan van den Heuvel},
            year = {2016},
        keywords = {ARRAY(0x5568fbbb7518)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22704/},
        abstract = {Mild cognitive impairment (MCI) is a state related to ageing, and sometimes evolves to dementia. As there is no pharmacological treatment for MCI, a non-pharmacological approach is very important. The use of Information and Communication Technologies (ICT) in care and assistance services for elderly people increases their chances of prolonging independence thanks to better cognitive efficiency. Robots are seen to have the potential to support the care and independence of elderly people. The project ENRICHME (funded by the EU H2020 Programme) focuses on developing and testing technologies for supporting elderly people with MCI in their living environment for a long time. This paper describes the results of the activities conducted during the first year of the ENRICHME project, in particular the definition of user needs and requirements and the resulting system architecture.}
}

@inproceedings{lincoln24853,
       booktitle = {29th International Workshop on Qualitative Reasoning (QR16), at IJCAI-16},
           month = {July},
           title = {QSRlib: a software library for online acquisition of qualitative spatial relations from video},
          author = {Y. Gatsoulis and M. Alomari and C. Burbridge and C. Dondrup and P. Duckworth and P. Lightbody and M. Hanheide and N. Hawes and D. C. Hogg and A. G. Cohn},
            year = {2016},
        keywords = {ARRAY(0x5568fbb94210)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24853/},
        abstract = {There is increasing interest in using Qualitative Spatial
Relations as a formalism to abstract from noisy and
large amounts of video data in order to form high level
conceptualisations, e.g. of activities present in video.
We present a library to support such work. It is compatible
with the Robot Operating System (ROS) but can
also be used stand alone. A number of QSRs are built
in; others can be easily added.}
}

@inproceedings{lincoln27953,
       booktitle = {2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
           month = {July},
           title = {A guided filtering and HCT integrated pansharpening method for WorldView-2 satellite images},
          author = {Weifeng Qi and Xu Li and Shigang Yue},
            year = {2016},
           pages = {7272--7275},
             doi = {10.1109/IGARSS.2016.7730896},
        keywords = {ARRAY(0x5568fbba6cd8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27953/},
        abstract = {Pansharpening has been an important tool in remote sensing field, which is a process of providing multispectral images with higher spatial resolution. When dealing with WorldView-2 satellite imagery having more bands and higher resolution, most existing methods are not effective. In this paper, we propose a novel and effective pansharpening methods combing guided filtering and hyperspherical color transformation (HCT) for WorldView-2 images. We use panchromatic image as the guidance to further refine the intensity of multispectral data and also to extract the sufficient details from the panchromatic image itself. Moreover, the guided filtering and HCT integrated scheme can inject the extracted details into the multispectral data and the multispectral images can be sharpened all at once with an arbitrary order. The experimental results show that our proposed method can obtain high-quality pansharpened results and outperforms some existing methods.}
}

@article{lincoln22698,
          volume = {1},
          number = {2},
           month = {July},
          author = {Joao Machado Santos and Tomas Krajnik and Jaime Pulido Fentanes and Tom Duckett},
           title = {Lifelong information-driven exploration to complete and refine 4-D spatio-temporal maps},
       publisher = {IEEE},
            year = {2016},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2016.2516594},
           pages = {684--691},
        keywords = {ARRAY(0x5568fba8d0f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22698/},
        abstract = {This paper presents an exploration method that allows
mobile robots to build and maintain spatio-temporal models
of changing environments. The assumption of a perpetuallychanging
world adds a temporal dimension to the exploration
problem, making spatio-temporal exploration a never-ending,
life-long learning process. We address the problem by application
of information-theoretic exploration methods to spatio-temporal
models that represent the uncertainty of environment states as
probabilistic functions of time. This allows to predict the potential
information gain to be obtained by observing a particular area
at a given time, and consequently, to decide which locations to
visit and the best times to go there.
To validate the approach, a mobile robot was deployed
continuously over 5 consecutive business days in a busy office
environment. The results indicate that the robot?s ability to spot
environmental changes im}
}

@article{lincoln23735,
          volume = {32},
          number = {3},
           month = {June},
          author = {Cai-Hua Xiong and Wen-Rui Chen and Bai-Yang Sun and Ming-Jin Liu and Shigang Yue and Wen-Bin Chen},
           title = {Design and implementation of an anthropomorphic hand for replicating human grasping functions},
       publisher = {Institute of Electrical and Electronics Engineers Inc.},
            year = {2016},
         journal = {IEEE Transactions on Robotics},
             doi = {10.1109/TRO.2016.2558193},
           pages = {652--671},
        keywords = {ARRAY(0x5568fba1a8a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23735/},
        abstract = {How to design an anthropomorphic hand with a few actuators to replicate the grasping functions of the human hand is still a challenging problem. This paper aims to develop a general theory for designing the anthropomorphic hand and endowing the designed hand with natural grasping functions. A grasping experimental paradigm was set up for analyzing the grasping mechanism of the human hand in daily living. The movement relationship among joints in a digit, among digits in the human hand, and the postural synergic characteristic of the fingers were studied during the grasping. The design principle of the anthropomorphic mechanical digit that can reproduce the digit grasping movement of the human hand was developed. The design theory of the kinematic transmission mechanism that can be embedded into the palm of the anthropomorphic hand to reproduce the postural synergic characteristic of the fingers by using a limited number of actuators is proposed. The design method of the anthropomorphic hand for replicating human grasping functions was formulated. Grasping experiments are given to verify the effectiveness of the proposed design method of the anthropomorphic hand. {\^A}{\copyright} 2016 IEEE.}
}

@inproceedings{lincoln25747,
          volume = {6},
           month = {June},
          author = {R. Akrour and A. Abdolmaleki and H. Abdulsamad and G. Neumann},
       booktitle = {33rd International Conference on Machine Learning},
           title = {Model-free trajectory optimization for reinforcement learning},
         journal = {33rd International Conference on Machine Learning, ICML 2016},
           pages = {4342--4352},
            year = {2016},
        keywords = {ARRAY(0x5568fb6b8728)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25747/},
        abstract = {Many of the recent Trajectory Optimization algorithms alternate between local approximation of the dynamics and conservative policy update.
However, linearly approximating the dynamics in order to derive the new policy can bias the update and prevent convergence to the optimal policy.
In this article, we propose a new model-free algorithm that backpropagates a local quadratic time-dependent Q-Function, allowing the derivation
of the policy update in closed form. Our policy update ensures exact KL-constraint satisfaction without simplifying assumptions on the system
dynamics demonstrating improved performance in comparison to related Trajectory Optimization algorithms linearizing the dynamics.}
}

@inproceedings{lincoln26195,
           month = {June},
          author = {Miroslav Kulich and Tomas Krajnik and Libor Preucil and Tom Duckett},
       booktitle = {International Workshop on Modelling and Simulation for Autonomous Systems},
           title = {To explore or to exploit? Learning humans' behaviour to maximize interactions with them},
       publisher = {Springer},
             doi = {10.1007/978-3-319-47605-6\_5},
           pages = {48--63},
            year = {2016},
        keywords = {ARRAY(0x5568fbacaf50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26195/},
        abstract = {Assume a robot operating in a public space (e.g., a library, a museum) and serving visitors as a companion, a guide or an information stand. To do  that, the robot has to interact with humans, which presumes that it actively searches for humans in order to interact with them. This paper addresses the problem how to plan robot's actions in order to maximize the number of such interactions in the case human behavior is not known in advance. We formulate this problem as the exploration/exploitation problem and design several strategies for the robot. The main contribution of the paper than lies in evaluation and comparison of the designed strategies on two datasets. The evaluation shows interesting properties of the strategies, which are discussed.}
}

@inproceedings{lincoln24851,
       booktitle = {International Workshop on Modelling and Simulation for Autonomous Systems},
           month = {June},
           title = {Stam: a framework for spatio-temporal affordance maps},
          author = {Francesco Riccio and Roberto Capobianco and Marc Hanheide and Daniele Nardi},
       publisher = {Springer},
            year = {2016},
           pages = {271--280},
        keywords = {ARRAY(0x5568fbaa23c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24851/},
        abstract = {A?ordances have been introduced in literature as action op-
portunities that objects o?er, and used in robotics to semantically rep-
resent their interconnection. However, when considering an environment
instead of an object, the problem becomes more complex due to the
dynamism of its state. To tackle this issue, we introduce the concept
of Spatio-Temporal A?ordances (STA) and Spatio-Temporal A?ordance
Map (STAM). Using this formalism, we encode action semantics re-
lated to the environment to improve task execution capabilities of an
autonomous robot. We experimentally validate our approach to support
the execution of robot tasks by showing that a?ordances encode accurate
semantics of the environment.}
}

@inproceedings{lincoln40824,
           month = {June},
          author = {Diederik Paul Moeys and Federico Corradi and Emmett Kerr and Philip Vance and Gautham Das and Daniel Neil and Dermot Kerr and Tobi Delbruck},
       booktitle = {2016 Second International Conference on Event-based Control, Communication, and Signal Processing (EBCCSP)},
           title = {Steering a predator robot using a mixed frame/event-driven convolutional neural network},
       publisher = {IEEE},
             doi = {10.1109/EBCCSP.2016.7605233},
           pages = {1--8},
            year = {2016},
        keywords = {ARRAY(0x5568fbac4970)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40824/},
        abstract = {This paper describes the application of a Convolutional Neural Network (CNN) in the context of a predator/prey scenario. The CNN is trained and run on data from a Dynamic and Active Pixel Sensor (DAVIS) mounted on a Summit XL robot (the predator), which follows another one (the prey). The CNN is driven by both conventional image frames and dynamic vision sensor "frames" that consist of a constant number of DAVIS ON and OFF events. The network is thus "data driven" at a sample rate proportional to the scene activity, so the effective sample rate varies from 15 Hz to 240 Hz depending on the robot speeds. The network generates four outputs: steer right, left, center and non-visible. After off-line training on labeled data, the network is imported on the on-board Summit XL robot which runs jAER and receives steering directions in real time. Successful results on closed-loop trials, with accuracies up to 87\% or 92\% (depending on evaluation criteria) are reported. Although the proposed approach discards the precise DAVIS event timing, it offers the significant advantage of compatibility with conventional deep learning technology without giving up the advantage of datadriven computing.}
}

@inproceedings{lincoln25742,
          volume = {2016-J},
           month = {June},
          author = {M. Ewerton and G. Maeda and G. Neumann and V. Kisner and G. Kollegger and J. Wiemeyer and J. Peters},
       booktitle = {Robotics and Automation (ICRA), 2016 IEEE International Conference on},
           title = {Movement primitives with multiple phase parameters},
            year = {2016},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
             doi = {10.1109/ICRA.2016.7487134},
           pages = {201--206},
        keywords = {ARRAY(0x5568fba14640)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25742/},
        abstract = {Movement primitives are concise movement representations that can be learned from human demonstrations, support generalization to novel situations and modulate the speed of execution of movements. The speed modulation mechanisms proposed so far are limited though, allowing only for uniform speed modulation or coupling changes in speed to local measurements of forces, torques or other quantities. Those approaches are not enough when dealing with general velocity constraints. We present a movement primitive formulation that can be used to non-uniformly adapt the speed of execution of a movement in order to satisfy a given constraint, while maintaining similarity in shape to the original trajectory. We present results using a 4-DoF robot arm in a minigolf setup.}
}

@inproceedings{lincoln27952,
       booktitle = {2016 IEEE 11th Conference on Industrial Electronics and Applications (ICIEA)},
           month = {June},
           title = {An effective pansharpening method based on guided filtering},
          author = {Xu Li and Weifeng Qi and Shigang Yue},
            year = {2016},
           pages = {534--538},
             doi = {10.1109/ICIEA.2016.7603642},
        keywords = {ARRAY(0x5568fbb08648)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27952/},
        abstract = {Pansharpening is an important tool in remote sensing applications. It transforms a set of low-spatial-resolution multispectral images to high-spatial-resolution images by fusing with a co-registered high-spatial-resolution panchromatic image. To deal with the increasing high resolution satellite images, wide varieties of pansharpening techniques have been developed. In this paper, we present an effective pansharpening method based on guided filtering. The method takes advantage of the guided filter to refine the blocking edges in the upscaled multispectral images and extract sufficient high frequency details from the panchromatic image. Moreover, it can be implemented to sharpen multispectral imagery in a convenient band-by-band manner. The experimental evaluations are carried out on QuickBird satellite images. Subjective and objective evaluations show that our proposed method can achieve high spectral and spatial quality and outperforms some existing methods.}
}

@article{lincoln22902,
          volume = {49},
          number = {4},
           month = {June},
          author = {Kathrin Gerling and Denise Hebesberger and Christian Dondrup and Tobias K{$\backslash$}"ortner and Marc Hanheide},
           title = {Robot deployment in long-term care: a case study of a mobile robot in physical therapy},
       publisher = {Springer for Bundesverband Geriatrie / Deutsche Gesellschaft f{\"u}r Gerontologie und Geriatrie},
            year = {2016},
         journal = {Zeitschrift f{\"u}r Geriatrie und Gerontologie},
             doi = {10.1007/s00391-016-1065-6},
           pages = {288--297},
        keywords = {ARRAY(0x5568fbb08c78)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22902/},
        abstract = {Background. Healthcare systems in industrialised countries are challenged to provide
care for a growing number of older adults. Information technology holds the promise of
facilitating this process by providing support for care staff, and improving wellbeing of
older adults through a variety of support systems. Goal. Little is known about the
challenges that arise from the deployment of technology in care settings; yet, the
integration of technology into care is one of the core determinants of successful
support. In this paper, we discuss challenges and opportunities associated with
technology integration in care using the example of a mobile robot to support physical
therapy among older adults with cognitive impairment in the European project
STRANDS. Results and discussion. We report on technical challenges along with
perspectives of physical therapists, and provide an overview of lessons learned which
we hope will help inform the work of researchers and practitioners wishing to integrate
robotic aids in the caregiving process.}
}

@article{lincoln25743,
          volume = {17},
           month = {June},
          author = {C. Daniel and G. Neumann and O. Kroemer and J. Peters},
           title = {Hierarchical relative entropy policy search},
       publisher = {Massachusetts Institute of Technology Press (MIT Press) / Microtome Publishing},
         journal = {Journal of Machine Learning Research},
           pages = {1--50},
            year = {2016},
        keywords = {ARRAY(0x5568fbaa7700)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25743/},
        abstract = {Many reinforcement learning (RL) tasks, especially in robotics, consist of multiple sub-tasks that
are strongly structured. Such task structures can be exploited by incorporating hierarchical policies
that consist of gating networks and sub-policies. However, this concept has only been partially explored
for real world settings and complete methods, derived from first principles, are needed. Real
world settings are challenging due to large and continuous state-action spaces that are prohibitive
for exhaustive sampling methods. We define the problem of learning sub-policies in continuous
state action spaces as finding a hierarchical policy that is composed of a high-level gating policy to
select the low-level sub-policies for execution by the agent. In order to efficiently share experience
with all sub-policies, also called inter-policy learning, we treat these sub-policies as latent variables
which allows for distribution of the update information between the sub-policies. We present three
different variants of our algorithm, designed to be suitable for a wide variety of real world robot
learning tasks and evaluate our algorithms in two real robot learning scenarios as well as several
simulations and comparisons.}
}

@misc{lincoln36757,
           month = {June},
           title = {Discovery Channel Daily Planet feature showing use of paper "Controlled comparison of machine vision algorithms for Rumex and Urtica detection in grassland" in use by Ibex Automation Ltd.},
          author = {Charles Fox},
            year = {2016},
         journal = {Daily Planet, Discovery Channel},
        keywords = {ARRAY(0x5568fba41ec0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36757/},
        abstract = {Discovery Channel Daily Planet feature showing use of paper "Controlled comparison of machine vision algorithms for Rumex and Urtica detection in grassland" in use by Ibex Automation Ltd.}
}

@article{lincoln22991,
          volume = {12},
          number = {3},
           month = {June},
          author = {Sepehr Maleki and Chris Bingham and Yu Zhang},
           title = {Development and realisation of changepoint analysis for the detection of emerging faults on industrial systems},
       publisher = {IEEE Institute of Electrical and Electronics Engineers (IEEE)},
            year = {2016},
         journal = {IEEE Transactions on Industrial Informatics},
             doi = {10.1109/TII.2016.2558181},
           pages = {1180--1187},
        keywords = {ARRAY(0x5568fbad40c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22991/},
        abstract = {An online 2-D changepoint detection algorithm for sensor-based fault detection, is proposed. The methodology con- sists of a differential detector which looks for characteristics across datasets at a particular instant, and a standard detector which when combined can identify anomalies and meaningful change- points while maintaining low rates of false-alarm generation. A key aspect of changepoint detection methodologies is the setting of relevant thresholds which are typically based on empirical trial and error. Here, a statistical methodology is adopted which provides the engineer with a trade-off between correct detection and false-alarm rates, thereby informing decision making at the design stage. The efficacy of the techniques is demonstrated through application to two industry case studies of fault detection on Industrial Gas Turbines, and are shown to readily provide an early warning indicator of impending failures.}
}

@article{lincoln27940,
          volume = {37},
          number = {6},
           month = {June},
          author = {Zheng Xuqiang and Li Fule and Wang Zhijun and Li Weitao and Jia Wen and Wang Zhihua and Shigang Yue},
           title = {An S/H circuit with parasitics optimized for IF-sampling},
       publisher = {IOP Publishing / Chinese Institute of Electronics},
            year = {2016},
         journal = {Journal of Semiconductors},
             doi = {10.1088/1674-4926/37/6/065005},
           pages = {065005},
        keywords = {ARRAY(0x5568fb6703b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27940/},
        abstract = {An IF-sampling S/H is presented, which adopts a flip-around structure, bottom-plate sampling technique and improved input bootstrapped switches. To achieve high sampling linearity over a wide input frequency range, the floating well technique is utilized to optimize the input switches. Besides, techniques of transistor load linearization and layout improvement are proposed to further reduce and linearize the parasitic capacitance. The S/H circuit has been fabricated in 0.18-{\ensuremath{\mu}}m CMOS process as the front-end of a 14 bit, 250 MS/s pipeline ADC. For 30 MHz input, the measured SFDR/SNDR of the ADC is 94.7 dB/68. 5dB, which can remain over 84.3 dB/65.4 dB for input frequency up to 400 MHz. The ADC presents excellent dynamic performance at high input frequency, which is mainly attributed to the parasitics optimized S/H circuit.}
}

@inproceedings{lincoln40825,
           month = {May},
          author = {Hongjie Liu and Diederik Paul Moeys and Gautham Das and Daniel Neil and Shih-Chii Liu and Tobi Delbruck},
       booktitle = {2016 IEEE International Symposium on Circuits and Systems (ISCAS)},
           title = {Combined frame- and event-based detection and tracking},
       publisher = {IEEE},
             doi = {10.1109/ISCAS.2016.7539103},
           pages = {2511--2514},
            year = {2016},
        keywords = {ARRAY(0x5568fbb4d6e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40825/},
        abstract = {This paper reports an object tracking algorithm for a moving platform using the dynamic and active-pixel vision sensor (DAVIS). It takes advantage of both the active pixel sensor (APS) frame and dynamic vision sensor (DVS) event outputs from the DAVIS. The tracking is performed in a three step-manner: regions of interest (ROIs) are generated by a cluster-based tracking using the DVS output, likely target locations are detected by using a convolutional neural network (CNN) on the APS output to classify the ROIs as foreground and background, and finally a particle filter infers the target location from the ROIs. Doing convolution only in the ROIs boosts the speed by a factor of 70 compared with full-frame convolutions for the 240x180 frame input from the DAVIS. The tracking accuracy on a predator and prey robot database reaches 90\% with a cost of less than 20ms/frame in Matlab on a normal PC without using a GPU.}
}

@inproceedings{lincoln25639,
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA) 2016},
           month = {May},
           title = {Learning soft task priorities for control of redundant robots},
          author = {V. Modugno and Gerhard Neumann and E. Rueckert and G. Oriolo and J. Peters and S. Ivaldi},
            year = {2016},
        keywords = {ARRAY(0x5568fb9d9888)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25639/},
        abstract = {Movement primitives (MPs) provide a powerful
framework for data driven movement generation that has been
successfully applied for learning from demonstrations and robot
reinforcement learning. In robotics we often want to solve a
multitude of different, but related tasks. As the parameters
of the primitives are typically high dimensional, a common
practice for the generalization of movement primitives to new
tasks is to adapt only a small set of control variables, also
called meta parameters, of the primitive. Yet, for most MP
representations, the encoding of these control variables is precoded
in the representation and can not be adapted to the
considered tasks. In this paper, we want to learn the encoding of
task-specific control variables also from data instead of relying
on fixed meta-parameter representations. We use hierarchical
Bayesian models (HBMs) to estimate a low dimensional latent
variable model for probabilistic movement primitives (ProMPs),
which is a recent movement primitive representation. We show
on two real robot datasets that ProMPs based on HBMs
outperform standard ProMPs in terms of generalization and
learning from a small amount of data and also allows for an
intuitive analysis of the movement. We also extend our HBM by
a mixture model, such that we can model different movement
types in the same dataset.}
}

@inproceedings{lincoln23261,
       booktitle = {ICRA Workshop AI for Long-Term Autonomy},
           month = {May},
           title = {Frequency map enhancement: introducing dynamics into static environment models},
          author = {Tomas Krajnik and Jaime Pulido Fentanes and Joao Santos and Tom Duckett},
            year = {2016},
        keywords = {ARRAY(0x5568fb9f1310)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23261/},
        abstract = {We present applications of the Frequency Map Enhancement (FreMEn), which improves the performance of mobile robots in long-term scenarios by introducing the notion of dynamics into their (originally static) environment models. Rather than using a fixed probability value, the method models the uncertainty of the elementary environment states by their frequency spectra. This allows to integrate sparse and irregular observations obtained during long-term deployments of mobile robots into memory-efficient spatio-temporal models that reflect mid- and long-term pseudo-periodic environment variations. The frequency-enhanced spatio-temporal models allow to predict the future environment states, which improves the efficiency of mobile robot operation in changing environments.   In a series of experiments performed over periods of weeks to years, we demonstrate that the proposed approach improves mobile robot localization, path and task planning, activity recognition and allows for life-long spatio-temporal exploration.}
}

@inproceedings{lincoln23220,
       booktitle = {ICRA 2016 Workshop: AI for Long-term Autonomy},
           month = {May},
           title = {A 3D simulation environment with real dynamics: a tool for benchmarking mobile robot performance in long-term deployments},
          author = {Joao Santos and Tomas Krajnik and Jaime Pulido Fentanes and Tom Duckett},
            year = {2016},
        keywords = {ARRAY(0x5568fbb75b10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23220/},
        abstract = {This paper describes a method to compare and evaluate mobile robot algorithms for long-term deployment in changing   environments. Typically, the long-term performance of state estimation algorithms for mobile robots is evaluated using pre-recorded sensory datasets. However such datasets are not suitable for evaluating decision-making and control  algorithms where the behaviour of the robot will be different in every trial. Simulation allows to overcome this issue and while it ensures repeatability of experiments, the development of 3D simulations for an extended period of time is a costly exercise.
In our approach long-term datasets comprising high-level tracks of dynamic entities such as people and furniture are recorded by ambient sensors placed in a real environment. The high-level tracks are then used to parameterise a 3D  simulation containing its own geometric models of the dynamic entities and the background scene. This simulation,  which is based on actual human activities, can then be used to benchmark and validate algorithms for long-term  operation of mobile robots.}
}

@article{lincoln22216,
          volume = {37},
           month = {May},
          author = {Nina Dethlefs and Helen Hastie and Heriberto Cuayahuitl and Yanchao Yu and Verena Rieser and Oliver Lemon},
           title = {Information density and overlap in spoken dialogue},
       publisher = {Elsevier for International Speech Communication Association (ISCA)},
            year = {2016},
         journal = {Computer Speech \& Language},
             doi = {10.1016/j.csl.2015.11.001},
           pages = {82--97},
        keywords = {ARRAY(0x5568fb67b5b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22216/},
        abstract = {Incremental dialogue systems are often perceived as more responsive and natural because they are able to address phenomena of turn-taking and overlapping speech, such as backchannels or barge-ins. Previous work in this area has often identified distinctive prosodic features, or features relating to syntactic or semantic completeness, as marking appropriate places of turn-taking. In a separate strand of work, psycholinguistic studies have established a connection between information density and prominence in language{--}the less expected a linguistic unit is in a particular context, the more likely it is to be linguistically marked. This has been observed across linguistic levels, including the prosodic, which plays an important role in predicting overlapping speech.

In this article, we explore the hypothesis that information density (ID) also plays a role in turn-taking. Specifically, we aim to show that humans are sensitive to the peaks and troughs of information density in speech, and that overlapping speech at ID troughs is perceived as more acceptable than overlaps at ID peaks. To test our hypothesis, we collect human ratings for three models of generating overlapping speech based on features of: (1) prosody and semantic or syntactic completeness, (2) information density, and (3) both types of information. Results show that over 50\% of users preferred the version using both types of features, followed by a preference for information density features alone. This indicates a clear human sensitivity to the effects of information density in spoken language and provides a strong motivation to adopt this metric for the design, development and evaluation of turn-taking modules in spoken and incremental dialogue systems.}
}

@article{lincoln31541,
          volume = {6},
          number = {1},
           month = {April},
          author = {Sepehr Maleki and Chris Bingham and Yu Zhang},
           title = {2-D online changepoint detection algorithm for sensor-based fault detection},
       publisher = {IRED},
            year = {2016},
         journal = {International Journal of Advances in Computer Science \& Its Applications},
           pages = {109--114},
        keywords = {ARRAY(0x5568fb9dc630)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31541/},
        abstract = {An online 2-D changepoint detection algorithm for sensor-based fault detection, is proposed. The algorithm consists of a differential detector and a standard detector and can detect anomalies and meaningful changepoints while maintaining a low false-alarm rate. The efficiency of the algorithm is validated by two industrial examples. It is thereby shown that the proposed algorithm can be used as an early warning indicator and prevent impending unit failures.}
}

@article{lincoln31542,
          volume = {6},
          number = {1},
           month = {April},
          author = {Sepehr Maleki and Chris Bingham and Yu Zhang},
           title = {An online changepoint detection algorithm for highly correlated dat},
       publisher = {IRED - The Institute of Research Engineers and Doctors},
            year = {2016},
         journal = {International Journal of Advances in Computer Science \& Its Applications},
           pages = {188--192},
        keywords = {ARRAY(0x5568fb9d4410)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31542/},
        abstract = {An online 2-D changepoint detection algorithm for sensor-based fault detection, is proposed. The algorithm consists of a differential detector and a standard detector and can detect anomalies and meaningful changepoints while maintaining a low false-alarm rate. A new approach for determining a threshold is introduced and the efficiency of the algorithm is validated by an industrial example. It is thereby shown that the proposed algorithm can be used as an early warning indicator and prevent impending unit failures.}
}

@article{lincoln31540,
          volume = {6},
          number = {1},
           month = {April},
          author = {Yu Zhang and Chris Bingham and Sepehr Maleki},
           title = {Measurement reconstruction in sensor networks for industrial systems},
       publisher = {IRED},
            year = {2016},
         journal = {International Journal of Advances in Computer Science \& Its Applications},
           pages = {105--108},
        keywords = {ARRAY(0x5568fba546b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31540/},
        abstract = {For signal processing in sensor networks there is an on-going challenge for filling missing information when it is either incomplete, uncertain or biased, in ways that are both efficient and with confidence. This paper reviews three established and additional newly developed techniques addressing the problem. Considering sensor signals that are highly correlated in a sensor network, one sensor measurement can be reconstructed based on measurements from other sensors. In such cases, three signal reconstruction methods are considered: 1) principal component analysis (PCA) based missing value approach; 2) self-organizing map neural network (SOMNN) based algorithm; and 3) an analytical optimization (AO) technique. To demonstrate the efficacy of the methods, temperature data are studied on an industrial gas turbine system, where, especially, a faulty sensor signal is utilized to be reconstructed from the other sensor measurements.}
}

@article{lincoln22466,
          volume = {24},
          number = {2},
           month = {April},
          author = {Farshad Arvin and Ali Emre Turgut and Tomas Krajnik and Shigang Yue},
           title = {Investigation of cue-based aggregation in static and dynamic environments with a mobile robot swarm},
       publisher = {SAGE},
            year = {2016},
         journal = {Adaptive Behavior},
             doi = {10.1177/1059712316632851},
           pages = {102--118},
        keywords = {ARRAY(0x5568fb9b99e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22466/},
        abstract = {Aggregation is one of the most fundamental behaviors that has been studied in swarm robotic researches for more than two decades. The studies in biology revealed that environment is a preeminent factor in especially cue-based aggregation that can be defined as aggregation at a particular location which is a heat or a light source acting as a cue indicating an optimal zone. In swarm robotics, studies on cue-based aggregation mainly focused on different methods of aggregation and different parameters such as population size. Although of utmost importance, environmental effects on aggregation performance have not been studied systematically. In this paper, we study the effects of different environmental factors; size, texture and number of cues in a static setting and moving cues in a dynamic setting using real robots. We used aggregation time and size of the aggregate as the two metrics to measure aggregation performance. We performed real robot experiments with different population sizes and evaluated the performance of aggregation using the defined metrics. We also proposed a probabilistic aggregation model and predicted the aggregation performance accurately in most of the settings. The results of the experiments show that environmental conditions affect the aggregation performance considerably and have to be studied in depth.}
}

@inproceedings{lincoln26735,
       booktitle = {Proceedings of the International Symposium on Experimental Robotics (ISER)},
           month = {April},
           title = {Experiments with hierarchical reinforcement learning of multiple grasping policies},
          author = {T. Osa and J. Peters and G. Neumann},
            year = {2016},
        keywords = {ARRAY(0x5568fbb728b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26735/},
        abstract = {Robotic grasping has attracted considerable interest, but it
still remains a challenging task. The data-driven approach is a promising
solution to the robotic grasping problem; this approach leverages a
grasp dataset and generalizes grasps for various objects. However, these
methods often depend on the quality of the given datasets, which are not
trivial to obtain with sufficient quality. Although reinforcement learning
approaches have been recently used to achieve autonomous collection
of grasp datasets, the existing algorithms are often limited to specific
grasp types. In this paper, we present a framework for hierarchical reinforcement
learning of grasping policies. In our framework, the lowerlevel
hierarchy learns multiple grasp types, and the upper-level hierarchy
learns a policy to select from the learned grasp types according to a point
cloud of a new object. Through experiments, we validate that our approach
learns grasping by constructing the grasp dataset autonomously.
The experimental results show that our approach learns multiple grasping
policies and generalizes the learned grasps by using local point cloud
information.}
}

@article{lincoln32033,
          volume = {28},
          number = {3},
           month = {March},
          author = {Yuhao Lu and Tom Stafford and Charles Fox},
           title = {Maximum saliency bias in binocular rivalry},
       publisher = {Taylor and Francis},
            year = {2016},
         journal = {Connection Science},
             doi = {10.1080/09540091.2016.1159181},
           pages = {258--269},
        keywords = {ARRAY(0x5568fbba8888)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32033/},
        abstract = {Subjective experience at any instant consists of a single (?unitary?), coherent interpretationof sense data rather than a ?Bayesian blur? of alternatives. However, computation of Bayes-optimal actions has no role for unitary perception, instead being required to integrate overeverypossible action-percept pair to maximise expected utility.So what is the role of unitarycoherent percepts, and how are they computed? Recent work provided objective evidence fornon-Bayes-optimal, unitary coherent, perception and action in humans; and further suggestedthat  the  percept  selected  is  not  the  maximuma posteriori(MAP)  percept  but  is  insteadaffected by utility. The present study uses a binocular fusion task first to reproduce the sameeffect in a new domain, and second, to test multiple hypotheses about exactlyhowutilitymay  affect  the  percept.  After  accounting  for  high  experimental  noise,  it  finds  that  bothBayes optimality (MEU) and the previously proposed maximum-utility (MU) hypothesis areoutperformed  in  fitting  the  data  by  a  modified  maximum-salience(MS)  hypothesis,  usingunsigned utility magnitudes in place of signed utilities inthe bias function.}
}

@inproceedings{lincoln42390,
       booktitle = {COGNITIVE 2016, The Eighth International Conference on Advanced Cognitive Technologies and Applications},
           month = {March},
           title = {Modelling Retinal Ganglion Cells Stimulated with Static Natural Images},
          author = {Gautham Das and Philip J. Vance and Dermot Kerr and Sonya A. Coleman and Thomas M. McGinnity},
       publisher = {IARIA},
            year = {2016},
           pages = {66--71},
        keywords = {ARRAY(0x5568fbad7d28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42390/},
        abstract = {A standard approach to model retinal ganglion cells uses reverse correlation to construct a linear-nonlinear model using a cascade of a linear filter and a static nonlinearity. A major constraint with this technique is the need to use a radially symmetric stimulus, such as Gaussian white noise. Natural visual stimuli are required to generate a more realistic ganglion-cell model. However, natural visual stimuli significantly differ from white noise stimuli and are not radially symmetric. Therefore a more sophisticated modelling approach than the linear-nonlinear method is required for modelling ganglion cells stimulated with natural images. Machine learning algorithms have proved very capable in modelling complex non-linear systems in other scientific domains. In this paper, we report on the development of computational models, using different machine learning regression algorithms, that model retinal ganglion cells stimulated with natural images in order to predict the number of spikes elicited. Neuronal recordings obtained from electro-physiological experiments in which isolated salamander retinas are stimulated with static natural images are used to develop these models. In order to compare the performance of the machine learning models, a linear-nonlinear model was also developed from separate experiments using Gaussian white noise stimuli. A comparison of the spike prediction using the models developed shows that the machine learning models perform better than the linear-nonlinear approach.}
}

@inproceedings{lincoln42392,
       booktitle = {COGNITIVE 2016, The Eighth International Conference on Advanced Cognitive Technologies and Applications},
           month = {March},
           title = {Refining Receptive Field Estimates using Natural Images for Retinal Ganglion Cells},
          author = {Philip J. Vance and Gautham Das and Dermot Kerr and Sonya A. Coleman and Thomas Martin McGinnity},
       publisher = {IARIA},
            year = {2016},
           pages = {77--82},
        keywords = {ARRAY(0x5568fbb701b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42392/},
        abstract = {Determining the structure and size of a retinal ganglion cell?s receptive field is critically important when formulating a computational model to describe the relationship between stimulus and response. This is commonly achieved using a process of reverse correlation through stimulation of the retinal ganglion cell with artificial stimuli (for example bars or gratings) in a controlled environment. It has been argued however, that artificial stimuli are generally not complex enough to encapsulate the full complexity of a visual scene?s stimuli and thus any model formulated under these conditions can only be considered to emulate a subset of the biological model. In this paper, we present an investigation into the use of natural images to refine the size of the receptive fields, where their initial location and shape have been pre-determined through reverse correlation. We present findings that show the use of natural images to determine the receptive field size provides a significant improvement over the standard approach for determining the receptive field.}
}

@inproceedings{lincoln42391,
       booktitle = {COGNITIVE 2016, The Eighth International Conference on Advanced Cognitive Technologies and Applications},
           month = {March},
           title = {Temporal Coding Model of Spiking Output for Retinal Ganglion Cells},
          author = {Philip J. Vance and Gautham Das and Dermot Kerr and Sonya A. Coleman and Thomas Martin McGinnity},
       publisher = {IARIA},
            year = {2016},
           pages = {83--89},
        keywords = {ARRAY(0x5568fba9bbd8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42391/},
        abstract = {Traditionally, it has been assumed that the important information from a visual scene is encoded within the average firing rate of a retinal ganglion cell. Many modelling techniques thus focus solely on estimating a firing rate rather than a cells temporal response. It has been argued however that the latter is more important, as intricate details of the visual scene are stored within the temporal nature of the code. In this paper, we present a model that accurately describes the input/output response of a retinal ganglion cell in terms of its temporal coding. The approach borrows a concept of layout from popular implementations, such as the linearnonlinear Poisson method that produces an estimated spike rate prior to generating a spiking output. Using the wellknown Izhikevich neuron as the spike generator and various approaches for spike rate estimation, we show that the resulting overall system predicts a retinal ganglion cells response to novel stimuli in terms of bursting and periods of silence with reasonable accuracy.}
}

@inproceedings{lincoln30203,
           month = {March},
          author = {Paul Baxter and James Kennedy and Emmanuel Senft and Severin Lemaignan and Tony Belpaeme},
       booktitle = {altHRI 2016},
         address = {Christchurch, New Zealand},
           title = {From characterising three years of HRI to methodology and reporting recommendations},
       publisher = {ACM Press},
           pages = {391--398},
            year = {2016},
        keywords = {ARRAY(0x5568fb9e80c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30203/},
        abstract = {Human-Robot Interaction (HRI) research requires
the integration and cooperation of multiple disciplines, technical and social, in order to make progress. In many cases using different motivations, each of these disciplines bring with them different assumptions and methodologies.We assess recent trends in the field of HRI by examining publications in the HRI conference over the past three years (over 100 full papers), and characterise them according to 14 categories.We focus primarily on aspects of methodology. From this, a series of practical rec- ommendations based on rigorous guidelines from other research fields that have not yet become common practice in HRI are proposed. Furthermore, we explore the primary implications of the observed recent trends for the field more generally, in terms of both methodology and research directions.We propose that the interdisciplinary nature of HRI must be maintained, but that a common methodological approach provides a much needed frame of reference to facilitate rigorous future progress.}
}

@inproceedings{lincoln30201,
       booktitle = {2nd Workshop on Evaluating Child-Robot Interaction at HRI'16},
           month = {March},
           title = {A Cautionary Note on Personality (Extroversion) Assessments in Child-Robot Interaction Studies},
          author = {Paul Baxter and Tony Belpaeme},
         address = {Christchurch, New Zealand},
            year = {2016},
        keywords = {ARRAY(0x5568fb9bd180)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30201/},
        abstract = {The relationship between personality and social human-robot interaction is a topic of increasing interest. There are further some indications from the literature that there is an association between personality dimensions and various aspects of educational behaviour and performance. This brief contribution seeks to explore the single personality dimension of extroversion/introversion: specifically, how children rate them- selves with a validated questionnaire in comparison to how teachers rate them using a relative scale. In an exploratory study conducted in a primary school, we find a non-significant association between these two ratings. We suggest that this mismatch is related to the context in which the respective ratings were made. In order to facilitate generalisation of personality- related results across studies, we propose two general reporting recommendations. Based on our results, we suggest that the application of personality assessments in a child-robot interaction context may be more complex than initially envisaged, with some dependence on context.}
}

@inproceedings{lincoln30197,
       booktitle = {HRI 2016},
           month = {March},
           title = {Workshop: Cognitive Architectures for Social Human-Robot Interaction},
          author = {Paul Baxter and Severin Lemaignan and J. Gregory Trafton},
         address = {Christchurch, New Zealand},
            year = {2016},
           pages = {579--580},
        keywords = {ARRAY(0x5568fbbc53d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30197/},
        abstract = {Social HRI requires robots able to use appropriate,
adaptive and contingent behaviours to form and maintain en- gaging social interactions with people. Cognitive Architectures emphasise a generality of mechanism and application, making them an ideal basis for such technical developments. Following the successful first workshop on Cognitive Architectures for HRI at the 2014 HRI conference, this second edition of the workshop focusses specifically on applications to social interaction. The full-day workshop is centred on participant contributions, and structured around a set of questions to provide a common basis of comparison between different assumptions, approaches, mechanisms, and architectures. These contributions will be used to support extensive and structured discussions, with the aim of facilitating the development and application of cognitive architectures to social HRI systems. By attending, we envisage that participants will gain insight into how the consideration of cognitive architectures complements the development of au- tonomous social robots.}
}

@inproceedings{lincoln30198,
       booktitle = {HRI 2016},
           month = {March},
           title = {Heart vs Hard Drive : Children Learn More From a Human Tutor Than a Social Robot},
          author = {James Kennedy and Paul Baxter and Emmanuel Senft and Tony Belpaeme},
         address = {Christchurch, New Zealand},
            year = {2016},
           pages = {451--452},
        keywords = {ARRAY(0x5568fbb75420)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30198/},
        abstract = {The field of Human-Robot Interaction (HRI) is
increasingly exploring the use of social robots for educating children. Commonly, non-academic audiences will ask how robots compare to humans in terms of learning outcomes. This question is also interesting for social roboticists as humans are often assumed to be an upper benchmark for social behaviour, which influences learning. This paper presents a study in which learning gains of children are compared when taught the same math- ematics material by a robot tutor and a non-expert human tutor. Significant learning occurs in both conditions, but the children improve more with the human tutor. This difference is not statistically significant, but the effect sizes fall in line with findings from other literature showing that humans outperform technology for tutoring. We discuss these findings in the context of applying social robots in child education.}
}

@inproceedings{lincoln30199,
       booktitle = {HRI 2016},
           month = {March},
           title = {Providing a Robot with Learning Abilities Improves its Perception by Users},
          author = {Emmanuel Senft and Paul Baxter and James Kennedy and Tony Belpaeme},
         address = {Christchurch, New Zealand},
            year = {2016},
           pages = {513--514},
        keywords = {ARRAY(0x5568fba9b0f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30199/},
        abstract = {Subjective appreciation and performance evaluation
of a robot by users are two important dimensions for Human- Robot Interaction, especially as increasing numbers of people become involved with robots. As roboticists we have to carefully design robots to make the interaction as smooth and enjoyable as possible for the users, while maintaining good performance in the task assigned to the robot. In this paper, we examine the impact of providing a robot with learning capabilities on how users report the quality of the interaction in relation to objective performance. We show that humans tend to prefer interacting with a learning robot and will rate its capabilities higher even if the actual performance in the task was lower. We suggest that adding learning to a robot could reduce the apparent load felt by a user for a new task and improve the user?s evaluation of the system, thus facilitating the integration of such robots into existing work flows}
}

@inproceedings{lincoln30200,
       booktitle = {HRI 2016},
           month = {March},
           title = {Socially Contingent Humanoid Robot Head Behaviour Results in Increased Charity Donations},
          author = {Paul Wills and Paul Baxter and James Kennedy and Emmanuel Senft and Tony Belpaeme},
         address = {Christchurch, New Zealand},
            year = {2016},
           pages = {533--534},
        keywords = {ARRAY(0x5568fbb70048)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30200/},
        abstract = {The role of robot social behaviour in changing
people?s behaviour is an interesting and yet still open question, with the general assumption that social behaviour is beneficial. In this study, we examine the effect of socially contingent robot behaviours on a charity collection task. Manipulating only behavioural cues (maintaining the same verbal content), we show that when the robot exhibits contingent behaviours consistent with those observable in humans, this results in a 32\% increase in money collected over a non-reactive robot. These results suggest that apparent social agency on the part of the robot, even when subtle behavioural cues are used, can result in behavioural change on the part of the interacting human.}
}

@inproceedings{lincoln24855,
           month = {March},
          author = {James Kennedy and Paul Baxter and Emmanuel Senft and Tony Belpaeme},
       booktitle = {Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction HRI 2016},
         address = {Christchurch, New Zealand},
           title = {Social robot tutoring for child second language learning},
       publisher = {ACM Press},
           pages = {231--238},
            year = {2016},
        keywords = {ARRAY(0x5568fba80390)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24855/},
        abstract = {An increasing amount of research is being conducted
to determine how a robot tutor should behave socially in educa- tional interactions with children. Both human-human and human- robot interaction literature predicts an increase in learning with increased social availability of a tutor, where social availability has verbal and nonverbal components. Prior work has shown that greater availability in the nonverbal behaviour of a robot tutor has a positive impact on child learning. This paper presents a study with 67 children to explore how social aspects of a tutor robot?s speech influences their perception of the robot and their language learning in an interaction. Children perceive the difference in social behaviour between ?low? and ?high? verbal availability conditions, and improve significantly between a pre- and a post-test in both conditions. A longer-term retention test taken the following week showed that the children had retained almost all of the information they had learnt. However, learning was not affected by which of the robot behaviours they had been exposed to. It is suggested that in this short-term interaction context, additional effort in developing social aspects of a robot?s verbal behaviour may not return the desired positive impact on learning gains.}
}

@article{lincoln17880,
          volume = {46},
          number = {3},
           month = {March},
          author = {Wenbin Chen and Caihua Xiong and Shigang Yue},
           title = {On configuration trajectory formation in spatiotemporal profile for reproducing human hand reaching movement},
       publisher = {IEEE},
            year = {2016},
         journal = {IEEE Transactions on Cybernetics},
             doi = {10.1109/TCYB.2015.2416311},
        keywords = {ARRAY(0x5568fbae5fd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17880/},
        abstract = {Most functional reaching activities in daily living generally require a hand to reach the functional position in appropriate orientation with invariant spatiotemporal profile. Effectively reproducing such spatiotemporal feature of hand configuration trajectory in real time is essential to understand the human motor control and plan human-like motion on anthropomorphic robotic arm. However, there are no novel computational models in literature toward reproducing hand configuration-to-configuration movement in spatiotemporal profile. In response to the problem, this paper presents a computational framework for hand configuration trajectory formation based on hierarchical principle of human motor control. The composite potential field is constructed on special Euclidean Group to induce time-varying configuration toward target. The dynamic behavior of hand is described by a second-order kinematic model to produce the external representation of high-level motor control. The multivariate regression relation between intrinsic and extrinsic coordinates of arm, is statistically analyzed for determining the arm orientation in real time, which produces the external representation of low-level motor control. The proposed method is demonstrated in an anthropomorphic arm by performing several highly curved self-reaching movements. The generated configuration trajectories are compared with actual human movement in spatiotemporal profile to validate the proposed method.}
}

@article{lincoln39197,
          volume = {122},
           month = {March},
          author = {D. Pavlou and A. Orfanou and P. Busato and R. Berruto and C. S{\o}rensen and D. Bochtis},
           title = {Functional modeling for green biomass supply chains},
         journal = {Computers and Electronics in Agriculture},
             doi = {doi:10.1016/j.compag.2016.01.014},
           pages = {29--40},
            year = {2016},
        keywords = {ARRAY(0x5568fb677658)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39197/},
        abstract = {The biomass supply chain is a multiple-segment chain characterized by prominent complexity and uncertainty, and as such, it requires increased managerial efforts as compared to the case of a single operation management. This paper deals with the supply chain management of green (e.g. grass) biomass. Specifically, three different supply chain systems, in terms of machinery configurations, were analyzed and evaluated in terms of task times and cost performance. By using a functional modeling methodology, the structural representations of the systems, in terms of activities, actions, processes, and operations, were generated and implemented by the ExtendSim? simulation software. It was shown that the models can identify the bottlenecks of the systems and can be further used as a decision support system by testing various alternatives, in terms of the resources used and their dimensioning. Finally, the models were evaluated against the sensitivity on input parameters which are known with a level of uncertainty, i.e. the expected yield and the expected machinery performance.}
}

@inproceedings{lincoln30202,
       booktitle = {2nd Workshop on Cognitive Architectures for Social Human-Robot Interaction at HRI'16},
           month = {February},
           title = {Memory-Centred Cognitive Architectures for Robots Interacting Socially with Humans},
          author = {Paul Baxter},
         address = {Christchurch, New Zealand},
            year = {2016},
        keywords = {ARRAY(0x5568fbb83018)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30202/},
        abstract = {The Memory-Centred Cognition perspective places an active association substrate at the heart of cognition, rather than as a passive adjunct. Consequently, it places prediction and priming on the basis of prior experience to be inherent and fundamental aspects of processing. Social interaction is taken here to minimally require contingent and co-adaptive behaviours from the interacting parties. In this contribution, I seek to show how the memory-centred cognition approach to cognitive architectures can provide an means of addressing these functions. A number of example implementations are briefly reviewed, particularly focusing on multi-modal alignment as a function of experience-based priming. While there is further refinement required to the theory, and implementations based thereon, this approach provides an interesting alternative perspective on the foundations of cognitive architectures to support robots engage in social interactions with humans.}
}

@inproceedings{lincoln25746,
       booktitle = {Thirtieth AAAI Conference on Artificial Intelligence},
           month = {February},
           title = {Model-free preference-based reinforcement learning},
          author = {C. Wirth and J. Furnkranz and G. Neumann},
            year = {2016},
           pages = {2222--2228},
         journal = {30th AAAI Conference on Artificial Intelligence, AAAI 2016},
        keywords = {ARRAY(0x5568fbaf9170)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25746/},
        abstract = {Specifying a numeric reward function for reinforcement learning typically requires a lot of hand-tuning from a human expert. In contrast, preference-based reinforcement learning (PBRL) utilizes only pairwise comparisons between trajectories as a feedback signal, which are often more intuitive to specify. Currently available approaches to PBRL for control problems with continuous state/action spaces require a known or estimated model, which is often not available and hard to learn. In this paper, we integrate preference-based estimation of the reward function into a model-free reinforcement learning (RL) algorithm, resulting in a model-free PBRL algorithm. Our new algorithm is based on Relative Entropy Policy Search (REPS), enabling us to utilize stochastic policies and to directly control the greediness of the policy update. REPS decreases exploration of the policy slowly by limiting the relative entropy of the policy update, which ensures that the algorithm is provided with a versatile set of trajectories, and consequently with informative preferences. The preference-based estimation is computed using a sample-based Bayesian method, which can also estimate the uncertainty of the utility. Additionally, we also compare to a linear solvable approximation, based on inverse RL. We show that both approaches perform favourably to the current state-of-the-art. The overall result is an algorithm that can learn non-parametric continuous action policies from a small number of preferences.}
}

@article{lincoln41513,
          volume = {6},
           month = {February},
          author = {Ziyi Liu and Junfeng Gao and Guoguo Yang and Huan Zhang and Yong He},
           title = {Localization and classification of paddy field pests using a saliency map and deep convolutional neural network},
       publisher = {Nature Publishing Group},
            year = {2016},
         journal = {Scientific Reports},
             doi = {10.1038/srep20410},
           pages = {20410},
        keywords = {ARRAY(0x5568fbb92a20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41513/},
        abstract = {We present a pipeline for the visual localization and classification of agricultural pest insects by computing a saliency map and applying deep convolutional neural network (DCNN) learning. First, we used a global contrast region-based approach to compute a saliency map for localizing pest insect objects. Bounding squares containing targets were then extracted, resized to a fixed size and used to construct a large standard database called Pest ID. This database was then utilized for self-learning of local image features which were, in turn, used for classification by DCNN. DCNN learning optimized the critical parameters, including size, number and convolutional stride of local receptive fields, dropout ratio and the final loss function. To demonstrate the practical utility of using DCNN, we explored different architectures by shrinking depth and width and found effective sizes that can act as alternatives for practical applications. On the test set of paddy field images, our architectures achieved a mean Accuracy Precision (mAP) of 0.951, a significant improvement over previous methods.}
}

@article{lincoln46162,
          volume = {1},
          number = {1},
           month = {January},
          author = {Marcello Calisti and Egidio Falotico and Cecilia Laschi},
           title = {Hopping on Uneven Terrains With an Underwater One-Legged Robot},
            year = {2016},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2016.2521928},
           pages = {461--468},
        keywords = {ARRAY(0x5568fba753a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46162/},
        abstract = {In this letter, a fundamental model for underwater legged locomotion, called U-SLIP, is presented and implemented on a robotic platform. Unlike traditional locomotion models, U-SLIP addresses specific hydrodynamic contributions, such as drag, buoyancy, and added mass. By taking as a reference the USLIP model, we derived the design principles to build an effective underwater legged robot able to achieve self-stabilizing running. For the first time, a robotic platform can exhibit a dynamic mode of locomotion composed of swimming and pushing phases, demonstrating self-stabilizing running with a little control. Experiments conducted over different uneven terrains corroborate the effectiveness of the proposed model.}
}

@article{lincoln26606,
          volume = {14},
          number = {1},
           month = {January},
          author = {C. Keeble and P. D. Baxter and S. Barber and G. R. Law},
           title = {Participation rates In epidemiology studies and surveys: a review 2005 - 2007},
       publisher = {Internet Scientific Publications, LLC},
            year = {2016},
         journal = {The Internet Journal of Epidemiology},
             doi = {10.5580/IJE.34897},
           pages = {1--14},
        keywords = {ARRAY(0x5568fbac2738)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26606/},
        abstract = {Understanding the factors associated with participation is key in addressing the problem of declining participation rates in epidemiological studies. This review aims to summarise factors affecting participation rates in articles published during the last nine years, to compare with previous findings to determine whether the research focus for non-participation has changed and whether the findings have been consistent over time. Web of Science was used to search titles of English articles from 2007?2015 for a range of synonymous words concerning participation rates. A predefined inclusion criteria was used to determine whether the resulting articles referred to participation in the context of study enrolment. Factors associated with participation were extracted from included articles. The search returned 626 articles, of which 162 satisfied the inclusion criteria. Compared with pre-2007, participant characteristics generally remained unchanged, but were topic-dependent. An increased focus on study design and a greater use of technology for enrolment and data collection was found, suggesting a transition towards technology-based methods. In addition to increased participation rates, studies should consider any bias arising from non-participation. When reporting results, authors are encouraged to include a standardised participation rate, a calculation of potential bias, and to apply an appropriate statistical method where appropriate. Requirements from journals to include these would allow for easier comparison of results between studies.}
}

@inproceedings{lincoln25741,
       booktitle = {Advances in Neural Information Processing Systems (NIPS)},
           title = {Model-based relative entropy stochastic search},
          author = {A. Abdolmaleki and R. Lioutikov and N. Lua and L. Paulo Reis and J. Peters and G. Neumann},
            year = {2016},
           pages = {153--154},
             doi = {10.1145/2908961.2930952},
         journal = {GECCO 2016 Companion - Proceedings of the 2016 Genetic and Evolutionary Computation Conference},
        keywords = {ARRAY(0x5568fbb74eb0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25741/},
        abstract = {Stochastic search algorithms are general black-box optimizers. Due to their ease
of use and their generality, they have recently also gained a lot of attention in operations
research, machine learning and policy search. Yet, these algorithms require
a lot of evaluations of the objective, scale poorly with the problem dimension, are
affected by highly noisy objective functions and may converge prematurely. To
alleviate these problems, we introduce a new surrogate-based stochastic search
approach. We learn simple, quadratic surrogate models of the objective function.
As the quality of such a quadratic approximation is limited, we do not greedily exploit
the learned models. The algorithm can be misled by an inaccurate optimum
introduced by the surrogate. Instead, we use information theoretic constraints to
bound the ?distance? between the new and old data distribution while maximizing
the objective function. Additionally the new method is able to sustain the exploration
of the search distribution to avoid premature convergence. We compare our
method with state of art black-box optimization methods on standard uni-modal
and multi-modal optimization functions, on simulated planar robot tasks and a
complex robot ball throwing task. The proposed method considerably outperforms
the existing approaches.}
}

@article{lincoln38417,
          volume = {7},
          number = {2-3},
          author = {K. Atkinson and F. Cerutti and P. McBurney and Simon Parsons and I. Rahwan},
            note = {cited By 3},
           title = {Special issue on argumentation in multi-agent systems},
            year = {2016},
         journal = {Argument and Computation},
             doi = {10.3233/AAC-160013},
           pages = {109--112},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38417/}
}

@inproceedings{lincoln38551,
           title = {Analysis of empirical results on argumentation-based dialogue to support shared decision making in a human-robot team},
          author = {M.Q. Azhar and Elizabeth Sklar},
            year = {2016},
           pages = {861--866},
             doi = {10.1109/ROMAN.2016.7745220},
            note = {cited By 2},
         journal = {25th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2016},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38551/}
}

@article{lincoln23074,
          volume = {5},
          number = {1},
          author = {Alexandre Coninx and Paul Baxter and Elettra Oleari and Sara Bellini and Bert Bierman and Olivier Blanson Henkemans and Lola Canamero and Piero Cosi and Valentin Enescu and Raquel Ros Espinoza and Antoine Hiolle and Remi Humbert and Bernd Kiefer and Ivana Kruijff-korbayova and Rosemarijn Looije and Marco Mosconi and Mark Neerincx and Giulio Paci and Georgios Patsis and Clara Pozzi and Francesca Sacchitelli and Hichem Sahli and Alberto Sanna and Giacomo Sommavilla and Fabio Tesser and Yiannis Demiris and Tony Belpaeme},
           title = {Towards long-term social child-robot interaction: using multi-activity switching to engage young users},
         journal = {Journal of Human-Robot Interaction},
             doi = {10.5898/JHRI.5.1.Coninx},
           pages = {32--67},
            year = {2016},
        keywords = {ARRAY(0x5568fbae1f60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23074/},
        abstract = {Social robots have the potential to provide support in a number of practical domains, such as learning and behaviour change. This potential is particularly relevant for children, who have proven receptive to interactions with social robots. To reach learning and therapeutic goals, a number of issues need to be investigated, notably the design of an effective child-robot interaction (cHRI) to ensure the child remains engaged in the relationship and that educational goals are met. Typically, current cHRI research experiments focus on a single type of interaction activity (e.g. a game). However, these can suffer from a lack of adaptation to the child, or from an increasingly repetitive nature of the activity and interaction. In this paper, we motivate and propose a practicable solution to this issue: an adaptive robot able to switch between multiple activities within single interactions. We describe a system that embodies this idea, and present a case study in which diabetic children collaboratively learn with the robot about various aspects of managing their condition. We demonstrate the ability of our system to induce a varied interaction and show the potential of this approach both as an educational tool and as a research method for long-term cHRI.}
}

@inproceedings{lincoln38552,
          volume = {1678},
           title = {An empirical investigation of adaptive traffic control parameters},
          author = {J. Raphael and Elizabeth Sklar and S. Maskell},
            year = {2016},
            note = {cited By 0},
         journal = {CEUR Workshop Proceedings},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38552/}
}

@article{lincoln38553,
          volume = {9716},
          author = {E. Schneider and Elizabeth Sklar and S. Parsons},
            note = {cited By 3},
           title = {Evaluating multi-robot teamwork in parameterised environments},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-40379-3},
           pages = {301--313},
            year = {2016},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38553/}
}

@article{lincoln38555,
          volume = {30},
          number = {1},
          author = {Elizabeth Sklar and S. Parsons and Z. Li and J. Salvit and S. Perumal and H. Wall and J. Mangels},
            note = {cited By 9},
           title = {Evaluation of a trust-modulated argumentation-based interactive decision-making tool},
            year = {2016},
         journal = {Autonomous Agents and Multi-Agent Systems},
             doi = {10.1007/s10458-015-9289-1},
           pages = {136--173},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38555/}
}

@article{lincoln38419,
          volume = {30},
          number = {1},
          author = {E.I. Sklar and S. Parsons and Z. Li and J. Salvit and S. Perumal and H. Wall and J. Mangels},
            note = {cited By 9},
           title = {Evaluation of a trust-modulated argumentation-based interactive decision-making tool},
            year = {2016},
         journal = {Autonomous Agents and Multi-Agent Systems},
             doi = {10.1007/s10458-015-9289-1},
           pages = {136--173},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38419/},
        abstract = {The interactive ArgTrust application is a decision-making tool that is based on an underlying formal system of argumentation in which the evidence that influences a recommendation, or conclusion, is modulated according to values of trust that the user places in that evidence. This paper presents the design and analysis of a user study which was intended to evaluate the effectiveness of ArgTrust in a collaborative human?agent decision-making task. The results show that users? interactions with ArgTrust helped them consider their decisions more carefully than without using the software tool.}
}

@inproceedings{lincoln33109,
       booktitle = {2016 International Joint Conference on Neural Networks (IJCNN)},
           title = {Bio-inspired small target motion detector with a new lateral inhibition mechanism},
          author = {Hongxin Wang and Jigen Peng and Shigang Yue},
       publisher = {IEEE},
            year = {2016},
           pages = {4751--4758},
             doi = {doi:10.1109/IJCNN.2016.7727824},
        keywords = {ARRAY(0x5568fbaa1bc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33109/},
        abstract = {In nature, it is an important task for animals to detect small targets which move within cluttered background. In recent years, biologists have found that a class of neurons in the lobula complex, called STMDs (small target motion detectors) which have extreme selectivity for small targets moving within visual clutter. At the same time, some researchers assert that lateral inhibition plays an important role in discriminating the motion of the target from the motion of the background , even account for many features of the tuning of higher order visual neurons. Inspired by the finding that complete lateral inhibition can only be seen when the motion of the central region is identical to the motion of the peripheral region, we propose a new lateral inhibition mechanism combined with motion velocity and direction to improve the performance of ESTMD model (elementary small target motion detector). In this paper, we will elaborate on the biological plausibility and functionality of this new lateral inhibition mechanism in small target motion
detection.}
}

@article{lincoln38415,
          volume = {17},
          author = {P.A.L. de Castro and A.R. Barreto Teodoro and L.I. de Castro and Simon Parsons},
            note = {cited By 2},
           title = {Expected utility or prospect theory: Which better fits agent-based modeling of markets?},
         journal = {Journal of Computational Science},
             doi = {10.1016/j.jocs.2016.10.002},
           pages = {97--102},
            year = {2016},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38415/}
}

@book{lincoln39210,
       booktitle = {Supply Chain Management for Sustainable Food Networks},
           month = {December},
           title = {Supply Chain Management for Sustainable Food Networks},
          author = {Eleftherios Iakovou and Dionysis Bochtis and Dimitrios Vlachos and Dimitrios Aidonis},
       publisher = {Wiley},
            year = {2015},
             doi = {doi:10.1002/9781118937495},
        keywords = {ARRAY(0x5568fb6d1838)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39210/},
        abstract = {Supply Chain Management for Sustainable Food Networks provides an up-to-date and interdisciplinary framework for designing and operating sustainable supply chains for agri-food products. Focus is given to decision-making procedures and methodologies enabling policy-makers, managers and practitioners to design and manage effectively sustainable agrifood supply chain networks.
Authored by high profile researchers with global expertise in designing and operating sustainable supply chains in the agri-food industry, this book:

Features the entire hierarchical decision-making process for managing sustainable agrifood supply chains.
Covers knowledge-based farming, management of agricultural wastes, sustainability, green supply chain network design, safety, security and traceability, IT in agrifood supply chains, carbon footprint management, quality management, risk management and policy- making.
Explores green supply chain management, sustainable knowledge-based farming, corporate social responsibility, environmental management and emerging trends in agri-food retail supply chain operations.
Examines sustainable practices that are unique for agriculture as well as practices that already have been implemented in other industrial sectors such as green logistics and Corporate Social Responsibility (CSR).
Supply Chain Management for Sustainable Food Networks provides a useful resource for researchers, practitioners, policy-makers, regulators and C-level executives that deal with strategic decision-making. Post-graduate students in the field of agriculture sciences, engineering, operations management, logistics and supply chain management will also benefit from this book.}
}

@inproceedings{lincoln37398,
           month = {December},
          author = {F. Comin and C. Saaj},
            note = {cited By 1},
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           title = {Planetary soil classification based on the analysis of the interaction with deformable terrain of a wheel-legged robot},
       publisher = {IEEE},
            year = {2015},
         journal = {IEEE International Conference on Intelligent Robots and Systems},
             doi = {10.1109/IROS.2015.7354150},
           pages = {5460--5465},
        keywords = {ARRAY(0x5568fbb51f30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37398/},
        abstract = {In off-road applications, where mobile robots operate on rough environments, the physical properties of the terrain play a key role on their performance. An extreme example is posed by planetary rover missions to Mars, for which communication constraints and the inability of vision-based approaches to detect non-geometric hazards, e.g. sand traps hidden below thin duricrusts, can lead to permanent immobilisation, as experienced by NASA's Spirit rover. To prevent such events, this paper proposes a method to classify dry granular soils according to their physical properties by using an on-board sensor system for on-line analysis of sinkage, slippage and vibrations of the hybrid wheel-legs mounted on a highly mobile robot. As reflected by the experimental results, obtained using a single wheel-leg test bed, the novel approach produces an efficient and robust differentiation of soils with dissimilar physical properties. This output can enable autonomous avoidance of non-geometric hazards without endangering the mobility of the mission. Different classifier algorithms are trained, validated and compared in terms of classification accuracy and computational efficiency, revealing the advantages and disadvantages of each approach.}
}

@inproceedings{lincoln22677,
       booktitle = {3rd International Conference on Advances in Information Processing and Communication Technology - IPCT},
           month = {December},
           title = {An online changepoint detection algorithm for highly correlated data},
          author = {Sepehr Maleki and Chris Bingham and Yu Zhang},
       publisher = {Institute of Research Engineers and Doctors},
            year = {2015},
             doi = {10.15224/978},
        keywords = {ARRAY(0x5568fba638e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22677/},
        abstract = {An online 2-D changepoint detection algorithm for sensor-based fault detection, is proposed. The algorithm consists of a differential detector and a standard detector and can detect anomalies and meaningful changepoints while maintaining a low false-alarm rate. A new approach for determining a threshold is introduced and the efficiency of the algorithm is validated by an industrial example. It is thereby shown that the proposed algorithm can be used as an early warning indicator and prevent impending unit failures.}
}

@article{lincoln43253,
          volume = {4},
          number = {3},
           month = {December},
          author = {Elizabeth Sklar and M. Q. Azhar},
           title = {Argumentation-Based Dialogue Games for Shared Control in Human-Robot Systems},
            year = {2015},
         journal = {Journal of Human-Robot Interaction},
             doi = {10.5898/JHRI.4.3.Sklar},
           pages = {120},
        keywords = {ARRAY(0x5568fb953b98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43253/},
        abstract = {Dialogue can support exchange of ideas and discussion of options as a means to enable shared decision making for human-robot collaboration. However, dialogue that supports dynamic, evidence-backed exchange of ideas is a major challenge for today's human-robot systems. The work presented here investigates the application of argumentation-based dialogue games as the means to facilitate flexible interaction, including unscripted changes in initiative. Two main contributions are provided in this paper. First, a methodology for implementing multiple types of argumentation-based dialogues for human-robot interaction is detailed. This includes explanation about which types of dialogues are appropriate given the beliefs of the participants and how multiple dialogues can occur simultaneously while maintaining a consistent set of beliefs for the participants. Second, a formal definition is presented for the Treasure Hunt Game (THG), a test environment that provides rich opportunities for experimentation in shared human-robot control, as well as motivating and engaging experiences for human subjects.}
}

@inproceedings{lincoln29367,
           month = {November},
          author = {Ayse Kucukyilmaz and Yiannis Demiris},
       booktitle = {Proceedings of the 24th IEEE International Symposium on Robot and Human Interactive Communication 2015 (RO-MAN'15)},
           title = {One-shot assistance estimation from expert demonstrations for a shared control wheelchair system},
       publisher = {IEEE},
         journal = {Proceedings of the 24th IEEE International Symposium on Robot and Human Interactive Communication 2015 (RO-MAN'15)},
             doi = {10.1109/ROMAN.2015.7333600},
            year = {2015},
        keywords = {ARRAY(0x5568fbba1240)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29367/},
        abstract = {An emerging research problem in the field of assistive robotics is the design of methodologies that allow robots to provide human-like assistance to the users. Especially within the rehabilitation domain, a grand challenge is to program a robot to mimic the operation of an occupational therapist, intervening with the user when necessary so as to improve the therapeutic power of the assistive robotic system. We propose a method to estimate assistance policies from expert demonstrations to present human-like intervention during navigation in a powered wheelchair setup. For this purpose, we constructed a setting, where a human offers assistance to the user over a haptic shared control system. The robot learns from human assistance demonstrations while the user is actively driving the wheelchair in an unconstrained environment. We train a Gaussian process regression model to learn assistance commands given past and current actions of the user and the state of the environment. The results indicate that the model can estimate human assistance after only a single demonstration, i.e. in one-shot, so that the robot can help the user by selecting the appropriate assistance in a human-like fashion.}
}

@article{lincoln17596,
          volume = {322},
           month = {November},
          author = {Nikolaos Mavridis and Nicola Bellotto and Konstantinos Iliopoulos and Nico Van de Weghe},
           title = {QTC3D: extending the qualitative trajectory calculus to three dimensions},
       publisher = {Elsevier},
            year = {2015},
         journal = {Information Sciences},
             doi = {10.1016/j.ins.2015.06.002},
           pages = {20--30},
        keywords = {ARRAY(0x5568fba96430)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17596/},
        abstract = {Spatial interactions between agents (humans, animals, or machines) carry information of high value to human or electronic observers. However, not all the information contained in a pair of continuous trajectories is important and thus the need for qualitative descriptions of interaction trajectories arises. The Qualitative Trajectory Calculus (QTC) (Van de Weghe, 2004) is a promising development towards this goal. Numerous variants of QTC have been proposed in the past and QTC has been applied towards analyzing various interaction domains. However, an inherent limitation of those QTC variations that deal with lateral movements is that they are limited to two-dimensional motion; therefore, complex three-dimensional interactions, such as those occurring between flying planes or birds, cannot be captured. Towards that purpose, in this paper QTC3D is presented: a novel qualitative trajectory calculus that can deal with full three-dimensional interactions. QTC3D is based on transformations of the Frenet-Serret frames accompanying the trajectories of the moving objects. Apart from the theoretical exposition, including definition and properties, as well as computational aspects, we also present an application of QTC3D towards modeling bird flight. Thus, the power of QTC is now extended to the full dimensionality of physical space, enabling succinct yet rich representations of spatial interactions between agents.}
}

@inproceedings{lincoln25748,
          volume = {2015-D},
           month = {November},
          author = {A. Abdolmaleki and N. Lau and L. P. Reis and G. Neumann},
       booktitle = {Humanoid Robots (Humanoids), 2015 IEEE-RAS 15th International Conference on},
           title = {Regularized covariance estimation for weighted maximum likelihood policy search methods},
            year = {2015},
         journal = {IEEE-RAS International Conference on Humanoid Robots},
             doi = {10.1109/HUMANOIDS.2015.7363529},
           pages = {154--159},
        keywords = {ARRAY(0x5568fbba4f60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25748/},
        abstract = {Many episode-based (or direct) policy search algorithms, maintain a multivariate Gaussian distribution as search distribution over the parameter space of some objective function. One class of algorithms, such as episodic REPS, PoWER or PI2 uses, a weighted maximum likelihood estimate (WMLE) to update the mean and covariance matrix of this distribution in each iteration. However, due to high dimensionality of covariance matrices and limited number of samples, the WMLE is an unreliable estimator. The use of WMLE leads to over-fitted covariance estimates, and, hence the variance/entropy of the search distribution decreases too quickly, which may cause premature convergence. In order to alleviate this problem, the estimated covariance matrix can be regularized in different ways, for example by using a convex combination of the diagonal covariance estimate and the sample covariance estimate. In this paper, we propose a new covariance matrix regularization technique for policy search methods that uses the convex combination of the sample covariance matrix and the old covariance matrix used in last iteration. The combination weighting is determined by specifying the desired entropy of the new search distribution. With this mechanism, the entropy of the search distribution can be gradually decreased without damage from the maximum likelihood estimate.}
}

@inproceedings{lincoln25751,
          volume = {2015-D},
           month = {November},
          author = {R. Lioutikov and G. Neumann and G. Maeda and J. Peters},
       booktitle = {15th IEEE-RAS International Conference on Humanoid Robots},
           title = {Probabilistic segmentation applied to an assembly task},
            year = {2015},
         journal = {IEEE-RAS International Conference on Humanoid Robots},
             doi = {10.1109/HUMANOIDS.2015.7363584},
           pages = {533--540},
        keywords = {ARRAY(0x5568fbaee048)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25751/},
        abstract = {Movement primitives are a well established approach
for encoding and executing robot movements. While
the primitives themselves have been extensively researched, the
concept of movement primitive libraries has not received as
much attention. Libraries of movement primitives represent
the skill set of an agent and can be queried and sequenced in
order to solve specific tasks. The goal of this work is to segment
unlabeled demonstrations into an optimal set of skills. Our
novel approach segments the demonstrations while learning
a probabilistic representation of movement primitives. The
method differs from current approaches by taking advantage of
the often neglected, mutual dependencies between the segments
contained in the demonstrations and the primitives to be encoded.
Therefore, improving the combined quality of both segmentation
and skill learning. Furthermore, our method allows
incorporating domain specific insights using heuristics, which
are subsequently evaluated and assessed through probabilistic
inference methods. We demonstrate our method on a real robot
application, where the robot segments demonstrations of a chair
assembly task into a skill library. The library is subsequently
used to assemble the chair in an order not present in the
demonstrations.}
}

@inproceedings{lincoln25750,
          volume = {2015-D},
           month = {November},
          author = {H. Van Hoof and T. Hermans and G. Neumann and J. Peters},
       booktitle = {International Conference on Humanoid Robots (HUMANOIDS)},
           title = {Learning robot in-hand manipulation with tactile features},
            year = {2015},
         journal = {IEEE-RAS International Conference on Humanoid Robots},
             doi = {10.1109/HUMANOIDS.2015.7363524},
           pages = {121--127},
        keywords = {ARRAY(0x5568fbb92cf0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25750/},
        abstract = {Dexterous manipulation enables repositioning of
objects and tools within a robot?s hand. When applying dexterous
manipulation to unknown objects, exact object models
are not available. Instead of relying on models, compliance and
tactile feedback can be exploited to adapt to unknown objects.
However, compliant hands and tactile sensors add complexity
and are themselves difficult to model. Hence, we propose acquiring
in-hand manipulation skills through reinforcement learning,
which does not require analytic dynamics or kinematics models.
In this paper, we show that this approach successfully acquires
a tactile manipulation skill using a passively compliant hand.
Additionally, we show that the learned tactile skill generalizes
to novel objects.}
}

@article{lincoln22214,
          volume = {34},
          number = {1},
           month = {November},
          author = {Heriberto Cuayahuitl and Kazunori Komatani and Gabriel Skantze},
           title = {Introduction for speech and language for interactive robots},
       publisher = {Elsevier for International Speech Communication Association (ISCA)},
            year = {2015},
         journal = {Computer Speech \& Language},
             doi = {10.1016/j.csl.2015.05.006},
           pages = {83--86},
        keywords = {ARRAY(0x5568fb678168)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22214/},
        abstract = {This special issue includes research articles which apply spoken language processing to robots that interact with human users through speech, possibly combined with other modalities. Robots that can listen to human speech, understand it, interact according to the conveyed meaning, and respond represent major research and technological challenges. Their common aim is to equip robots with natural interaction abilities. However, robotics and spoken language processing are areas that are typically studied within their respective communities with limited communication across disciplinary boundaries. The articles in this special issue represent examples that address the need for an increased multidisciplinary exchange of ideas.}
}

@article{lincoln44701,
           month = {October},
           title = {Failure identification for linear repetitive processes},
          author = {Sepehr Maleki and Paolo Rapisarda and Eric Rogers},
       publisher = {Springer},
            year = {2015},
             doi = {https://doi.org/10.1007/s11045-015-0345-4},
         journal = {Multidimensional Systems and Signal Processing},
        keywords = {ARRAY(0x5568fbb02478)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44701/},
        abstract = {This paper investigates the fault detection and isolation (FDI) problem for discrete-time linear repetitive processes using a geometric approach, starting from a 2-D model for these processes that incorporates a representation of the failure. Based on this model, the FDI problem is formulated in the geometric setting and sufficient conditions for solvability of this problem are given. Moreover, the processes' behaviour in the presence of noise is considered, leading to the development of a statistical approach for determining a decision threshold. Finally, an FDI procedure is developed based on an asymptotic observer reconstruction of the state vector.}
}

@inproceedings{lincoln25753,
          volume = {2015-D},
           month = {October},
          author = {M. Ewerton and G. Maeda and J. Peters and G. Neumann},
       booktitle = {IEEE/RSJ Conference on Intelligent Robots and Systems (IROS)},
           title = {Learning motor skills from partially observed movements executed at different speeds},
            year = {2015},
         journal = {IEEE International Conference on Intelligent Robots and Systems},
             doi = {10.1109/IROS.2015.7353412},
           pages = {456--463},
        keywords = {ARRAY(0x5568fba49618)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25753/},
        abstract = {Learning motor skills from multiple demonstrations
presents a number of challenges. One of those challenges
is the occurrence of occlusions and lack of sensor coverage,
which may corrupt part of the recorded data. Another issue
is the variability in speed of execution of the demonstrations,
which may require a way of finding the correspondence between
the time steps of the different demonstrations. In this paper,
an approach to learn motor skills is proposed that accounts
both for spatial and temporal variability of movements. This
approach, based on an Expectation-Maximization algorithm to
learn Probabilistic Movement Primitives, also allows for learning
motor skills from partially observed demonstrations, which may
result from occlusion or lack of sensor coverage. An application
of the algorithm proposed in this work lies in the field of
Human-Robot Interaction when the robot has to react to human
movements executed at different speeds. Experiments in which
a robotic arm receives a cup handed over by a human illustrate
this application. The capabilities of the algorithm in learning
and predicting movements are also evaluated in experiments
using a data set of letters and a data set of golf putting
movements.}
}

@inproceedings{lincoln19407,
       booktitle = {WONDER 2015, First International Workshop on Educational Robotics},
           month = {October},
           title = {Educational robotics for teaching computer science in Africa - pilot study},
          author = {Ernest Gyebi and Marc Hanheide and Grzegorz Cielniak},
            year = {2015},
        keywords = {ARRAY(0x5568fba72010)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/19407/},
        abstract = {Educational robotics can play a key role in addressing some of the challenges faced by higher education institutions in Africa. A remaining and open question is related to effectiveness of activities involving educational robots for teaching but also for improving learner's experience. This paper addresses that question by evaluating a short pilot study which introduced students at the Department of Computer Science, University of Ghana to robot programming. The initial positive results from the study indicate a potential for such activities to enhance teaching experience and practice at African institutions. The proposed integrated set-up including robotic hardware, software and educational tasks was effective and will form a solid base for a future, full scale integration of robotic activities into the undergraduate curricula at this particular institution. This evaluation should be valuable to other educators integrating educational robots into undergraduate curricula in developing countries and elsewhere.}
}

@inproceedings{lincoln19696,
       booktitle = {Towards a Framework for Joint Action},
           month = {October},
           title = {Make me a sandwich! Intrinsic human identification from their course of action},
          author = {Peter Lightbody and Christian Dondrup and Marc Hanheide},
            year = {2015},
        keywords = {ARRAY(0x5568fba063c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/19696/},
        abstract = {In order to allow humans and robots to work closely together and as a team, we need to equip robots not only with a general understanding of joint action, but also with an understanding of the idiosyncratic differences in the ways humans perform certain tasks. This will allow robots to be better colleagues, by anticipating an individual's actions, and acting accordingly. In this paper, we present a way of encoding a human's course of action as a probabilistic sequence of qualitative states, and show that such a model can be employed to identify individual humans from their respective course of action, even when accomplishing the very same goal state. We conclude from our findings that there are significant variations in the ways humans accomplish the very same task, and that our representation could in future work inform robot (task) planning in collaborative settings.}
}

@inproceedings{lincoln18457,
       booktitle = {Third International Conference on Advances in Computing, Electronics and Communication},
           month = {October},
           title = {2-D online changepoint detection algorithm for sensor-based fault detection},
          author = {Sepehr Maleki and Chris Bingham and Yu Zhang},
            year = {2015},
           pages = {94--99},
             doi = {10.15224/978-1-63248-064-4-20},
        keywords = {ARRAY(0x5568fbacac68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/18457/},
        abstract = {An online 2-D changepoint detection algorithm for sensor-based fault detection, is proposed. The algorithm consists of a differential detector and a standard detector and can detect anomalies and meaningful changepoints while maintaining a low false-alarm rate. The efficiency of the algorithm is validated by two industrial examples. It is thereby shown that the proposed algorithm can be used as an early warning indicator and prevent impending unit failures.}
}

@inproceedings{lincoln19219,
       booktitle = {Third International Conference on Advances in Computing, Electronics and Communication},
           month = {October},
           title = {Measurement reconstruction in sensor networks for industrial systems},
          author = {Yu Zhang and Chris Bingham and Sepehr Maleki},
            year = {2015},
        keywords = {ARRAY(0x5568fbaf6198)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/19219/},
        abstract = {For signal processing in sensor networks there is an on-going challenge for filling missing information when it is either incomplete, uncertain or biased, in ways that are both efficient and with confidence. This paper reviews three established and additional newly developed techniques addressing the problem. Considering sensor signals that are highly correlated in a sensor network, one sensor measurement can be reconstructed based on measurements from other sensors. In such cases, three signal reconstruction methods are considered: 1) principal component analysis (PCA) based missing value approach; 2) self-organizing map neural network (SOMNN) based algorithm; and 3) an analytical optimization (AO) technique. To demonstrate the efficacy of the methods, temperature data are studied on an industrial gas turbine system, where, especially, a faulty sensor signal is utilized to be reconstructed from the other sensor measurements.}
}

@inproceedings{lincoln18477,
       booktitle = {IEEE/RSJ IROS Workshop on Assistance and Service Robotics in a Human Environment},
           month = {October},
           title = {Applying a 3D qualitative trajectory calculus to human action recognition using depth cameras},
          author = {Claudio Coppola and Oscar Martinez Mozos and Nicola Bellotto},
       publisher = {IEEE},
            year = {2015},
            note = {2015 IEEE/RSJ International Conference on Intelligent Robots and Systems},
        keywords = {ARRAY(0x5568fba5c800)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/18477/},
        abstract = {The life span of ordinary people is increasing steadily and many developed countries are facing the big challenge of dealing with an ageing population at greater risk of impairments and cognitive disorders, which hinder their quality of life. Monitoring human activities of daily living (ADLs) is important in order to identify potential health problems and apply corrective strategies as soon as possible. Towards this long term goal, the research here presented is a first step to monitor ADLs using 3D sensors in an Ambient Assisted Living (AAL) environment. In particular, the work here presented adopts a new 3D Qualitative Trajectory Calculus (QTC3D) to represent human actions that belong to such activities, designing and implementing a set of computational tools (i.e. Hidden Markov Models) to learn and classify them from standard datasets. Preliminary results show the good performance of our system and its potential application to a large number of scenarios, including mobile robots for AAL.}
}

@article{lincoln19405,
          volume = {4},
          number = {4},
           month = {October},
          author = {Farshad Arvin and Caihua Xiong and Shigang Yue},
           title = {Colias-{\ensuremath{\Phi}}: an autonomous micro robot for artificial pheromone communication},
            year = {2015},
         journal = {International Journal of Mechanical Engineering and Robotics Research},
             doi = {10.18178/ijmerr.4.4.349-353},
           pages = {349--353},
        keywords = {ARRAY(0x5568fbba1b70)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/19405/},
        abstract = {Ants pheromone communication is an efficient mechanism which took inspiration from nature. It has been used in various artificial intelligence and multi robotics researches. This paper presents the development of an autonomous micro robot to be used in swarm robotic researches especially in pheromone based communication systems. The robot is an extended version of Colias micro robot with capability of decoding and following artificial pheromone trails. We utilize a low-cost experimental setup to implement pheromone-based scenarios using a flat LCD screen and a USB camera. The results of the performed experiments with group of robots demonstrated the feasibility of Colias-{\ensuremath{\Phi}} to be used in pheromone based experiments.}
}

@article{lincoln40826,
          volume = {80},
          number = {1},
           month = {October},
          author = {Gautham Das and Thomas M. McGinnity and Sonya A. Coleman and Laxmidhar Behera},
           title = {A Distributed Task Allocation Algorithm for a Multi-Robot System in Healthcare Facilities},
       publisher = {Springer},
            year = {2015},
         journal = {Journal of Intelligent \& Robotic Systems},
             doi = {10.1007/s10846-014-0154-2},
           pages = {33--58},
        keywords = {ARRAY(0x5568fbb617b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40826/},
        abstract = {Various ambient assisted living (AAL) technologies have been proposed for improving the living conditions of elderly people. One of them is to introduce robots to reduce dependency on support staff. The tasks commonly encountered in a healthcare facility such as a care home for elderly people are heterogeneous and are of different priorities. A care home environment is also dynamic and new emergency priority tasks, which if not attended shortly may result in fatal situations, may randomly appear. Therefore, it is better to use a multi-robot system (MRS) consisting of heterogeneous robots than designing a single robot capable of doing all tasks. An efficient task allocation algorithm capable of handling the dynamic nature of the environment, the heterogeneity of robots and tasks, and the prioritisation of tasks is required to reap the benefits of introducing an MRS.
This paper proposes Consensus Based Parallel Auction and Execution (CBPAE), a distributed algorithm for task allocation in a system of multiple heterogeneous autonomous robots deployed in a healthcare facility, based on auction and consensus principles. Unlike many of the existing market based task allocation algorithms, which use a time extended allocation of tasks before the actual execution is initialised, the proposed algorithm uses a parallel auction and execution framework, and is thus suitable for highly dynamic real world environments. The robots continuously resolve any conflicts in the bids on tasks using inter-robot communication and a consensus process in each robot before a task is assigned to a robot. We demonstrate the effectiveness of the CBPAE by comparing its simulation results with those of an existing market based distributed multi-robot task allocation algorithm and through experiments on real robots.}
}

@article{lincoln17957,
           month = {September},
          author = {Farshad Arvin and Tomas Krajnik and Ali Emre Turgut and Shigang Yue},
            note = {Conference:
2015 IEEE/RSJ International Conference on  Intelligent Robots and Systems (IROS 2015), 28 September - 2 October 2015, Hamburg, Germany},
           title = {COS-{\ensuremath{\Phi}}: artificial pheromone system for robotic swarms research},
       publisher = {IEEE},
         journal = {IEEE/RSJ International Conference on Intelligent Robots and Systems 2015},
             doi = {10.1109/IROS.2015.7353405},
            year = {2015},
        keywords = {ARRAY(0x5568fbb37a58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17957/},
        abstract = {Pheromone-based communication is one of the most effective ways of communication widely observed in nature. It is particularly used by social insects such as bees, ants and termites; both for inter-agent and agent-swarm communications. Due to its effectiveness; artificial pheromones have been adopted in multi-robot and swarm robotic systems for more than a decade. Although, pheromone-based communication was implemented by different means like chemical (use of particular chemical compounds) or physical (RFID tags, light, sound) ways, none of them were able to replicate all the aspects of pheromones as seen in nature. In this paper, we propose a novel artificial pheromone system that is reliable, accurate and it uses off-the-shelf components only -- LCD screen and low-cost USB camera. The system allows to simulate several pheromones and their interactions and to change parameters of the pheromones (diffusion, evaporation, etc.) on the fly allowing for controllable experiments. We tested the performance of the system using the Colias platform in single-robot and swarm scenarios. To allow the swarm robotics community to use the system for their research, we provide it as a freely available open-source package.}
}

@inproceedings{lincoln18860,
       booktitle = {IROS Workshop on "Bridging user needs to deployed applications of service robots"},
           month = {September},
           title = {What do staff in eldercare want a robot for? An assessment of potential tasks and user requirements for a long-term deployment},
          author = {Denise Hebesberger and Tobias K{\"o}rtner and J{\"u}rgen Pripfl and Christoph Gisinger and Marc Hanheide},
         address = {Hamburg},
            year = {2015},
            note = {The Robot-Era Project has received funding from the European Community's Seventh Framework Programme (FP7/2007-2013) under grant agreement num. 288899 
FP7 - ICT - Challenge 5: ICT for Health, Ageing Well, Inclusion and Governance},
        keywords = {ARRAY(0x5568fb9ba420)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/18860/},
        abstract = {Robotic aids could help to overcome the gap between rising numbers of older adults and at the same time declining numbers of care staff. Assessments of end-user requirements, especially focusing on staff in eldercare facilities are still sparse. Contributing to this field of research this study presents end-user requirements and task analysis gained from a methodological combination of interviews and focus group discussions. The findings suggest different tasks robots in eldercare could engage in such as ?fetch and carry? tasks, specific entertainment and information tasks, support in physical and occupational therapy, and in security. Furthermore this paper presents an iterative approach that closes the loop between requirements-assessments and subsequent implementations that follow the found requirements.}
}

@inproceedings{lincoln18877,
       booktitle = {IROS Workshop on Aerial Open-source Robotics},
           month = {September},
           title = {WhyCon: an efficient, marker-based localization system},
          author = {Matias Nitsche and Tomas Krajnik and Petr Cizek and Marta Mejail and Tom Duckett},
            year = {2015},
        keywords = {ARRAY(0x5568fb2d9fe0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/18877/},
        abstract = {We present an open-source marker-based localization system intended as a low-cost easy-to-deploy solution for aerial and swarm robotics. The main advantage of the presented method is its high computational efficiency, which allows its deployment on small robots with limited computational resources. Even on low-end computers, the core component of the system can detect and estimate 3D positions of hundreds of black and white markers at the maximum frame-rate of standard cameras. The method is robust to changing lighting conditions and achieves accuracy in the order of millimeters to centimeters. Due to its reliability, simplicity of use and availability as an open-source ROS module (http://purl.org/robotics/whycon), the system is now used in a number of aerial robotics projects where fast and precise relative localization is required.}
}

@inproceedings{lincoln25752,
          volume = {2015-D},
           month = {September},
          author = {A. Paraschos and E. Rueckert and J. Peters and G. Neumann},
       booktitle = {IEEE/RSJ Conference on Intelligent Robots and Systems (IROS)},
           title = {Model-free Probabilistic Movement Primitives for physical interaction},
            year = {2015},
         journal = {IEEE International Conference on Intelligent Robots and Systems},
             doi = {10.1109/IROS.2015.7353771},
           pages = {2860--2866},
        keywords = {ARRAY(0x5568fbb54dc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25752/},
        abstract = {Physical interaction in robotics is a complex problem
that requires not only accurate reproduction of the kinematic
trajectories but also of the forces and torques exhibited
during the movement. We base our approach on Movement
Primitives (MP), as MPs provide a framework for modelling
complex movements and introduce useful operations on the
movements, such as generalization to novel situations, time
scaling, and others. Usually, MPs are trained with imitation
learning, where an expert demonstrates the trajectories. However,
MPs used in physical interaction either require additional
learning approaches, e.g., reinforcement learning, or are based
on handcrafted solutions. Our goal is to learn and generate
movements for physical interaction that are learned with imitation
learning, from a small set of demonstrated trajectories.
The Probabilistic Movement Primitives (ProMPs) framework
is a recent MP approach that introduces beneficial properties,
such as combination and blending of MPs, and represents the
correlations present in the movement. The ProMPs provides
a variable stiffness controller that reproduces the movement
but it requires a dynamics model of the system. Learning such
a model is not a trivial task, and, therefore, we introduce the
model-free ProMPs, that are learning jointly the movement and
the necessary actions from a few demonstrations. We derive
a variable stiffness controller analytically. We further extent
the ProMPs to include force and torque signals, necessary for
physical interaction. We evaluate our approach in simulated
and real robot tasks.}
}

@inproceedings{lincoln46176,
       booktitle = {OCEANS 2015 - Genova},
           month = {September},
           title = {Underwater running on uneven terrain},
          author = {Marcello Calisti and Cecilia Laschi},
            year = {2015},
           pages = {1--5},
             doi = {10.1109/OCEANS-Genova.2015.7271366},
        keywords = {ARRAY(0x5568fbb5a960)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46176/},
        abstract = {In this work a punting gait model, describing a robot running underwater, is studied with respect to unknown variations of the ground and design parameters of the robot. The model, described through a dynamical system, is actuated with an open-loop control and exhibits self-stabilizing running, represented by the limit cycle of the system, on flat terrain. By introducing a simulated uneven terrain and by keeping the same open-loop control, it appears that the self-stable gait is not affected by disturbances until a certain threshold, when the robot falls to the ground. Moreover, the stability appears to be proportional to the density of the robot and inversely proportional to the drag coefficient of the body, thus suggesting some criteria for the design of underwater running robots.}
}

@inproceedings{lincoln46175,
       booktitle = {OCEANS 2015 - Genova},
           month = {September},
           title = {Thrust depletion at high pulsation frequencies in underactuated, soft-bodied, pulsed-jet vehicles},
          author = {Francesco Giorgio-Serchi and Federico Renda and Marcello Calisti and Cecilia Laschi},
            year = {2015},
           pages = {1--6},
             doi = {10.1109/OCEANS-Genova.2015.7271369},
        keywords = {ARRAY(0x5568fbaee8e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46175/},
        abstract = {In this paper we examine the passive stage in the propulsive cycle of a soft-bodied, pulsed-jet, underwater vehicle and its effect on the resultant thrust. This vehicle consists of an elastic shell which propels itself via the discontinuous expulsion and ingestion of finite slugs of ambient water, resulting in a pulsated routine. The activation routine involves the collapse of the elastic shell via cable transmission and its subsequent passive inflation driven by the elastic energy stored in the strained shell walls. Earlier analysis by the authors have found that the thrust generated at each pulsation depends massively on the resilience of the elastic material which composes the shell. In order to improve the design of these vehicle it is thus necessary to characterize the dynamic behaviour of the elastic shell during its stage of inflation by resorting to a coupled potential flow-elastodynamics model. The results enable to better parametrize the thrust model so far employed for this kind of vehicles and in this way achieve a more rigorous description of the vehicle dynamics for design and control purposes.}
}

@inproceedings{lincoln24940,
       booktitle = {2015 IEEE International Workshop on Machine Learning for Signal Processing},
           month = {September},
           title = {Modelling LGMD2 visual neuron system},
          author = {Qinbing Fu and Shigang Yue},
            year = {2015},
        keywords = {ARRAY(0x5568fbb7a588)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24940/},
        abstract = {Two Lobula Giant Movement Detectors (LGMDs) have been identified in the lobula region of the locust visual system: LGMD1 and LGMD2. LGMD1 had been successfully used in robot navigation to avoid impending collision. LGMD2 also responds to looming stimuli in depth, and shares most the same properties with LGMD1; however, LGMD2 has its specific collision selective responds when dealing with different visual stimulus. Therefore, in this paper, we propose a novel way to model LGMD2, in order to emulate its predicted bio-functions, moreover, to solve some defects of previous LGMD1 computational models. The mechanism of ON and OFF cells, as well as bioinspired nonlinear functions, are introduced in our model, to achieve LGMD2?s collision selectivity. Our model has been tested by a miniature mobile robot in real time. The results suggested this model has an ideal performance in both software and hardware for collision recognition.}
}

@inproceedings{lincoln46167,
       booktitle = {2015 International Conference on Advanced Robotics (ICAR)},
           month = {September},
           title = {Evolutionary discovery of self-stabilized dynamic gaits for a soft underwater legged robot},
          author = {Francesco Corucci and Marcello Calisti and Helmut Hauser and Cecilia Laschi},
            year = {2015},
           pages = {337--344},
             doi = {10.1109/ICAR.2015.7251477},
        keywords = {ARRAY(0x5568fb670be0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46167/},
        abstract = {In recent years a number of robotic platforms have been developed, that are capable of robust locomotion in presence of a simple open loop control. Relying on the self-stabilizing properties of their mechanical structure, morphology assumes a crucial role in the design process, that is, however, usually guided by a set of heuristic principles falling under what is commonly known as embodied intelligence. Despite many impressive demonstrations, the result of such a methodology may be sub-optimal, given the dimension of the design space and the complex intertwining of involved dynamical effects. Encouraged by the growing consensus that embodied solutions can indeed be produced by bio-inspired computational techniques in a more automated manner, this work proposes a computer-aided methodology to explore in simulation the design space of an existing robot, by harnessing computational techniques inspired by natural evolution. Although many works exist on the application of evolutionary algorithms in robotics, few of them embrace this design perspective. The idea is to have an evolutionary process suggesting to the human designer a number of interesting robot configurations and embodied behaviors, from whose analysis design hints can be gained to improve the platform. The focus will be on enhancing the locomotion capabilities of a multi-legged, soft, underwater robot. We investigate for the first time the suitability of a recently introduced open-ended evolutionary algorithm (novelty search) for the intended study, and demonstrate its benefits in the comparison with a more conventional genetic algorithm. Results confirm that evolutionary algorithms are indeed capable of producing new, elaborate dynamic gaits, with evolved designs exhibiting several regularities. Possible future directions are also pointed out, in which the passive exploitation of robot's morphological features could bring additional advantages in achieving diverse, robust behaviors.}
}

@inproceedings{lincoln17955,
       booktitle = {European Conference on Mobile Robots 2015 (ECMR 15)},
           month = {September},
           title = {Life-long spatio-temporal exploration of dynamic environments},
          author = {Tomas Krajnik and Joao Santos and Tom Duckett},
       publisher = {IEEE},
            year = {2015},
        keywords = {ARRAY(0x5568fbbc1e78)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17955/},
        abstract = {We propose a new idea for life-long mobile robot spatio-temporal exploration of dynamic environments.  Our method assumes that the world is subject to perpetual change, which adds an extra, temporal dimension to the explored space and makes the exploration task a never-ending data-gathering process. To create and maintain a spatio-temporal model of a dynamic environment, the robot has to determine not only where, but also when to perform observations.  We address the problem by application of information-theoretic exploration to world representations that model the uncertainty of environment states as probabilistic functions of time.

We compare the performance of different exploration strategies and temporal models on real-world data gathered over the course of several months and show that combination of dynamic environment representations with information-gain exploration principles allows to create and maintain up-to-date models of constantly changing environments.}
}

@inproceedings{lincoln17954,
       booktitle = {European Conference on Mobile Robots 2015 (ECMR 15)},
           month = {September},
           title = {Image features and seasons revisited},
          author = {Tomas Krajnik and Pablo deCristoforis and Matias Nitsche and Keerthy Kusumam and Tom Duckett},
       publisher = {IEEE},
            year = {2015},
        keywords = {ARRAY(0x5568fbb84e38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17954/},
        abstract = {We present an evaluation of standard image features in the context of long-term visual teach-and-repeat mobile robot navigation, where the environment exhibits significant changes in appearance caused by seasonal weather variations and daily illumination changes. We argue that in the given long-term scenario, the viewpoint, scale and rotation invariance of the standard feature extractors is less important than their robustness to the mid- and long-term environment appearance changes. Therefore, we focus our evaluation on the robustness of image registration to variable lighting and naturally-occurring seasonal changes.  We evaluate the image feature extractors on three datasets collected by mobile robots in two different outdoor environments over the course of one year. Based on this analysis, we propose a novel feature descriptor based on a combination of evolutionary algorithms and Binary Robust Independent Elementary Features, which we call GRIEF (Generated BRIEF). In terms of robustness to seasonal changes, the GRIEF feature descriptor outperforms the other ones while being computationally more efficient.}
}

@article{lincoln46171,
          volume = {31},
          number = {4},
           month = {August},
          author = {Michele Giorelli and Federico Renda and Marcello Calisti and Andrea Arienti and Gabriele Ferri and Cecilia Laschi},
           title = {Neural Network and Jacobian Method for Solving the Inverse Statics of a Cable-Driven Soft Arm With Nonconstant Curvature},
            year = {2015},
         journal = {IEEE Transactions on Robotics},
             doi = {10.1109/TRO.2015.2428511},
           pages = {823--834},
        keywords = {ARRAY(0x5568fbb08ee8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46171/},
        abstract = {The solution of the inverse kinematics problem of soft manipulators is essential to generate paths in the task space. The inverse kinematics problem of constant curvature or piecewise constant curvature manipulators has already been solved by using different methods, which include closed-form analytical approaches and iterative methods based on the Jacobian method. On the other hand, the inverse kinematics problem of nonconstant curvature manipulators remains unsolved. This study represents one of the first attempts in this direction. It presents both a model-based method and a supervised learning method to solve the inverse statics of nonconstant curvature soft manipulators. In particular, a Jacobian-based method and a feedforward neural network are chosen and tested experimentally. A comparative analysis has been conducted in terms of accuracy and computational time.}
}

@inproceedings{lincoln37448,
          volume = {9246},
           month = {August},
          author = {S.M. Mustaza and D. Mahdi and C. Saaj and W.A. Albukhanajer and C. Lekakou and Y. Elsayed and J. Fras},
            note = {cited By 3},
       booktitle = {International Conference on Intelligent Robotics and Applications},
           title = {Tuneable stiffness design of soft continuum manipulator},
       publisher = {Springer},
            year = {2015},
             doi = {10.1007/978-3-319-22873-0\_14},
           pages = {152--163},
        keywords = {ARRAY(0x5568fbb70108)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37448/},
        abstract = {Soft continuum robots are highly deformable and manoeuvrable manipulators, capable of navigating through confined space and interacting safely with their surrounding environment, making them ideal for minimally invasive surgical applications. A crucial requirement of a soft robot is to control its overall stiffness efficiently, in order to execute the necessary surgical task in an unstructured environment. This paper presents a comparative study detailing the stiffness characterization of two soft manipulator designs and the formulation of a dynamic stiffness matrix for the purpose of disturbance rejection and stiffness control for precise tip positioning. An empirical approach is used to accurately describe the stiffness characteristics along the length of the manipulator and the derived stiffness matrix is applied in real-time control to reject disturbances. Further, the capability of the two types of soft robots to reject disturbances using the dynamic control technique is tested and compared. The results presented in this paper provide new insights into controlling the stiffness of soft continuum robots for minimally invasive surgical applications.}
}

@article{lincoln37429,
          volume = {17},
          number = {8},
           month = {August},
          author = {C. Lekakou and Y. Elsayed and T. Geng and C. Saaj},
            note = {cited By 7},
           title = {Skins and Sleeves for Soft Robotics: Inspiration from Nature and Architecture},
       publisher = {Wiley},
            year = {2015},
         journal = {Advanced Engineering Materials},
             doi = {10.1002/adem.201400406},
           pages = {1180--1188},
        keywords = {ARRAY(0x5568fb9c1258)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37429/},
        abstract = {This paper is on the design, fabrication, and testing of skins and sleeves for soft robotics with the focus on the mechanical features of the microstructure of these skins, drawing inspiration from nature and architecture. Biological inspirations drawn from animals are used for designing skin membranes or skin structures for soft robotic actuators, in particular pneumatic actuators that protect, guide, and contribute to the development of the actuated shape. The results presented in this paper will be a new step toward advancing the state-of-the-art of biologically inspired soft robots for minimally invasive surgery. Inspirations from architecture are of particular interest in the areas of formability of design and continuous flow. The report presents a trade-off study using various skin and sleeve technologies of innovative fiber structures and combinations of different materials in different innovative designs, surrounding a pneumatically actuated, soft robot of variable stiffness.}
}

@article{lincoln26608,
          volume = {5},
          number = {3},
           month = {August},
          author = {C. Keeble and G. R. Law and S. Barber and P. D. Baxter},
            note = {{\copyright} 2015 by authors and Scientific Research Publishing Inc. This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/},
           title = {Choosing a method to reduce selection bias: a tool for researchers},
       publisher = {Scientific Research Publishing},
            year = {2015},
         journal = {Open Journal of Epidemiology},
             doi = {10.4236/ojepi.2015.53020},
           pages = {155 -- 162},
        keywords = {ARRAY(0x5568fbbc1448)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26608/},
        abstract = {Selection bias is well known to affect surveys and epidemiological studies. There have been numerous methods proposed to reduce its effects, so many that researchers may be unclear which method is most suitable for their study; the wide choice may even deter some researchers, for fear of choosing a sub-optimal approach. We propose a straightforward tool to inform researchers of the most promising methods available to reduce selection bias and to assist the search for an appropriate method given their study design and details. We demonstrate the tool using three exam- ples where selection bias may occur; the tool quickly eliminates inappropriate methods and guides the researcher towards those to consider implementing. If more studies con- sider selection bias and adopt methods to reduce it, valuable time and resources will be saved, and should lead to more focused research towards disease prevention or cure.}
}

@article{lincoln46195,
          volume = {10},
          number = {4},
           month = {July},
          author = {Marcello Calisti and F Corucci and A Arienti and C Laschi},
           title = {Dynamics of underwater legged locomotion: modeling and experiments on an octopus-inspired robot},
            year = {2015},
         journal = {Bioinspiration \& Biomimetics},
             doi = {10.1088/1748-3190/10/4/046012},
           pages = {46012},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46195/},
        abstract = {This paper studies underwater legged locomotion (ULL) by means of a robotic octopus-inspired prototype and its associated model. Two different types of propulsive actions are embedded into the robot model: reaction forces due to leg contact with the ground and hydrodynamic forces such as the drag arising from the sculling motion of the legs. Dynamic parameters of the model are estimated by means of evolutionary techniques and subsequently the model is exploited to highlight some distinctive features of ULL. Specifically, the separation between the center of buoyancy (CoB)/center of mass and density affect the stability and speed of the robot, whereas the sculling movements contribute to propelling the robot even when its legs are detached from the ground. The relevance of these effects is demonstrated through robotic experiments and model simulations; moreover, by slightly changing the position of the CoB in the presence of the same feed-forward activation, a number of different behaviors (i.e. forward and backward locomotion at different speeds) are achieved.}
}

@inproceedings{lincoln17501,
       booktitle = {12th International Conference on Informatics in Control, Automation and Robotics (ICINCO 2015)},
           month = {July},
           title = {Progressive co-adaptation in human-machine interaction},
          author = {Paolo Gallina and Nicola Bellotto and Massimiliano Di Luca},
            year = {2015},
        keywords = {ARRAY(0x5568fba861f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17501/},
        abstract = {In this paper we discuss the concept of co-adaptation between a human operator and a machine interface and we summarize its application with emphasis on two different domains, teleoperation and assistive technology. The analysis of the literature reveals that only in few cases the possibility of a temporal evolution of the co-adaptation parameters has been considered. In particular, it has been overlooked the role of time-related indexes that capture changes in motor and cognitive abilities of the human operator. We argue that for a more effective long-term co-adaptation process, the interface should be able to predict and adjust its parameters according to the evolution of human skills and performance. We thus propose a novel approach termed progressive co-adaptation, whereby human performance is continuously monitored and the system makes inferences about changes in the users' cognitive and motor skills. We illustrate the features of progressive co-adaptation in two possible applications, robotic telemanipulation and active vision for the visually impaired.}
}

@inproceedings{lincoln40827,
           month = {July},
          author = {Philip Vance and Sonya A. Coleman and Dermot Kerr and Gautham Das and Thomas M. McGinnity},
       booktitle = {2015 International Joint Conference on Neural Networks (IJCNN)},
           title = {Modelling of a retinal ganglion cell with simple spiking models},
       publisher = {IEEE},
             doi = {10.1109/IJCNN.2015.7280759},
           pages = {1--8},
            year = {2015},
        keywords = {ARRAY(0x5568fba5eac8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40827/},
        abstract = {Modelling aspects of the human vision system, including the retina, is difficult due to insufficient knowledge about the internal components, organisation and complexity of the interactions within the system. Retinal ganglion cells are considered a core component of the human visual system as they convey the accumulated data as action potentials onto the optic nerve. Current techniques capable of mapping this input-output response involve computational combinations of linear and nonlinear models that are generally complex and lack any relevance to the underlying biophysics. This paper aims to model a retinal ganglion cell with a simple spiking neuron combined with a pre-processing method, which accounts for the preceding retinal neural structure. Performance of the models is compared with the spike responses obtained in the electrophysiological recordings from a mammalian retina subjected to visual stimulation.}
}

@inproceedings{lincoln46187,
       booktitle = {Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation},
           month = {July},
           title = {Novelty-Based Evolutionary Design of Morphing Underwater Robots},
          author = {Francesco Corucci and Marcello Calisti and Helmut Hauser and Cecilia Laschi},
            year = {2015},
           pages = {145--152},
             doi = {10.1145/2739480.2754686},
        keywords = {ARRAY(0x5568fbbb4180)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46187/},
        abstract = {Recent developments in robotics demonstrated that bioinspiration and embodiement are powerful tools to achieve robust behavior in presence of little control. In this context morphological design is usually performed by humans, following a set of heuristic principles: in general this can be limiting, both from an engineering and an artificial life perspectives. In this work we thus suggest a different approach, leveraging evolutionary techniques. The case study is the one of improving the locomotion capabilities of an existing bioinspired robot. First, we explore the behavior space of the robot to discover a number of qualitatively different morphology-enabled behaviors, from whose analysis design indications are gained. The suitability of novelty search -- a recent open-ended evolutionary algorithm -- for this intended purpose is demonstrated. Second, we show how it is possible to condense such behaviors into a reconfigurable robot capable of online morphological adaptation (morphosis, morphing). Examples of successful morphing are demonstrated, in which changing just one morphological parameter entails a dramatic change in the behavior: this is promising for a future robot design. The approach here adopted represents a novel computed-aided, bioinspired, design paradigm, merging human and artificial creativity. This may result in interesting implications also for artificial life, having the potential to contribute in exploring underwater locomotion "as-it-could-be".}
}

@inproceedings{lincoln34493,
       booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA)},
           month = {July},
           title = {An incremental approach to learning generalizable robot tasks from human demonstration},
          author = {Amir Ghalamzan Esfahani},
       publisher = {IEEE},
            year = {2015},
             doi = {10.1109/ICRA.2015.7139985},
        keywords = {ARRAY(0x5568fb9fbba8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34493/},
        abstract = {Dynamic Movement Primitives (DMPs) are a common method for learning a control policy for a task from demonstration. This control policy consists of differential equations that can create a smooth trajectory to a new goal point. However, DMPs only have a limited ability to generalize the demonstration to new environments and solve problems such as obstacle avoidance. Moreover, standard DMP learning does not cope with the noise inherent to human demonstrations. Here, we propose an approach for robot learning from demonstration that can generalize noisy task demonstrations to a new goal point and to an environment with obstacles. This strategy for robot learning from demonstration results in a control policy that incorporates different types of learning from demonstration, which correspond to different types of observational learning as outlined in developmental psychology.}
}

@inproceedings{lincoln20151,
          volume = {2015-A},
           month = {July},
          author = {Dongdong Wang and Shigang Yue and Jiawei Xu and Xinwen Hou and Cheng-Lin Liu},
            note = {Conference Code:117127},
       booktitle = {Intelligent Vehicles Symposium, IV 2015},
           title = {A saliency-based cascade method for fast traffic sign detection},
       publisher = {Institute of Electrical and Electronics Engineers Inc.},
            year = {2015},
         journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
             doi = {10.1109/IVS.2015.7225683},
           pages = {180--185},
        keywords = {ARRAY(0x5568fbb5f0d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/20151/},
        abstract = {We propose a cascade method for fast and accurate traffic sign detection. The main feature of the method is that mid-level saliency test is used to efficiently and reliably eliminate background windows. Fast feature extraction is adopted in the subsequent stages for rejecting more negatives. Combining with neighbor scales awareness in window search, the proposed method runs at 3{\texttt{\char126}}5 fps for high resolution (1360x800) images, 2{\texttt{\char126}}7 times as fast as most state-of-the-art methods. Compared with them, the proposed method yields competitive performance on prohibitory signs while sacrifices performance moderately on danger and mandatory signs. {\copyright} 2015 IEEE.}
}

@article{lincoln17879,
          volume = {20},
          number = {3},
           month = {June},
          author = {Wenbin Chen and Caihua Xiong and Shigang Yue},
           title = {Mechanical implementation of kinematic synergy for continual grasping generation of anthropomorphic hand},
       publisher = {IEEE},
            year = {2015},
         journal = {IEEE/ASME Transactions on Mechatronics},
             doi = {10.1109/TMECH.2014.2329006},
           pages = {1249--1263},
        keywords = {ARRAY(0x5568fb9b80a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17879/},
        abstract = {The synergy-based motion generation of current anthropomorphic hands generally employ the static posture synergy, which is extracted from quantities of joint trajectory, to design the mechanism or control strategy. Under this framework, the temporal weight sequences of each synergy from pregrasp phase to grasp phase are required for reproducing any grasping task. Moreover, the zero-offset posture has to be preset before starting any grasp. Thus, the whole grasp phase appears to be unlike natural human grasp. Up until now, no work in the literature addresses these issues toward simplifying the continual grasp by only inputting the grasp pattern. In this paper, the kinematic synergies observed in angular velocity profile are employed to design the motion generation mechanism. The kinematic synergy extracted from quantities of grasp tasks is implemented by the proposed eigen cam group in tendon space. The completely continual grasp from the fully extending posture only require averagely rotating the two eigen cam groups one cycle. The change of grasp pattern only depends on respecifying transmission ratio pair for the two eigen cam groups. An illustrated hand prototype is developed based on the proposed design principle and the grasping experiments demonstrate the feasibility of the design method. The potential applications include the prosthetic hand that is controlled by the classified pattern from the bio-signal.}
}

@article{lincoln17877,
          volume = {61},
          number = {7},
           month = {June},
          author = {Jigen Peng and Shigang Yue and Haiyang Li},
           title = {NP/CMP equivalence: a phenomenon hidden among sparsity models l\_\{0\} minimization and l\_\{p\} minimization for information processing},
       publisher = {IEEE},
            year = {2015},
         journal = {IEEE Transactions on Information Theory},
             doi = {10.1109/TIT.2015.2429611},
           pages = {4028--4033},
        keywords = {ARRAY(0x5568fba87fc0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17877/},
        abstract = {In this paper, we have proved that in every underdetermined linear system Ax = b, there corresponds a constant p*(A, b) {\ensuremath{>}} 0 such that every solution to the l p-norm minimization problem also solves the l0-norm minimization problem whenever 0 {\ensuremath{<}}; p {\ensuremath{<}}; p*(A, b). This phenomenon is named NP/CMP equivalence.}
}

@inproceedings{lincoln17829,
       booktitle = {IEEE international conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)},
           month = {June},
           title = {Operational pattern analysis for predictive maintenance scheduling of industrial systems},
          author = {Yu Zhang and Chris Bingham and Michael Gallimore and Sepehr Maleki},
            year = {2015},
        keywords = {ARRAY(0x5568fb96a1e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17829/},
        abstract = {The paper presents a method to identify the operational usage patterns for industrial systems. Specifically, power measurements from an industrial gas turbine generator are studied. A fast Fourier transform (FFT) and image segmentation is used to develop an intuitive representation of operation. A spectrogram is adopted to study the average usage through the use of spectral power indices, with singular spectral analysis (SSA) applied for operational trend extraction.  Through use of these techniques, two fundamental inputs for predictive maintenance scheduling viz. the users behaviour with regard to long-term unit startups patterns, and the duty cycle of power requirements, can be readily identified.}
}

@article{lincoln20639,
          volume = {29},
          number = {4},
           month = {June},
          author = {Jiawei Xu and Shigang Yue},
           title = {Building up a bio-inspired visual attention model by integrating top-down shape bias and improved mean shift adaptive segmentation},
       publisher = {World Scientific Publishing Co. Pte Ltd},
            year = {2015},
         journal = {International Journal of Pattern Recognition and Artificial Intelligence},
             doi = {10.1142/S0218001415550058},
        keywords = {ARRAY(0x5568fbaf5ef8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/20639/},
        abstract = {The driver-assistance system (DAS) becomes quite necessary in-vehicle equipment nowadays due to the large number of road traffic accidents worldwide. An efficient DAS detecting hazardous situations robustly is key to reduce road accidents. The core of a DAS is to identify salient regions or regions of interest relevant to visual attended objects in real visual scenes for further process. In order to achieve this goal, we present a method to locate regions of interest automatically based on a novel adaptive mean shift segmentation algorithm to obtain saliency objects. In the proposed mean shift algorithm, we use adaptive Bayesian bandwidth to find the convergence of all data points by iterations and the k-nearest neighborhood queries. Experiments showed that the proposed algorithm is efficient, and yields better visual salient regions comparing with ground-truth benchmark. The proposed algorithm continuously outperformed other known visual saliency methods, generated higher precision and better recall rates, when challenged with natural scenes collected locally and one of the largest publicly available data sets. The proposed algorithm can also be extended naturally to detect moving vehicles in dynamic scenes once integrated with top-down shape biased cues, as demonstrated in our experiments. {\^A}{\copyright} 2015 World Scientific Publishing Company.}
}

@inproceedings{lincoln17627,
           month = {June},
          author = {Farshad Arvin and Rahman Attar and Ali Emre Turgut and Shigang Yue},
       booktitle = {International Conference on Swarm Intelligence},
           title = {Power-law distribution of long-term experimental data in swarm robotics},
       publisher = {Springer},
             doi = {10.1007/978-3-319-20466-6 58},
           pages = {551--559},
            year = {2015},
        keywords = {ARRAY(0x5568fb9b60d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17627/},
        abstract = {Bio-inspired aggregation is one of the most fundamental behaviours that has been 
studied in swarm robotic for more than two decades. Biology revealed that the 
environmental characteristics are very important factors in aggregation of social insects and 
other animals. In this paper, we study the effects of different environmental factors such as 
size and texture of aggregation cues using real robots. In addition, we propose a 
mathematical model to predict the behaviour of the aggregation during an experiment.}
}

@article{lincoln46173,
          volume = {10},
          number = {3},
           month = {June},
          author = {M Giorelli and F Renda and M Calisti and A Arienti and G Ferri and C Laschi},
           title = {Learning the inverse kinetics of an octopus-like manipulator in three-dimensional space},
            year = {2015},
         journal = {Bioinspiration \& Biomimetics},
             doi = {10.1088/1748-3190/10/3/035006},
           pages = {035006},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46173/},
        abstract = {This work addresses the inverse kinematics problem of a bioinspired octopus-like manipulator moving in three-dimensional space. The bioinspired manipulator has a conical soft structure that confers the ability of twirling around objects as a real octopus arm does. Despite the simple design, the soft conical shape manipulator driven by cables is described by nonlinear differential equations, which are difficult to solve analytically. Since exact solutions of the equations are not available, the Jacobian matrix cannot be calculated analytically and the classical iterative methods cannot be used. To overcome the intrinsic problems of methods based on the Jacobian matrix, this paper proposes a neural network learning the inverse kinematics of a soft octopus-like manipulator driven by cables. After the learning phase, a feed-forward neural network is able to represent the relation between manipulator tip positions and forces applied to the cables. Experimental results show that a desired tip position can be achieved in a short time, since heavy computations are avoided, with a degree of accuracy of 8\% relative average error with respect to the total arm length.}
}

@inproceedings{lincoln25759,
          volume = {2015-J},
          number = {June},
           month = {June},
          author = {Oliver Kroemer and Christian Daniel and Gerhard Neumann and Herke Van Hoof and Jan Peters},
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           title = {Towards learning hierarchical skills for multi-phase manipulation tasks},
       publisher = {IEEE},
            year = {2015},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
             doi = {10.1109/ICRA.2015.7139389},
           pages = {1503--1510},
        keywords = {ARRAY(0x5568fba1b400)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25759/},
        abstract = {Most manipulation tasks can be decomposed into
a sequence of phases, where the robot?s actions have different
effects in each phase. The robot can perform actions to
transition between phases and, thus, alter the effects of its
actions, e.g. grasp an object in order to then lift it. The robot
can thus reach a phase that affords the desired manipulation.
In this paper, we present an approach for exploiting the
phase structure of tasks in order to learn manipulation skills
more efficiently. Starting with human demonstrations, the robot
learns a probabilistic model of the phases and the phase
transitions. The robot then employs model-based reinforcement
learning to create a library of motor primitives for transitioning
between phases. The learned motor primitives generalize to new
situations and tasks. Given this library, the robot uses a value
function approach to learn a high-level policy for sequencing
the motor primitives. The proposed method was successfully
evaluated on a real robot performing a bimanual grasping task.}
}

@article{lincoln17577,
          volume = {2015},
           month = {June},
          author = {Haiyang Li and Jigen Peng and Shigang Yue},
            note = {Article ID 584712, 6 pages},
           title = {The sparsity of underdetermined linear system via lp minimization for 0 {\ensuremath{<}} p {\ensuremath{<}} 1},
       publisher = {Hindawi Publishing Corporation},
            year = {2015},
         journal = {Mathematical Problems in Engineering},
             doi = {10.1155/2015/584712},
        keywords = {ARRAY(0x5568fba57250)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17577/},
        abstract = {The sparsity problems have attracted a great deal of attention in recent years, which aim to find the sparsest solution of a representation or an equation. In the paper, we mainly study the sparsity of underdetermined linear system via lp minimization for 0{\ensuremath{<}}p{\ensuremath{<}}1. We show, for a given underdetermined linear system of equations pm{$\times$}np = p, that although it is not certain that the problem (pp) (i.e., minlx{\ensuremath{|}}{\ensuremath{|}}X{\ensuremath{|}}{\ensuremath{|}}plp subject to pp = b, where  0{\ensuremath{<}}p{\ensuremath{<}}1 ) generates sparser solutions as the value of p decreases and especially the problem (plp) generates sparser solutions than the problem (p1) (i.e., minlx{\ensuremath{|}}{\ensuremath{|}}X{\ensuremath{|}}{\ensuremath{|}}1 subject to AX = b ), there exists a sparse constant {\ensuremath{\gamma}}(A, p) {\ensuremath{>}} 0 such that the following conclusions hold when p {\ensuremath{<}} {\ensuremath{\gamma}}(A, b): (1) the problem (pp) generates sparser solution as the value of p decreases; (2) the sparsest optimal solution to the problem (pp) is unique under the sense of absolute value permutation; (3) let X1 and X2 be the sparsest optimal solution to the problems (pp1) and (pp2) , respectively, and let  X1 not be the absolute value permutation of  X2. Then there exist t1,t2 {\ensuremath{\epsilon}} [p1,p2]  such that X1 is the sparsest optimal solution to the problem (pt) (?t {\ensuremath{\epsilon}} [p1, t1])  and X2 is the sparsest optimal solution to the problem (pt) (?t {\ensuremath{\epsilon}} (t2, p2]).}
}

@article{lincoln17143,
          volume = {9107},
           month = {June},
          author = {Virginia Sandulescu and Sally Andrews and David Ellis and Nicola Bellotto and Oscar Martinez Mozos},
            note = {Series: Lecture Notes in Computer Science
Artificial Computation in Biology and Medicine: International Work-Conference on the Interplay Between Natural and Artificial Computation, IWINAC 2015, Elche, Spain, June 1-5, 2015, Proceedings, Part I},
           title = {Stress detection using wearable physiological sensors},
       publisher = {Springer verlag},
            year = {2015},
         journal = {Lecture Notes in Computer Science},
           pages = {526--532},
        keywords = {ARRAY(0x5568fba57220)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17143/},
        abstract = {As the population increases in the world, the ratio of health carers is rapidly decreasing. Therefore, there is an urgent need to create new technologies to monitor the physical and mental health of people during their  daily life. In particular, negative mental states like depression and anxiety are big problems in modern societies, usually due to stressful situations during everyday activities including work. This paper presents a machine learning approach for stress detection on people using wearable physiological sensors with the ?final aim of improving their quality of life. The presented technique can monitor the state of the subject continuously and classify it into "stressful" or "non-stressful" situations. Our classification results show that this method is a good starting point towards real-time stress detection.}
}

@inproceedings{lincoln25762,
          volume = {2015-J},
          number = {June},
           month = {May},
          author = {Marco Ewerton and Gerhard Neumann and Rudolf Lioutikov and Heni Ben Amor and Jan Peters and Guilherme Maeda},
            note = {cited By 2},
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           title = {Learning multiple collaborative tasks with a mixture of interaction primitives},
       publisher = {IEEE},
            year = {2015},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
             doi = {10.1109/ICRA.2015.7139393},
           pages = {1535--1542},
        keywords = {ARRAY(0x5568fbb90ac8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25762/},
        abstract = {Robots that interact with humans must learn to
not only adapt to different human partners but also to new
interactions. Such a form of learning can be achieved by
demonstrations and imitation. A recently introduced method
to learn interactions from demonstrations is the framework
of Interaction Primitives. While this framework is limited
to represent and generalize a single interaction pattern, in
practice, interactions between a human and a robot can consist
of many different patterns. To overcome this limitation this
paper proposes a Mixture of Interaction Primitives to learn
multiple interaction patterns from unlabeled demonstrations.
Specifically the proposed method uses Gaussian Mixture Models
of Interaction Primitives to model nonlinear correlations
between the movements of the different agents. We validate
our algorithm with two experiments involving interactive tasks
between a human and a lightweight robotic arm. In the first,
we compare our proposed method with conventional Interaction
Primitives in a toy problem scenario where the robot and the
human are not linearly correlated. In the second, we present a
proof-of-concept experiment where the robot assists a human
in assembling a box.}
}

@inproceedings{lincoln25760,
          volume = {2015-J},
          number = {June},
           month = {May},
          author = {E. Rueckert and J. Mundo and A. Paraschos and J. Peters and Gerhard Neumann},
       booktitle = {IEEE International Conference on Robotics and Automation 2015},
           title = {Extracting low-dimensional control variables for movement primitives},
            year = {2015},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
             doi = {10.1109/ICRA.2015.7139390},
           pages = {1511--1518},
        keywords = {ARRAY(0x5568fbbb8770)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25760/},
        abstract = {Movement primitives (MPs) provide a powerful framework for data driven movement generation that has been successfully applied for learning from demonstrations and robot reinforcement learning. In robotics we often want to solve a multitude of different, but related tasks. As the parameters of the primitives are typically high dimensional, a common practice for the generalization of movement primitives to new tasks is to adapt only a small set of control variables, also called meta parameters, of the primitive. Yet, for most MP representations, the encoding of these control variables is pre-coded in the representation and can not be adapted to the considered tasks. In this paper, we want to learn the encoding of task-specific control variables also from data instead of relying on fixed meta-parameter representations. We use hierarchical Bayesian models (HBMs) to estimate a low dimensional latent variable model for probabilistic movement primitives (ProMPs), which is a recent movement primitive representation. We show on two real robot datasets that ProMPs based on HBMs outperform standard ProMPs in terms of generalization and learning from a small amount of data and also allows for an intuitive analysis of the movement. We also extend our HBM by a mixture model, such that we can model different movement types in the same dataset.}
}

@inproceedings{lincoln17558,
       booktitle = {Developing Countries Forum at ICRA 2015},
           month = {May},
           title = {Colias: towards an affordable mobile robot for education in developing countries},
          author = {Ernest Gyebi and Farshad Arvin and Marc Hanheide and Shigang Yue and Grzegorz Cielniak},
            year = {2015},
        keywords = {ARRAY(0x5568fbb44b80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17558/},
        abstract = {Educational robotics can play a key role in addressing some of the important challenges faced by higher education
in developing countries. One of the major obstacles preventing a wider adoption of initiatives involving educational robotics in these parts of the world is a lack of robot platforms which would be affordable for the local educational institutions. In this paper, we present our inexpensive mobile robot platform Colias and assess its potential for education in developing countries. To this end, we describe hardware and software components of the robot, assess its suitability for education and discuss the missing features which will need to be developed to turn Colias into a fully featured educational platform. The presented robot is one of the key components of our current efforts in popularising
educational robotics at African universities.}
}

@inproceedings{lincoln17545,
       booktitle = {Workshop on Machine Learning for Social Robotics at ICRA 2015},
           month = {May},
           title = {Real-time multisensor people tracking for human-robot spatial interaction},
          author = {Christian Dondrup and Nicola Bellotto and Ferdian Jovan and Marc Hanheide},
       publisher = {ICRA / IEEE},
            year = {2015},
        keywords = {ARRAY(0x5568fbb47318)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17545/},
        abstract = {All currently used mobile robot platforms are able to navigate safely through their environment, avoiding static and dynamic obstacles. However, in human populated environments mere obstacle avoidance is not sufficient to make humans feel comfortable and safe around robots. To this end, a large community is currently producing human-aware navigation approaches to create a more socially acceptable robot behaviour. Amajorbuilding block for all Human-Robot Spatial Interaction is the ability of detecting and tracking humans in the vicinity of the robot. We present a fully integrated people perception framework, designed to run in real-time on a mobile robot. This framework employs detectors based on laser and RGB-D data and a tracking approach able to fuse multiple detectors using different versions of data association and Kalman filtering. The resulting trajectories are transformed into Qualitative Spatial Relations based on a Qualitative Trajectory Calculus, to learn and classify different encounters using a Hidden Markov Model based representation. We present this perception pipeline, which is fully implemented into the Robot Operating System (ROS), in a small proof of concept experiment. All components are readily available for download, and free to use under the MIT license, to researchers in all fields, especially focussing on social interaction learning by providing different kinds of output, i.e. Qualitative Relations and trajectories.}
}

@inproceedings{lincoln17952,
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA 2015)},
           month = {May},
           title = {COS{\ensuremath{\Phi}}: Vision-based artificial pheromone system for robotic swarms},
          author = {Tomas Krajnik and Farshad Arvin and Ali Emre Turgut and Shigang Yue and Tom Duckett},
       publisher = {IEEE},
            year = {2015},
        keywords = {ARRAY(0x5568fba9b4a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17952/},
        abstract = {We propose a novel spatio-temporal mobile-robot exploration method for dynamic, human-populated environments. In contrast to other exploration methods that model the environment as being static, our spatio-temporal exploration method creates and maintains a world model that not only represents the environment's structure, but also its dynamics over time.  Consideration of the world dynamics adds an extra, temporal dimension to the explored space and makes the exploration task a never-ending data-gathering process to keep the robot's environment model up-to-date.
Thus, the crucial question is not only where, but also when to observe the explored environment. 
We address the problem by application of information-theoretic exploration to world representations that model the environment states' uncertainties as probabilistic functions of time. The predictive ability of the spatio-temporal model allows the exploration method to decide not only where, but also when to make environment observations. 

To verify the proposed approach, an evaluation of several exploration strategies and spatio-temporal models was carried out using real-world data gathered over several months. The evaluation indicates that through understanding of the environment dynamics, the proposed spatio-temporal exploration method could predict which locations were going to change at a specific time and use this knowledge to guide the robot.  Such an ability is crucial for long-term deployment of mobile robots in human-populated spaces that change over time.}
}

@inproceedings{lincoln17949,
           month = {May},
          author = {Tomas Krajnik and Miroslav Kulich and Lenka Mudrova and Rares Ambrus and Tom Duckett},
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
           title = {Where's Waldo at time t? Using spatio-temporal models for mobile robot search},
       publisher = {Institute of Electrical and Electronics Engineers},
             doi = {10.1109/ICRA.2015.7139481},
           pages = {2140--2146},
            year = {2015},
        keywords = {ARRAY(0x5568fbb93fa0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17949/},
        abstract = {We present a novel approach to mobile robot search for non-stationary objects in partially known environments. We formulate the search as a path planning problem in an environment where the probability of object occurrences at particular locations is a function of time. We propose to explicitly model the dynamics of the object occurrences by their frequency spectra. Using this spectral model, our path planning algorithm can construct plans that reflect the likelihoods of object locations at the time the search is performed. Three datasets collected over several months containing person and object occurrences in residential and office environments were chosen to evaluate the approach. Several types of spatio-temporal models were created for each of these datasets and the efficiency of the search method was assessed by measuring the time it took to locate a particular object. The results indicate that modeling the dynamics of object occurrences reduces the search time by 25\% to 65\% compared to maps that neglect these dynamics.}
}

@inproceedings{lincoln17953,
       booktitle = {ICRA 2015 Workshop on Visual Place Recognition in Changing Environments},
           month = {May},
           title = {FreMEn: frequency map enhancement for long-term mobile robot autonomy in changing environments},
          author = {Tomas Krajnik and Jaime Pulido Fentanes and Joao Santos and Keerthy Kusumam and Tom Duckett},
       publisher = {IEEE},
            year = {2015},
        keywords = {ARRAY(0x5568fbbc57c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17953/},
        abstract = {We present a method for introducing representation of dynamics into environment models that were originally tailored to represent static scenes. Rather than using a fixed probability value, the method models the uncertainty of the elementary environment states by probabilistic functions of time. These are composed of combinations of harmonic functions, which are obtained by means of frequency analysis. The use of frequency analysis allows to integrate long-term observations into memory-efficient spatio-temporal models that reflect the mid- to long-term environment dynamics. These frequency-enhanced spatio-temporal models allow to predict the future environment states, which improves the efficiency of mobile robot operation in changing environments.   In a series of experiments performed over periods of days to years, we demonstrate that the proposed approach improves localization, path planning and exploration.}
}

@inproceedings{lincoln25696,
          volume = {2015-J},
          number = {June},
           month = {May},
          author = {O. Kroemer and C. Daniel and G. Neumann and H. Van Hoof and J. Peters},
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA), 2015},
           title = {Towards learning hierarchical skills for multi-phase manipulation tasks},
       publisher = {IEEE},
            year = {2015},
             doi = {10.1109/ICRA.2015.7139389},
           pages = {1503--1510},
        keywords = {ARRAY(0x5568fbb9ceb0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25696/},
        abstract = {Most manipulation tasks can be decomposed into a sequence of phases, where the robot's actions have different effects in each phase. The robot can perform actions to transition between phases and, thus, alter the effects of its actions, e.g. grasp an object in order to then lift it. The robot can thus reach a phase that affords the desired manipulation. In this paper, we present an approach for exploiting the phase structure of tasks in order to learn manipulation skills more efficiently. Starting with human demonstrations, the robot learns a probabilistic model of the phases and the phase transitions. The robot then employs model-based reinforcement learning to create a library of motor primitives for transitioning between phases. The learned motor primitives generalize to new situations and tasks. Given this library, the robot uses a value function approach to learn a high-level policy for sequencing the motor primitives. The proposed method was successfully evaluated on a real robot performing a bimanual grasping task.}
}

@inproceedings{lincoln17745,
       booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA 2015)},
           month = {May},
           title = {Now or later? Predicting and maximising success of navigation actions from long-term experience},
          author = {Jaime Pulido Fentanes and Bruno Lacerda and Tomas Krajnik and Nick Hawes and Marc Hanheide},
       publisher = {IEEE/RAS},
            year = {2015},
        keywords = {ARRAY(0x5568fba41ce0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17745/},
        abstract = {In planning for deliberation or navigation in real-world robotic systems, one of the big challenges is to cope with change. It lies in the nature of planning that it has to make assumptions about the future state of the world, and the robot?s chances of successively accomplishing actions in this future.
Hence, a robot?s plan can only be as good as its predictions about the world. In this paper, we present a novel approach to specifically represent changes that stem from periodic events in the environment (e.g. a door being opened or closed), which impact on the success probability of planned actions. We show that our approach to model the probability of action success as a set of superimposed periodic processes allows the robot to predict action outcomes in a long-term data obtained in two real-life offices better than a static model. We furthermore discuss and showcase how this knowledge gathered can be successfully employed in a probabilistic planning framework to devise better navigation plans. The key contributions of this paper are (i) the formation of the spectral model of action outcomes from non-uniform sampling, the (ii) analysis of its predictive power using two long-term datasets, and (iii) the application of the predicted outcomes in an MDP-based planning framework.}
}

@inproceedings{lincoln17951,
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
           month = {May},
           title = {Lifelong exploration of dynamic environments},
          author = {Joao Santos and Tomas Krajnik and Jaime Pulido Fentanes and Tom Duckett},
       publisher = {IEEE},
            year = {2015},
        keywords = {ARRAY(0x5568fbbba548)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17951/},
        abstract = {We propose a novel spatio-temporal mobile-robot exploration method for dynamic, human-populated environments.
In contrast to other exploration methods that model the environment as being static, our spatio-temporal exploration method creates and maintains a world model that not only represents the environment's structure, but also its dynamics over time. Consideration of the world dynamics adds an extra, temporal dimension to the explored space and makes the exploration task a never-ending data-gathering process to keep the robot's environment model up-to-date. Thus, the crucial question is not only where, but also when to observe the explored environment. We address the problem by application of information-theoretic exploration to world representations that model the environment states' uncertainties as probabilistic functions of time. The predictive ability of the spatio-temporal model allows the exploration method to decide not only where, but also when to make environment observations.

To verify the proposed approach, an evaluation of several exploration strategies and spatio-temporal models was carried out using real-world data gathered over several months. The evaluation indicates that through understanding of the environment dynamics, the proposed spatio-temporal exploration method could predict which locations were going to change at a specific time and use this knowledge to guide the robot. Such an ability is crucial for long-term deployment of mobile robots in human-populated spaces that change over time.}
}

@inproceedings{lincoln17557,
       booktitle = {6th International Conference on Robotics in Education},
           month = {May},
           title = {Affordable mobile robotic platforms for teaching computer science at African universities},
          author = {Ernest Gyebi and Marc Hanheide and Grzegorz Cielniak},
            year = {2015},
        keywords = {ARRAY(0x5568fb9c46c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17557/},
        abstract = {Educational robotics can play a key role in addressing some of the challenges faced by higher education in Africa. One of the major obstacles preventing a wider adoption of initiatives involving educational robotics in this part of the world is lack of robots that would be affordable by African institutions. In this paper, we present a survey and analysis of currently available affordable mobile robots and their suitability for teaching computer science at African universities. To this end, we propose a set of assessment criteria and review a number of platforms costing an order of magnitude less than the existing popular educational robots. Our analysis identifies suitable candidates offering contrasting features and benefits. We also discuss potential issues and promising directions which can be considered by both educators in Africa but also designers and manufacturers of future robot platforms.}
}

@article{lincoln46194,
          volume = {10},
          number = {3},
           month = {May},
          author = {M Cianchetti and M Calisti and L Margheri and M Kuba and C Laschi},
           title = {Bioinspired locomotion and grasping in water: the soft eight-arm OCTOPUS robot},
            year = {2015},
         journal = {Bioinspiration \& Biomimetics},
             doi = {10.1088/1748-3190/10/3/035003},
           pages = {35003},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46194/},
        abstract = {The octopus is an interesting model for the development of soft robotics, due to its high deformability, dexterity and rich behavioural repertoire. To investigate the principles of octopus dexterity, we designed an eight-arm soft robot and evaluated its performance with focused experiments. The OCTOPUS robot presented here is a completely soft robot, which integrates eight arms extending in radial direction and a central body which contains the main processing units. The front arms are mainly used for elongation and grasping, while the others are mainly used for locomotion. The robotic octopus works in water and its buoyancy is close to neutral. The experimental results show that the octopus-inspired robot can walk in water using the same strategy as the animal model, with good performance over different surfaces, including walking through physical constraints. It can grasp objects of different sizes and shapes, thanks to its soft arm materials and conical shape.}
}

@article{lincoln25757,
          volume = {38},
           month = {May},
          author = {Herke Van Hoof and Jan Peters and Gerhard Neumann},
            note = {Proceedings of the 18th International Conference
on Artificial Intelligence and Statistics (AISTATS), 9-12 May
2015, San Diego, CA,},
       booktitle = {18th International Conference on Artificial Intelligence and Statistics (AISTATS)},
           title = {Learning of non-parametric control policies with high-dimensional state features},
       publisher = {MIT Press},
            year = {2015},
         journal = {Journal of Machine Learning Research: Workshop and Conference Proceedings},
           pages = {995--1003},
        keywords = {ARRAY(0x5568fbb80030)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25757/},
        abstract = {Learning complex control policies from highdimensional sensory input is a challenge for
reinforcement learning algorithms. Kernel methods that approximate values functions
or transition models can address this problem. Yet, many current approaches rely on
instable greedy maximization. In this paper, we develop a policy search algorithm that
integrates robust policy updates and kernel embeddings. Our method can learn nonparametric
control policies for infinite horizon continuous MDPs with high-dimensional
sensory representations. We show that our method outperforms related approaches, and
that our algorithm can learn an underpowered swing-up task task directly from highdimensional
image data.}
}

@article{lincoln17367,
          volume = {2015},
           month = {May},
          author = {Yi Gao and W. Wang and Shigang Yue},
            note = {This is an open access article distributed under the Creative Commons Attribution License, which
permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
           title = {On the rate of convergence by generalized Baskakov operators},
       publisher = {Hindawi Publishing Corporation},
            year = {2015},
         journal = {Advances in Mathematical Physics},
             doi = {10.1155/2015/564854},
           pages = {564854},
        keywords = {ARRAY(0x5568fbb89c00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17367/},
        abstract = {We firstly construct generalized Baskakov operators V n, {\ensuremath{\alpha}}, q (f; x) and their truncated sum B n, {\ensuremath{\alpha}}, q (f; {\ensuremath{\gamma}} n, x). Secondly, we study the pointwise convergence and the uniform convergence of the operators V n, {\ensuremath{\alpha}}, q (f; x), respectively, and estimate that the rate of convergence by the operators V n, {\ensuremath{\alpha}}, q (f; x) is 1 / n q / 2. Finally, we study the convergence by the truncated operators B n, {\ensuremath{\alpha}}, q (f; {\ensuremath{\gamma}} n, x) and state that the finite truncated sum B n, {\ensuremath{\alpha}}, q (f; {\ensuremath{\gamma}} n, x) can replace the operators V n, {\ensuremath{\alpha}}, q (f; x) in the computational point of view provided that l i m n {$\rightarrow$} ? n {\ensuremath{\gamma}} n = ?. {\copyright} 2015 Yi Gao et al.}
}

@inproceedings{lincoln39638,
       booktitle = {14th Symposium on Advanced Space Technologies in Robotics and Automation},
           month = {May},
           title = {FP7 FASTER Project - Demonstration of Multi-platform Operation for Safer Planetary Traverses},
          author = {E. Allouis and F. Comin and W. Lewinger and B. Yeomans and C. Saaj and Y. Gao and J. Delfa and  et al.},
            year = {2015},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39638/}
}

@inproceedings{lincoln39637,
       booktitle = {14th Symposium on Advanced Space Technologies in Robotics and Automation},
           month = {May},
           title = {SysML-MOTIVE: SysML Based Spacecraft Power Management Function Modeling, Testing, Integration, Verification and Execution},
          author = {S. Chhaniyara and C. Saaj and P. Gineste and V. Coipeau},
            year = {2015},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39637/}
}

@inproceedings{lincoln25698,
           month = {April},
          author = {A. Abdolmaleki and N. Lau and L. P. Reis and J. Peters and G. Neumann},
       booktitle = {IEEE International Conference on  Autonomous Robot Systems and Competitions (ICARSC)},
           title = {Contextual policy search for generalizing a parameterized biped walking controller},
       publisher = {IEEE},
             doi = {10.1109/ICARSC.2015.43},
           pages = {17--22},
            year = {2015},
        keywords = {ARRAY(0x5568fbacce18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25698/},
        abstract = {We investigate learning of flexible Robot locomotion controller, i.e., the controllers should be applicable for multiple contexts, for example different walking speeds, various slopes of the terrain or other physical properties of the robot. In our experiments, contexts are desired walking linear speed and the direction of the gait. Current approaches for learning control parameters of biped locomotion controllers are typically only applicable for a single context. They can be used for a particular context, for example to learn a gait with highest speed, lowest energy consumption or a combination of both. The question of our research is, how can we obtain a flexible walking controller that controls the robot (near) optimally for many different contexts? We achieve the desired flexibility of the controller by applying the recently developed contextual relative entropy policy search(REPS) method. With such a contextual policy search algorithm, we can generalize the robot walking controller for different contexts, where a context is described by a real valued vector. In this paper we also extend the contextual REPS algorithm to learn a non-linear policy instead of a linear one over the contexts. In order to validate our method, we perform a simulation experiment using a simulated NAO humanoid robot. The robot now learns a policy to choose the controller parameters for a continuous set of walking speeds and directions.}
}

@article{lincoln17881,
          volume = {153},
          number = {4},
           month = {April},
          author = {Zhuhong Zhang and Shigang Yue and Guopeng Zhang},
           title = {Fly visual system inspired artificial neural network for collision detection},
       publisher = {Elsevier},
            year = {2015},
         journal = {Neurocomputing},
             doi = {10.1016/j.neucom.2014.11.033},
           pages = {221--234},
        keywords = {ARRAY(0x5568fba54b08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17881/},
        abstract = {This work investigates one bio-inspired collision detection system based on fly visual neural structures, in which collision alarm is triggered if an approaching object in a direct collision course appears in the field of view of a camera or a robot, together with the relevant time region of collision. One such artificial system consists of one artificial fly visual neural network model and one collision detection mechanism. The former one is a computational model to capture membrane potentials produced by neurons. The latter one takes the outputs of the former one as its inputs, and executes three detection schemes: (i) identifying when a spike takes place through the membrane potentials and one threshold scheme; (ii) deciding the motion direction of a moving object by the Reichardt detector model; and (iii) sending collision alarms and collision regions. Experimentally, relying upon a series of video image sequences with different scenes, numerical results illustrated that the artificial system with some striking characteristics is a potentially alternative tool for collision detection.}
}

@inproceedings{lincoln37399,
           month = {April},
          author = {W. Mahmood and C. Saaj},
            note = {cited By 1},
       booktitle = {2009 European Control Conference (ECC)},
           title = {Pinpoint planetary landers: Vision based hazard detection and obstacle avoidance},
       publisher = {IEEE},
            year = {2015},
         journal = {2009 European Control Conference, ECC 2009},
             doi = {10.23919/ECC.2009.7074872},
           pages = {3045--3051},
        keywords = {ARRAY(0x5568fbbbaa10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37399/},
        abstract = {Current lunar and planetary missions aim for pinpoint landing accuracy. Landing a set of science instruments at the edge of a particular crater or critical life-supporting supplies in proximity of a lunar outpost is not possible with the kilometer level precision of past. To achieve this level of precise landing, accurate identification of potential hazards (like craters, boulders, steep slopes, etc.) is necessary. In this paper, a robust algorithm for autonomous Hazard detection and Avoidance (HDA) for a low cost, pinpoint planetary lander, Magnolia-1 is proposed. The algorithm requires no input from classical inertial sensors. The hazard assessment and navigation is done purely by using imaging camera. The primary algorithm incorporates different functions which include (a) Feature selection and hazard identification, (b) Feature transformation and hazard mapping, (c) Safe site selection and (d) Site tracking and retargeting. Implementation of each functional block and simulation results for the algorithm are presented in this paper.}
}

@inproceedings{lincoln37439,
           month = {April},
          author = {C. Saaj and V. Lappas and D. Richie and V. Gazi and H. Schaub},
            note = {cited By 3},
       booktitle = {2009 European Control Conference (ECC)},
           title = {Satellite formation flying: Robust algorithms for propulsion, path planning and control},
       publisher = {2009 European Control Conference (ECC)},
            year = {2015},
         journal = {2009 European Control Conference, ECC 2009},
             doi = {10.23919/ECC.2009.7074774},
           pages = {2456--2463},
        keywords = {ARRAY(0x5568fbaf8ab0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37439/},
        abstract = {Propulsion, path planning and control of satellite formations in Geostationary Earth Orbits (GEO) and other high Earth Orbits is a challenging problem. This paper presents the results of the analysis of two types of controllers for satellite formation flying; the first one linear, using classical Proportional-Derivative (PD) control, and the second one nonlinear, using Sliding Mode Control (SMC). The Artificial Potential Field (APF) method is used for collision-free path planning of the satellites in the formation. The satellites are propelled using Coulomb forces and conventional electric/ion thrusters. This hybrid propulsion is more efficient as it minimizes the use of on-board power. Simulation results show that for the formation flying scenario considered in this study, the sliding mode controller gives better performance over the PD controller. Simulation results prove that for the tetrahedron formation considered in this study, both the control effort and drift in the geometric center of the formation are less when a sliding mode controller is used.}
}

@inproceedings{lincoln37400,
           month = {April},
          author = {D.L. Sancho-Pradel and C. Saaj},
            note = {cited By 2},
       booktitle = {2009 European Control Conference (ECC)},
           title = {Assessment of Artificial Potential Field methods for navigation of planetary rovers},
       publisher = {IEEE},
            year = {2015},
         journal = {2009 European Control Conference, ECC 2009},
             doi = {10.23919/ECC.2009.7074869},
           pages = {3027--3032},
        keywords = {ARRAY(0x5568fba0d7a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37400/},
        abstract = {Abstract:
The lack of research into Artificial Potential Field (APF) applications for planetary exploration drove the authors to put forward the following question: Can APF methods be used for autonomous navigation (path planning and control) of a surface robot in realistic planetary exploration scenarios? In order to answer that question, this paper presents a comprehensive review of different APF methods under a planetary exploration point of view. Finally, realistic scenarios where APF methods could outperform other navigation techniques are proposed, the most suitable approaches for these scenarios analysed, and some initial results provided.}
}

@article{lincoln23075,
          volume = {7},
          number = {2},
           month = {April},
          author = {James Kennedy and Paul Baxter and Tony Belpaeme},
           title = {Comparing robot embodiments in a guided discovery learning interaction with children},
       publisher = {Springer verlag},
            year = {2015},
         journal = {International Journal of Social Robotics},
             doi = {10.1007/s12369-014-0277-4},
           pages = {293--308},
        keywords = {ARRAY(0x5568fba71a40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23075/},
        abstract = {The application of social robots to the domain of education is becoming more prevalent. However, there re- main a wide range of open issues, such as the effectiveness of robots as tutors on student learning outcomes, the role of social behaviour in teaching interactions, and how the em- bodiment of a robot influences the interaction. In this paper, we seek to explore children?s behaviour towards a robot tutor for children in a novel guided discovery learning interac- tion. Since the necessity of real robots (as opposed to virtual agents) in education has not been definitively established in the literature, the effect of robot embodiment is assessed. The results demonstrate that children overcome strong incorrect biases in the material to be learned, but with no significant dif- ferences between embodiment conditions. However, the data do suggest that the use of real robots carries an advantage in terms of social presence that could provide educational benefits}
}

@article{lincoln44720,
          volume = {26},
          number = {2},
           month = {April},
          author = {Sepehr Maleki and Paolo Rapisarda and Lorenzo Ntogramatzidis and Eric Rogers},
           title = {Failure identification for 3D linear systems},
       publisher = {Springer},
            year = {2015},
         journal = {Multidimensional Systems and Signal Processing},
             doi = {10.1007/s11045-013-0271-2},
           pages = {481--502},
        keywords = {ARRAY(0x5568fbb9d3c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44720/},
        abstract = {Geometric control theory is used to investigate the problem of fault detection and isolation for 3D linear systems described by Fornasini---Marchesini models with the aim using these results in applications areas such as wireless sensor networks. Necessary and sufficient conditions for the existence of a solution to this problem are established together with constructive methods for the design of observers for fault detection and identification.}
}

@article{lincoln16987,
          volume = {4},
          number = {1},
           month = {March},
          author = {Christian Dondrup and Nicola Bellotto and Marc Hanheide and Kerstin Eder and Ute Leonards},
            note = {This article belongs to the Special Issue Representations and Reasoning for Robotics},
           title = {A computational model of human-robot spatial interactions based on a qualitative trajectory calculus},
       publisher = {MDPI},
            year = {2015},
         journal = {Robotics},
             doi = {10.3390/robotics4010063},
           pages = {63--102},
        keywords = {ARRAY(0x5568fbb90750)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/16987/},
        abstract = {In this paper we propose a probabilistic sequential model of Human-Robot Spatial Interaction (HRSI) using a well-established Qualitative Trajectory Calculus (QTC) to encode HRSI between a human and a mobile robot in a meaningful, tractable, and systematic manner. Our key contribution is to utilise QTC as a state descriptor and model HRSI as a probabilistic sequence of such states. Apart from the sole direction of movements of human and robot modelled by QTC, attributes of HRSI like proxemics and velocity profiles play vital roles for the modelling and generation of HRSI behaviour. In this paper, we particularly present how the concept of proxemics can be embedded in QTC to facilitate richer models. To facilitate reasoning on HRSI with qualitative representations, we show how we can combine the representational power of QTC with the concept of proxemics in a concise framework, enriching our probabilistic representation by implicitly modelling distances. We show the appropriateness of our sequential model of QTC by encoding different HRSI behaviours observed in two spatial interaction experiments. We classify these encounters, creating a comparative measurement, showing the representational capabilities of the model.}
}

@article{lincoln37453,
          volume = {24},
          number = {4},
           month = {March},
          author = {Y. Elsayed and C. Lekakou and T. Ranzani and M. Cianchetti and M. Morino and A. Arezzo and A. Menciassi and T. Geng and C. Saaj},
            note = {cited By 3},
           title = {Crimped braided sleeves for soft, actuating arm in robotic abdominal surgery},
       publisher = {Taylor \& Francis},
            year = {2015},
         journal = {Minimally Invasive Therapy and Allied Technologies},
             doi = {10.3109/13645706.2015.1012083},
           pages = {204--210},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37453/},
        abstract = {BACKGROUND:
This paper investigates different types of crimped, braided sleeve used for a soft arm for robotic abdominal surgery, with the sleeve required to contain balloon expansion in the pneumatically actuating arm while it follows the required bending, elongation and diameter reduction of the arm.

MATERIAL AND METHODS:
Three types of crimped, braided sleeves from PET (BraidPET) or nylon (BraidGreyNylon and BraidNylon, with different monofilament diameters) were fabricated and tested including geometrical and microstructural characterisation of the crimp and braid, mechanical tests and medical scratching tests for organ damage of domestic pigs.

RESULTS:
BraidPET caused some organ damage, sliding under normal force of 2-5 N; this was attributed to the high roughness of the braid pattern, the higher friction coefficient of polyethylene terephthalate (PET) compared to nylon, and the high frequency of the crimp peaks for this sleeve. No organ damage was observed for the BraidNylon, attributed to both the lower roughness of the braid pattern and the low friction coefficient of nylon. BraidNylon also required the lowest tensile force during its elongation to similar maximum strain as that of BraidPET, translating to low power requirements.

CONCLUSION:
BraidNylon is recommended for the crimped sleeve of the arm designed for robotic abdominal surgery.}
}

@inproceedings{lincoln24856,
           month = {March},
          author = {James Kennedy and Paul Baxter and Tony Belpaeme},
       booktitle = {Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction - HRI '15},
           title = {The robot who tried too hard: social behaviour of a robot tutor can negatively affect child learning},
       publisher = {ACM},
             doi = {10.1145/2696454.2696457},
           pages = {67--74},
            year = {2015},
        keywords = {ARRAY(0x5568fba5ef60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24856/},
        abstract = {Social robots are finding increasing application in the domain of education, particularly for children, to support and augment learning opportunities. With an implicit assumption that social and adaptive behaviour is desirable, it is therefore of interest to determine precisely how these aspects of behaviour may be exploited in robots to support children in their learning. In this paper, we explore this issue by evaluating the effect of a social robot tutoring strategy with children learning about prime numbers. It is shown that the tutoring strategy itself leads to improvement, but that the presence of a robot employing this strategy amplifies this effect, resulting in significant learning. However, it was also found that children interacting with a robot using social and adaptive behaviours in addition to the teaching strategy did not learn a significant amount. These results indicate that while the presence of a physical robot leads to improved learning, caution is required when applying social behaviour to a robot in a tutoring context.}
}

@inproceedings{lincoln25755,
          volume = {2015-F},
          number = {Februa},
           month = {February},
          author = {A. Paraschos and Gerhard Neumann and J. Peters},
       booktitle = {International Conference on Humanoid Robots (HUMANOIDS)},
           title = {A probabilistic approach to robot trajectory generation},
       publisher = {IEEE},
            year = {2015},
         journal = {IEEE-RAS International Conference on Humanoid Robots},
             doi = {10.1109/HUMANOIDS.2013.7030017},
           pages = {477--483},
        keywords = {ARRAY(0x5568fb9c4c80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25755/},
        abstract = {Motor Primitives (MPs) are a promising approach
for the data-driven acquisition as well as for the modular and
re-usable generation of movements. However, a modular control
architecture with MPs is only effective if the MPs support
co-activation as well as continuously blending the activation
from one MP to the next. In addition, we need efficient
mechanisms to adapt a MP to the current situation. Common
approaches to movement primitives lack such capabilities or
their implementation is based on heuristics. We present a
probabilistic movement primitive approach that overcomes the
limitations of existing approaches. We encode a primitive as a
probability distribution over trajectories. The representation as
distribution has several beneficial properties. It allows encoding
a time-varying variance profile. Most importantly, it allows
performing new operations {--} a product of distributions for
the co-activation of MPs conditioning for generalizing the MP
to different desired targets. We derive a feedback controller
that reproduces a given trajectory distribution in closed form.
We compare our approach to the existing state-of-the art and
present real robot results for learning from demonstration.}
}

@article{lincoln37438,
          volume = {63},
          number = {P1},
           month = {January},
          author = {X. Wang and T. Geng and Y. Elsayed and C. Saaj and C. Lekakou},
            note = {cited By 4},
           title = {A unified system identification approach for a class of pneumatically-driven soft actuators},
       publisher = {Elsevier},
            year = {2015},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2014.08.017},
           pages = {136--149},
        keywords = {ARRAY(0x5568fb9c0d78)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37438/},
        abstract = {The class of Pneumatically-driven Low-pressure Soft Actuators (PLSA) is a popular choice potentially used in the surgical robotic applications. One fundamental problem lying in the PLSA research is the lack of a generally validated model for the complex nonlinear dynamic behaviours. In this paper, a unified identification approach for the general PLSAs is proposed. It is a parameter-independent way directly used to identify the dynamical relation between the actuating pressures and the principal degrees of freedom of a PLSA, the bending and the steering. The approach is based on a modified auxiliary kinematic setting and a newly developed identification model structure, named DIO?PWL?OBF. Following the concluded identification procedure, the implementations for the single chamber bending and the double chamber bending and steering are demonstrated separately. The results show that the proposed approach can accurately capture the nonlinear pressure?shape dynamical relation. The approach is also efficient in real-time applications. It can be further used to improve the current control design for the PLSAs in robotic applications.}
}

@misc{lincoln17950,
           month = {January},
           title = {Long-term mobile robot localization in dynamic environments using spectral maps},
          author = {Tomas Krajnik and Jaime Pulido Fentanes and Oscar Martinez Mozos and Johan Ekekrantz and Marc Hanheide and Tom Duckett},
       publisher = {Association for the Advancement of Artificial Intelligence (AAAI)},
            year = {2015},
        keywords = {ARRAY(0x5568fba4b1a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17950/},
        abstract = {The video presents a novel approach for vision-based topological localisation in dynamic indoor environments. In contrast to other approaches that rely on static image features, our method explicitly models the temporal dynamics of the visibility of image features. The proposed spatio-temporal world model is able to predict the visibility of image features at different times of day, which allows to construct time-specific environment appearance models. This approach improves the robot localisation capabilities during long-term operations.}
}

@article{lincoln22215,
          volume = {36},
          number = {1},
           month = {January},
          author = {Stefano Albrecht and Andr{\'e} da Motta Salles Barreto and Darius Braziunas and David Buckeridge and Heriberto Cuayahuitl},
           title = {Reports of the AAAI 2014 Conference Workshops},
       publisher = {Association for the Advancemant of Artificial Intelligence},
            year = {2015},
         journal = {AI Magazine},
           pages = {87--98},
        keywords = {ARRAY(0x5568fbb0dc98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22215/},
        abstract = {The AAAI-14 Workshop program was held Sunday and Monday, July 27?28, 2012, at the Qu{\'e}bec City Convention Centre in Qu{\'e}bec, Canada. Canada. The AAAI-14 workshop program included fifteen workshops covering a wide range of topics in artificial intelligence. The titles of the workshops were AI and Robotics; Artificial Intelligence Applied to Assistive Technologies and Smart Environments; Cognitive Computing for Augmented Human Intelligence; Computer Poker and Imperfect Information; Discovery Informatics; Incentives and Trust in Electronic Communities; Intelligent Cinematography and Editing; Machine Learning for Interactive Systems: Bridging the Gap between Perception, Action and Communication; Modern Artificial Intelligence for Health Analytics; Multiagent Interaction without Prior Coordination; Multidisciplinary Workshop on Advances in Preference Handling; Semantic Cities {--} Beyond Open Data to Models, Standards and Reasoning; Sequential Decision Making with Big Data; Statistical Relational AI; and The World Wide Web and Public Health Intelligence. This article presents short summaries of those events.}
}

@article{lincoln29368,
          volume = {8},
          number = {1},
           month = {January},
          author = {Cigil Ece Madan and Ayse Kucukyilmaz and T.M. Sezgin and C. Basdogan},
           title = {Recognition of haptic interaction patterns in dyadic joint object manipulation},
       publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
            year = {2015},
         journal = {Haptics, IEEE Transactions on},
             doi = {10.1109/TOH.2014.2384049},
           pages = {54--66},
        keywords = {ARRAY(0x5568fbb87b58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29368/},
        abstract = {The development of robots that can physically cooperate with humans has attained interest in the last decades. Obviously, this effort requires a deep understanding of the intrinsic properties of interaction. Up to now, many researchers have focused on inferring human intents in terms of intermediate or terminal goals in physical tasks. On the other hand, working side by side with people, an autonomous robot additionally needs to come up with in-depth information about underlying haptic interaction patterns that are typically encountered during human-human cooperation. However, to our knowledge, no study has yet focused on characterizing such detailed information. In this sense, this work is pioneering as an effort to gain deeper understanding of interaction patterns involving two or more humans in a physical task. We present a labeled human-human-interaction dataset, which captures the interaction of two humans, who collaboratively transport an object in an haptics-enabled virtual environment. In the light of information gained by studying this dataset, we propose that the actions of cooperating partners can be examined under three interaction types: In any cooperative task, the interacting humans either 1) work in harmony, 2) cope with conflicts, or 3) remain passive during interaction. In line with this conception, we present a taxonomy of human interaction patterns; then propose five different feature sets, comprising force-, velocity-and power-related information, for the classification of these patterns. Our evaluation shows that using a multi-class support vector machine (SVM) classifier, we can accomplish a correct classification rate of 86 percent for the identification of interaction patterns, an accuracy obtained by fusing a selected set of most informative features by Minimum Redundancy Maximum Relevance (mRMR) feature selection method.}
}

@inproceedings{lincoln38420,
          volume = {2015-D},
          author = {A. Applebaum and K. Levitt and Z. Li and Simon Parsons and J. Rowe and Elizabeth Sklar},
            note = {cited By 1},
           title = {Cyber reasoning with argumentation: Abstracting from incomplete and contradictory evidence},
         journal = {Proceedings - IEEE Military Communications Conference MILCOM},
             doi = {10.1109/MILCOM.2015.7357513},
           pages = {623--628},
            year = {2015},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38420/}
}

@inproceedings{lincoln38556,
          volume = {2015-D},
          author = {A. Applebaum and K. Levitt and Z. Li and Simon Parsons and J. Rowe and Elizabeth Sklar},
            note = {cited By 1},
           title = {Cyber reasoning with argumentation: Abstracting from incomplete and contradictory evidence},
         journal = {Proceedings - IEEE Military Communications Conference MILCOM},
             doi = {10.1109/MILCOM.2015.7357513},
           pages = {623--628},
            year = {2015},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38556/}
}

@inproceedings{lincoln38425,
          volume = {3},
           title = {Survival of the chartist: An evolutionary agent-based analysis of stock market trading},
          author = {D. Bloembergen and D. Hennes and Simon Parsons and K. Tuyls},
            year = {2015},
           pages = {1699--1700},
            note = {cited By 2},
         journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38425/}
}

@article{lincoln38562,
          volume = {9287},
          author = {B. Broecker and I. Caliskanelli and K. Tuyls and Elizabeth Sklar and D. Hennes},
            note = {cited By 3},
           title = {Hybrid insect-inspired multi-robot coverage in complex environments},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-22416-9},
           pages = {56--68},
            year = {2015},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38562/}
}

@inproceedings{lincoln38563,
          volume = {3},
           title = {Social insect-inspired multi-robot coverage},
          author = {B. Broecker and I. Caliskanelli and K. Tuyls and Elizabeth Sklar and D. Hennes},
            year = {2015},
           pages = {1775--1776},
            note = {cited By 4},
         journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38563/}
}

@inproceedings{lincoln25994,
       booktitle = {NIPS Workshop on Deep Reinforcement Learning},
          volume = {abs/16},
           title = {Strategic dialogue management via deep reinforcement learning},
          author = {Heriberto Cuayahuitl and Simon Keizer and Oliver Lemon},
       publisher = {arXiv},
            year = {2015},
         journal = {CoRR},
        keywords = {ARRAY(0x5568fb969cf0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25994/},
        abstract = {Artificially intelligent agents equipped with strategic skills that can negotiate during their interactions with other natural or artificial agents are still underdeveloped. This paper describes a successful application of Deep Reinforcement Learning (DRL) for training intelligent agents with strategic conversational skills, in a situated dialogue setting. Previous studies have modelled the behaviour of strategic agents using supervised learning and traditional reinforcement learning techniques, the latter using tabular representations or learning with linear function approximation. In this study, we apply DRL with a high-dimensional state space to the strategic board game of Settlers of Catan---where players can offer resources in exchange for others and they can also reply to offers made by other players. Our experimental results report that the DRL-based learnt policies significantly outperformed several baselines including random, rule-based, and supervised-based behaviours. The DRL-based policy has a 53\% win rate versus 3 automated players (`bots'), whereas a supervised player trained on a dialogue corpus in this setting achieved only 27\%, versus the same 3 bots. This result supports the claim that DRL is a promising framework for training dialogue systems, and strategic agents with negotiation abilities.}
}

@article{lincoln38427,
          volume = {9368},
          author = {S.L. Epstein and A. Aroor and M. Evanusa and Elizabeth Sklar and Simon Parsons},
            note = {cited By 7},
           title = {Learning spatial models for navigation},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-23374-1},
           pages = {403--425},
            year = {2015},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38427/}
}

@article{lincoln38557,
          volume = {16},
          author = {S.L. Epstein and A. Aroor and M. Evanusa and Elizabeth Sklar and Simon Parsons},
            note = {cited By 3},
           title = {Spatial abstraction for autonomous robot navigation},
         journal = {Cognitive Processing},
             doi = {10.1007/s10339-015-0713-x},
           pages = {215--219},
            year = {2015},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38557/}
}

@article{lincoln17374,
          volume = {2015},
          author = {Yi Gao and Jigen Peng and Shigang Yue and Yuan Zhao},
            note = {This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
Journal Title History
Journal of Function Spaces 2014?Current
Journal of Function Spaces and Applications 2003?2013 (Title Changed)  (ISSN 2090-8997, eISSN 0972-6802)},
           title = {On the null space property of lq -minimization for 0{\ensuremath{<}}q{$\leq$}1 in compressed sensing},
       publisher = {Hindawi Publishing Corporation},
            year = {2015},
         journal = {Journal of Function Spaces},
             doi = {10.1155/2015/579853},
           pages = {579853},
        keywords = {ARRAY(0x5568fba7e9c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17374/},
        abstract = {The paper discusses the relationship between the null space property (NSP) and the lq-minimization in compressed sensing. Several versions of the null space property, that is, the lq stable NSP, the lq robust NSP, and the lq,p robust NSP for 0{\ensuremath{<}}p{$\leq$}q{\ensuremath{<}}1 based on the standard lq NSP, are proposed, and their equivalent forms are derived. Consequently, reconstruction results for the lq-minimization can be derived easily under the NSP condition and its equivalent form. Finally, the lq NSP is extended to the lq-synthesis modeling and the mixed l2/lq-minimization, which deals with the dictionary-based sparse signals and the block sparse signals, respectively. {\copyright} 2015 Yi Gao et al}
}

@inproceedings{lincoln38424,
          volume = {2},
           title = {A dialogue game for recommendation with adaptive preference models},
          author = {C. Labreuche and N. Maudet and W. Ouerdane and Simon Parsons},
            year = {2015},
           pages = {959--967},
            note = {cited By 1},
         journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38424/}
}

@article{lincoln38422,
          volume = {9310},
          author = {Z. Li and Simon Parsons},
            note = {cited By 3},
           title = {On argumentation with purely defeasible rules},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-23540-0},
           pages = {330--343},
            year = {2015},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38422/}
}

@inproceedings{lincoln38558,
          volume = {9086},
          author = {J. Raphael and S. Maskell and Elizabeth Sklar},
            note = {cited By 0},
           title = {First steps toward an auction-based traffic signal controller},
         journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
             doi = {10.1007/978-3-319-18944-4},
           pages = {300--303},
            year = {2015},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38558/}
}

@inproceedings{lincoln38559,
          volume = {9086},
          author = {J. Raphael and S. Maskell and Elizabeth Sklar},
            note = {cited By 8},
           title = {From goods to traffic: First steps toward an auction-based traffic signal controller},
         journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
             doi = {10.1007/978-3-319-18944-4},
           pages = {187--198},
            year = {2015},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38559/}
}

@article{lincoln38423,
          volume = {9287},
          author = {E. Schneider and Elizabeth Sklar and Simon Parsons and A.T. {\"O}zgelen},
            note = {cited By 14},
           title = {Auction-based task allocation for multi-robot teams in dynamic environments},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-22416-9},
           pages = {246--257},
            year = {2015},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38423/}
}

@article{lincoln38426,
          volume = {56},
          author = {P. Shakarian and G.I. Simari and G. Moores and Simon Parsons},
            note = {cited By 10},
           title = {Cyber attribution: An argumentation-based approach},
         journal = {Advances in Information Security},
             doi = {10.1007/978-3-319-14039-1},
           pages = {151--171},
            year = {2015},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38426/}
}

@article{lincoln37452,
          volume = {1},
          number = {4},
           month = {December},
          author = {Y. Elsayed and A. Vincensi and C. Lekakou and T. Geng and C. Saaj and T. Ranzani and M. Cianchetti and A. Menciassi},
            note = {cited By 48},
           title = {Finite Element Analysis and Design Optimization of a Pneumatically Actuating Silicone Module for Robotic Surgery Applications},
       publisher = {Mary Ann Liebert},
            year = {2014},
         journal = {Soft Robotics},
             doi = {10.1089/soro.2014.0016},
           pages = {255--262},
        keywords = {ARRAY(0x5568fbb60e08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37452/},
        abstract = {The design of a pneumatically actuated silicone module, resembling soft tissue, with three pneumatic chambers is considered and optimized in this study with the aim of using it in a soft robot arm for robotic surgery applications. Three types of silicone materials, Ecoflex 0030 and 0050 and Dragonskin 0030, have been investigated, and a constitutive model has been derived for each of them. Design optimization of the silicone module was based on finite element analysis (FEA) that was validated against experimental data of one-degree bending under one-channel actuation. This was followed by FEA parametric studies for module design optimization to minimize the ballooning effect in one-degree bending as well as reduce the actuation pressure. Modules made from Ecoflex 0030 and Ecoflex 0050 exhibited the same bending shape in FEA, but about three times higher actuation pressure was required for the harder Ecoflex 0050. Design parameters under investigation in the parametric FEA studies included the shape of the pneumatic channel cross section, the ratio of channel length to module length, the distance of channel from the module wall, and the ratio of channel to module cross-sectional area. After FEA design optimization yielded least ballooning for pneumatic chambers of semicircular cross section, an internal dragonskin structure was added internally below the module surface to enable and guide the bending under one-channel pneumatic actuation and further contain the ballooning effect: the benefits of this design were successfully verified under both FEA and experimental analysis.}
}

@inproceedings{lincoln40829,
           month = {December},
          author = {Gautham Das and Thomas M. McGinnity and Sonya A. Coleman},
       booktitle = {2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014)},
           title = {Simultaneous allocations of multiple tightly-coupled multi-robot tasks to coalitions of heterogeneous robots},
       publisher = {IEEE},
             doi = {10.1109/ROBIO.2014.7090496},
           pages = {1198--1204},
            year = {2014},
        keywords = {ARRAY(0x5568fba3add0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40829/},
        abstract = {Most multi-robot task allocation algorithms are concerned with the allocation of individual tasks to single robots. However certain types of tasks require a team of robots for their execution, and for the allocation of such tasks non-conflicting robot teams have to be formed. Most of the existing allocation algorithms for such tasks mainly address the robot-team formation and the tasks are allocated sequentially. However, allocating multiple tasks simultaneously will result in a more balanced distribution of robots into teams. A market based algorithm for simultaneous allocation of multiple tightly couple multi-robot tasks to coalitions of heterogeneous robots are proposed in this paper. The simultaneous allocations are deadlock-free and significant improvement in overall execution time is achieved as demonstrated by empirical evaluations.}
}

@inproceedings{lincoln40828,
           month = {December},
          author = {Philip J. Vance and Gautham Das and Thomas M. McGinnity and Sonya A. Coleman and Liam P. Maguire},
       booktitle = {2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014)},
           title = {Novelty detection in user behavioural models within ambient assisted living applications: An experimental evaluation},
       publisher = {IEEE},
             doi = {10.1109/ROBIO.2014.7090608},
           pages = {1868--1873},
            year = {2014},
        keywords = {ARRAY(0x5568fba74c68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40828/},
        abstract = {Current approaches to networked robot systems (or ecology of robots and sensors) in ambient assisted living applications (AAL) rely on pre-programmed models of the environment and do not evolve to address novel states of the environment. Envisaged as part of a robotic ecology in an AAL environment to provide different services based on the events and user activities, a Markov based approach to establishing a user behavioural model through the use of a cognitive memory module is presented in this paper. Upon detecting changes in the normal user behavioural pattern, the ecology tries to adapt its response to these changes in an intelligent manner. The approach is evaluated with physical robots and an experimental evaluation is presented in this paper. A major challenge associated with data storage in a sensor rich environment is the expanding memory requirements. In order to address this, a bio-inspired data retention strategy is also proposed. These contributions can enable a robotic ecology to adapt to evolving environmental states while efficiently managing the memory footprint.}
}

@article{lincoln13653,
          volume = {76},
          number = {3-4},
           month = {December},
          author = {Tomas Krajnik and Nitsche Matias and Jan Faigl and Petr Vanek and Martin Saska and Libor Preucil and Tom Duckett and Mejail Marta},
           title = {A practical multirobot localization system},
       publisher = {Springer Heidelberg},
            year = {2014},
         journal = {Journal of Intelligent and Robotic Systems},
             doi = {10.1007/s10846-014-0041-x},
           pages = {539--562},
        keywords = {ARRAY(0x5568fba3b310)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13653/},
        abstract = {We present a fast and precise vision-based software intended for multiple robot localization. The core component of the software is a novel and efficient algorithm for black and white pattern detection. The method is robust to variable lighting conditions, achieves sub-pixel precision and its computational complexity is independent of the processed image size. With off-the-shelf computational equipment and low-cost cameras, the core algorithm is able to process hundreds of images per second while tracking hundreds of objects with a millimeter precision. In addition, we present the method's mathematical model, which allows to estimate the expected localization precision, area of coverage, and processing speed from the camera's intrinsic parameters and hardware's processing capacity. The correctness of the presented model and performance of the algorithm in real-world conditions is verified in several experiments.  Apart from the method description, we also make its source code public at {$\backslash$}emph\{http://purl.org/robotics/whycon\}; so, it can be used as an enabling technology for various mobile robotic problems.}
}

@article{lincoln16505,
          volume = {52},
          number = {6},
           month = {December},
          author = {H. Liu and Shigang Yue},
           title = {An efficient method to structural static reanalysis with deleting support constraints},
       publisher = {Techno Press},
            year = {2014},
         journal = {Structural Engineering and Mechanics},
             doi = {10.12989/sem.2014.52.6.1121},
           pages = {1121--1134},
        keywords = {ARRAY(0x5568fbb49a30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/16505/},
        abstract = {Structural design is usually an optimization process. Numerous parameters such as the member shapes and sizes, the elasticity modulus of material, the locations of nodes and the support constraints can be selected as design variables. These variables are progressively revised in order to obtain a satisfactory structure. Each modification requires a fresh analysis for the displacements and stresses, and reanalysis can be employed to reduce the computational cost. This paper is focused on static reanalysis problem with modification of deleting some supports. An efficient reanalysis method is proposed. The method makes full use of the initial information and preserves the ease of implementation. Numerical examples show that the calculated results of the proposed method are the identical as those of the direct analysis, while the computational time is remarkably reduced.}
}

@inproceedings{lincoln25756,
          volume = {2015-F},
           month = {November},
          author = {A. Colome and G. Neumann and J. Peters and C. Torras},
       booktitle = {Humanoid Robots (Humanoids), 2014 14th IEEE-RAS International Conference on},
           title = {Dimensionality reduction for probabilistic movement primitives},
            year = {2014},
         journal = {IEEE-RAS International Conference on Humanoid Robots},
             doi = {10.1109/HUMANOIDS.2014.7041454},
           pages = {794--800},
        keywords = {ARRAY(0x5568fbb04960)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25756/},
        abstract = {Humans as well as humanoid robots can use a large number of degrees of freedom to solve very complex motor tasks. The high-dimensionality of these motor tasks adds difficulties to the control problem and machine learning algorithms. However, it is well known that the intrinsic dimensionality of many human movements is small in comparison to the number of employed DoFs, and hence, the movements can be represented by a small number of synergies encoding the couplings between DoFs. In this paper, we want to apply Dimensionality Reduction (DR) to a recent movement representation used in robotics, called Probabilistic Movement Primitives (ProMP). While ProMP have been shown to have many benefits, they suffer with the high-dimensionality of a robotic system as the number of parameters of a ProMP scales quadratically with the dimensionality. We use probablistic dimensionality reduction techniques based on expectation maximization to extract the unknown synergies from a given set of demonstrations. The ProMP representation is now estimated in the low-dimensional space of the synergies. We show that our dimensionality reduction is more efficient both for encoding a trajectory from data and for applying Reinforcement Learning with Relative Entropy Policy Search (REPS).}
}

@inproceedings{lincoln25764,
          volume = {2015-F},
           month = {November},
          author = {G. Maeda and M. Ewerton and R. Lioutikov and H. Ben Amor and J. Peters and G. Neumann},
       booktitle = {14th IEEE-RAS International Conference on Humanoid Robots (Humanoids)},
           title = {Learning interaction for collaborative tasks with probabilistic movement primitives},
            year = {2014},
         journal = {IEEE-RAS International Conference on Humanoid Robots},
             doi = {10.1109/HUMANOIDS.2014.7041413},
           pages = {527--534},
        keywords = {ARRAY(0x5568fbb698e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25764/},
        abstract = {This paper proposes a probabilistic framework
based on movement primitives for robots that work in collaboration
with a human coworker. Since the human coworker
can execute a variety of unforeseen tasks a requirement of our
system is that the robot assistant must be able to adapt and
learn new skills on-demand, without the need of an expert
programmer. Thus, this paper leverages on the framework
of imitation learning and its application to human-robot interaction
using the concept of Interaction Primitives (IPs).
We introduce the use of Probabilistic Movement Primitives
(ProMPs) to devise an interaction method that both recognizes
the action of a human and generates the appropriate movement
primitive of the robot assistant. We evaluate our method
on experiments using a lightweight arm interacting with a
human partner and also using motion capture trajectories of
two humans assembling a box. The advantages of ProMPs in
relation to the original formulation for interaction are exposed
and compared.}
}

@inproceedings{lincoln25754,
          volume = {2015-F},
           month = {November},
          author = {E. Rueckert and M. Mindt and J. Peters and G. Neumann},
       booktitle = {Humanoid Robots (Humanoids), 2014 14th IEEE-RAS International Conference on},
           title = {Robust policy updates for stochastic optimal control},
            year = {2014},
         journal = {IEEE-RAS International Conference on Humanoid Robots},
             doi = {10.1109/HUMANOIDS.2014.7041389},
           pages = {388--393},
        keywords = {ARRAY(0x5568fbbc4898)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25754/},
        abstract = {For controlling high-dimensional robots, most stochastic optimal control algorithms use approximations of the system dynamics and of the cost function (e.g., using linearizations and Taylor expansions). These approximations are typically only locally correct, which might cause instabilities in the greedy policy updates, lead to oscillations or the algorithms diverge. To overcome these drawbacks, we add a regularization term to the cost function that punishes large policy update steps in the trajectory optimization procedure. We applied this concept to the Approximate Inference Control method (AICO), where the resulting algorithm guarantees convergence for uninformative initial solutions without complex hand-tuning of learning rates. We evaluated our new algorithm on two simulated robotic platforms. A robot arm with five joints was used for reaching multiple targets while keeping the roll angle constant. On the humanoid robot Nao, we show how complex skills like reaching and balancing can be inferred from desired center of gravity or end effector coordinates.}
}

@inproceedings{lincoln37444,
           month = {November},
          author = {X. Wang and T. Geng and Y. Elsayed and T. Ranzani and C. Saaj and C. Lekakou},
            note = {cited By 3},
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
           title = {A new coefficient-adaptive orthonormal basis function model structure for identifying a class of pneumatic soft actuators},
       publisher = {IEEE},
            year = {2014},
         journal = {IEEE International Conference on Intelligent Robots and Systems},
             doi = {10.1109/IROS.2014.6942610},
           pages = {530--535},
        keywords = {ARRAY(0x5568fb6e9458)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37444/},
        abstract = {The class of Pneumatically-driven Lower-pressure Soft Actuators (PLSA) is a popular research topic as it can be potentially used in the surgical robotic applications. One fundamental problem lying in the PLSA research is the lack of a generally validated model for the complex nonlinear dynamic behaviours. In this paper, a new coefficient-adaptive orthonormal basis function model structure is specifically developed for the identification of the general PLSAs. It is a parameter-independent way directly used to identify the dynamic relation between the actuating pressures and the principal degrees of freedom of a PLSA, the bending and the steering. The approach is based on a modified auxiliary kinematic setting. Following the discussion of the identification procedure, the implementations for the double chamber bending and steering are demonstrated. The results show that the proposed approach can accurately capture the nonlinear pressure-shape dynamics. The approach is also efficient in the real-time applications. It can be further used to improve the current control design for the PLSAs in robotic applications.}
}

@article{lincoln46178,
          volume = {30},
          number = {5},
           month = {October},
          author = {Federico Renda and Michele Giorelli and Marcello Calisti and Matteo Cianchetti and Cecilia Laschi},
           title = {Dynamic Model of a Multibending Soft Robot Arm Driven by Cables},
            year = {2014},
         journal = {IEEE Transactions on Robotics},
             doi = {10.1109/TRO.2014.2325992},
           pages = {1109--1122},
        keywords = {ARRAY(0x5568fb674c40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46178/},
        abstract = {The new and promising field of soft robotics has many open areas of research such as the development of an exhaustive theoretical and methodological approach to dynamic modeling. To help contribute to this area of research, this paper develops a dynamic model of a continuum soft robot arm driven by cables and based upon a rigorous geometrically exact approach. The model fully investigates both dynamic interaction with a dense medium and the coupled tendon condition. The model was experimentally validated with satisfactory results, using a soft robot arm working prototype inspired by the octopus arm and capable of multibending. Experimental validation was performed for the octopus most characteristic movements: bending, reaching, and fetching. The present model can be used in the design phase as a dynamic simulation platform and to design the control strategy of a continuum robot arm moving in a dense medium.}
}

@inproceedings{lincoln15832,
           month = {October},
          author = {Christian Dondrup and Nicola Bellotto and Marc Hanheide},
       booktitle = {Robot and Human Interactive Communication, 2014 RO-MAN},
           title = {Social distance augmented qualitative trajectory calculus for human-robot spatial interaction},
       publisher = {IEEE},
             doi = {10.1109/ROMAN.2014.6926305},
           pages = {519--524},
            year = {2014},
        keywords = {ARRAY(0x5568fbb5cae0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/15832/},
        abstract = {In this paper we propose to augment a wellestablished Qualitative Trajectory Calculus (QTC) by incorporating social distances into the model to facilitate a richer and more powerful representation of Human-Robot Spatial Interaction (HRSI). By combining two variants of QTC that implement different resolutions and switching between them based on distance thresholds we show that we are able to both reduce the complexity of the representation and at the same time enrich QTC with one of the core HRSI concepts: proxemics. Building on this novel integrated QTC model, we propose to represent the joint spatial behaviour of a human and a robot employing a probabilistic representation based on Hidden Markov Models. We show the appropriateness of our approach by encoding different HRSI behaviours observed in a human-robot interaction study and show how the models can be used to represent and classify these behaviours using  social distance-augmented QTC.}
}

@article{lincoln21430,
          volume = {8810},
           month = {October},
          author = {S. Lemaignan and M. Hanheide and M. Karg and H. Khambhaita and L. Kunze and F. Lier and I. L{\~A}?tkebohle and G. Milliez},
            note = {Find out how to access preview-only content
Chapter
Simulation, Modeling, and Programming for Autonomous Robots
Volume 8810 of the series Lecture Notes in Computer Science pp 13-24
Simulation and HRI Recent Perspectives with the MORSE Simulator

S{\'e}verin Lemaignan, Marc Hanheide, Michael Karg, Harmish Khambhaita, Lars Kunze, Florian Lier, Ingo L{\"u}tkebohle, Gr{\'e}goire Milliez
Buy chapter
\$29.95 / ?24.95 / {\pounds}19.95 *
Buy eBook
\$89.00 / ?67.82 / {\pounds}56.99*
* Final gross prices may vary according to local VAT.Get Access
Abstract
Simulation in robotics is often a love-hate relationship: while simulators do save us a lot of time and effort compared to regular deployment of complex software architectures on complex hardware, simulators are also known to evade many of the real issues that robots need to manage when they enter the real world. Because humans are the paragon of dynamic, unpredictable, complex, real world entities, simulation of human-robot interactions may look condemn to fail, or, in the best case, to be mostly useless. This collective article reports on five independent applications of the MORSE simulator in the field of human-robot interaction: It appears that simulation is already useful, if not essential, to successfully carry out research in the field of HRI, and sometimes in scenarios we do not anticipate.
Simulation, Modeling, and Programming for Autonomous RobotsSimulation, Modeling, and Programming for Autonomous Robots Look 
Inside
Chapter Metrics
Downloads
367
Provided by Bookmetrix
Reference tools
Export citation
Add to Papers
Other actions
About this Book
Reprints and Permissions
Share
Share this content on Facebook Share this content on Twitter Share this content on LinkedIn
Supplementary Material (0)
References (24)

About this Chapter
Title
Simulation and HRI Recent Perspectives with the MORSE Simulator
Book Title
Simulation, Modeling, and Programming for Autonomous Robots
Book Subtitle
4th International Conference, SIMPAR 2014, Bergamo, Italy, October 20-23, 2014. Proceedings},
           title = {Simulation and HRI recent perspectives with the MORSE simulator},
       publisher = {Springer Verlag},
            year = {2014},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-11900-7\_2},
           pages = {13--24},
        keywords = {ARRAY(0x5568fba336b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/21430/},
        abstract = {Simulation in robotics is often a love-hate relationship: while simulators do save us a lot of time and effort compared to regular deployment of complex software architectures on complex hardware, simulators are also known to evade many of the real issues that robots need to manage when they enter the real world. Because humans are the paragon of dynamic, unpredictable, complex, real world entities, simulation of human-robot interactions may look condemn to fail, or, in the best case, to be mostly useless. This collective article reports on five independent applications of the MORSE simulator in the field of human-robot interaction: It appears that simulation is already useful, if not essential, to successfully carry out research in the field of HRI, and sometimes in scenarios we do not anticipate. {\^A}{\copyright} 2014 Springer International Publishing Switzerland.}
}

@inproceedings{lincoln16334,
           month = {October},
          author = {Cheng Hu and Farshad Arvin and Shigang Yue},
       booktitle = {IEEE International Conferences on Development and Learning and Epigenetic Robotics (ICDL-Epirob)},
           title = {Development of a bio-inspired vision system for mobile micro-robots},
       publisher = {IEEE},
             doi = {10.1109/DEVLRN.2014.6982958},
           pages = {81--86},
            year = {2014},
        keywords = {ARRAY(0x5568fbab23c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/16334/},
        abstract = {In this paper, we present a new bio-inspired vision system for mobile micro-robots. The processing method takes inspiration from vision of locusts in detecting the fast approaching objects. Research suggested that locusts use wide field visual neuron called the lobula giant movement detector to respond to imminent collisions. We employed the locusts' vision mechanism to motion control of a mobile robot. The selected image processing method is implemented on a developed extension module using a low-cost and fast ARM processor. The vision module is placed on top of a micro-robot to control its trajectory and to avoid obstacles. The observed results from several performed experiments demonstrated that the developed extension module and the inspired vision system are feasible to employ as a vision module for obstacle avoidance and motion control.}
}

@article{lincoln22212,
          volume = {4},
          number = {3},
           month = {October},
          author = {Heriberto Cuayahuitl and Lutz Frommberger and Nina Dethlefs and Antoine Raux and Mathew Marge and Hendrik Zender},
           title = {Introduction to the special issue on Machine learning for multiple modalities in interactive systems and robots},
       publisher = {Association for Computing Machinery (ACM)},
            year = {2014},
         journal = {ACM Transactions on Interactive Intelligent Systems (TiiS)},
             doi = {10.1145/2670539},
           pages = {12e},
        keywords = {ARRAY(0x5568fbab1910)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22212/},
        abstract = {This special issue highlights research articles that apply machine learning to robots and other systems that interact with users through more than one modality, such as speech, gestures, and vision. For example, a robot may coordinate its speech with its actions, taking into account (audio-)visual feedback during their execution. Machine learning provides interactive systems with opportunities to improve performance not only of individual components but also of the system as a whole. However, machine learning methods that encompass multiple modalities of an interactive system are still relatively hard to find. The articles in this special issue represent examples that contribute to filling this gap.}
}

@article{lincoln22211,
          volume = {4},
          number = {3},
           month = {October},
          author = {Heriberto Cuayahuitl and Ivana Kruijff-Korbayov{\'a} and Nina Dethlefs},
           title = {Nonstrict hierarchical reinforcement learning for interactive systems and robots},
       publisher = {Association for Computing Machinery (ACM)},
            year = {2014},
         journal = {ACM Transactions on Interactive Intelligent Systems (TiiS)},
             doi = {10.1145/2659003},
           pages = {15},
        keywords = {ARRAY(0x5568fb9e3f40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22211/},
        abstract = {Conversational systems and robots that use reinforcement learning for policy optimization in large domains often face the problem of limited scalability. This problem has been addressed either by using function approximation techniques that estimate the approximate true value function of a policy or by using a hierarchical decomposition of a learning task into subtasks. We present a novel approach for dialogue policy optimization that combines the benefits of both hierarchical control and function approximation and that allows flexible transitions between dialogue subtasks to give human users more control over the dialogue. To this end, each reinforcement learning agent in the hierarchy is extended with a subtask transition function and a dynamic state space to allow flexible switching between subdialogues. In addition, the subtask policies are represented with linear function approximation in order to generalize the decision making to situations unseen in training. Our proposed approach is evaluated in an interactive conversational robot that learns to play quiz games. Experimental results, using simulation and real users, provide evidence that our proposed approach can lead to more flexible (natural) interactions than strict hierarchical control and that it is preferred by human users.}
}

@inproceedings{lincoln14927,
           month = {October},
          author = {Farshad Arvin and Ali Emre Turgut and Nicola Bellotto and Shigang Yue},
            note = {Proceedings, Part I, series volume 8794},
       booktitle = {International Conference in Swarm Intelligence},
           title = {Comparison of different cue-based swarm aggregation strategies},
       publisher = {Springer},
            year = {2014},
             doi = {10.1007/978-3-319-11857-4\_1},
           pages = {1--8},
        keywords = {ARRAY(0x5568fba11b00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/14927/},
        abstract = {In this paper, we compare different aggregation strategies for cue-based aggregation with a mobile robot swarm. We used a sound source as the cue in the environment and performed real robot and simulation based experiments. We compared the performance of two proposed aggregation algorithms we called as the vector averaging and na{\"i}ve with the state-of-the-art cue-based aggregation strategy BEECLUST. We showed that the proposed strategies outperform BEECLUST method. We also illustrated the feasibility of the method in the presence of noise. The results showed that the vector averaging algorithm is more robust to noise when compared to the na{\"i}ve method.}
}

@inproceedings{lincoln25769,
           month = {September},
          author = {O. Kroemer and H. Van Hoof and G. Neumann and J. Peters},
       booktitle = {2014 IEEE International Conference on Robotics and Automation},
           title = {Learning to predict phases of manipulation tasks as hidden states},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
             doi = {10.1109/ICRA.2014.6907441},
           pages = {4009--4014},
            year = {2014},
        keywords = {ARRAY(0x5568fbbc55f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25769/},
        abstract = {Phase transitions in manipulation tasks often occur
when contacts between objects are made or broken. A
switch of the phase can result in the robot?s actions suddenly
influencing different aspects of its environment. Therefore, the
boundaries between phases often correspond to constraints or
subgoals of the manipulation task.
In this paper, we investigate how the phases of manipulation
tasks can be learned from data. The task is modeled as an
autoregressive hidden Markov model, wherein the hidden phase
transitions depend on the observed states. The model is learned
from data using the expectation-maximization algorithm. We
demonstrate the proposed method on both a pushing task
and a pepper mill turning task. The proposed approach was
compared to a standard autoregressive hidden Markov model.
The experiments show that the learned models can accurately
predict the transitions in phases during the manipulation tasks.}
}

@inproceedings{lincoln25771,
           month = {September},
          author = {R. Lioutikov and A. Paraschos and J. Peters and G. Neumann},
       booktitle = {Proceedings of 2014 IEEE International Conference on Robotics and Automation},
           title = {Sample-based information-theoretic stochastic optimal control},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
             doi = {10.1109/ICRA.2014.6907424},
           pages = {3896--3902},
            year = {2014},
        keywords = {ARRAY(0x5568fbaae738)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25771/},
        abstract = {Many Stochastic Optimal Control (SOC) approaches
rely on samples to either obtain an estimate of the
value function or a linearisation of the underlying system model.
However, these approaches typically neglect the fact that the
accuracy of the policy update depends on the closeness of the
resulting trajectory distribution to these samples. The greedy
operator does not consider such closeness constraint to the
samples. Hence, the greedy operator can lead to oscillations
or even instabilities in the policy updates. Such undesired
behaviour is likely to result in an inferior performance of the
estimated policy. We reuse inspiration from the reinforcement
learning community and relax the greedy operator used in SOC
with an information theoretic bound that limits the ?distance? of
two subsequent trajectory distributions in a policy update. The
introduced bound ensures a smooth and stable policy update.
Our method is also well suited for model-based reinforcement
learning, where we estimate the system dynamics model from
data. As this model is likely to be inaccurate, it might be
dangerous to exploit the model greedily. Instead, our bound
ensures that we generate new data in the vicinity of the current
data, such that we can improve our estimate of the system
dynamics model. We show that our approach outperforms
several state of the art approaches on challenging simulated
robot control tasks.}
}

@article{lincoln25767,
          volume = {11},
          number = {9},
           month = {September},
          author = {R. Lioutikov and A. Paraschos and J. Peters and G. Neumann},
           title = {Generalizing movements with information-theoretic stochastic optimal control},
       publisher = {American Institute of Aeronautics and Astronautics},
            year = {2014},
         journal = {Journal of Aerospace Information Systems},
             doi = {10.2514/1.I010195},
           pages = {579--595},
        keywords = {ARRAY(0x5568fb9cc5e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25767/},
        abstract = {Stochastic optimal control is typically used to plan a movement for a specific situation. Although most stochastic optimal control methods fail to generalize this movement plan to a new situation without replanning, a stochastic optimal control method is presented that allows reuse of the obtained policy in a new situation, as the policy is more robust to slight deviations from the initial movement plan. To improve the robustness of the policy, we employ information-theoretic policy updates that explicitly operate on trajectory distributions instead of single trajectories. To ensure a stable and smooth policy update, the ?distance? is limited between the trajectory distributions of the old and the new control policies. The introduced bound offers a closed-form solution for the resulting policy and extends results from recent developments in stochastic optimal control. In contrast to many standard stochastic optimal control algorithms, the current approach can directly infer the system dynamics from data points, and hence can also be used for model-based reinforcement learning. This paper represents an extension of the paper by Lioutikov et al. (?Sample-Based Information-Theoretic Stochastic Optimal Control,? Proceedings of 2014 IEEE International Conference on Robotics and Automation (ICRA), IEEE, Piscataway, NJ, 2014, pp. 3896?3902). In addition to revisiting the content, an extensive theoretical comparison is presented of the approach with related work, additional aspects of the implementation are discussed, and further evaluations are introduced.}
}

@inproceedings{lincoln14423,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {September},
           title = {Long-term topological localisation for service robots in dynamic environments using spectral maps},
          author = {Tomas Krajnik and Jaime Pulido Fentanes and Oscar Martinez Mozos and Tom Duckett and Johan Ekekrantz and Marc Hanheide},
       publisher = {IEEE},
            year = {2014},
        keywords = {ARRAY(0x5568fba11800)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/14423/},
        abstract = {This paper presents a new approach for topological localisation of service robots in dynamic indoor environments. In contrast to typical localisation approaches that rely mainly on static parts of the environment, our approach makes explicit use of information about changes by learning and modelling the spatio-temporal dynamics of the environment where the robot is acting.  The proposed spatio-temporal world model is able to predict environmental changes in time, allowing the robot to improve its localisation capabilities during long-term operations in populated environments. To investigate the proposed approach, we have enabled a mobile robot to autonomously patrol a populated environment over a period of one week while building the proposed model representation. We demonstrate that the experience learned during one week is applicable for topological localization even after a hiatus of three months by showing that the localization error rate is significantly lower compared to static environment representations.}
}

@inproceedings{lincoln25772,
           month = {September},
          author = {K. S. Luck and G. Neumann and E. Berger and J. Peters and H. B. Amor},
       booktitle = {IEEE/RSJ Conference on Intelligent Robots and Systems (IROS)},
           title = {Latent space policy search for robotics},
         journal = {IEEE International Conference on Intelligent Robots and Systems},
             doi = {10.1109/IROS.2014.6942745},
           pages = {1434--1440},
            year = {2014},
        keywords = {ARRAY(0x5568fba0d970)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25772/},
        abstract = {Learning motor skills for robots is a hard
task. In particular, a high number of degrees-of-freedom
in the robot can pose serious challenges to existing reinforcement
learning methods, since it leads to a highdimensional
search space. However, complex robots are
often intrinsically redundant systems and, therefore, can
be controlled using a latent manifold of much smaller
dimensionality. In this paper, we present a novel policy
search method that performs efficient reinforcement learning
by uncovering the low-dimensional latent space of
actuator redundancies. In contrast to previous attempts
at combining reinforcement learning and dimensionality
reduction, our approach does not perform dimensionality
reduction as a preprocessing step but naturally combines
it with policy search. Our evaluations show that the new
approach outperforms existing algorithms for learning
motor skills with high-dimensional robots.}
}

@incollection{lincoln14895,
          volume = {8717},
           month = {September},
          author = {Tomas Krajnik and Joao Santos and Bianca Seemann and Tom Duckett},
          series = {Lecture Notes in Computer Science},
       booktitle = {Advances in Autonomous Robotics Systems},
          editor = {Michael Mistry and Ale Leonardis and Mark Witkowski},
           title = {FROctomap: an efficient spatio-temporal environment representation},
       publisher = {Springer International Publishing},
            year = {2014},
             doi = {10.1007/978-3-319-10401-0},
           pages = {281--282},
        keywords = {ARRAY(0x5568fbbb87d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/14895/},
        abstract = {We present a novel software tool intended for mobile robot mapping in long-term scenarios. The method allows for efficient volumetric representation of dynamic three-dimensional environments over long periods of time. It is based on a combination of a well-established 3D mapping framework called Octomaps and an idea to model environment dynamics by its frequency spectrum. The proposed method allows not only for efficient representation, but also reliable prediction of the future states of dynamic three-dimensional environments. Our spatio-temporal mapping framework is available as an open-source C++ library and a ROS module which allows its easy integration in robotics projects.}
}

@inproceedings{lincoln43300,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2014)},
           month = {September},
           title = {Run-time Detection of Faults in Autonomous Mobile Robots Based on the Comparison of Simulated and Real Robot Behaviour},
          author = {Alan Millard and Jon Timmis and Alan F.T. Winfield},
            year = {2014},
             doi = {10.1109/IROS.2014.6943084},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43300/},
        abstract = {This paper presents a novel approach to the runtime detection of faults in autonomous mobile robots, based on simulated predictions of real robot behaviour. We show that although simulation can be used to predict real robot behaviour, drift between simulation and reality occurs over time due to the reality gap. This necessitates periodic reinitialisation of the simulation to reduce false positives. Using a simple obstacle avoidance controller afflicted with partial motor failure, we show that selecting the length of this reinitialisation time period is non-trivial, and that there exists a trade-off between minimising drift and the ability to detect the presence of faults.}
}

@inproceedings{lincoln39639,
       booktitle = {18th International ISTVS Conference},
           month = {September},
           title = {Development of a Wheeled Bevameter as a Real-Time Terrain Sensing Instrument for Robotic Vehicles},
          author = {L. Richter and V. Eder and W. Hohender and B. Imhof and W. Lewinger and S. Ransom and C. Saaj and P. Weclewski and R. Waclavicek},
            year = {2014},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39639/}
}

@inproceedings{lincoln39640,
       booktitle = {European Planetary Science Congress EPSC2014-818},
           month = {September},
           title = {Development of the FASTER Wheeled Bevameter},
          author = {L. Richter and V. Eder and W. Hohender and B. Imhof and W. Lewinger and S. Ransom and C. Saaj and P. Weclewski and R. Waclavicek},
            year = {2014},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39640/}
}

@article{lincoln43686,
          volume = {28},
          number = {3},
           month = {August},
          author = {Anthony Hunter and Simon Parsons and Michael Wooldridge},
           title = {Measuring Inconsistency in Multi-Agent Systems},
            year = {2014},
         journal = {K{\"u}nstl Intell},
             doi = {10.1007/s13218-014-0306-3},
           pages = {169--178},
        keywords = {ARRAY(0x5568fb6e9908)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43686/},
        abstract = {We introduce and investigate formal quantitative measures of inconsistency between the beliefs of agents in multi-agent systems. We start by recalling a well-known model of belief in multi-agent systems, and then, using this model,present two classes of inconsistency metrics. First, we consider metrics that attempt to characterise the overall degree of inconsistency of a multi-agent system in a single numeric value, where inconsistency is considered to be individuals within the system having contradictory beliefs. While this metric is useful as a high-level indicator of the degree of in-consistency between the beliefs of members of a multi-agent system,  it  is  of  limited  value  for  understanding  the  structure of inconsistency in a system: it gives no indication of the sources of inconsistency. We therefore introduce metrics that quantify for a given individual the extent to which that individual is in conflict with other members of the society.These metrics are based on power indices, which were developed within the cooperative game theory community in order to understand the power that individuals wield in co-operative settings.}
}

@incollection{lincoln17582,
           month = {August},
          author = {Abdolrahman Attar and Xiang Xie and Chun Zhang and Zhihua Wang and Shigang Yue},
            note = {Conference of 2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC 2014 ; Conference Date: 26 - 30 August 2014; Chicago, USA  Conference Code:109045},
       booktitle = {Conference proceedings of the 2014 Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
           title = {Wireless Micro-Ball endoscopic image enhancement using histogram information},
       publisher = {Institute of Electrical and Electronics Engineers Inc.},
            year = {2014},
         journal = {2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC 2014},
             doi = {10.1109/EMBC.2014.6944337},
           pages = {3337--3340},
        keywords = {ARRAY(0x5568fbb38340)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17582/},
        abstract = {Wireless endoscopy systems is a new innovative method widely used for gastrointestinal tract examination in recent decade. Wireless Micro-Ball endoscopy system with multiple image sensors is the newest proposed method which can make a full view image of the gastrointestinal tract. But still the quality of images from this new wireless endoscopy system is not satisfactory. It's hard for doctors and specialist to easily examine and interpret the captured images. The image features also are not distinct enough to be used for further processing. So as to enhance these low-contrast endoscopic images a new image enhancement method based on the endoscopic images features and color distribution is proposed in this work. The enhancement method is performed on three main steps namely color space transformation, edge preserving mask formation, and histogram information correction. The luminance component of CIE Lab, YCbCr, and HSV color space is enhanced in this method and then two other components added finally to form an enhanced color image. The experimental result clearly show the robustness of the method. {\copyright} 2014 IEEE.}
}

@inproceedings{lincoln37430,
           month = {August},
          author = {Y. Elsayed and C. Lekakou and T. Geng and C. Saaj},
            note = {cited By 10},
       booktitle = {2014 IEEE/ASME International Conference on Advanced Intelligent Mechatronics},
           title = {Design optimisation of soft silicone pneumatic actuators using finite element analysis},
       publisher = {IEEE},
            year = {2014},
         journal = {IEEE/ASME International Conference on Advanced Intelligent Mechatronics, AIM},
             doi = {10.1109/AIM.2014.6878044},
           pages = {44--49},
        keywords = {ARRAY(0x5568fbb75a80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37430/},
        abstract = {The current trend in soft robotic solutions is to pneumatically actuate chambers within manipulators that feature elastomeric material. This work describes the development of a repeating module actuator with each module capable of producing 3 degrees of freedom, as well as longitudinal expansion, intended for use as a laparoscopic tool in minimal invasive surgery. The design of the manipulator geometry as well as the choice of suitable material is dependent on the application, range of motion, and the suitable actuation pressure. This work describes the use of finite element analysis to simulate the range of motion of the hyperelastic response of two different soft silicones. Different geometry ratios and channel designs of the actuator are then optimized in terms of bending angle, maximum stress generated, radial expansion due to air pressure, and the amount of free area that the design allows in the actuator for other tools necessary in laparoscopic surgery. The optimum geometries are then selected as candidates for the development of the repeating module design, and the addition of skins to the module is investigated for the optimized module design.}
}

@article{lincoln14764,
          volume = {8},
          number = {1},
           month = {August},
          author = {Jiawei Xu and Ruisheng Wang and Shigang Yue},
           title = {Bio-inspired classifier for road extraction from remote sensing imagery},
       publisher = {Society of Photo-optical Instrumentation Engineers (SPIE)},
            year = {2014},
         journal = {Journal of Applied Remote Sensing},
             doi = {10.1117/1.JRS.8.083577},
           pages = {083577},
        keywords = {ARRAY(0x5568fb9f9f20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/14764/},
        abstract = {An adaptive approach for road extraction inspired by the mechanism of primary visual cortex (V1) is proposed. The motivation is originated by the characteristics in the receptive field from V1. It has been proved that human or primate visual systems can distinguish useful cues from real scenes effortlessly while traditional computer vision techniques cannot accomplish this task easily. This idea motivates us to design a bio-inspired model for road extraction from remote sensing imagery. The proposed approach is an improved support vector machine (SVM) based on the pooling of feature vectors, using an improved Gaussian radial basis function (RBF) kernel with tuning on synaptic gains. The synaptic gains comprise the feature vectors through an iterative optimization process representing the strength and width of Gaussian RBF kernel. The synaptic gains integrate the excitation and inhibition stimuli based on internal connections from V1. The summation of synaptic gains contributes to pooling of feature vectors. The experimental results verify the correlation between the synaptic gain and classification rules, and then show better performance in comparison with hidden Markov model, SVM, and fuzzy classification approaches. Our contribution is an automatic approach to road extraction without prelabeling and postprocessing work. Another apparent advantage is that our method is robust for images taken even under complex weather conditions such as snowy and foggy weather. {\^A}{\copyright} 2014 SPIE.}
}

@inproceedings{lincoln14837,
           month = {August},
          author = {Farshad Arvin and John Murray and Licheng Shi and Chun Zhang and Shigang Yue},
       booktitle = {IEEE International Conference on Mechatronics and Automation (ICMA)},
           title = {Development of an autonomous micro robot for swarm robotics},
       publisher = {IEEE},
             doi = {10.1109/ICMA.2014.6885771},
           pages = {635--640},
            year = {2014},
        keywords = {ARRAY(0x5568fb96a6b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/14837/},
        abstract = {Swarm robotic systems which are inspired from social behaviour of animals especially insects are becoming a fascinating topic for multi-robot researchers. Simulation software is mostly used for performing research in swarm robotics due the hardware complexities and cost of robot platforms. However, simulation of large numbers of these swarm robots is extremely complex and often inaccurate. In this paper we present the design of a low-cost, open-platform, autonomous micro robot (Colias) for swarm robotic applications. Colias uses a circular platform with a diameter of 4 cm. Long-range infrared modules with adjustable output power allow the robot to communicate with its direct neighbours. The robot has been tested in individual and swarm scenarios and the observed results demonstrate its feasibility to be used as a micro sized mobile robot as well as a low-cost platform for robot swarm applications.}
}

@article{lincoln14585,
          volume = {11},
          number = {113},
           month = {July},
          author = {Farshad Arvin and John Murray and Chun Zhang and Shigang Yue},
           title = {Colias: an autonomous micro robot for swarm robotic applications},
       publisher = {InTech},
            year = {2014},
         journal = {International Journal of Advanced Robotic Systems},
             doi = {10.5772/58730},
           pages = {1--10},
        keywords = {ARRAY(0x5568fbb0df20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/14585/},
        abstract = {Robotic swarms that take inspiration from nature are becoming a fascinating topic for multi-robot researchers. The aim is to control a large number of simple robots enables them in order to solve common complex tasks. Due to the hardware complexities and cost of robot platforms, current research in swarm robotics is mostly performed by simulation software. Simulation of large numbers of these robots which are used in swarm robotic applications is extremely complex and often inaccurate due to poor modelling of external conditions. In this paper we present the design of a low-cost, open-platform, autonomous micro robot (Colias) for swarm robotic applications. Colias employs a circular platform with a diameter of 4 cm. It has a maximum speed of 35 cm/s that gives the ability to be used in swarm scenarios very quickly in large arenas. Long-range infrared modules with adjustable output power allow the robot to communicate with its direct neighbours from a range of 0.5 cm to 3 m. Colias has been designed as a complete platform with supporting software development tools for robotics education and research. It has been tested in individual and swarm scenarios and the observed results demonstrate its feasibility to be used as a micro sized mobile robot as well as a low-cost platform for robot swarm applications.}
}

@inproceedings{lincoln14603,
       booktitle = {International Workshop on Recent Advances in Agricultural Robotics},
           month = {July},
           title = {On-line trajectory planning for autonomous spraying vehicles},
          author = {Pablo Urcola and Tom Duckett and Grzegorz Cielniak},
            year = {2014},
        keywords = {ARRAY(0x5568fbb69240)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/14603/},
        abstract = {In this paper, we present a new application of on-line trajectory planning for autonomous sprayers. The current generation of these vehicles use automatic controllers to maintain the height of the spraying booms above the crop. However, such systems are typically based on ultrasonic sensors mounted directly on the booms, which limits the
response of the controller to changes in the terrain, resulting in a suboptimal spraying process. To overcome these limitations, we propose to use 3D maps of the terrain ahead of the spraying booms based on laser range-fi?nder measurements combined with GPS-based localisation. Four different boom trajectory planning solutions which utilise the 3D maps are considered and their accuracy and real-time suitability is evaluated based on data collected from ?field tests. The point optimisation and interpolation technique presents a practical solution demonstrating satisfactory performance under real-time constraints.}
}

@inproceedings{lincoln37402,
          volume = {8069 L},
           month = {June},
          author = {H.D. Ibrahim and C. Saaj},
            note = {cited By 0},
       booktitle = {Conference Towards Autonomous Robotic Systems},
           title = {On new algorithms for path planning and control of micro-rover swarms},
       publisher = {Springer},
            year = {2014},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-662-43645-5\_38},
           pages = {353--362},
        keywords = {ARRAY(0x5568fba44670)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37402/},
        abstract = {In this paper, a new approach to modelling the dynamics of the Pioneer-3AT robot on planetary soil is presented. This model is used to design a robust traction control algorithm that makes use of the Sliding Mode Control (SMC), the Artificial Potential Field (APF) and a Fethi Beckoche navigation function for collision avoidance with predefined obstacles. Simulations were carried out for swarms of micro-rovers using the parameters of an in-house planetary soil simulant. The controller was designed to control the wheel movements of the robot on an unstructured environment using the SMC and APF. Simulation results show that the controller and the navigation function effectively achieves the permitted slip rate, sinkage, angular and longitudinal velocities, sliding surface and torque for the wheels, thus offering efficient traction while avoiding the excessive wheel slip and sinkage.}
}

@incollection{lincoln19647,
          volume = {8069},
           month = {June},
          author = {Francisco-Angel Moreno and Grzegorz Cielniak and Tom Duckett},
          series = {Lecture Notes in Computer Science},
            note = {14th Annual Conference, TAROS 2013, Oxford, UK, August 28--30, 2013, Revised Selected Papers},
       booktitle = {Towards autonomous robotic systems},
          editor = {Ashutosh Natraj and Stephen Cameron and Chris Melhuish and Mark Witkowski},
           title = {Evaluation of laser range-finder mapping for agricultural spraying vehicles},
       publisher = {Springer Berlin Heidelberg},
            year = {2014},
             doi = {10.1007/978-3-662-43645-5\_22},
           pages = {210--221},
        keywords = {ARRAY(0x5568fbaee300)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/19647/},
        abstract = {In this paper, we present a new application of laser range-finder sensing to agricultural spraying vehicles. The current generation of spraying vehicles use automatic controllers to maintain the height of the sprayer booms above the crop. However, these control systems are typically based on ultrasonic sensors mounted on the booms, which limits the accuracy of the measurements and the response of the controller to changes in the terrain, resulting in a sub-optimal spraying process. To overcome these limitations, we propose to use a laser scanner, attached to the front of the sprayer?s cabin, to scan the ground surface in front of the vehicle and to build a scrolling 3d map of the terrain. We evaluate the proposed solution in a series of field tests, demonstrating that the approach provides a more detailed and accurate representation of the environment than the current sonar-based solution, and which can lead to the development of more efficient boom control systems.}
}

@inproceedings{lincoln17531,
           month = {June},
          author = {Licheng Shi and Chun Zhang and Shigang Yue},
            note = {Conference Code:111593},
       booktitle = {2014 IEEE International Conference on Electron Devices and Solid-State Circuits (EDSSC)},
           title = {Vector control IC for permanent magnet synchronous motor},
       publisher = {Institute of Electrical and Electronics Engineers Inc.},
            year = {2014},
         journal = {2014 IEEE International Conference on Electron Devices and Solid-State Circuits, EDSSC 2014},
             doi = {10.1109/EDSSC.2014.7061126},
        keywords = {ARRAY(0x5568fbbc2ca0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/17531/},
        abstract = {This paper presents a full-digital vector control integrated circuit(IC) for permanent magnet synchronous motor (PMSM) with considering hardware structure. We adopted top-down and modular partitioning logic optimization design. Design specification of space vector pulse width modulation (SVPWM) unit, vector coordinate transformation are illustrated. All of the modules were implemented with pure hardware and designed with Verilog hardware description language (HDL). Moreover, the proposed design was verified by Simulink-Matlab and field programmable gate array (FPGA). {\copyright} 2014 IEEE.}
}

@article{lincoln25765,
          volume = {8},
          number = {JUN},
           month = {June},
          author = {G. Neumann and C. Daniel and A. Paraschos and A. Kupcsik and J. Peters},
           title = {Learning modular policies for robotics},
       publisher = {Frontiers Media},
            year = {2014},
         journal = {Frontiers in Computational Neuroscience},
             doi = {10.3389/fncom.2014.00062},
        keywords = {ARRAY(0x5568fbb547b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25765/},
        abstract = {A promising idea for scaling robot learning to more complex tasks is to use elemental behaviors as building blocks to compose more complex behavior. Ideally, such building blocks are used in combination with a learning algorithm that is able to learn to select, adapt, sequence and co-activate the building blocks. While there has been a lot of work on approaches that support one of these requirements, no learning algorithm exists that unifies all these properties in one framework. In this paper we present our work on a unified approach for learning such a modular control architecture. We introduce new policy search algorithms that are based on information-theoretic principles and are able to learn to select, adapt and sequence the building blocks. Furthermore, we developed a new representation for the individual building block that supports co-activation and principled ways for adapting the movement. Finally, we summarize our experiments for learning modular control architectures in simulation and with real robots.}
}

@article{lincoln13453,
          volume = {133},
           month = {June},
          author = {Jiawei Xu and Shigang Yue},
           title = {Mimicking visual searching with integrated top down cues and low-level features},
       publisher = {Elsevier},
            year = {2014},
         journal = {Neurocomputing},
             doi = {10.1016/j.neucom.2013.11.037},
           pages = {1--17},
        keywords = {ARRAY(0x5568fbba4fa8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13453/},
        abstract = {Visual searching is a perception task involved with visual attention, attention shift and active scan of the visual environment for a particular object or feature. The key idea of our paper is to mimic the human visual searching under the static and dynamic scenes. To build up an artificial vision system that performs the visual searching could be helpful to medical and psychological application development to human machine interaction. Recent state-of-the-art researches focus on the bottom-up and top-down saliency maps. Saliency maps indicate that the saliency likelihood of each pixel, however, understanding the visual searching process can help an artificial vision system exam details in a way similar to human and they will be good for future robots or machine vision systems which is a deeper digest than the saliency map. This paper proposed a computational model trying to mimic human visual searching process and we emphasis the motion cues on the visual processing and searching. Our model analysis the attention shifts by fusing the top-down bias and bottom-up cues. This model also takes account the motion factor into the visual searching processing. The proposed model involves five modules: the pre-learning process; top-down biasing; bottom-up mechanism; multi-layer neural network and attention shifts. Experiment evaluation results via benchmark databases and real-time video showed the model demonstrated high robustness and real-time ability under complex dynamic scenes.}
}

@inproceedings{lincoln25773,
           month = {June},
          author = {H. Ben Amor and Gerhard Neumann and S. Kamthe and O. Kroemer and J. Peters},
       booktitle = {2014 IEEE International Conference on Robotics and Automation (ICRA 2014)},
           title = {Interaction primitives for human-robot cooperation tasks},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
             doi = {10.1109/ICRA.2014.6907265},
           pages = {2831--2837},
            year = {2014},
        keywords = {ARRAY(0x5568fb9fe9d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25773/},
        abstract = {To engage in cooperative activities with human
partners, robots have to possess basic interactive abilities
and skills. However, programming such interactive skills is a
challenging task, as each interaction partner can have different
timing or an alternative way of executing movements. In this
paper, we propose to learn interaction skills by observing how
two humans engage in a similar task. To this end, we introduce
a new representation called Interaction Primitives. Interaction
primitives build on the framework of dynamic motor primitives
(DMPs) by maintaining a distribution over the parameters of
the DMP. With this distribution, we can learn the inherent
correlations of cooperative activities which allow us to infer the
behavior of the partner and to participate in the cooperation.
We will provide algorithms for synchronizing and adapting the
behavior of humans and robots during joint physical activities.}
}

@inproceedings{lincoln14422,
       booktitle = {ICRA 2014 Workshop on Long Term Autonomy},
           month = {June},
           title = {A frequency-based approach to long-term robotic mapping},
          author = {Tom Duckett and Tomas Krajnik},
            year = {2014},
        keywords = {ARRAY(0x5568fb678730)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/14422/},
        abstract = {While mapping of static environments has been widely studied, long-term mapping in non-stationary environments is still an open problem. In this talk, we present a novel approach for long-term representation of populated environments, where many of the observed changes are caused by humans performing their daily activities. We propose to model the environment's dynamics by its frequency spectrum, as a combination of harmonic functions that correspond to periodic processes influencing the environment. Such a representation not only allows representation of environment dynamics over arbitrary timescales with constant memory requirements, but also prediction of future environment states. The proposed approach can be applied to many of the state-of-the-art environment models. In particular, we show that occupancy grids, topological or landmark maps can be easily extended to represent dynamic environments. We present experiments using data collected by a mobile robot patrolling an indoor environment over a period of one month, where frequency-enhanced models were compared to their static counterparts in four scenarios: i) 3D map building, ii) environment state prediction, iii) topological localisation and iv) anomaly detection, in order to verify the model's ability to detect unusual events. In all these cases, the frequency-enhanced models outperformed their static counterparts.}
}

@article{lincoln13932,
          volume = {22},
          number = {3},
           month = {June},
          author = {Farshad Arvin and Ali Emre Turgut and Farhad Bazyari and Kutluk Bilge Arikan and Nicola Bellotto and Shigang Yue},
           title = {Cue-based aggregation with a mobile robot swarm: a novel fuzzy-based method},
       publisher = {Sage for International Society for Adaptive Behavior (ISAB)},
            year = {2014},
         journal = {Adaptive Behavior},
             doi = {10.1177/1059712314528009},
           pages = {189--206},
        keywords = {ARRAY(0x5568fbba6408)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13932/},
        abstract = {Aggregation in swarm robotics is referred to as the gathering of spatially distributed robots into a single aggregate. Aggregation can be classified as cue-based or self-organized. In cue-based aggregation, there is a cue in the environment that points to the aggregation area, whereas in self-organized aggregation no cue is present. In this paper, we proposed a novel fuzzy-based method for cue-based aggregation based on the state-of-the-art BEECLUST algorithm. In particular, we proposed three different methods: na{\"i}ve, that uses a deterministic decision-making mechanism; vector-averaging, using a vectorial summation of all perceived inputs; and fuzzy, that uses a fuzzy logic controller. We used different experiment settings: one-source and two-source environments with static and dynamic conditions to compare all the methods. We observed that the fuzzy method outperformed all the other methods and it is the most robust method against noise.}
}

@inproceedings{lincoln39641,
       booktitle = {14th World Congress of Endoscopic Surgery and 22nd Congress of the European Association of Endoscopic Surgery},
           month = {June},
           title = {Robotic uterine manipulator: A novel concept inspired by octopus},
          author = {S. Mustaza and C. Saaj},
            year = {2014},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39641/}
}

@inproceedings{lincoln39642,
       booktitle = {14th World Congress of Endoscopic Surgery and 22nd Congress of the European Association of Endoscopic Surgery},
           month = {June},
           title = {How to control a surgical robot?},
          author = {C. Saaj},
            year = {2014},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39642/}
}

@article{lincoln11574,
          volume = {66},
          number = {2},
           month = {June},
          author = {Yuchao Tang and Jigen Peng and Shigang Yue},
           title = {Cyclic and simultaneous iterative methods to matrix equations of the form AiX Bi = Fi},
       publisher = {Springer},
            year = {2014},
         journal = {Numerical Algorithms},
             doi = {10.1007/s11075-013-9740-9},
           pages = {379--397},
        keywords = {ARRAY(0x5568fba56968)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/11574/},
        abstract = {This paper deals with a general type of linear matrix equation problem. It presents new iterative algorithms to solve the matrix equations of the form AiX Bi = Fi. These algorithms are based on the incremental subgradient and the parallel subgradient methods. The convergence region of these algorithms are larger than other existing iterative algorithms. Finally, some experimental results are presented to show the efficiency of the proposed algorithms. {\^A}{\copyright} 2013 Springer Science+Business Media New York.}
}

@article{lincoln14660,
          volume = {6},
          number = {2},
           month = {June},
          author = {Shigang Yue and Karl Harmer and Kun Guo and Karen Adams and Andrew Hunter},
           title = {Automatic blush detection in ?concealed information? test using visual stimuli},
       publisher = {Inderscience},
            year = {2014},
         journal = {International Journal of Data Mining, Modelling and Management},
             doi = {10.1504/IJDMMM.2014.063197},
           pages = {187--201},
        keywords = {ARRAY(0x5568fbaa7a90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/14660/},
        abstract = {Blushing has been identified as an indicator of deception, shame, anxiety and embarrassment. Although normally associated with the skin coloration of the face, a blush response also affects skin surface temperature. In this paper, an approach to detect a blush response automatically is presented using the Argus P7225 thermal camera from e2v. The algorithm was tested on a sample population of 51 subjects, while using visual stimuli to elicit a response,  and achieved recognition rates of {\texttt{\char126}}77\% TPR and {\texttt{\char126}}60\% TNR, indicating a thermal image sensor is the prospective device to pick up subtle temperature change synchronised with stimuli.}
}

@inproceedings{lincoln13273,
       booktitle = {2014 IEEE International Conference on Robotics and Automation (ICRA 2014)},
           month = {May},
           title = {Spectral analysis for long-term robotic mapping},
          author = {Tomas Krajnik and Jaime Pulido Fentanes and Grzegorz Cielniak and Christian Dondrup and Tom Duckett},
       publisher = {IEEE},
            year = {2014},
        keywords = {ARRAY(0x5568fbb99870)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13273/},
        abstract = {This paper presents a new approach to mobile robot mapping in long-term scenarios. So far, the environment models used in mobile robotics have been tailored to capture static scenes and dealt with the environment changes by means of ?memory decay?. While these models keep up with slowly changing environments, their utilization in dynamic, real world
environments is difficult.

The representation proposed in this paper models the environment?s spatio-temporal dynamics by its frequency spectrum. The spectral representation of the time domain allows to identify, analyse and remember regularly occurring environment processes in a computationally efficient way. Knowledge of the periodicity of the different environment processes constitutes the model predictive capabilities, which are especially useful for long-term mobile robotics scenarios.

In the experiments presented, the proposed approach is applied to data collected by a mobile robot patrolling an indoor
environment over a period of one week. Three scenarios are investigated, including intruder detection and 4D mapping. The results indicate that the proposed method allows to represent arbitrary timescales with constant (and low) memory requirements, achieving compression rates up to 106 . Moreover, the representation allows for prediction of future environment?s state with {$\sim$} 90\% precision.}
}

@article{lincoln22213,
          volume = {21},
          number = {3},
           month = {May},
          author = {Nina Dethlefs and Heriberto Cuayahuitl},
           title = {Hierarchical reinforcement learning for situated language generation},
       publisher = {Cambridge University Press},
            year = {2014},
         journal = {Natural Language Engineering},
             doi = {10.1017/S1351324913000375},
           pages = {391--435},
        keywords = {ARRAY(0x5568fbba1930)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22213/},
        abstract = {Natural Language Generation systems in interactive settings often face a multitude of choices, given that the communicative effect of each utterance they generate depends crucially on the interplay between its physical circumstances, addressee and interaction history. This is particularly true in interactive and situated settings. In this paper we present a novel approach for situated Natural Language Generation in dialogue that is based on hierarchical reinforcement learning and learns the best utterance for a context by optimisation through trial and error. The model is trained from human?human corpus data and learns particularly to balance the trade-off between efficiency and detail in giving instructions: the user needs to be given sufficient information to execute their task, but without exceeding their cognitive load. We present results from simulation and a task-based human evaluation study comparing two different versions of hierarchical reinforcement learning: One operates using a hierarchy of policies with a large state space and local knowledge, and the other additionally shares knowledge across generation subtasks to enhance performance. Results show that sharing knowledge across subtasks achieves better performance than learning in isolation, leading to smoother and more successful interactions that are better perceived by human users.}
}

@inproceedings{lincoln48359,
          volume = {8514},
           month = {April},
          author = {Penny Standen and David Brown and Jess Roscoe and Joseph Hedgecock and David Stewart and Maria Jose Galvez Trigo and Elmunir Elgajiji},
       booktitle = {Universal Access in Human-Computer Interaction. Universal Access to Information and Knowledge},
           title = {Engaging Students with Profound and Multiple Disabilities Using Humanoid Robots},
       publisher = {Springer},
            year = {2014},
         journal = {Lecture Notes in Computer Science},
             doi = {10.1007/978-3-319-07440-5\_39},
           pages = {419--430},
        keywords = {ARRAY(0x5568fb9d0688)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48359/},
        abstract = {Engagement is the single best predictor of successful learning for children with intellectual disabilities yet achieving engagement with pupils who have profound or multiple disabilities (PMD) presents a challenge to educators. Robots have been used to engage children with autism but are they effective with pupils whose disabilities limit their ability to control other technology? Learning objectives were identified for eleven pupils with PMD and a humanoid robot was programmed to enable teachers to use it to help pupils achieve these objectives. These changes were evaluated with a series of eleven case studies where teacher-pupil dyads were observed during four planned video recorded sessions. Engagement was rated in a classroom setting and during the last session with the robot. Video recordings were analysed for duration of engagement and teacher assistance and number of goals achieved. Rated engagement was significantly higher with the robot than in the classroom. Observations of engagement, assistance and goal achievement remained at the same level throughout the sessions suggesting no reduction in the novelty factor.}
}

@inproceedings{lincoln13523,
       booktitle = {AAAI Spring Symposium: "Qualitative Representations for Robots"},
           month = {March},
           title = {A probabilistic model of human-robot spatial interaction using a qualitative trajectory calculus},
          author = {Christian Dondrup and Marc Hanheide and Nicola Bellotto},
       publisher = {AAAI / AI Access Foundation},
            year = {2014},
        keywords = {ARRAY(0x5568fbb949f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13523/},
        abstract = {In this paper we propose a probabilistic model for Human-Robot Spatial Interaction (HRSI) using a Qualitative Trajectory Calculus (QTC). In particular, we will build on previous work representing HRSI as a Markov chain of QTC states and evolve this to an approach using a Hidden Markov Model representation. Our model accounts for the invalidity of certain transitions within the QTC to reduce the complexity of the probabilistic model and to ensure state sequences in accordance to this representational framework. We show the appropriateness of our approach by using the probabilistic model to encode different HRSI behaviours observed in a human-robot interaction study and show how the models can be used to classify these behaviours reliably. Copyright {\^A}{\copyright} 2014, Association for the Advancement of Artificial Intelligence. All rights reserved.}
}

@inproceedings{lincoln13570,
           month = {March},
          author = {Christian Dondrup and Christina Lichtenthaeler and Marc Hanheide},
       booktitle = {9th ACM/IEEE International Conference on Human Robot Interaction},
           title = {Hesitation signals in human-robot head-on encounters: a pilot study},
       publisher = {IEEE},
             doi = {10.1145/2559636.2559817},
           pages = {154--155},
            year = {2014},
        keywords = {ARRAY(0x5568fb674d00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13570/},
        abstract = {The motivation for this research stems from the future vision of being able to buy a mobile service robot for your own household, unpack it, switch it on, and have it behave in an intelligent way; but of course it also has to adapt to your personal preferences over time. My work is focusing on the spatial aspect of the robot?s behaviours, which means when it is moving in a confined, shared space with a human it will also take the communicative character of these movements into account. This adaptation to the users preferences should come from experience which the robot gathers throughout several days or months of interaction and not from a programmer hard-coding certain behaviours}
}

@article{lincoln25768,
          volume = {15},
           month = {March},
          author = {C. Dann and G. Neumann and J. Peters},
           title = {Policy evaluation with temporal differences: a survey and comparison},
       publisher = {Massachusetts Institute of Technology Press (MIT Press) / Microtome Publishing},
         journal = {Journal of Machine Learning Research},
           pages = {809--883},
            year = {2014},
        keywords = {ARRAY(0x5568fbb5b0e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25768/},
        abstract = {Policy evaluation is an essential step in most reinforcement learning approaches. It yields a value function, the quality assessment of states for a given policy, which can be used in a policy improvement step. Since the late 1980s, this research area has been dominated by temporal-difference (TD) methods due to their data-efficiency. However, core issues such as stability guarantees in the off-policy scenario, improved sample efficiency and probabilistic treatment of the uncertainty in the estimates have only been tackled recently, which has led to a large number of new approaches.

This paper aims at making these new developments accessible in a concise overview, with foci on underlying cost functions, the off-policy scenario as well as on regularization in high dimensional feature spaces. By presenting the first extensive, systematic comparative evaluations comparing TD, LSTD, LSPE, FPKF, the residual- gradient algorithm, Bellman residual minimization, GTD, GTD2 and TDC, we shed light on the strengths and weaknesses of the methods. Moreover, we present alternative versions of LSTD and LSPE with drastically improved off-policy performance.}
}

@inproceedings{lincoln13519,
       booktitle = {AAAI Spring Symposium: "Qualitative Representations for Robots"},
           month = {March},
           title = {From sequence to trajectory and vice versa: solving the inverse QTC problem and coping with real-world trajectories},
          author = {Konstantinos Iliopoulos and Nicola Bellotto and Nikolaos Mavridis},
       publisher = {AAAI},
            year = {2014},
        keywords = {ARRAY(0x5568fbb754f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13519/},
        abstract = {Spatial interactions between agents carry information of high value to human observers, as exemplified by the high-level interpretations that humans make when watching the Heider and Simmel movie, or other such videos which just contain motions of simple objects, such as points, lines and triangles. However, not all the information contained in a pair of continuous trajectories is important; and thus the need for qualitative descriptions of interaction trajectories arises. Towards that purpose, Qualitative Trajectory Calculus (QTC) has been proposed in (Van de Weghe, 2004). However, the original definition of QTC handles uncorrupted continuous-time trajectories, while real-world signals are noisy and sampled in discrete-time. Also, although QTC presents a method for transforming trajectories to qualitative descriptions, the inverse problem has not yet been studied. Thus, in this paper, after discussing several aspects of the transition from ideal QTC to discrete-time noisy QTC, we introduce a novel algorithm for solving the QTC inverse problem; i.e. transforming qualitative descriptions to archetypal trajectories that satisfy them. Both of these problems are particularly important for the successful application of qualitative trajectory calculus to Human-Robot Interaction.}
}

@inproceedings{lincoln46198,
       booktitle = {OCEANS},
           month = {February},
           title = {PoseiDRONE: Design of a soft-bodied ROV with crawling, swimming and manipulation ability},
          author = {A Arienti and M Calisti and F Giorgio-Serchi and C Laschi},
            year = {2014},
           pages = {1--7},
             doi = {10.23919/OCEANS.2013.6741155},
        keywords = {ARRAY(0x5568fbaca380)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46198/},
        abstract = {The design concept and development of a multi-purpose, underwater robot is presented. The final robot consists of a continuum composed for 80\% of its volume of rubber-like materials and it combines locomotion (i.e. crawling and swimming) and manipulation capabilities. A first prototype of the robot is illustrated based on the integration of existing prototypes.}
}

@article{lincoln37401,
          volume = {9},
          number = {1},
           month = {January},
          author = {B. Yeomans and C. Saaj},
            note = {cited By 10},
           title = {Towards terrain interaction prediction for bioinspired planetary exploration rovers},
       publisher = {IOP Science},
            year = {2014},
         journal = {Bioinspiration and Biomimetics},
             doi = {10.1088/1748-3182/9/1/016009},
        keywords = {ARRAY(0x5568fbaf8930)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37401/},
        abstract = {Deployment of a small legged vehicle to extend the reach of future planetary exploration missions is an attractive possibility but little is known about the behaviour of a walking rover on deformable planetary terrain. This paper applies ideas from the developing study of granular materials together with a detailed characterization of the sinkage process to propose and validate a combined model of terrain interaction based on an understanding of the physics and micro mechanics at the granular level. Whilst the model reflects the complexity of interactions expected from a walking rover, common themes emerge which enable the model to be streamlined to the extent that a simple mathematical representation is possible without resorting to numerical methods. Bespoke testing and analysis tools are described which reveal some unexpected conclusions and point the way towards intelligent control and foot geometry techniques to improve thrust generation.}
}

@article{lincoln11410,
          volume = {18},
          number = {1},
           month = {January},
          author = {Zhuhong Zhang and Shigang Yue and Min Liao and Fei Long},
           title = {Danger theory based artificial immune system solving dynamic constrained single-objective optimization},
       publisher = {Springer Verlag (Germany)},
            year = {2014},
         journal = {Soft Computing},
             doi = {10.1007/s00500-013-1048-0},
           pages = {185--206},
        keywords = {ARRAY(0x5568fba8f4f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/11410/},
        abstract = {In this paper, we propose an artificial immune system (AIS) based on the danger theory in immunology for solving dynamic nonlinear constrained single-objective optimization problems with time-dependent design spaces. Such proposed AIS executes orderly three modules-danger detection, immune evolution and memory update. The first module identifies whether there are changes in the optimization environment and decides the environmental level, which helps for creating the initial population in the environment and promoting the process of solution search. The second module runs a loop of optimization, in which three sub-populations each with a dynamic size seek simultaneously the location of the optimal solution along different directions through co-evolution. The last module stores and updates the memory cells which help the first module decide the environmental level. This optimization system is an on-line and adaptive one with the characteristics of simplicity, modularization and co-evolution. The numerical experiments and the results acquired by the nonparametric statistic procedures, based on 22 benchmark problems and an engineering problem, show that the proposed approach performs globally well over the compared algorithms and is of potential use for many kinds of dynamic optimization problems. {\^A}{\copyright} 2013 Springer-Verlag Berlin Heidelberg.}
}

@article{lincoln38432,
          volume = {13},
          number = {4},
          author = {K. Cai and J. Niu and Simon Parsons},
            note = {cited By 2},
           title = {On the effects of competition between agent-based double auction markets},
            year = {2014},
         journal = {Electronic Commerce Research and Applications},
             doi = {10.1016/j.elerap.2014.04.002},
           pages = {229--242},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38432/}
}

@inproceedings{lincoln46197,
          author = {Marcello Calisti and Francesco Corucci and Andrea Arienti and Cecilia Laschi},
       booktitle = {Biomimetic and Biohybrid Systems: Third International Conference, Living Machines 2014, Milan, Italy, July 30 {--} August 1, 2014. Proceedings},
         address = {Cham},
           title = {Bipedal Walking of an Octopus-Inspired Robot},
       publisher = {Springer International Publishing},
             doi = {10.1007/978-3-319-09435-9\_4},
           pages = {35--46},
            year = {2014},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46197/},
        abstract = {In this paper a model is presented which describes an octopus-inspired robot capable of two kinds of locomotion: crawling and bipedal walking. Focus will be placed on the latter type of locomotion to demonstrate, through model simulations and experimental trials, that the robot?s speed increases by about 3 times compared to crawling. This finding is coherent with the performances of the biological counterpart when adopting this gait. Specific features of underwater legged locomotion are then derived from the model, which prompt the possibility of controlling locomotion by using simple control and by exploiting slight morphological adaptations.}
}

@inproceedings{lincoln38429,
          volume = {WS-14-},
           title = {Modeling agent's preferences based on prospect theory},
          author = {P.A.L. Castro and Simon Parsons},
            year = {2014},
           pages = {32--36},
            note = {cited By 1},
         journal = {AAAI Workshop - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38429/}
}

@inproceedings{lincoln38435,
           title = {Playing hide-and-seek: An abstract game for cyber security},
          author = {M. Chapman and G. Tyson and P. McBurney and M. Luck and Simon Parsons},
            year = {2014},
             doi = {10.1145/2602945.2602946},
            note = {cited By 5},
         journal = {ACM International Conference Proceeding Series},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38435/}
}

@article{lincoln38431,
          volume = {187},
          author = {P.A.L. De Castro and Simon Parsons},
            note = {cited By 0},
           title = {Towards modeling securities markets as a society of heterogeneous trading agents},
         journal = {Lecture Notes in Business Information Processing},
             doi = {10.1007/978-3-319-13218-1},
           pages = {16--25},
            year = {2014},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38431/}
}

@inproceedings{lincoln25770,
          volume = {8724 L},
          number = {PART 1},
          author = {Vincenc Gomez and Hilbert J. Kappen and Jan Peters and Gerhard Neumann},
       booktitle = {Machine Learning and Knowledge Discovery in Databases - European Conference, ECML/PKDD 2014},
           title = {Policy search for path integral control},
       publisher = {Springer},
            year = {2014},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-662-44848-9{$_3$}{$_1$}},
           pages = {482--497},
        keywords = {ARRAY(0x5568fbb6dd38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25770/},
        abstract = {Path integral (PI) control defines a general class of control problems for which the optimal control computation is equivalent to an inference problem that can be solved by evaluation of a path integral over state trajectories. However, this potential is mostly unused in real-world problems because of two main limitations: first, current approaches can typically only be applied to learn open-loop controllers and second, current sampling procedures are inefficient and not scalable to high dimensional systems. We introduce the efficient Path Integral Relative-Entropy Policy Search (PI-REPS) algorithm for learning feedback policies with PI control. Our algorithm is inspired by information theoretic policy updates that are often used in policy search. We use these updates to approximate the state trajectory distribution that is known to be optimal from the PI control theory. Our approach allows for a principled treatment of different sampling distributions and can be used to estimate many types of parametric or non-parametric feedback controllers. We show that PI-REPS significantly outperforms current methods and is able to solve tasks that are out of reach for current methods.}
}

@inproceedings{lincoln16638,
          author = {Daqi Liu and Shigang Yue},
       booktitle = {International Conference on Multisensor Fusion and Information Integration for Intelligent Systems, MFI 2014},
           title = {Spiking neural network for visual pattern recognition},
       publisher = {Institute of Electrical and Electronics Engineers Inc.},
         journal = {Processing of 2014 International Conference on Multisensor Fusion and Information Integration for Intelligent Systems, MFI 2014},
             doi = {10.1109/MFI.2014.6997737},
           pages = {1--5},
            year = {2014},
        keywords = {ARRAY(0x5568fb6d6420)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/16638/},
        abstract = {Most of visual pattern recognition algorithms try to emulate the mechanism of visual pathway within the human brain. Regarding of classic face recognition task, by using the spatiotemporal information extracted from Spiking neural network (SNN), batch learning rule and on-line learning rule stand out from their competitors. However, the former one simply considers the average pattern within the class, and the latter one just relies on the nearest relevant single pattern. In this paper, a novel learning rule and its SNN framework has been proposed. It considers all relevant patterns in the local domain around the undetermined sample rather than just nearest relevant single pattern. Experimental results show the proposed learning rule and its SNN framework obtains satisfactory testing results under the ORL face database.}
}

@inproceedings{lincoln38568,
           title = {A continuum body force sensor designed for flexible surgical robotics devices},
          author = {Y. Noh and E.L. Secco and S. Sareh and H. Wurdemann and A. Faragasso and J. Back and H. Liu and Elizabeth Sklar and K. Althoefer},
            year = {2014},
           pages = {3711--3714},
             doi = {10.1109/EMBC.2014.6944429},
            note = {cited By 19},
         journal = {2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC 2014},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38568/}
}

@article{lincoln38428,
          volume = {5},
          number = {2-3},
          author = {Simon Parsons and K. Atkinson and Z. Li and P. McBurney and Elizabeth Sklar and M. Singh and K. Haigh and K. Levitt and J. Rowe},
            note = {cited By 13},
           title = {Argument schemes for reasoning about trust},
            year = {2014},
         journal = {Argument and Computation},
             doi = {10.1080/19462166.2014.913075},
           pages = {160--190},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38428/}
}

@article{lincoln38430,
          volume = {945},
           title = {The qualitative verification of quantitative uncertainty},
          author = {Simon Parsons and A. Saffiotti},
            year = {2014},
           pages = {180--189},
            note = {cited By 0},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38430/}
}

@inproceedings{lincoln38433,
          volume = {2},
           title = {Behaviour mining for collision avoidance in multi-robot systems},
          author = {J. Raphael and E. Schneider and Simon Parsons and Elizabeth Sklar},
            year = {2014},
           pages = {1445--1446},
            note = {cited By 3},
         journal = {13th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2014},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38433/}
}

@inproceedings{lincoln38434,
          volume = {2},
           title = {An empirical evaluation of auction-based task allocation in multi-robot teams},
          author = {E. Schneider and O. Balas and A.T. {\"O}zgelen and Elizabeth Sklar and Simon Parsons},
            year = {2014},
           pages = {1443--1444},
            note = {cited By 10},
         journal = {13th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2014},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38434/}
}

@inproceedings{lincoln38565,
          volume = {FS-14-},
           title = {Toward human/multi-robot systems to support emergency services agencies},
          author = {Elizabeth Sklar and E. Schneider and A.T. {\"O}zgelen and M.Q. Azhar},
            year = {2014},
           pages = {145--147},
            note = {cited By 1},
         journal = {AAAI Fall Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38565/}
}

@inproceedings{lincoln16637,
          author = {Gabriel Zahi and Shigang Yue},
       booktitle = {International Conference on Multisensor Fusion and Information Integration for Intelligent Systems, MFI 2014},
           title = {Reducing motion blurring associated with temporal summation in low light scenes for image quality enhancement},
       publisher = {Institute of Electrical and Electronics Engineers Inc.},
         journal = {Processing of 2014 International Conference on Multisensor Fusion and Information Integration for Intelligent Systems, MFI 2014},
             doi = {10.1109/MFI.2014.6997725},
           pages = {1--5},
            year = {2014},
        keywords = {ARRAY(0x5568fb9b7688)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/16637/},
        abstract = {In order to see under low light conditions nocturnal insects rely on neural strategies based on combinations of spatial and temporal summations. Though these summation techniques when modelled are effective in improving the quality of low light images, using the temporal summation in scenes where image velocity is high only come at a cost of motion blurring in the output scenes. Most recent research has been towards reducing motion blurring in scenes where motion is caused by moving objects rather than effectively reducing motion blurring in scenes where motion is caused by moving cameras. This makes it impossible to implement the night vision algorithm in moving robots or cars that operate under low light conditions. In this paper we present a generic new method that can replace the normal temporal summation in scenes where motion is detected. The proposed method is both suitable for motion caused by moving objects as well as moving cameras. The effectiveness of this new generic method is shown with relevant supporting experiments.}
}

@article{lincoln12817,
          volume = {2013},
           month = {December},
          author = {Pin Shen Teh and Andrew Beng Jin Teoh and Shigang Yue},
           title = {A survey of keystroke dynamics biometrics},
       publisher = {Hindawi Publishing Corporation / Scientific World},
            year = {2013},
         journal = {The Scientific World Journal},
             doi = {10.1155/2013/408280},
           pages = {408280},
        keywords = {ARRAY(0x5568fba800c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/12817/},
        abstract = {Research on keystroke dynamics biometrics has been increasing, especially in the last decade. The main motivation behind this effort is due to the fact that keystroke dynamics biometrics is economical and can be easily integrated into the existing computer security systems with minimal alteration and user intervention. Numerous studies have been conducted in terms of data acquisition devices, feature representations, classification methods, experimental protocols, and evaluations. However, an up-to-date extensive survey and evaluation is not yet available. The objective of this paper is to provide an insightful survey and comparison on keystroke dynamics biometrics research performed throughout the last three decades, as well as offering suggestions and possible future research directions.}
}

@inproceedings{lincoln25785,
       booktitle = {Advances in Neural Information Processing Systems, (NIPS)},
           month = {December},
           title = {Probabilistic movement primitives},
          author = {A. Paraschos and C. Daniel and J. Peters and G. Neumann},
            year = {2013},
         journal = {Advances in Neural Information Processing Systems},
        keywords = {ARRAY(0x5568fba2a7c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25785/},
        abstract = {Movement Primitives (MP) are a well-established approach for representing modular
and re-usable robot movement generators. Many state-of-the-art robot learning
successes are based MPs, due to their compact representation of the inherently
continuous and high dimensional robot movements. A major goal in robot learning
is to combine multiple MPs as building blocks in a modular control architecture
to solve complex tasks. To this effect, a MP representation has to allow for
blending between motions, adapting to altered task variables, and co-activating
multiple MPs in parallel. We present a probabilistic formulation of the MP concept
that maintains a distribution over trajectories. Our probabilistic approach
allows for the derivation of new operations which are essential for implementing
all aforementioned properties in one framework. In order to use such a trajectory
distribution for robot movement control, we analytically derive a stochastic feedback
controller which reproduces the given trajectory distribution. We evaluate
and compare our approach to existing methods on several simulated as well as
real robot scenarios.}
}

@inproceedings{lincoln12670,
       booktitle = {16th International Conference on Advanced Robotics (ICAR 2013)},
           month = {November},
           title = {External localization system for mobile robotics},
          author = {Tomas Krajnik and Matias Nitsche and Jan Faigl and Marta Mejail and Libor Preucil and Tom Duckett},
       publisher = {IEEE},
            year = {2013},
         journal = {International Conference on Advanced Robotics, ICAR 2013 (Proceedings)},
        keywords = {ARRAY(0x5568fbb902e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/12670/},
        abstract = {We present a fast and precise vision-based software intended for multiple robot localization. The core component of
the proposed localization system is an efficient method for black and white circular pattern detection. The method is robust to variable lighting conditions, achieves sub-pixel precision, and its computational complexity is independent of the processed image size. With off-the-shelf computational equipment and low-cost camera, its core algorithm is able to process hundreds of images per second while tracking hundreds of objects with millimeter precision. We propose a mathematical model of the method that allows to calculate its precision, area of coverage, and processing speed from the camera?s intrinsic parameters and hardware?s processing capacity. The correctness of the presented model and
performance of the algorithm in real-world conditions are verified in several experiments. Apart from the method description, we also publish its source code; so, it can be used as an enabling technology for various mobile robotics problems.}
}

@inproceedings{lincoln13757,
           month = {November},
          author = {Gabriel Zahi and Shigang Yue},
       booktitle = {Modelling Symposium (EMS), 2013 European},
           title = {Automatic detection of low light images in a video sequence Shot under different light conditions},
       publisher = {IEEE},
             doi = {10.1109/EMS.2013.47},
           pages = {271--276},
            year = {2013},
        keywords = {ARRAY(0x5568fba790f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13757/},
        abstract = {Nocturnal insects have the ability to neurally sum visual signals in space and time to be able to see under very low light conditions. This ability shown by nocturnal insects has inspired many researchers to develop a night vision algorithm, that is capable of significantly improving the quality and reliability of digital images captured under very low light conditions. This algorithm however when applied to day time images rather degrades their quality. It is therefore not suitable to apply the night vision algorithms equally to an image stream with different light conditions. This paper introduces a quick method of automatically determining when to apply the nocturnal vision algorithm by analysing the cumulative intensity histogram of each image in the stream. The effectiveness of this method is demonstrated with relevant experiments in a good and acceptable way.}
}

@inproceedings{lincoln11637,
       booktitle = {International Conference on Social Robotics (ICSR)},
           month = {October},
           title = {Qualitative design and implementation of human-robot spatial interactions},
          author = {Nicola Bellotto and Marc Hanheide and Nico Van de Weghe},
       publisher = {Springer},
            year = {2013},
             doi = {10.1007/978-3-319-02675-6\_33},
        keywords = {ARRAY(0x5568fbb6c6d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/11637/},
        abstract = {Despite the large number of navigation algorithms available for mobile robots, in many social contexts they often exhibit inopportune motion behaviours in proximity of people, often with very "unnatural" movements due to the execution of segmented trajectories or the sudden activation of safety mechanisms (e.g., for obstacle avoidance). We argue that the reason of the problem is not only the difficulty of modelling human behaviours and generating opportune robot control policies, but also the way human-robot spatial interactions are represented and implemented.
In this paper we propose a new methodology based on a qualitative representation of spatial interactions, which is both flexible and compact, adopting the well-defined and coherent formalization of Qualitative Trajectory Calculus (QTC). We show the potential of a QTC-based approach to abstract and design complex robot behaviours, where the desired robot's behaviour is represented together with its actual performance in one coherent approach, focusing on spatial interactions rather than pure navigation problems.}
}

@inproceedings{lincoln25693,
          volume = {2015-F},
          number = {Februa},
           month = {October},
          author = {A. Paraschos and G. Neumann and J. Peters},
       booktitle = {13th IEEE-RAS International Conference on  Humanoid Robots (Humanoids)},
           title = {A probabilistic approach to robot trajectory generation},
       publisher = {IEEE},
            year = {2013},
             doi = {10.1109/HUMANOIDS.2013.7030017},
           pages = {477--483},
        keywords = {ARRAY(0x5568fbba11e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25693/},
        abstract = {Motor Primitives (MPs) are a promising approach for the data-driven acquisition as well as for the modular and re-usable generation of movements. However, a modular control architecture with MPs is only effective if the MPs support co-activation as well as continuously blending the activation from one MP to the next. In addition, we need efficient mechanisms to adapt a MP to the current situation. Common approaches to movement primitives lack such capabilities or their implementation is based on heuristics. We present a probabilistic movement primitive approach that overcomes the limitations of existing approaches. We encode a primitive as a probability distribution over trajectories. The representation as distribution has several beneficial properties. It allows encoding a time-varying variance profile. Most importantly, it allows performing new operations - a product of distributions for the co-activation of MPs conditioning for generalizing the MP to different desired targets. We derive a feedback controller that reproduces a given trajectory distribution in closed form. We compare our approach to the existing state-of-the art and present real robot results for learning from demonstration.}
}

@inproceedings{lincoln11636,
       booktitle = {IEEE SMC Int. Workshop on Human-Machine Systems, Cyborgs and Enhancing Devices (HUMASCEND)},
           month = {October},
           title = {A multimodal smartphone interface for active perception by visually impaired},
          author = {Nicola Bellotto},
       publisher = {IEEE},
            year = {2013},
        keywords = {ARRAY(0x5568fbaf1f60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/11636/},
        abstract = {The diffuse availability of mobile devices, such as smartphones and tablets, has the potential to bring substantial benefits to the people with sensory impairments. The solution proposed in this paper is part of an ongoing effort to create an accurate obstacle and hazard detector for the visually impaired, which is embedded in a hand-held device. In particular, it presents a proof of concept for a multimodal interface to control the orientation of a smartphone's camera, while being held by a person, using a combination of vocal messages, 3D sounds and vibrations. The solution, which is to be evaluated experimentally by users, will enable further research in the area of active vision with human-in-the-loop, with potential application to mobile assistive devices for indoor navigation of visually impaired people.}
}

@article{lincoln23076,
          volume = {6},
           month = {October},
          author = {Paul E. Baxter and Joachim de Greeff and Tony Belpaeme},
           title = {Cognitive architecture for human?robot interaction: towards behavioural alignment},
       publisher = {Elsevier B.V.},
            year = {2013},
         journal = {Biologically Inspired Cognitive Architectures},
             doi = {10.1016/j.bica.2013.07.002},
           pages = {30--39},
        keywords = {ARRAY(0x5568fb7450f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23076/},
        abstract = {Abstract With increasingly competent robotic systems desired and required for social human?robot interaction comes the necessity for more complex means of control. Cognitive architectures (specifically the perspective where principles of structure and function are sought to account for multiple cognitive competencies) have only relatively recently been considered for applica- tion to this domain. In this paper, we describe one such set of architectural principles ? acti- vation dynamics over a developmental distributed associative substrate ? and show how this enables an account of a fundamental competence for social cognition: multi-modal behavioural alignment. Data from real human?robot interactions is modelled using a computational system based on this set of principles to demonstrate how this competence can therefore be consid- ered as embedded in wider cognitive processing. It is shown that the proposed system can model the behavioural characteristics of human subjects. While this study is a simulation using real interaction data, the results obtained validate the application of the proposed approach to this issue.}
}

@article{lincoln12768,
          volume = {61},
          number = {10},
           month = {October},
          author = {Tom Duckett and Achim Lilienthal},
            note = {Selected Papers from the 5th European Conference on Mobile Robots (ECMR 2011)},
           title = {Editorial},
       publisher = {Elsevier for North-Holland / Intelligent Autonomous Systems (IAS) Society},
            year = {2013},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2013.01.005},
           pages = {1049--1050},
        keywords = {ARRAY(0x5568fbb049c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/12768/},
        abstract = {.}
}

@article{lincoln13793,
          volume = {27},
          number = {06},
           month = {September},
          author = {Jiawei Xu and Shigang Yue and Yuchao Tang},
           title = {A motion attention model based on rarity weighting and motion cues in dynamic scenes},
       publisher = {World Scientific Publishing},
            year = {2013},
         journal = {International Journal of Pattern Recognition and Artificial Intelligence},
             doi = {10.1142/S0218001413550094},
           pages = {1355009},
        keywords = {ARRAY(0x5568fb717670)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13793/},
        abstract = {Nowadays, motion attention model is a controversial topic in the biological computer vision area. The computational attention model can be decomposed into a set of features via predefined channels. Here we designed a bio-inspired vision attention model, and added the rarity measurement onto it. The priority of rarity is emphasized under the assumption of weighting effect upon the features logic fusion. At this stage, a final saliency map at each frame is adjusted by the spatiotemporal and rarity values. By doing this, the process of mimicking human vision attention becomes more realistic and logical to the real circumstance. The experiments are conducted on the benchmark dataset of static images and video sequences. We simulated the attention shift based on several dataset. Most importantly, our dynamic scenes are mostly selected from the objects moving on the highway and dynamic scenes. The former one can be developed on the detection of car collision and will be a useful tool for further application in robotics. We also conduct experiment on the other video clips to prove the rationality of rarity factor and feature cues fusion methods. Finally, the evaluation results indicate our visual attention model outperforms several state-of-the-art motion attention models.


Read More: http://www.worldscientific.com/doi/abs/10.1142/S0218001413550094}
}

@article{lincoln28029,
          volume = {2},
          number = {1-2},
           month = {August},
          author = {M. P. Deisenroth and G. Neumann and J. Peters},
           title = {A survey on policy search for robotics},
       publisher = {Now Publishers},
            year = {2013},
         journal = {Foundations and Trends in Robotics},
             doi = {10.1561/2300000021},
           pages = {388--403},
        keywords = {ARRAY(0x5568fbab9000)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28029/},
        abstract = {Policy search is a subfield in reinforcement learning which focuses on
finding good parameters for a given policy parametrization. It is well
suited for robotics as it can cope with high-dimensional state and action
spaces, one of the main challenges in robot learning. We review recent
successes of both model-free and model-based policy search in robot
learning.
Model-free policy search is a general approach to learn policies
based on sampled trajectories. We classify model-free methods based on
their policy evaluation strategy, policy update strategy, and exploration
strategy and present a unified view on existing algorithms. Learning a
policy is often easier than learning an accurate forward model, and,
hence, model-free methods are more frequently used in practice. However,
for each sampled trajectory, it is necessary to interact with the
* Both authors contributed equally.
robot, which can be time consuming and challenging in practice. Modelbased
policy search addresses this problem by first learning a simulator
of the robot?s dynamics from data. Subsequently, the simulator generates
trajectories that are used for policy learning. For both modelfree
and model-based policy search methods, we review their respective
properties and their applicability to robotic systems.}
}

@inproceedings{lincoln11330,
       booktitle = {Towards Autonomous Robotic Systems},
           month = {August},
           title = {Evaluation of laser range-finder mapping for agricultural spraying vehicles},
          author = {Francisco-Angel Moreno and Grzegorz Cielniak and Tom Duckett},
            year = {2013},
           pages = {210--221},
             doi = {10.1007/978-3-662-43645-5\_22},
        keywords = {ARRAY(0x5568fba87f18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/11330/},
        abstract = {In this paper, we present a new application of laser range-finder sensing to agricultural spraying vehicles. The current generation of spraying vehicles use automatic controllers to maintain the height of the sprayer booms above the crop.
However, these control systems are typically based on ultrasonic sensors mounted on the booms, which limits the accuracy of the measurements and the response of the controller to changes in the terrain, resulting in a sub-optimal spraying process. To overcome these limitations, we propose to use a laser scanner, attached to the front of the sprayer's cabin, to scan the ground surface in front of the vehicle and to build a scrolling 3d map of the terrain. We evaluate the proposed solution in a series of field tests, demonstrating that the approach provides a more detailed and accurate representation of the environment than the current sonar-based solution, and which can lead to the development of more efficient boom control systems.}
}

@misc{lincoln53189,
       booktitle = {Living machines: An exhibition of biomimetic and biohybrid technologies and artworks},
           month = {August},
           title = {Living machines: An exhibition of biomimetic and biohybrid technologies and artworks},
          author = {Tony Prescott and Paul Verschure and Charles Fox and Anna Mura and Stuart Wilson and Gill Ryder},
            year = {2013},
        keywords = {ARRAY(0x5568fb9fc700)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53189/},
        abstract = {Living Machines is an international conference series concerned with the development of future real-world technologies that harness the principles underlying living systems and the flow of communication signals between living and artificial systems.  The conference highlights the most exciting contemporary research in biomimetics{--}the development of ovel technologies through the distillation of principles from the study of biological systems, and biohybrids{--}formed by combining a biological component{--}an existing living system{--}with an artificial, newly-engineered component. The concept of ?Living Machine? captures the insight that useful artificial entities can be designed by copying life, and, at the same time, that we can understand biological organisms, including ourselves, as living machines ?designed? by nature. Some of the most interesting new developments in biomimetic and biohybrid technologies, grouped under five themes, together with some striking examples of contemporary biomimetic or biohybrid art, have been selected for  presentation at the Living Machines Exhibition, a one-day event at the Science Museum in London.  Highlights of the 2013 Living Machines exhibition include:
? A musical performance featuring the iCub humanoid robot
? Mammal-like robots with whiskered touch systems
? A robot model of fossilised animal behaviour from the dawn of life
? Biomimetic medical devices including a wasp-like needle for minimally-invasive
surgery
? A robot that powers itself by digesting human waste
? Micro-flying robots, worm, octopus, fish and mammal-like robots
? Biohybrid clothing made with living cells and robots controlled by slime mould
? Live visual art generated by the Artificial Intelligence AARON, created by Harold Cohen
? A string quartet performing music generated by the Artificial Intelligence EMI, created
by David Cope.}
}

@article{lincoln25777,
           month = {July},
           title = {Data-efficient generalization of robot skills with contextual policy search},
          author = {A. G. Kupcsik and M. P. Deisenroth and J. Peters and Gerhard Neumann},
            year = {2013},
           pages = {1401--1407},
            note = {27th AAAI Conference on Artificial Intelligence, AAAI 2013; Bellevue, WA; United States; 14 - 18 July 2013},
         journal = {Proceedings of the 27th AAAI Conference on Artificial Intelligence, AAAI 2013},
        keywords = {ARRAY(0x5568fbbb1d68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25777/},
        abstract = {In robotics, controllers make the robot solve a task within a specific context. The context can describe the objectives of
the robot or physical properties of the environment and is always specified before task execution. To generalize the controller to multiple contexts, we follow a hierarchical approach for policy learning: A lower-level policy controls the robot for a given context and an upper-level policy generalizes among contexts. Current approaches for learning such upper-level policies are based on model-free policy search, which require an excessive number of interactions of the robot with its environment.
More data-efficient policy search approaches are model based but, thus far, without the capability of learning
hierarchical policies. We propose a new model-based policy search approach that can also learn contextual upper-level
policies. Our approach is based on learning probabilistic forward models for long-term predictions. Using these  redictions, we use information-theoretic insights to improve the upper-level policy. Our method achieves a substantial improvement in learning speed compared to existing methods on simulated and real robotic tasks.}
}

@inproceedings{lincoln51742,
       booktitle = {Conference on Biomimetic and Biohybrid Systems},
           month = {June},
           title = {Where wall-following works: case study of simple
heuristics vs. optimal exploratory behaviour},
          author = {Charles Fox},
            year = {2013},
        keywords = {ARRAY(0x5568fb9c4da0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/51742/},
        abstract = {Where wall-following works: case study of simple heuristics vs. optimal exploratory behaviour}
}

@phdthesis{lincoln29374,
           month = {June},
           title = {Haptic role allocation and intention negotiation in human-robot collaboration},
          school = {Koc University},
          author = {Ayse Kucukyilmaz},
            year = {2013},
        keywords = {ARRAY(0x5568fba00c70)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29374/},
        abstract = {This dissertation aims to present a perspective to build more natural shared control systems for physical human-robot cooperation. As the tasks become more complex and more dynamic, many shared control schemes fail to meet the expectation of an effortless interaction that resembles human-human sensory communication. Since such systems are mainly built to improve task performance, the richness of sensory communication is of secondary concern. We suggest that effective cooperation can be achieved when the human?s and the robot?s roles within the task are dynamically updated during the execution of the task. These roles define states for the system, in which the robot?s control leads or follows the human?s actions. In such a system, a state transition can occur at certain times if the robot can determine the user?s intention for gaining/relinquishing control. Specifically, with these state transitions we assign certain roles to the human and the robot. We believe that only by employing the robot with tools to change its behavior during collaboration, we can improve the collaboration experience. 

We explore how human-robot cooperation in virtual and physical worlds can be improved using a force-based role-exchange mechanism. Our findings indicate that the proposed role exchange framework is beneficial in a sense that it can improve task performance and the efficiency of the partners during the task, and decrease the energy requirement of the human. Moreover, the results imply that the subjective acceptability of the proposed model is attained only when role exchanges are performed in a smooth and transparent fashion. Finally, we illustrate that adding extra sensory cues on top of a role exchange scheme is useful for improving the sense of interaction during the task, as well as making the system more comfortable and easier to use, and the task more enjoyable.}
}

@article{lincoln9307,
          volume = {5},
          number = {2},
           month = {June},
          author = {Shigang Yue and F. Claire Rind},
           title = {Redundant neural vision systems: competing for collision recognition roles},
       publisher = {IEEE / Institute of Electrical and Electronics Engineers Incorporated},
            year = {2013},
         journal = {IEEE Transactions on Autonomous Mental Development},
             doi = {10.1109/TAMD.2013.2255050},
           pages = {173--186},
        keywords = {ARRAY(0x5568fb73df60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/9307/},
        abstract = {Ability to detect collisions is vital for future robots that interact with humans in complex visual environments. Lobula giant movement detectors (LGMD) and directional selective neurons (DSNs) are two types of identified neurons found in the visual pathways of insects such as locusts. Recent modelling studies showed that the LGMD or grouped DSNs could each be tuned for collision recognition. In both biological and artificial vision systems, however, which one should play the collision recognition role and the way the two types of specialized visual neurons could be functioning together are not clear. In this modeling study, we compared the competence of the LGMD and the DSNs, and also investigate the cooperation of the two neural vision systems for collision recognition via artificial evolution. We implemented three types of collision recognition neural subsystems ? the LGMD, the DSNs and a hybrid system which combines the LGMD and the DSNs subsystems together, in each individual agent. A switch gene determines which of the three redundant neural subsystems plays the collision recognition role. We found that, in both robotics and driving environments, the LGMD was able to build up its ability for collision recognition quickly and robustly therefore reducing the chance of other types of neural networks to play the same role. The results suggest that the LGMD neural network could be the ideal model to be realized in hardware for collision recognition.}
}

@manual{lincoln22903,
           month = {May},
            type = {Documentation},
           title = {FUBUTEC-ECEC'2013},
          author = {Cristina Cherino and Grzegorz Cielniak and Patrick Dickinson and Philippe Geril},
       publisher = {EUROSIS-ETI BVBA},
            year = {2013},
            note = {FUBUTEC'2013, Future Business Technology Conference, June 10-12, 2013, University of Lincoln, Lincoln, UK},
        keywords = {ARRAY(0x5568fb9d9318)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22903/},
        abstract = {This edition covers Risk Management, Management Techniques, Production Design Optimization and Video Applications}
}

@article{lincoln29366,
          volume = {6},
          number = {1},
           month = {May},
          author = {Ayse Kucukyilmaz and Tevfik Metin Sezgin and Cagatay Basdogan},
           title = {Intention recognition for dynamic role exchange in haptic collaboration},
       publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
            year = {2013},
         journal = {IEEE Transactions on Haptics},
             doi = {10.1109/TOH.2012.21},
           pages = {58--68},
        keywords = {ARRAY(0x5568fbb83138)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29366/},
        abstract = {In human-computer collaboration involving haptics, a key issue that remains to be solved is to establish an intuitive communication between the partners. Even though computers are widely used to aid human operators in teleoperation, guidance, and training, since they lack the adaptability, versatility, and  awareness of a human, their ability to improve efficiency and effectiveness in dynamic tasks is limited. We suggest that the communication between a human and a computer can be improved if it involves a decision making process in which the computer is programmed to infer the intentions of the human operator and dynamically adjust the control levels of the interacting parties to facilitate a more intuitive interaction setup. In this paper, we investigate the utility of such a dynamic role exchange mechanism where partners negotiate through the haptic channel to trade their control levels on a collaborative task. We examine the energy consumption, the work done on the manipulated object, and the joint efficiency in addition to the task performance. We show that when compared to an equal control condition, a role exchange mechanism improves task performance and the joint efficiency of the partners. We also show that augmenting the system with additional informative visual and vibrotactile cues, which are used to display the state of interaction, allows the users to become aware of the underlying role exchange mechanism and utilize it in favor of the task. These cues also improve the user's sense of interaction and reinforce his/her belief that the computer aids with the execution of the task.}
}

@inproceedings{lincoln25781,
           month = {May},
          author = {C. Daniel and G. Neumann and O. Kroemer and J. Peters},
            note = {cited By 3},
       booktitle = {IEEE International Conference on Robotics and Automation},
           title = {Learning sequential motor tasks},
            year = {2013},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
             doi = {10.1109/ICRA.2013.6630937},
           pages = {2626--2632},
        keywords = {ARRAY(0x5568fbae5a90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25781/},
        abstract = {Many real robot applications require the sequential use of multiple distinct motor primitives. This requirement implies the need to learn the individual primitives as well as a strategy to select the primitives sequentially. Such hierarchical learning problems are commonly either treated as one complex monolithic problem which is hard to learn, or as separate tasks learned in isolation. However, there exists a strong link between the robots strategy and its motor primitives. Consequently, a consistent framework is needed that can learn jointly on the level of the individual primitives and the robots strategy. We present a hierarchical learning method which improves individual motor primitives and, simultaneously, learns how to combine these motor primitives sequentially to solve complex motor tasks. We evaluate our method on the game of robot hockey, which is both difficult to learn in terms of the required motor primitives as well as its strategic elements.}
}

@inproceedings{lincoln13775,
           month = {May},
          author = {C. Lang and S. Wachsmuth and M. Hanheide and H. Wersing},
            note = {Conference Code:100673},
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
           title = {Facial communicative signal interpretation in human-robot interaction by discriminative video subsequence selection},
         address = {Karlsruhe},
       publisher = {IEEE},
            year = {2013},
             doi = {10.1109/ICRA.2013.6630572},
           pages = {170--177},
        keywords = {ARRAY(0x5568fba80d68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13775/},
        abstract = {Facial communicative signals (FCSs) such as head gestures, eye gaze, and facial expressions can provide useful feedback in conversations between people and also in human-robot interaction. This paper presents a pattern recognition approach for the interpretation of FCSs in terms of valence, based on the selection of discriminative subsequences in video data. These subsequences capture important temporal dynamics and are used as prototypical reference subsequences in a classification procedure based on dynamic time warping and feature extraction with active appearance models. Using this valence classification, the robot can discriminate positive from negative interaction situations and react accordingly. The approach is evaluated on a database containing videos of people interacting with a robot by teaching the names of several objects to it. The verbal answer of the robot is expected to elicit the display of spontaneous FCSs by the human tutor, which were classified in this work. The achieved classification accuracies are comparable to the average human recognition performance and outperformed our previous results on this task. {\^A}{\copyright} 2013 IEEE.}
}

@inproceedings{lincoln7880,
           month = {May},
          author = {Christian Lang and Sven Wachsmuth and Marc Hanheide and Heiko Wersing},
            note = {Facial communicative signals (FCSs) such as head gestures, eye gaze, and facial expressions can provide useful feedback in conversations between people and also in humanrobot interaction. This paper presents a pattern recognition approach for the interpretation of FCSs in terms of valence, based on the selection of discriminative subsequences in video data. These subsequences capture important temporal dynamics and are used as prototypical reference subsequences in a classi?cation procedure based on dynamic time warping and feature extraction with active appearance models. Using this valence classi?cation, the robot can discriminate positive from negative interaction situations and react accordingly. The approach is evaluated on a database containing videos of people interacting with a robot by teaching the names of several objects to it. The verbal answer of the robot is expected to elicit the display of spontaneous FCSs by the human tutor, which were classi?ed in this work. The achieved classi?cation accuracies are comparable to the average human recognition performance and outperformed our previous results on this task.},
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           title = {Facial communicative signal interpretation in human-robot interaction by discriminative video subsequence selection},
       publisher = {IEEE},
            year = {2013},
             doi = {10.1109/ICRA.2013.6630572},
           pages = {170--177},
        keywords = {ARRAY(0x5568fbbae810)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/7880/},
        abstract = {Facial communicative signals (FCSs) such as head gestures, eye gaze, and facial expressions can provide useful feedback in conversations between people and also in humanrobot interaction. This paper presents a pattern recognition approach for the interpretation of FCSs in terms of valence, based on the selection of discriminative subsequences in video data. These subsequences capture important temporal dynamics and are used as prototypical reference subsequences in a classi?cation procedure based on dynamic time warping and feature extraction with active appearance models. Using this valence classi?cation, the robot can discriminate positive from negative interaction situations and react accordingly. The approach is evaluated on a database containing videos of people interacting with a robot by teaching the names of several objects to it. The verbal answer of the robot is expected to elicit the display of spontaneous FCSs by the human tutor, which were classi?ed in this work. The achieved classi?cation accuracies are comparable to the average human recognition performance and outperformed our previous results on this task.}
}

@inproceedings{lincoln39644,
       booktitle = {12th Symposium on Advanced Space Technologies in Robotics and Automation},
           month = {May},
           title = {Multi-Level Soil Sensing Systems to Identify Safe Trafficability Areas for Extra-Planetary Rovers},
          author = {W.A. Lewinger and F. Comin and S. Ransom and L. Richter and S. Al-Milli and C. Spiteri and M. Gao and M. Matthews and C. Saaj},
            year = {2013},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39644/}
}

@inproceedings{lincoln39647,
       booktitle = {12th Symposium on Advanced Space Technologies in Robotics and Automation, ESA/ESTEC},
           month = {May},
           title = {Safe Long-Range Travel for Planetary Rovers through Forward Sensing},
          author = {Y. Nevatia and F. Bulens and J. Gancet and Y. Gao and S. Al-Mili and R.U. Sonsalla and T.P. Kaupisch and M. Fritsche and T. Vogele and E. Allouis and K. Skocki and S. Ransom and C. Saaj and M. Matthews and B. Yeomans and L. Richter},
            year = {2013},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39647/}
}

@inproceedings{lincoln39643,
       booktitle = {IEEE International Conference on Robotics and Automation Planetary Rovers Workshop},
           month = {May},
           title = {Improved Traversal for Planetary Rovers through Forward Acquisition of Terrain Trafficability},
          author = {Y.H. Nevatia and J. Gancet and F. Bulens and T. Voegele and U. Sonsalla and C.M. Saaj and W.A. Lewinger and M. Matthews and F.J.C. Cabrera and Y. Gao and E. Allouis and B. Imhof and S. Ransom and L. Richter and K. Skocki},
            year = {2013},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39643/}
}

@inproceedings{lincoln39646,
       booktitle = {12th Symposium on Advanced Space Technologies in Robotics and Automation, ESA/ESTEC},
           month = {May},
           title = {Modelling Leg / Terrain Interaction for a Legged Planetary Micro-Rover},
          author = {B. Yeomans and C. Saaj and M. van Winnedael},
            year = {2013},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39646/}
}

@incollection{lincoln29369,
           month = {April},
          author = {Ayse Kucukyilmaz and Tevfik Metin Sezgin and Cagatay Basdogan},
       booktitle = {2013 21st Signal Processing and Communications Applications Conference (SIU)},
           title = {Role allocation through haptics in physical human-robot interaction},
       publisher = {IEEE},
             doi = {10.1109/SIU.2013.6531558},
           pages = {1--5},
            year = {2013},
        keywords = {ARRAY(0x5568fba8f280)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29369/},
        abstract = {This paper presents a summary of our efforts to enable dynamic role allocation between humans and robots in physical collaboration tasks. A major goal in physical human-robot interaction research is to develop tacit and natural communication between partners. In previous work, we suggested that the communication between a human and a robot would benefit from a decision making process in which the robot can dynamically adjust its control level during the task based on the intentions of the human. In order to do this, we define leader and follower roles for the partners, and using a role exchange mechanism, we enable the partners to negotiate solely through force information to exchange roles. We show that when compared to an ?equal control? condition, the role exchange mechanism improves task performance and the joint efficiency of the partners.}
}

@article{lincoln37414,
          volume = {50},
          number = {2},
           month = {April},
          author = {B. Yeomans and C. Saaj and M. Van Winnendael},
            note = {cited By 10},
           title = {Walking planetary rovers-Experimental analysis and modelling of leg thrust in loose granular soils},
       publisher = {Elsevier},
            year = {2013},
         journal = {Journal of Terramechanics},
             doi = {10.1016/j.jterra.2013.01.006},
           pages = {107--120},
        keywords = {ARRAY(0x5568fbb99af8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37414/},
        abstract = {One of the principal differences between locomotion in granular soils using legs when compared with wheels is that the drag between the leg assembly and the regolith material provides additional thrust. Experimental work is presented which demonstrates that this additional force is substantial, and can significantly augment legged vehicle Drawbar Pull. The paper also demonstrates that the drag force depends in a highly non-linear manner on sinkage depth, and linearly on leg cross section yet is only weakly dependent on leg cross-sectional shape, leg material frictional properties, or leg velocity. Comparison with modelled forces using established wedge theory techniques demonstrates poor correlation between predicted and actual results; in contrast, a modelling approach based on an analysis of the dynamics of granular materials produces an excellent correlation with experimental results and enables the drag force to be accurately characterised by deriving a constant coefficient which is characteristic of the soil material. Future work will investigate the relationship between this characteristic coefficient and the physical properties of the soil material to develop a robust method of predicting the coefficient for any soil.}
}

@article{lincoln23077,
          volume = {3},
          number = {4},
           month = {April},
          author = {Paul Baxter and Joachim De Greeff and Rachel Wood and Tony Belpaeme},
            note = {Issue cover date: December 2012},
           title = {Modelling concept prototype competencies using a developmental memory model},
       publisher = {De Gruyter/Springer},
            year = {2013},
         journal = {Paladyn, Journal of Behavioral Robotics},
             doi = {10.2478/s13230-013-0105-9},
           pages = {200--208},
        keywords = {ARRAY(0x5568fbb69a80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23077/},
        abstract = {The use of concepts is fundamental to human-level cognition, but there remain a number of open questions as to the structures supporting this competence. Specifically, it has been shown that humans use concept prototypes, a flexible means of representing concepts such that it can be used both for categorisation and for similarity judgements. In the context of autonomous robotic agents, the processes by which such concept functionality could be acquired would be particularly useful, enabling flexible knowledge representation and application. This paper seeks to explore this issue of autonomous concept acquisition. By applying a set of structural and operational principles, that support a wide range of cognitive competencies, within a developmental framework, the intention is to explicitly embed the development of concepts into a wider framework of cognitive processing. Comparison with a benchmark concept modelling system shows that the proposed approach can account for a number of features, namely concept-based classification, and its extension to prototype-like functionality.}
}

@inproceedings{lincoln14893,
       booktitle = {International IEEE/EPSRC Workshop on Autonomous Cognitive Robotics},
           month = {March},
           title = {Spatio-temporal representation for cognitive control in long-term scenarios},
          author = {Tom Duckett and Marc Hanheide and Tomas Krajnik and Jaime Pulido Fentanes and Christian Dondrup},
            year = {2013},
             doi = {10.13140/2.1.2678.7205},
        keywords = {ARRAY(0x5568fba4f2d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/14893/},
        abstract = {The FP-7 Integrated Project STRANDS [1] is aimed at producing intelligent mobile robots that are able to operate robustly for months in dynamic human environments. To achieve long-term autonomy, the robots would need to understand the environment and how it changes over time. For that, we will have to develop novel approaches to extract 3D shapes, objects, people, and models of activity from sensor data gathered during months of autonomous operation.
So far, the environment models used in mobile robotics have been tailored to capture static scenes and environment variations are largely treated as noise. Therefore, utilization of the static models in ever-changing, real world environments is difficult. We propose to represent the environment?s spatio-temporal dynamics by its frequency spectrum.}
}

@inproceedings{lincoln8365,
           month = {March},
          author = {Michael Zillich and Kai Zhou and Danijel Skocaj and Matej Kristan and Alen Vrecko and Marko Mahnic and Miroslav Janicek and Geert-Jan M. Kruijff and Thomas Keller and Marc Hanheide and Nick Hawes},
       booktitle = {Proceedings of the 8th ACM/IEEE international conference on Human-robot interaction},
           title = {Robot George: interactive continuous learning of visual concepts},
       publisher = {IEEE Press},
             doi = {10.1109/HRI.2013.6483629},
           pages = {425},
            year = {2013},
        keywords = {ARRAY(0x5568fb9ece20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8365/},
        abstract = {The video presents the robot George learning visual concepts in dialogue with a tutor}
}

@article{lincoln9308,
          volume = {103},
           month = {March},
          author = {Shigang Yue and F. Claire Rind},
           title = {Postsynaptic organizations of directional selective visual neural networks for collision detection},
       publisher = {Elsevier Science Limited},
            year = {2013},
         journal = {Neurocomputing},
             doi = {10.1016/j.neucom.2012.08.027},
           pages = {50--62},
        keywords = {ARRAY(0x5568fbac3b90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/9308/},
        abstract = {In this paper, we studied the postsynaptic organizations of directional selective visual neurons for collision detection. Directional selective neurons can extract different directional visual motion cues fast and reliably by allowing inhibition spreads to further layers in specific directions with one or several time steps delay. Whether these directional selective neurons can be easily organised for other specific visual tasks is not known. Taking collision detection as the primary visual task, we investigated the postsynaptic organizations of these directional selective neurons through evolutionary processes. The evolved postsynaptic organizations demonstrated robust properties in detecting imminent collisions in complex visual environments with many of which achieved 94\% success rate after evolution suggesting active roles in collision detection directional selective neurons and its postsynaptic organizations can play.}
}

@article{lincoln33061,
          volume = {61},
          number = {5},
           month = {February},
          author = {Abdullah Almeshal and Khaled Goher and Osman Tokhi},
            note = {The final published version of this article is available online at https://www.sciencedirect.com/science/article/pii/S0921889013000195?via\%3Dihub},
           title = {Dynamic Modelling and Stabilization of a New Configuration of Two-Wheeled Machines},
       publisher = {Elsevier},
            year = {2013},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2013.01.006},
           pages = {443--472},
        keywords = {ARRAY(0x5568fbbc1e18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33061/},
        abstract = {This paper presents a novel design of two-wheeled vehicles and an associated stabilization approach. The proposed design provides the vehicle with more flexibility in terms of increased degrees of freedom which enable the vehicle to enlarge its working space. The additional translational degree of freedom (DOF), offered by the linear actuator, assists an attached payload to reach different levels of height as and when required. The model of the system mimics the scenario of the double inverted pendulum on a moving base, with the added DOF. Lagrangian dynamic formulation is used to derive the system dynamics. Joints frictions based on the Coulomb friction model are considered so as to retain nonlinear characteristics of the system. A PD-PID robust control approach is derived for the stabilization of the system. An investigation of the impact of damping associated with joints on the stability of the system is carried out. Simulation results validating the model and the control approach are presented and discussed.}
}

@article{lincoln6031,
          volume = {56},
          number = {1},
           month = {February},
          author = {Grzegorz Cielniak and Nicola Bellotto and Tom Duckett},
           title = {Integrating mobile robotics and vision with undergraduate computer science},
       publisher = {The IEEE Education Society},
            year = {2013},
         journal = {IEEE Transactions on Education},
             doi = {10.1109/TE.2012.2213822},
           pages = {48--53},
        keywords = {ARRAY(0x5568fba80258)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6031/},
        abstract = {This paper describes the integration of robotics education into an undergraduate Computer Science curriculum. The proposed approach delivers mobile robotics as well as covering the closely related field of Computer Vision, and is directly linked to the research conducted at the authors? institution. The paper describes the most relevant details of the module content and assessment strategy, paying particular attention to the practical sessions using Rovio mobile robots. The specific choices are discussed that were made with regard to the mobile platform, software libraries and lab environment. The paper also presents a detailed qualitative and quantitative analysis of student results, including the correlation between student engagement and performance, and discusses the outcomes of this experience.}
}

@article{lincoln37415,
          volume = {25},
          number = {1},
           month = {January},
          author = {B.J. Smith and C. Saaj and E. Allouis},
            note = {cited By 1},
           title = {ANUBIS: artificial neuromodulation using a Bayesian inference system},
       publisher = {MIT Press},
            year = {2013},
         journal = {Neural computation},
             doi = {10.1162/NECO\_a\_00376},
           pages = {221--258},
        keywords = {ARRAY(0x5568fba0b268)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37415/},
        abstract = {Gain tuning is a crucial part of controller design and depends not only on an accurate understanding of the system in question, but also on the designer's ability to predict what disturbances and other perturbations the system will encounter throughout its operation. This letter presents ANUBIS (artificial neuromodulation using a Bayesian inference system), a novel biologically inspired technique for automatically tuning controller parameters in real time. ANUBIS is based on the Bayesian brain concept and modifies it by incorporating a model of the neuromodulatory system comprising four artificial neuromodulators. It has been applied to the controller of EchinoBot, a prototype walking rover for Martian exploration. ANUBIS has been implemented at three levels of the controller; gait generation, foot trajectory planning using B{\'e}zier curves, and foot trajectory tracking using a terminal sliding mode controller. We compare the results to a similar system that has been tuned using a multilayer perceptron. The use of Bayesian inference means that the system retains mathematical interpretability, unlike other intelligent tuning techniques, which use neural networks, fuzzy logic, or evolutionary algorithms. The simulation results show that ANUBIS provides significant improvements in efficiency and adaptability of the three controller components; it allows the robot to react to obstacles and uncertainties faster than the system tuned with the MLP, while maintaining stability and accuracy. As well as advancing rover autonomy, ANUBIS could also be applied to other situations where operating conditions are likely to change or cannot be accurately modeled in advance, such as process control. In addition, it demonstrates one way in which neuromodulation could fit into the Bayesian brain framework.}
}

@article{lincoln25789,
          volume = {6},
           month = {January},
          author = {Elmar A. Rueckert and Gerhard Neumann and Marc Toussaint and Wolfgang Maass},
           title = {Learned graphical models for probabilistic planning provide a new class of movement primitives},
       publisher = {Frontiers Media},
         journal = {Frontiers in Computational Neuroscience},
             doi = {10.3389/fncom.2012.00097},
            year = {2013},
        keywords = {ARRAY(0x5568fba423a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25789/},
        abstract = {Biological movement generation combines three interesting aspects: its modular organization in movement primitives (MPs), its characteristics of stochastic optimality under perturbations, and its efficiency in terms of learning. A common approach to motor skill learning is to endow the primitives with dynamical systems. Here, the parameters of the primitive indirectly define the shape of a reference trajectory. We propose an alternative MP representation based on probabilistic inference in learned graphical models with new and interesting properties that complies with salient features of biological movement control. Instead of endowing the primitives with dynamical systems, we propose to endow MPs with an intrinsic probabilistic planning system, integrating the power of stochastic optimal control (SOC) methods within a MP. The parameterization of the primitive is a graphical model that represents the dynamics and intrinsic cost function such that inference in this graphical model yields the control policy. We parameterize the intrinsic cost function using task-relevant features, such as the importance of passing through certain via-points. The system dynamics as well as intrinsic cost function parameters are learned in a reinforcement learning (RL) setting. We evaluate our approach on a complex 4-link balancing task. Our experiments show that our movement representation facilitates learning significantly and leads to better generalization to new task settings without re-learning.}
}

@inproceedings{lincoln38439,
          volume = {2},
           title = {An argumentation-based dialogue system for human-robot collaboration},
          author = {M.Q. Azhar and Simon Parsons and Elizabeth Sklar},
            year = {2013},
           pages = {1353--1354},
            note = {cited By 3},
         journal = {12th International Conference on Autonomous Agents and Multiagent Systems 2013, AAMAS 2013},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38439/}
}

@inproceedings{lincoln13462,
          author = {C. Lang and S. Wachsmuth and M. Hanheide and H. Wersing},
            note = {Conference Code:100673},
       booktitle = {IEEE International Conference on Robotics and Automation, ICRA 2013},
         address = {Karlsruhe},
           title = {Facial communicative signal interpretation in human-robot interaction by discriminative video subsequence selection},
       publisher = {IEEE},
            year = {2013},
             doi = {10.1109/ICRA.2013.6630572},
           pages = {170--177},
        keywords = {ARRAY(0x5568fb6f2908)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13462/},
        abstract = {Facial communicative signals (FCSs) such as head gestures, eye gaze, and facial expressions can provide useful feedback in conversations between people and also in human-robot interaction. This paper presents a pattern recognition approach for the interpretation of FCSs in terms of valence, based on the selection of discriminative subsequences in video data. These subsequences capture important temporal dynamics and are used as prototypical reference subsequences in a classification procedure based on dynamic time warping and feature extraction with active appearance models. Using this valence classification, the robot can discriminate positive from negative interaction situations and react accordingly. The approach is evaluated on a database containing videos of people interacting with a robot by teaching the names of several objects to it. The verbal answer of the robot is expected to elicit the display of spontaneous FCSs by the human tutor, which were classified in this work. The achieved classification accuracies are comparable to the average human recognition performance and outperformed our previous results on this task. {\^A}{\copyright} 2013 IEEE.}
}

@inproceedings{lincoln38438,
          volume = {2},
           title = {Maximizing matching in double-sided auctions},
          author = {J. Niu and Simon Parsons},
            year = {2013},
           pages = {1283--1284},
            note = {cited By 2},
         journal = {12th International Conference on Autonomous Agents and Multiagent Systems 2013, AAMAS 2013},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38438/}
}

@inproceedings{lincoln38441,
          volume = {2},
           title = {ArgTrust: Decision making with information from sources of varying trustworthiness},
          author = {Simon Parsons and Elizabeth Sklar and J. Salvit and H. Wall and Z. Li},
            year = {2013},
           pages = {1395--1396},
            note = {cited By 7},
         journal = {12th International Conference on Autonomous Agents and Multiagent Systems 2013, AAMAS 2013},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38441/}
}

@inproceedings{lincoln38437,
          volume = {SS-13-},
           title = {An argumentation-based approach to handling trust in distributed decision making},
          author = {Simon Parsons and Elizabeth Sklar and M. Singh and K. Levitt and J. Rowe},
            year = {2013},
           pages = {66--71},
            note = {cited By 4},
         journal = {AAAI Spring Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38437/}
}

@inproceedings{lincoln38440,
          volume = {2},
           title = {Enabling human-robot collaboration via argumentation},
          author = {Elizabeth Sklar and M.Q. Azhar and T. Flyr and Simon Parsons},
            year = {2013},
           pages = {1251--1252},
            note = {cited By 1},
         journal = {12th International Conference on Autonomous Agents and Multiagent Systems 2013, AAMAS 2013},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38440/}
}

@inproceedings{lincoln38442,
          volume = {2},
           title = {HRTeam: A framework to support research on human/multi-robot interaction},
          author = {Elizabeth Sklar and Simon Parsons and A.T. Ozgelen and E. Schneider and M. Costantino and S.L. Epstein},
            year = {2013},
           pages = {1409--1410},
            note = {cited By 3},
         journal = {12th International Conference on Autonomous Agents and Multiagent Systems 2013, AAMAS 2013},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38442/}
}

@inproceedings{lincoln38436,
          volume = {SS-13-},
           title = {Unsupervised modeling of patient-level disease dynamics},
          author = {S. Tamang and Simon Parsons},
            year = {2013},
           pages = {78--80},
            note = {cited By 0},
         journal = {AAAI Spring Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38436/}
}

@inproceedings{lincoln46181,
          volume = {7375},
           month = {December},
          author = {Michele Giorelli and Federico Renda and Andrea Arienti and Marcello Calisti and Matteo Cianchetti and Gabriele Ferri and Cecilia Laschi},
       booktitle = {Biomimetic and Biohybrid Systems},
           title = {Inverse and Direct Model of a Continuum Manipulator Inspired by the Octopus Arm},
             doi = {10.1007/978-3-642-31525-1\_36},
           pages = {347--348},
            year = {2012},
        keywords = {ARRAY(0x5568fba66220)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46181/},
        abstract = {The extraordinary manipulation capabilities of the octopus arm generate a big interest in the robotics community. Many researchers have put a big effort in the design, modelling and control of continuum manipulators inspired by the octopus arm. New mathematical tools could be introduced in the robotics community and new sources of inspiration are needed in order to simplify the use of the continuum manipulator. A geometrical exact approach for direct model and a Jacobian method for the inverse model are implemented for a continuum manipulator driven by cables. The first experimental results show an average tip error of less than 6\% of the manipulator length, and a good numerical performance to solve the inverse kinetics model.}
}

@inproceedings{lincoln25788,
           month = {December},
          author = {Heni Ben Amor and Oliver Kroemer and Ulrich Hillenbrand and Gerhard Neumann and Jan Peters},
       booktitle = {International Conference on Robot Systems (IROS)},
           title = {Generalization of human grasping for multi-fingered robot hands},
         journal = {IEEE International Conference on Intelligent Robots and Systems},
             doi = {10.1109/IROS.2012.6386072},
           pages = {2043--2050},
            year = {2012},
        keywords = {ARRAY(0x5568fb95d410)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25788/},
        abstract = {Multi-fingered robot grasping is a challenging
problem that is difficult to tackle using hand-coded programs.
In this paper we present an imitation learning approach for
learning and generalizing grasping skills based on human
demonstrations. To this end, we split the task of synthesizing
a grasping motion into three parts: (1) learning efficient grasp
representations from human demonstrations, (2) warping contact
points onto new objects, and (3) optimizing and executing
the reach-and-grasp movements. We learn low-dimensional
latent grasp spaces for different grasp types, which form the
basis for a novel extension to dynamic motor primitives. These
latent-space dynamic motor primitives are used to synthesize
entire reach-and-grasp movements. We evaluated our method
on a real humanoid robot. The results of the experiment
demonstrate the robustness and versatility of our approach.}
}

@article{lincoln22210,
          volume = {1},
          number = {2},
           month = {December},
          author = {Tony Belpaeme and Paul Baxter and Robin Read and Rachel Wood and Heriberto Cuay{\'a}huitl and Bernd Kiefer and Stefania Racioppa and Ivana Kruijff-Korbayov{\'a} and Georgios Athanasopoulos and Valentin Enescu and Rosemarijn Looije and Mark Neerincx and Yiannis Demiris and Raquel Ros-Espinoza and Aryel Beck and Lola Ca{\~n}amero and Antione Hiolle and Matthew Lewis and Ilaria Baroni and Marco Nalin and Piero Cosi and Giulio Paci and Fabio Tesser and Giacomo Sommavilla and Remi Humbert},
           title = {Multimodal child-robot interaction: building social bonds},
       publisher = {Clear Facts Research},
            year = {2012},
         journal = {Journal of Human-Robot Interaction},
             doi = {10.5898/JHRI.1.2.Belpaeme},
        keywords = {ARRAY(0x5568fbb87798)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22210/},
        abstract = {For robots to interact effectively with human users they must be capable of coordinated, timely behavior in response to social context. The Adaptive Strategies for Sustainable Long-Term Social Interaction (ALIZ-E) project focuses on the design of long-term, adaptive social interaction between robots and child users in real-world settings. In this paper, we report on the iterative approach taken to scientific and technical developments toward this goal: advancing individual technical competencies and integrating them to form an autonomous robotic system for evaluation ?in the wild.? The first evaluation iterations have shown the potential of this methodology in terms of adaptation of the robot to the interactant and the resulting influences on engagement. This sets the foundation for an ongoing research program that seeks to develop technologies for social robot companions.}
}

@inproceedings{lincoln6900,
           month = {November},
          author = {Jake Bird and Tom Feltwell and Grzegorz Cielniak},
            note = {Real-time Adaptive Track Generation in Racing Games},
       booktitle = {GAMEON '2012},
           title = {Real-time adaptive track generation in racing games},
       publisher = {Eurosis},
           pages = {17--24},
            year = {2012},
        keywords = {ARRAY(0x5568fba6d838)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6900/},
        abstract = {Real-time Adaptive Track Generation in Racing Games}
}

@inproceedings{lincoln6889,
           month = {November},
          author = {Tom Feltwell and Patrick Dickinson and Grzegorz Cielniak},
            note = {This paper proposes a new framework for automated
analysis of game-play metrics for aiding game designers
in finding out the critical aspects of the game caused
by factors like design modications, change in playing
style, etc. The core of the algorithm measures similarity
between spatial distribution of user generated in-game
events and automatically ranks them in order of importance. The feasibility of the method is demonstrated on
a data set collected from a modern, multiplayer First
Person Shooter, together with application examples of
its use. The proposed framework can be used to accompany traditional testing tools and make the game design
process more efficient.},
       booktitle = {GAMEON '2012},
           title = {A framework for quantitative analysis of user-generated spatial data},
       publisher = {Eurosis},
           pages = {17--24},
            year = {2012},
        keywords = {ARRAY(0x5568fb95d2f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6889/},
        abstract = {This paper proposes a new framework for automated
analysis of game-play metrics for aiding game designers
in finding out the critical aspects of the game caused
by factors like design modications, change in playing
style, etc. The core of the algorithm measures similarity
between spatial distribution of user generated in-game
events and automatically ranks them in order of importance. The feasibility of the method is demonstrated on
a data set collected from a modern, multiplayer First
Person Shooter, together with application examples of
its use. The proposed framework can be used to accompany traditional testing tools and make the game design
process more efficient.}
}

@article{lincoln31162,
          volume = {31},
          number = {13},
           month = {November},
          author = {Alexander M{\"o}rtl and Martin Lawitzky and Ayse Kucukyilmaz and Tevfik Metin Sezgin and Cagatay Basdogan and Sandra Hirche},
           title = {The Role of Roles: Physical Cooperation between Humans and Robots},
            year = {2012},
         journal = {The International Journal of Robotics Research},
             doi = {10.1177/0278364912455366},
           pages = {1656--1674},
        keywords = {ARRAY(0x5568fb95db48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31162/},
        abstract = {Since the strict separation of working spaces of humans and robots has experienced a softening due to recent robotics research achievements, close interaction of humans and robots comes rapidly into reach. In this context, physical human?robot interaction raises a number of questions regarding a desired intuitive robot behavior. The continuous bilateral information and energy exchange requires an appropriate continuous robot feedback. Investigating a cooperative manipulation task, the desired behavior is a combination of an urge to fulfill the task, a smooth instant reactive behavior to human force inputs and an assignment of the task effort to the cooperating agents. In this paper, a formal analysis of human?robot cooperative load transport is presented. Three different possibilities for the assignment of task effort are proposed. Two proposed dynamic role exchange mechanisms adjust the robot?s urge to complete the task based on the human feedback. For comparison, a static role allocation strategy not relying on the human agreement feedback is investigated as well. All three role allocation mechanisms are evaluated in a user study that involves large-scale kinesthetic interaction and full-body human motion. Results show tradeoffs between subjective and objective performance measures stating a clear objective advantage of the proposed dynamic role allocation scheme.}
}

@inproceedings{lincoln25787,
           month = {October},
          author = {C. Daniel and G. Neumann and J. Peters},
       booktitle = {International Conference on Intelligent Robot Systems (IROS)},
           title = {Learning concurrent motor skills in versatile solution spaces},
         journal = {IEEE International Conference on Intelligent Robots and Systems},
             doi = {10.1109/IROS.2012.6386047},
           pages = {3591--3597},
            year = {2012},
        keywords = {ARRAY(0x5568fba32f18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25787/},
        abstract = {Future robots need to autonomously acquire motor
skills in order to reduce their reliance on human programming.
Many motor skill learning methods concentrate
on learning a single solution for a given task. However, discarding
information about additional solutions during learning
unnecessarily limits autonomy. Such favoring of single solutions
often requires re-learning of motor skills when the task, the
environment or the robot?s body changes in a way that renders
the learned solution infeasible. Future robots need to be able to
adapt to such changes and, ideally, have a large repertoire of
movements to cope with such problems. In contrast to current
methods, our approach simultaneously learns multiple distinct
solutions for the same task, such that a partial degeneration of
this solution space does not prevent the successful completion
of the task. In this paper, we present a complete framework
that is capable of learning different solution strategies for a
real robot Tetherball task.}
}

@article{lincoln5513,
          volume = {112},
          number = {3},
           month = {October},
          author = {Michael Barnes and Michael Dudbridge and Tom Duckett},
           title = {Polarised light stress analysis and laser scatter imaging for non-contact inspection of heat seals in food trays},
       publisher = {Elsevier},
            year = {2012},
         journal = {Journal of Food Engineering},
             doi = {10.1016/j.jfoodeng.2012.02.040},
           pages = {183--190},
        keywords = {ARRAY(0x5568fb677388)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/5513/},
        abstract = {This paper introduces novel non-contact methods for detecting faults in heat seals of food packages. Two alternative imaging technologies are investigated; laser scatter imaging and polarised light stress images. After segmenting the seal area from the rest of the respective image, a classifier is trained to detect faults in different regions of the seal area using features extracted from the pixels in the respective region. A very large set of candidate features, based on statistical information relating to the colour and texture of each region, is first extracted. Then an adaptive boosting algorithm (AdaBoost) is used to automatically select the best features for discriminating faults from non-faults. With this approach, different features can be selected and optimised for the different imaging methods. In experiments we compare the performance of classifiers trained using features extracted from laser scatter images only, polarised light stress images only, and a combination of both image types. The results show that the polarised light and laser scatter classifiers achieved accuracies of 96{$\backslash$}\% and 90{$\backslash$}\%, respectively, while the combination of both sensors achieved an accuracy of 95{$\backslash$}\%. These figures suggest that both systems have potential for commercial development.}
}

@incollection{lincoln6574,
           month = {October},
          author = {Oliver Szymanezyk and Tom Duckett and Patrick Dickinson},
          series = {Lecture Notes in Computer Science},
            note = {Volume VIII, Issue 7430},
       booktitle = {Transactions on computational collective intelligence},
           title = {Agent-based crowd simulation in airports using games technology},
       publisher = {SPRINGER},
            year = {2012},
             doi = {10.1007/978-3-642-34645-3\_9},
        keywords = {ARRAY(0x5568fba640d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6574/},
        abstract = {We adapt popular video-games technology for an agent-based crowd simulation framework in an airport terminal. To achieve this, we investigate game technology, crowd simulation and the unique traits of airports. Our findings are implemented in a virtual airport environment that exploits a scalable layered intelligence technique in combination with physics middleware and a social force approach for crowd simulation. Our experiments show that
the framework runs at interactive frame-rate and evaluate the scalability with increasing number of agents demonstrating event triggered airport behaviour.}
}

@article{lincoln9309,
          volume = {4},
          number = {5/6},
           month = {October},
          author = {Shigang Yue and Claire Rind},
            note = {Special Issue on Advanced Application of Modelling, Identification and Control},
           title = {Visually stimulated motor control for a robot with a pair of LGMD visual neural networks},
       publisher = {Inderscience},
            year = {2012},
         journal = {International Journal of Advanced Mechatronic Systems},
             doi = {10.1504/IJAMECHS.2012.052219},
           pages = {237--247},
        keywords = {ARRAY(0x5568fbbc8570)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/9309/},
        abstract = {In this paper, we proposed a visually stimulated motor control (VSMC) system
for autonomous navigation of mobile robots. Inspired from a locusts? motion sensitive
interneuron ? lobula giant movement detector (LGMD), the presented VSMC system enables a
robot exploring local paths or interacting with dynamic objects effectively using visual input
only. The VSMC consists of a pair of LGMD visual neural networks and a simple motor
command generator. Each LGMD processes images covering part of the wide field of view and
extracts relevant visual cues. The outputs from the two LGMDs are compared and interpreted
into executable motor commands directly. These motor commands are then executed by the
robot?s wheel control system in real-time to generate corresponded motion adjustment
accordingly. Our experiments showed that this bio-inspired VSMC system worked well in
different scenarios.}
}

@article{lincoln7328,
          volume = {7461},
           month = {September},
          author = {Farshad Arvin and Ali Emre Turgut and Shigang Yue},
           title = {Fuzzy-based aggregation with a mobile robot swarm},
       publisher = {Springer},
            year = {2012},
         journal = {Lecture Notes in Computer Science},
             doi = {10.1007/978-3-642-32650-9\_39},
           pages = {346--347},
        keywords = {ARRAY(0x5568fba973a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/7328/},
        abstract = {Aggregation is a widely observed phenomenon in social insects and animals such as cockroaches, honeybees and birds. From swarm robotics perspective [3], aggregation can be defined as gathering randomly distributed robots to form an aggregate. Honeybee aggregation is an example of cue-based aggregation method that was studied in [4]. In that study, micro robots were deployed in a gradually lighted environment to mimic the behavior of honeybees which aggregate around a zone that has the optimal temperature (BEECLUST). In our previous study [2], two modifications on BEECLUST ? dynamic velocity and comparative waiting time ? were applied to increase the performance of aggregation.}
}

@article{lincoln11608,
          volume = {311},
           month = {September},
          author = {Jiawei Xu and Shigang Yue},
            note = {13th International Conference, EANN 2012, London, UK, September 20-23, 2012. Conference Code:98083},
           title = {Visual based contour detection by using the improved short path finding},
         address = {Chengdu},
       publisher = {Springer Verlag},
            year = {2012},
         journal = {Communications in Computer and Information Science},
             doi = {10.1007/978-3-642-32909-8\_15},
           pages = {145--151},
        keywords = {ARRAY(0x5568fb677ac0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/11608/},
        abstract = {Contour detection is an important characteristic of human vision perception. Humans can easily find the objects contour in a complex visual scene; however, traditional computer vision cannot do well. This paper primarily concerned with how to track the objects contour using a human-like vision. In this article, we propose a biologically motivated computational model to track and detect the objects contour. Even the previous research has proposed some models by using the Dijkstra algorithm 1, our work is to mimic the human eye movement and imitate saccades in our humans. We use natural images with associated ground truth contour maps to assess the performance of the proposed operator regarding the detection of contours while suppressing texture edges. The results show that our method enhances contour detection in cluttered visual scenes more effectively than classical edge detectors proposed by other methods. {\^A}{\copyright} Springer-Verlag Berlin Heidelberg 2012.}
}

@inproceedings{lincoln6750,
           month = {September},
          author = {Marc Hanheide and Annika Peters and Nicola Bellotto},
       booktitle = {21st IEEE International Symposium on Robot and Human Interactive Communication},
          editor = {B. Gottfried and H. Aghajan},
           title = {Analysis of human-robot spatial behaviour applying a qualitative trajectory calculus},
       publisher = {IEEE},
            year = {2012},
             doi = {10.1109/ROMAN.2012.6343831},
           pages = {689--694},
        keywords = {ARRAY(0x5568fbab2618)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6750/},
        abstract = {The analysis and understanding of human-robot joint spatial behaviour (JSB) such as guiding, approaching, departing, or coordinating movements in narrow spaces and its communicative and dynamic aspects are key requirements on the road towards more intuitive interaction, safe encounter, and appealing living with mobile robots. This endeavours demand for appropriate models and methodologies to represent JSB and facilitate its analysis. In this paper, we adopt a qualitative trajectory calculus (QTC) as a formal foundation for the analysis and representation of such spatial behaviour of a human and a robot based on a compact encoding of the relative trajectories of two interacting agents in a sequential model. We present this QTC together with a distance measure and a probabilistic behaviour model and outline its usage in an actual JSB study.We argue that the proposed QTC coding scheme and derived methodologies for analysis and modelling are flexible and extensible to be adapted for a variety of other scenarios and studies. I.}
}

@inproceedings{lincoln11609,
          volume = {311},
           month = {September},
          author = {Chrisina Jayne and Shigang Yue and Lazaros Iliadis},
            note = {Conference Code:98083},
       booktitle = {13th International Conference, EANN 2012},
         address = {Chengdu},
           title = {Engineering Applications of Neural Networks: 13th International Conference, EANN 2012 London, UK, September 20-23, 2012 Proceedings},
       publisher = {Springer},
            year = {2012},
             doi = {10.1007/978-3-642-32909-8},
        keywords = {ARRAY(0x5568fba5d250)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/11609/},
        abstract = {.}
}

@inproceedings{lincoln10769,
           month = {September},
          author = {S. Liu and Y. Tang and C. Zhang and S. Yue},
            note = {Conference Code:94291},
       booktitle = {IASTED International Conference on Artificial Intelligence and Soft Computing},
           title = {Self-map building in wireless sensor network based on TDOA measurements},
         address = {Hamburg},
       publisher = {IASTED},
            year = {2012},
             doi = {10.1109/MFI.2012.6343041},
           pages = {150--155},
        keywords = {ARRAY(0x5568fb9ed240)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/10769/},
        abstract = {Node localization has long been established as a key problem in the sensor networks. Self-mapping in wireless sensor network which enables beacon-based systems to build a node map on-the-fly extends the range of the sensor network's applications. A variety of self-mapping algorithms have been developed for the sensor networks. Some algorithms assume no information and estimate only the relative location of the sensor nodes. In this paper, we assume a very small percentage of the sensor nodes aware of their own locations, so the proposed algorithm estimates other node's absolute location using the distance differences. In particular, time difference of arrival (TDOA) technology is adopted to obtain the distance difference. The obtained time difference accuracy is 10ns which corresponds to a distance difference error of 3m. We evaluate self-mapping's accuracy with a small number of seed nodes. Overall, the accuracy and the coverage are shown to be comparable to those achieved results with other technologies and algorithms. {\^A}{\copyright} 2012 IEEE.}
}

@article{lincoln37403,
          volume = {49},
          number = {3-4},
           month = {August},
          author = {G.P. Scott and C. Saaj},
            note = {cited By 8},
           title = {The development of a soil trafficability model for legged vehicles on granular soils},
       publisher = {Elsevier},
            year = {2012},
         journal = {Journal of Terramechanics},
             doi = {10.1016/j.jterra.2011.12.002},
           pages = {133--146},
        keywords = {ARRAY(0x5568fb9c96d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37403/},
        abstract = {This paper extends previous research in planetary microrover locomotion system analysis at the University of Surrey through the development of a legged microrover mobility model. This model compares various two- and three-dimensional soil cutting models to determine the most applicable model to legged locomotion in deformable soils, and is flexible to use any of these models depending on the leg shape, sinkage and other conditions. This baseline draught force model is used for determining the soil forces available for legged vehicle locomotion, as well as the soil thrust available to the vehicle footprint. Empirical investigations were performed with a robotic arm in planetary soil simulants to validate a legged mobility model through determination of the draft force of a robotic leg pushing through soil at constant and varying sinkage levels. The resulting locomotion performance model will be used to predict the ability of the legged vehicle to traverse a specific soil. An introduction to the planetary soil simulants used in this study (SSC-1 quartz-based sand and SSC-2 garnet-based sand) and the process used to determine their mechanical properties is also briefly presented to provide a baseline for this research.}
}

@inproceedings{lincoln46199,
       booktitle = {IEEE Mechatronics and Automation},
           month = {August},
           title = {Octopus-Inspired Sensorimotor Control of a Multi-Arm Soft Robot},
          author = {Tao Li and Kohei Nakajima and Marcello Calisti and Cecilia Laschi and Rolf Pfeifer},
            year = {2012},
           pages = {948--955},
             doi = {10.1109/ICMA.2012.6283271},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46199/},
        abstract = {Soft robots have significant advantages over traditional rigid robots because of their morphological flexibility. However, the use of conventional engineering approaches to control soft robots is difficult, especially to achieve autonomous behaviors. With its completely soft body, the octopus has a rich behavioral repertoire, so it is frequently used as a model in building and controlling soft robots. However, the sensorimotor control strategies in some interesting behaviors of the octopus, such as octopus crawling, remain largely unknown. In this study, we review related biological studies on octopus crawling behavior and propose its sensorimotor control strategy. The proposed strategy is implemented with an echo state network on an octopus-inspired, multi-arm crawling robot. We also demonstrate the control strategy in the robot for autonomous direction and speed control. Finally, the implications of this study are discussed.}
}

@article{lincoln29372,
          volume = {5},
          number = {3},
           month = {August},
          author = {Salih Ozgur Oguz and Ayse Kucukyilmaz and Tevfik Metin Sezgin and Cagatay Basdogan},
           title = {Supporting negotiation behavior with haptics-enabled human-computer interfaces},
       publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
            year = {2012},
         journal = {IEEE Transactions on Haptics},
             doi = {10.1109/TOH.2012.37},
           pages = {274--284},
        keywords = {ARRAY(0x5568fb9fe8b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29372/},
        abstract = {An active research goal for human-computer interaction is to allow humans to communicate with computers in an intuitive and natural fashion, especially in real-life interaction scenarios. One approach that has been advocated to achieve this has been to build computer systems with human-like qualities and capabilities. In this paper, we present insight on how human-computer interaction can be enriched by employing the computers with behavioral patterns that naturally appear in human-human negotiation scenarios. For this purpose, we introduce a two-party negotiation game specifically built for studying the effectiveness of haptic and audio-visual cues in conveying negotiation related behaviors. The game is centered around a real-time continuous two-party negotiation scenario based on the existing game-theory and negotiation literature. During the game, humans are confronted with a computer opponent, which can display different behaviors, such as concession, competition, and negotiation. Through a user study, we show that the behaviors that are associated with human negotiation can be incorporated into human-computer interaction, and the addition of haptic cues provides a statistically significant increase in the human-recognition accuracy of machine-displayed behaviors. In addition to aspects of conveying these negotiation-related behaviors, we also focus on and report game-theoretical aspects of the overall interaction experience. In particular, we show that, as reported in the game-theory literature, certain negotiation strategies such as tit-for-tat may generate maximum combined utility for the negotiating parties, providing an excellent balance between the energy spent by the user and the combined utility of the negotiating parties.}
}

@article{lincoln6561,
          volume = {4},
          number = {3},
           month = {August},
          author = {Christian Lang and Sven Wachsmuth and Marc Hanheide and Heiko Wersing},
            note = {From the issue entitled "Measuring Human-Robots Interactions"
This paper investigates facial communicative signals (head gestures, eye gaze, and facial expressions) as nonverbal feedback in human-robot interaction. Motivated by a discussion of the literature, we suggest scenario-specific investigations due to the complex nature of these signals and present an object-teaching scenario where subjects teach the names of objects to a robot, which in turn shall term these objects correctly afterwards. The robot?s verbal answers are to elicit facial communicative signals of its interaction partners. We investigated the human ability to recognize this spontaneous facial feedback and also the performance of two automatic recognition approaches. The first one is a static approach yielding baseline results, whereas the second considers the temporal dynamics and achieved classification rates},
           title = {Facial communicative signals: valence recognition in task-oriented human-robot interaction},
       publisher = {Springer},
            year = {2012},
         journal = {International Journal of Social Robotics},
             doi = {10.1007/s12369-012-0145-z},
           pages = {249--262},
        keywords = {ARRAY(0x5568fbab60f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6561/},
        abstract = {From the issue entitled "Measuring Human-Robots Interactions"
This paper investigates facial communicative signals (head gestures, eye gaze, and facial expressions) as nonverbal feedback in human-robot interaction. Motivated by a discussion of the literature, we suggest scenario-specific investigations due to the complex nature of these signals and present an object-teaching scenario where subjects teach the names of objects to a robot, which in turn shall term these objects correctly afterwards. The robot?s verbal answers are to elicit facial communicative signals of its interaction partners. We investigated the human ability to recognize this spontaneous facial feedback and also the performance of two automatic recognition approaches. The first one is a static approach yielding baseline results, whereas the second considers the temporal dynamics and achieved classification rates}
}

@inproceedings{lincoln46202,
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
           month = {June},
           title = {Design and development of a soft robot with crawling and grasping capabilities},
          author = {Marcello Calisti and Andrea Arienti and Federico Renda and Guy Levy and Barbara Mazzolai and B Hochner and Cecilia Laschi and Paolo Dario},
            year = {2012},
           pages = {4950--4955},
             doi = {10.1109/ICRA.2012.6224671},
        keywords = {ARRAY(0x5568fbb74fe8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46202/},
        abstract = {This paper describes the design and development of a robot with six soft limbs, with the dual capability of pushing-based locomotion and grasping by wrapping around objects. Specifically, a central platform lodges six silicone limbs, radially distributed, with cables embedded. A new mechanism-specific gait, invariant regarding the number of limbs, has been implemented. Functionally, some limbs provide stability while others push and pull the robot to locomote in the desired direction. Once the robot is close to a target, one limb is elected to wrap around the object and, thanks to the particular limb structure and the soft material, a friction-based grasping is achieved. The robot is inspired by the octopus and implements the key principles of locomotion in this animal, without coping the full body structure. For this reason it works in water, but it is not restricted to this environment. The experiments show the effectiveness of the original solution in locomotion and grasping.}
}

@inproceedings{lincoln46200,
       booktitle = {IEEE International Conference on Robotics and Automation},
           month = {June},
           title = {A two dimensional inverse kinetics model of a cable driven manipulator inspired by the octopus arm},
          author = {Michele Giorelli and Federico Renda and Marcello Calisti and Andrea Arienti and Gabriele Ferri and Cecilia Laschi},
            year = {2012},
           pages = {3819--3824},
             doi = {10.1109/ICRA.2012.6225254},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46200/},
        abstract = {Control of soft robots remains nowadays a big challenge, as it does in the larger category of continuum robots. In this paper a direct and inverse kinetics models are described for a non-constant curvature structure. A major effort has been put recently in modelling and controlling constant curvature structures, such as cylindrical shaped manipulators. Manipulators with non-constant curvature, on the other hand, have been treated with a piecewise constant curvature approximation. In this work a non-constant curvature manipulator with a conical shape is built, taking inspiration from the anatomy of the octopus arm. The choice of a conical shape manipulator made of soft material is justified by its enhanced capability in grasping objects of different sizes. A different approach from the piecewise constant curvature approximation is employed for direct and inverse kinematics model. A continuum geometrically exact approach for direct kinetics model and a Jacobian method for inverse case are proposed. They are validated experimentally with a prototype soft robot arm moving in water. Results show a desired tip position in the task-space can be achieved automatically with a satisfactory degree of accuracy.}
}

@inproceedings{lincoln5935,
       booktitle = {The 12th International Conference on Intelligent Autonomous Systems},
           month = {June},
           title = {Texture-based crowd detection and localisation},
          author = {Stefano Ghidoni and Grzegorz Cielniak and Emanuele Menegatti},
       publisher = {IEEE / Robotics and Automation Society},
            year = {2012},
           pages = {725--736},
        keywords = {ARRAY(0x5568fba0dbc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/5935/},
        abstract = {This paper presents a crowd detection system based on texture analysis. The state-of-the-art techniques based on co-occurrence matrix have been revisited and a novel set of features proposed. These features provide a richer description of the co-occurrence matrix, and can be exploited to obtain stronger classification results, especially when smaller portions of the image are considered. This is extremely useful for crowd localisation: acquired images are divided into smaller regions in order to perform a classification on each one. A thorough evaluation of the proposed system on a real world data set is also presented: this validates the improvements in reliability of the crowd detection and localisation.}
}

@inproceedings{lincoln4836,
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA 2012)},
           month = {May},
           title = {Cognitive active vision for human identification},
          author = {Yuzuko Utsumi and Eric Sommerlade and Nicola Bellotto and Ian Reid},
            year = {2012},
            note = {We describe an integrated, real-time multi-camera surveillance system that is able to find and track individuals, acquire and archive facial image sequences, and perform face recognition. The system is based around an inference engine that can extract high-level information from an observed scene, and generate appropriate commands for a set of pan-tilt-zoom (PTZ) cameras. The incorporation of a reliable facial recognition into the high-level feedback is a main novelty of our work, showing how high-level understanding of a scene can be used to deploy PTZ sensing resources effectively. The system comprises a distributed camera system using SQL tables as virtual communication channels, Situation Graph
Trees for knowledge representation, inference and high-level camera control, and a variety of visual processing algorithms including an on-line acquisition of facial images, and on-line recognition of faces by comparing image sets using subspace distance. We provide an extensive evaluation of this method using our system for both acquisition of training data, and later recognition. A set of experiments in a surveillance scenario show the effectiveness of our approach and its potential for real applications of cognitive vision.},
        keywords = {ARRAY(0x5568fbb7ed08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/4836/},
        abstract = {We describe an integrated, real-time multi-camera surveillance system that is able to find and track individuals, acquire and archive facial image sequences, and perform face recognition. The system is based around an inference engine that can extract high-level information from an observed scene, and generate appropriate commands for a set of pan-tilt-zoom (PTZ) cameras. The incorporation of a reliable facial recognition into the high-level feedback is a main novelty of our work, showing how high-level understanding of a scene can be used to deploy PTZ sensing resources effectively. The system comprises a distributed camera system using SQL tables as virtual communication channels, Situation Graph
Trees for knowledge representation, inference and high-level camera control, and a variety of visual processing algorithms including an on-line acquisition of facial images, and on-line recognition of faces by comparing image sets using subspace distance. We provide an extensive evaluation of this method using our system for both acquisition of training data, and later recognition. A set of experiments in a surveillance scenario show the effectiveness of our approach and its potential for real applications of cognitive vision.}
}

@article{lincoln37449,
          volume = {49},
          number = {2},
           month = {April},
          author = {S. Chhaniyara and C. Brunskill and B. Yeomans and M.C. Matthews and C. Saaj and S. Ransom and L. Richter},
            note = {cited By 27},
           title = {Terrain trafficability analysis and soil mechanical property identification for planetary rovers: A survey},
       publisher = {Elsevier},
            year = {2012},
         journal = {Journal of Terramechanics},
             doi = {10.1016/j.jterra.2012.01.001},
           pages = {115--128},
        keywords = {ARRAY(0x5568fb9b7e50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37449/},
        abstract = {The advances in the field of robotics enabled successful exploration of the Moon and Mars. Over the years, rover missions have demonstrated deployment of various scientific payloads for robotic field geology on these extra-terrestrial bodies. The success of these missions clearly emphasises the need to further advance rover technology in order to maximise scientific return. The success of future robotic surface exploration missions will depend on two key factors ? autonomy and mobility on soft sandy and unstructured terrains. The main contribution of this paper is that it brings together vital information pertaining to various terrain characterisation techniques into a single article. Special care is taken in structuring the paper so that all the relevant terrain characterisation methods that have been used in past planetary exploration missions and those under consideration for future space exploration missions are covered. This paper will not only lists advantages and disadvantages of various terrain characterisation techniques but also presents the methodology for evaluating and comparing terrain characterisation techniques and provides a trade-off study of existing and potential approaches that could improve the mobility of future planetary exploration rovers. This survey shows that further advances in currently deployed technology are required in order to develop intelligent, on-board sensing systems which will detect and identify near surface and sub-surface terrain properties to enhance the mobility of rovers.}
}

@inproceedings{lincoln25791,
          volume = {22},
           month = {April},
          author = {Christian Daniel and Gerhard Neumann and Jan Peters},
       booktitle = {Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS) 2012},
           title = {Hierarchical relative entropy policy search},
       publisher = {MIT Press},
           pages = {273--281},
            year = {2012},
        keywords = {ARRAY(0x5568fb670aa8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25791/},
        abstract = {Many real-world problems are inherently hierarchically
structured. The use of this structure
in an agent?s policy may well be the
key to improved scalability and higher performance.
However, such hierarchical structures
cannot be exploited by current policy
search algorithms. We will concentrate on
a basic, but highly relevant hierarchy {--} the
?mixed option? policy. Here, a gating network
first decides which of the options to execute
and, subsequently, the option-policy determines
the action.
In this paper, we reformulate learning a hierarchical
policy as a latent variable estimation
problem and subsequently extend the
Relative Entropy Policy Search (REPS) to
the latent variable case. We show that our
Hierarchical REPS can learn versatile solutions
while also showing an increased performance
in terms of learning speed and quality
of the found policy in comparison to the nonhierarchical
approach.}
}

@inproceedings{lincoln5516,
       booktitle = {3rd International Workshop Teaching Robotics Teaching with Robotics: Integrating Robotics in School Curriculum},
           month = {April},
           title = {Integrating vision and robotics into the computer science curriculum},
          author = {Grzegorz Cielniak and Nicola Bellotto and Tom Duckett},
            year = {2012},
            note = {This paper describes our efforts in integrating Robotics education into the undergraduate Computer Science curriculum. Our approach delivers Mobile Robotics together with the closely related field of Computer Vision and is directly linked to the research conducted at our institution. The paper describes the most relevant details related to the module content and assessment strategy, paying particular attention to the practical sessions using Rovio mobile webcams. We discuss the specific choices made with regard to the mobile platform, software libraries and lab environment. We also present a detailed qualitative and quantitative analysis, including the correlation between student engagement and performance, and discuss the outcomes of this experience.},
        keywords = {ARRAY(0x5568fbb92420)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/5516/},
        abstract = {This paper describes our efforts in integrating Robotics education into the undergraduate Computer Science curriculum. Our approach delivers Mobile Robotics together with the closely related field of Computer Vision and is directly linked to the research conducted at our institution. The paper describes the most relevant details related to the module content and assessment strategy, paying particular attention to the practical sessions using Rovio mobile webcams. We discuss the specific choices made with regard to the mobile platform, software libraries and lab environment. We also present a detailed qualitative and quantitative analysis, including the correlation between student engagement and performance, and discuss the outcomes of this experience.}
}

@article{lincoln23079,
          volume = {20},
          number = {2},
           month = {April},
          author = {Rachel Wood and Paul Baxter and Tony Belpaeme},
           title = {A Review of long-term memory in natural and synthetic systems},
       publisher = {Sage for International Society for Adaptive Behavior (ISAB)},
            year = {2012},
         journal = {Adaptive Behavior},
           pages = {81--103},
        keywords = {ARRAY(0x5568fba966a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23079/},
        abstract = {Memory may be broadly regarded as information gained from past experi- ence which is available in the service of ongoing and future adaptive behavior. The biological implementation ofmemory shares little with memory in synthetic cognitive systems where it is typically regarded as a passive storage structure. Neurophysiological evidence indicates that memory is neither passive nor cen- tralised. A review of the relevant literature in the biological and computer sciences is conducted and a novel methodology is applied that incorporates neuroethological approaches with general biological inspiration in the design of synthetic cognitive systems: a case study regarding episodic memory provides an illustration of the utility of this methodology. As a consequence of applying this approach to the reinterpretation of the implementation of memory in syn- thetic systems, four fundamental functional principles are derived that are in accordance with neuroscientific theory, and which may be applied to the design of more adaptive and robust synthetic cognitive systems: priming, cross-modal associations, cross-modal coordination without semantic information transfer, and global system behavior resulting from activation dynamics within the mem- ory system.}
}

@article{lincoln6562,
          volume = {4},
          number = {2},
           month = {April},
          author = {M. Hanheide and M. Lohse and H. Zender},
            note = {From the issue entitled "Expectations, Intentions \& Actions"
Human-robot interaction is becoming increasingly complex
through the growing number of abilities, both cognitive and
physical, available to today?s robots. At the same time, interaction is still often dif?cult because the users do not understand the robots? internal states, expectations, intentions, and
actions. Vice versa, robots lack understanding of the users?
expectations, intentions, actions, and social signals.},
           title = {Expectations, intentions, and actions in human-robot interaction},
       publisher = {Springer},
            year = {2012},
         journal = {Internation Journal of Social Robotics},
             doi = {10.1007/s12369-012-0139-x},
           pages = {107--108},
        keywords = {ARRAY(0x5568fba85d40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6562/},
        abstract = {From the issue entitled "Expectations, Intentions \& Actions"
Human-robot interaction is becoming increasingly complex
through the growing number of abilities, both cognitive and
physical, available to today?s robots. At the same time, interaction is still often dif?cult because the users do not understand the robots? internal states, expectations, intentions, and
actions. Vice versa, robots lack understanding of the users?
expectations, intentions, actions, and social signals.}
}

@inproceedings{lincoln4780,
       booktitle = {AAAI Spring Symposium, "Designing Intelligent Robots: Reintegrating AI"},
           month = {March},
           title = {Robot control based on qualitative representation of human trajectories},
          author = {Nicola Bellotto},
       publisher = {AAAI - Association for the Advancement of Artificial Intelligence},
            year = {2012},
            note = {A major challenge for future social robots is the high-level interpretation of human motion, and the consequent generation of appropriate robot actions. This paper describes some fundamental steps towards the real-time implementation of a system that allows a mobile robot to transform quantitative information about human trajectories (i.e. coordinates and speed) into qualitative concepts, and from these to generate appropriate control commands. The problem is formulated using a simple version of qualitative trajectory calculus, then solved using an inference engine based on fuzzy temporal logic and situation graph trees. Preliminary results are discussed and future directions of the current research are drawn.},
        keywords = {ARRAY(0x5568fb9b60f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/4780/},
        abstract = {A major challenge for future social robots is the high-level interpretation of human motion, and the consequent generation of appropriate robot actions. This paper describes some fundamental steps towards the real-time implementation of a system that allows a mobile robot to transform quantitative information about human trajectories (i.e. coordinates and speed) into qualitative concepts, and from these to generate appropriate control commands. The problem is formulated using a simple version of qualitative trajectory calculus, then solved using an inference engine based on fuzzy temporal logic and situation graph trees. Preliminary results are discussed and future directions of the current research are drawn.}
}

@inproceedings{lincoln37416,
           month = {March},
          author = {S. Bandyopadhyay and C. Saaj and B. Bandyopadhyay},
            note = {cited By 2},
       booktitle = {2012 12th International Workshop on Variable Structure Systems},
           title = {Stability analysis of small satellite formation flying and reconfiguration missions in deep space},
       publisher = {IEEE},
            year = {2012},
         journal = {Proceedings of IEEE International Workshop on Variable Structure Systems},
             doi = {10.1109/VSS.2012.6163516},
           pages = {285--290},
        keywords = {ARRAY(0x5568fbbac9c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37416/},
        abstract = {Close-proximity (10-150 m) formation flying using low cost, small satellites is an emerging field. In such missions, control of satellite formations is a challenging problem and requires robust on-board control systems. This paper describes a modified approach to designing Sliding Mode Control (SMC) for satellite formation and reconfiguration missions, in deep space with external disturbances. Based on this dynamic model, a new approach for implementing path planning of satellites using Artificial Potential Field (APF) method is presented in this paper. This paper discusses stability of the sliding surfaces designed using gradient of the potential function for the closed loop system. The stability analysis is demonstrated by presenting a scenario in which six satellites aggregates to form an octahedron formation and subsequently reconfigure to a hexagon formation. This paper thus presents further progress in the state of-the-art of path planning and control for the framework of satellite formation and reconfiguration missions.}
}

@article{lincoln4823,
          volume = {116},
          number = {3},
           month = {March},
          author = {Nicola Bellotto and Ben Benfold and Hanno Harland and Hans-Hellmut Nagel and Nicola Pirlo and Ian Reid and Eric Sommerlade and Chuan Zhao},
           title = {Cognitive visual tracking and camera control},
       publisher = {Elsevier},
            year = {2012},
         journal = {Computer Vision and Image Understanding},
             doi = {10.1016/j.cviu.2011.09.011},
           pages = {457--471},
        keywords = {ARRAY(0x5568fb670400)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/4823/},
        abstract = {Cognitive visual tracking is the process of observing and understanding the behaviour of a moving person. This paper presents an efficient solution to extract, in real-time, high-level information from an observed scene, and generate the most appropriate commands for a set of pan-tilt-zoom (PTZ) cameras in a surveillance scenario. Such a high-level feedback control loop, which is the main novelty of our work, will serve to reduce uncertainties in the observed scene and to maximize the amount of information extracted from it. It is implemented with a distributed camera system using SQL tables as virtual communication channels, and Situation Graph Trees for knowledge representation, inference and high-level camera control. A set of experiments in a surveillance scenario show the effectiveness of our approach and its potential for real applications of cognitive vision.}
}

@inproceedings{lincoln14511,
       booktitle = {The  Dundee Conference  - Crop  Protection  in  Northern  Britain  2012},
           month = {February},
           title = {A prototype low-cost machine vision system for automatic identification and quantification of potato defects},
          author = {Jamie Hutton and Glyn Harper and Tom Duckett},
       publisher = {Proceedings Crop Protection in Northern Britain 2012},
            year = {2012},
           pages = {273--278},
        keywords = {ARRAY(0x5568fb707bf0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/14511/},
        abstract = {This paper reports on a current project to develop a prototype system
for the automatic identification and quantification of potato defects based on
machine vision. The system developed uses off-the-shelf hardware, including a
low-cost vision sensor and a standard desktop computer with a graphics processing
unit (GPU), together with software algorithms to enable detection, identification
and quantification of common defects affecting potatoes at near-real-time frame
rates. The system uses state-of-the-art image processing and machine learning
techniques to automatically learn the appearance of different defect types. It also
incorporates an intuitive graphical user interface (GUI) to enable easy set-up of the
system by quality control (QC) staff working in the industry.}
}

@incollection{lincoln26517,
           month = {February},
          author = {Graham R. Law and Paul D. Baxter and Mark S. Gilthorpe},
       booktitle = {Modern methods for epidemiology},
           title = {Selection bias in epidemiologic studies},
       publisher = {Springer Netherlands},
            year = {2012},
         journal = {Modern Methods for Epidemiology},
             doi = {10.1007/978-94-007-3024-3{$_4$}},
           pages = {57--71},
        keywords = {ARRAY(0x5568fbbc5a30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26517/},
        abstract = {Bias is inherent in epidemiology, and researchers go to great lengths to avoid introducing bias into their studies. However, some bias is inevitable, and bias due to selection is particularly common. We discuss ways to identify bias and how authors have approached removing or adjusting for bias using statistical methods. {\^A}{\copyright} Springer Science+Business Media Dordrecht 2012.}
}

@incollection{lincoln29365,
           month = {January},
          author = {Ayse Kucukyilmaz and Salih Ozgur Oguz and Tevfik Metin Sezgin and Cagatay Basdogan},
          series = {Springer Series on Touch and Haptic Systems},
       booktitle = {Peer A., Giachritsis C. (eds) Immersive Multimodal Interactive Presence},
          editor = {A. Peer and C. Giachritsis},
           title = {Improving human-computer cooperation through haptic role exchange and negotiation},
       publisher = {Springer London},
            year = {2012},
             doi = {10.1007/978-1-4471-2754-3\_13},
           pages = {229--254},
        keywords = {ARRAY(0x5568fbb92b28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29365/},
        abstract = {Even though in many systems, computers have been programmed to share control with human operators in order to increase task performance, the interaction in such systems is still artificial when compared to natural human-human cooperation. In complex tasks, cooperating human partners may have their own agendas and take initiatives during the task. Such initiatives contribute to a richer interaction between cooperating parties, yet little research exists on how this can be established between a human and a computer. In a cooperation involving haptics, the coupling between the human and the computer should be defined such that the computer can understand the intentions of the human operator and respond accordingly. We believe that this will make the haptic interactions between the human and the computer more natural and human-like. In this regard, we suggest (1) a role exchange mechanism that is activated based on the magnitude of the force applied by the cooperating parties and (2) a negotiation model that enables more human-like coupling between the cooperating parties. We argue that when presented through the haptic channel, the proposed role exchange mechanism and the negotiation model serve to communicate the cooperating parties dynamically, naturally, and seamlessly, in addition to improving the task efficiency of the user. In this chapter, we explore how human-computer cooperation can be improved using a role-exchange mechanism and a haptic negotiation framework. We also discuss the use of haptic negotiation in assigning different behaviors to the computer; and the effectiveness of visual and haptic cues in conveying negotiation-related complex affective states. Throughout this chapter, we will adopt a broad terminology and speak of cooperative systems, in which both parties take some part in control, as shared control schemes, but the term ?control? is merely used to address the partners? manipulation capacities on the task.}
}

@article{lincoln38457,
          volume = {245},
          number = {1},
          author = {A. Applebaum and K. Levitt and J. Rowe and Simon Parsons},
            note = {cited By 11},
           title = {Arguing about firewall policy},
            year = {2012},
         journal = {Frontiers in Artificial Intelligence and Applications},
             doi = {10.3233/978-1-61499-111-3-91},
           pages = {91--102},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38457/}
}

@article{lincoln38454,
          volume = {118 LN},
          author = {K. Cai and J. Niu and Simon Parsons},
            note = {cited By 1},
           title = {Network effects in double auction markets with automated traders},
         journal = {Lecture Notes in Business Information Processing},
             doi = {10.1007/978-3-642-34200-4},
           pages = {19--33},
            year = {2012},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38454/}
}

@inproceedings{lincoln46201,
          volume = {7375},
          author = {Marcello Calisti and Michele Giorelli and Cecilia Laschi},
          series = {Lecture Notes in Computer Science},
       booktitle = {Living Machines},
           title = {A Locomotion Strategy for an Octopus-Bioinspired Robot},
       publisher = {Springer},
            year = {2012},
             doi = {10.1007/978-3-642-31525-1\_31},
           pages = {337--338},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46201/},
        abstract = {In this paper a locomotion strategy for a six-limb robot inspired by the octopus is shown. A tight relationship between the muscular system and the nervous systems exists in the octopus. At a high level of abstraction, the same relationship between the mechanical structure and the control of the robot is presented here. The control board sends up to six signals to the limbs, which mechanically perform a stereotypical rhythmical movement. The results show how by coordinating only two limbs an effective locomotion is achieved.}
}

@article{lincoln38447,
          volume = {7543 L},
          author = {C.D. Emele and T.J. Norman and Simon Parsons},
            note = {cited By 0},
           title = {Argumentation strategies for collaborative plan resourcing},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-33152-7},
           pages = {154--173},
            year = {2012},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38447/}
}

@article{lincoln38445,
          volume = {7541 L},
          author = {C.D. Emele and T.J. Norman and Simon Parsons},
            note = {cited By 0},
           title = {Argumentation strategies for task delegation},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-34799-3-6},
           pages = {80--96},
            year = {2012},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38445/}
}

@article{lincoln38458,
          volume = {7103 L},
          author = {C.D. Emele and T.J. Norman and M. {\c S}ensoy and Simon Parsons},
            note = {cited By 3},
           title = {Exploiting domain knowledge in making delegation decisions},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-27609-5},
           pages = {117--131},
            year = {2012},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38458/}
}

@article{lincoln38449,
          volume = {25},
          number = {3},
          author = {C.D. Emele and T.J. Norman and M. {\c S}ensoy and Simon Parsons},
            note = {cited By 2},
           title = {Learning strategies for task delegation in norm-governed environments},
            year = {2012},
         journal = {Autonomous Agents and Multi-Agent Systems},
             doi = {10.1007/s10458-012-9194-9},
           pages = {499--525},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38449/}
}

@article{lincoln38455,
          volume = {11},
          number = {1},
          author = {E.H. Gerding and P. McBurney and Simon Parsons},
            note = {cited By 0},
           title = {Competition between markets and the CAT Tournament: Guest editors' introduction to the special issue},
            year = {2012},
         journal = {Electronic Commerce Research and Applications},
             doi = {10.1016/j.elerap.2011.09.001},
           pages = {1--3},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38455/}
}

@inproceedings{lincoln38451,
           title = {Evolutionary advantage of foresight in markets},
          author = {D. Hennes and D. Bloembergen and M. Kaisers and K. Tuyls and Simon Parsons},
            year = {2012},
           pages = {943--949},
             doi = {10.1145/2330163.2330294},
            note = {cited By 5},
         journal = {GECCO'12 - Proceedings of the 14th International Conference on Genetic and Evolutionary Computation},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38451/}
}

@book{lincoln7434,
          volume = {311},
          author = {Crisina Jayne and Shigang Yue and Lazaros Iliadis},
          series = {Communications in computer and information science},
            note = {Proceeedings of the 13th International Conference, EANN 2012, London, UK, September 20-23, 2012},
         address = {Heidelberg},
           title = {Engineering applications of neural networks},
       publisher = {Springer},
            year = {2012},
        keywords = {ARRAY(0x5568fb9b7700)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/7434/},
        abstract = {Proceeedings of the 13th International Conference, EANN 2012, London, UK, September 20-23, 2012}
}

@article{lincoln38446,
          volume = {7543 L},
           title = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics): Preface},
          author = {P. McBurney and Simon Parsons and I. Rahwan},
            year = {2012},
           pages = {V--VI},
            note = {cited By 0},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38446/}
}

@misc{lincoln30870,
           title = {The Role of Roles: Physical Cooperation between Humans and Robots - Supplementary Material to Article, The International Journal of Robotics Research},
          author = {Alexander Moertl and Martin Lawitzky and Ayse Kucukyilmaz and Tevfik Metin Sezgin and Cagatay Basdogan and Sandra Hirche},
            year = {2012},
             doi = {10.1177/0278364912455366},
        keywords = {ARRAY(0x5568fb6d51e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30870/},
        abstract = {Since the strict separation of working spaces of humans and robots has experienced a softening due to recent robotics research achievements, close interaction of humans and robots comes rapidly into reach. In this context, physical human?robot interaction raises a number of questions regarding a desired intuitive robot behavior. The continuous bilateral information and energy exchange requires an appropriate continuous robot feedback. Investigating a cooperative manipulation task, the desired behavior is a combination of an urge to fulfill the task, a smooth instant reactive behavior to human force inputs and an assignment of the task effort to the cooperating agents. In this paper, a formal analysis of human?robot cooperative load transport is presented. Three different possibilities for the assignment of task effort are proposed. Two proposed dynamic role exchange mechanisms adjust the robot?s urge to complete the task based on the human feedback. For comparison, a static role allocation strategy not relying on the human agreement feedback is investigated as well. All three role allocation mechanisms are evaluated in a user study that involves large-scale kinesthetic interaction and full-body human motion. Results show tradeoffs between subjective and objective performance measures stating a clear objective advantage of the proposed dynamic role allocation scheme.}
}

@article{lincoln38453,
          volume = {118 LN},
          author = {J. Niu and K. Cai and Simon Parsons},
            note = {cited By 1},
           title = {A grey-box approach to automated mechanism design},
         journal = {Lecture Notes in Business Information Processing},
             doi = {10.1007/978-3-642-34200-4},
           pages = {47--61},
            year = {2012},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38453/}
}

@inproceedings{lincoln37445,
          volume = {10},
          author = {E. Ogunshile and C. Saaj and S. Chhaniyara and X. Wang and C. Langef and R. Findlay},
            note = {cited By 0},
       booktitle = {63rd International Astronautical Congress},
           title = {Application of model based systems engineering for an asteroid lander},
       publisher = {International Astronautical Federation},
            year = {2012},
         journal = {Proceedings of the International Astronautical Congress, IAC},
           pages = {8445--8453},
        keywords = {ARRAY(0x5568fbb44a60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37445/},
        abstract = {Surface exploration of asteroids are scientifically important for understanding of the origin and history of our solar system. Space agencies all over the world have started to launch exploration missions to asteroids. Low cost, small-sized landers with some capability to move on the surface of an asteroid would be highly suitable for in-situ observations.

This paper primarily proposes on Model Based Systems Engineering (MBSE) tool to handle the functional modelling of a class of small-scaled asteroid lander that would have requirements similar to the Mobile Asteroid Surface Scout (MASCOT) mission from the German Aerospace Centre (DLR). The latter aims at developing a landing package for the Hayabusa-2 mission. In this paper, System Modelling Language (SysML) is selected as the domain-specific language, and the lander system context is developed in the integrated development environmental (IDE) of IBM Rational Rhapsody.

The proposed unified functional modelling tool is platform independent. It covers a wide range of features for the lander system under consideration and proposes a clear decomposition of its functionalities. This MBSE approach can be easily adapted for other asteroid landers. Through this approach, systems engineers would make a rapid transformation from stakeholders' requirements to a functional model.

To this end, the proposed MBSE approach allows systems engineers and associated stakeholders at varying levels to define a number of common and basic lander scenarios derived from different levels of abstractions of the model system under test (i.e. the MASCOT lander). Furthermore, this proposed MBSE technique offers a structured and well-formed set of script templates for the lander model execution. Thus, allowing system engineers and stakeholders the privilege to verify, test and validate all functional, systems and interfacing requirements in a timely and efficient manner ? at varying stages in the project lifecycle. Further, the use of the animation feature of the Rational Rhapsody IDE to engineer the acquisition of visualised levels of detail for all SysML model elements and their respective executions will be presented.

Finally, to further show that the theoretical purity of the proposed MBSE approach does not mitigate against practical concerns, this approach is exemplified in a SysML model implementation of a shadow mission scenario ? the MASCOT lander}
}

@article{lincoln38448,
          volume = {7543 L},
          author = {Simon Parsons and Elizabeth Sklar and P. McBurney},
            note = {cited By 8},
           title = {Using argumentation to reason with and about trust},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-33152-7},
           pages = {194--212},
            year = {2012},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38448/}
}

@inproceedings{lincoln38443,
           title = {Argumentation logic to assist in security administration},
          author = {J. Rowe and Elizabeth Sklar and K. Levitt and A. Applebaum and Simon Parsons and S. Jalal},
            year = {2012},
           pages = {43--51},
            note = {cited By 11},
         journal = {Proceedings New Security Paradigms Workshop},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38443/}
}

@article{lincoln38576,
          volume = {7543 L},
          author = {Elizabeth Sklar and M.Q. Azhar},
            note = {cited By 0},
           title = {Toward the application of argumentation to interactive learning systems},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-33152-7},
           pages = {213--230},
            year = {2012},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38576/}
}

@article{lincoln38580,
          volume = {7103 L},
          author = {Elizabeth Sklar and C. Jansen and J. Chan and M. Byrd},
            note = {cited By 2},
           title = {Toward a methodology for agent-based data mining and visualization},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-27609-5},
           pages = {4--15},
            year = {2012},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38580/}
}

@article{lincoln38452,
          volume = {7068 L},
          author = {Elizabeth Sklar and A.T. Ozgelen and J.P. Munoz and J. Gonzalez and M. Manashirov and S.L. Epstein and Simon Parsons},
            note = {cited By 3},
           title = {Designing the hrteam framework: Lessons learned from a rough-and-ready human/multi-robot team},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-27216-5},
           pages = {232--251},
            year = {2012},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38452/}
}

@inproceedings{lincoln38444,
          volume = {FS-12-},
           title = {Learning to avoid collisions},
          author = {Elizabeth Sklar and Simon Parsons and S.L. Epstein and A.T. {\"O}zgelen and J.P. Mu{\~n}oz and F. Abbasi and E. Schneider and M. Costantino},
            year = {2012},
           pages = {53--60},
            note = {cited By 0},
         journal = {AAAI Fall Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38444/}
}

@article{lincoln38450,
          volume = {22},
          number = {5},
          author = {Y. Tang and K. Cai and P. McBurney and Elizabeth Sklar and Simon Parsons},
            note = {cited By 28},
           title = {Using argumentation to reason about trust and belief},
            year = {2012},
         journal = {Journal of Logic and Computation},
             doi = {10.1093/logcom/exr038},
           pages = {979--1018},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38450/}
}

@article{lincoln38456,
          volume = {245},
          number = {1},
          author = {Y. Tang and C.-W. Hang and Simon Parsons and M. Singh},
            note = {cited By 14},
           title = {Towards argumentation with symbolic dempster-shafer evidence},
            year = {2012},
         journal = {Frontiers in Artificial Intelligence and Applications},
             doi = {10.3233/978-1-61499-111-3-462},
           pages = {462--469},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38456/}
}

@inproceedings{lincoln13409,
          author = {Y. Tang and Jigen Peng and Shigang Yue and Jiawei Xu},
       booktitle = {5th International Conference on Biomedical Engineering and Informatics, BMEI 2012},
         address = {Chongqing},
           title = {A primal dual proximal point method of Chambolle-Pock algorithms for ?1-TV minimization problems in image reconstruction},
       publisher = {IEEE},
            year = {2012},
         journal = {2012 5th International Conference on Biomedical Engineering and Informatics, BMEI 2012},
             doi = {10.1109/BMEI.2012.6513092},
           pages = {12--16},
        keywords = {ARRAY(0x5568fb9bdfe8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13409/},
        abstract = {Computed tomography (CT) image reconstruction problems can be solved by finding the minimizer of a suitable objective function. The objective function usually consists of a data fidelity term and a regularization term. Total variation (TV) minimization problems are widely used for solving incomplete data problems in CT image reconstruction. In this paper, we focus on the CT image reconstruction model which combines the TV regularization and ?1 data error term. We introduce a primal dual proximal point method of Chambolle-Pock algorithm to solve the proposed optimization problem. We tested it on computer simulated data and the experiment results shown it exhibited good performance when used to few-view CT image reconstruction. {\copyright} 2012 IEEE.}
}

@inproceedings{lincoln10860,
          author = {Pin Shen Teh and Shigang Yue and A. B. J. Teoh},
            note = {Conference Code:92830},
       booktitle = {2012 International Conference on Cyber Security, Cyber Warfare and Digital Forensic (CyberSec)},
         address = {Kuala Lumpur},
           title = {Improving keystroke dynamics authentication system via multiple feature fusion scheme},
       publisher = {IEEE},
            year = {2012},
             doi = {10.1109/CyberSec.2012.6246096},
           pages = {277--282},
        keywords = {ARRAY(0x5568fbb472b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/10860/},
        abstract = {This paper reports the performance and effect of diverse keystroke features combination on keystroke dynamic authentication system by using fusion scheme. First of all, four types of keystroke features are acquired from our collected dataset, later then transformed into similarity scores by the use of Gaussian Probability Density Function (GPD) and Direction Similarity Measure (DSM). Next, three fusion schemes are introduced to merge the scores pairing with six fusion rules. Result shows that the finest performance is obtained by the combination of both dwell time and flight time collectively. Finally, this experiment also investigates the effect of using larger dataset on performance, which turns out to be rather consistent. {\^A}{\copyright} 2012 IEEE.}
}

@inproceedings{lincoln13408,
          author = {Jiawei Xu and Shigang Yue},
       booktitle = {5th International Conference on Biomedical Engineering and Informatics, BMEI 2012},
         address = {Chongqing},
           title = {A top-down attention model based on the semi-supervised learning},
       publisher = {IEEE},
            year = {2012},
         journal = {2012 5th International Conference on Biomedical Engineering and Informatics, BMEI 2012},
             doi = {10.1109/BMEI.2012.6513070},
           pages = {1011--1014},
        keywords = {ARRAY(0x5568fbbbac50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13408/},
        abstract = {In this paper, we proposed a top-down motion tracking model to detect the attention region. Many biological inspired systems have been studied and most of them are consisted by bottom-up mechanisms and top-down processes. Top-down attention is guided by task-driven information that is acquired through learning procedures. Our model improves the top-down mechanisms by using a probability map (PM). The PM follows to track if all the potential locations of targets based on the information contained in the frame sequences. By using this, PM can be regarded as a short term memory for attended saliency regions. This function is similar to the dorsal stream of V1 primary area. The semi-learning model constructs an efficient mechanism for attention detection to simulate the eye movements and fixations in our human visual systems. Generally, our work is to mimic human visual systems and it will further be applied on the robotics platform. From the random selected video clips, our performances are better than other state-of-the-art approaches. {\^A}{\copyright} 2012 IEEE.}
}

@article{lincoln37450,
          volume = {48},
          number = {6},
           month = {December},
          author = {C. Brunskill and N. Patel and T.P. Gouache and G.P. Scott and C. Saaj and M. Matthews and L. Cui},
            note = {cited By 19},
           title = {Characterisation of martian soil simulants for the ExoMars rover testbed},
       publisher = {Elsevier},
            year = {2011},
         journal = {Journal of Terramechanics},
             doi = {10.1016/j.jterra.2011.10.001},
           pages = {419--438},
        keywords = {ARRAY(0x5568fbb80dc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37450/},
        abstract = {The European Space Agency (ESA) ExoMars mission involves landing a rover on the surface of Mars on an exobiology mission to extend the search for life. The locomotion capabilities of the ExoMars rover will enable it to use its scientific instruments in a wide variety of locations. Before it is sent to Mars, this locomotion system must be tested and its performance limitations understood. To test the locomotion performance of the ExoMars rover, three martian regolith simulants were selected: a fine dust analogue, a fine Aeolian sand analogue, and a coarse sand analogue. To predict the performance of the ExoMars rover locomotion system in these three regolith simulants, it is necessary to measure some fundamental macroscopic properties of the materials: cohesion, friction angle, and various bearing capacity constants. This paper presents the tests conducted to determine these properties. During these tests, emphasis was placed on preparing the regolith simulants at different levels of density in order to evaluate its impact on the value of the parameters in particular. It was shown that compaction can influence the Bekker coefficients of pressure-sinkage. The shear properties are consistent with the critical state model at normal stresses similar to those of the ExoMars rover in all but one of the simulants, which showed behaviour more consistent with transitional soil behaviour. It is necessary to give due consideration to these variations to ensure a robust test regime is developed when testing the tractive ability of the ExoMars mobility system.}
}

@article{lincoln6560,
          volume = {25},
          number = {18},
           month = {December},
          author = {Michael L. Walters and Manja Lohse and Marc Hanheide and Britte Wrede and Dag Sverre Syrdal and Kheng Lee Koay and Anders Green and Helge Huttenrauch and Kerstin Dautenhahn and Gerhard Sagerer and Kerstin Severinson-Eklundh},
            note = {Robots are increasingly being used in domestic environments and should be able to interact with inexperienced users. Human-human interaction and human-computer interaction research findings are relevant, but often limited because robots are different from both humans and computers. Therefore, new human-robot interaction (HRI) research methods can inform the design of robots suitable for inexperienced users. A video-based HRI (VHRI) methodology was here used to carry out a multi-national HRI user study for the prototype domestic robot BIRON (BIelefeld RObot companioN). Previously, the VHRI methodology was used in constrained HRI situations, while in this study HRIs involved a series of events as part of a 'hometour' scenario. Thus, the present work is the first study of this methodology in extended HRI contexts with a multi-national approach. Participants watched videos of the robot interacting with a human actor and rated two robot behaviors (Extrovert and Introvert). Participants' perceptions and ratings of the robot's behaviors differed with regard to both verbal interactions and person following by the robot. The study also confirms that the VHRI methodology provides a valuable means to obtain early user feedback, even before fully working prototypes are available. This can usefully guide the future design work on robots, and associated verbal and non-verbal behaviors.},
           title = {Evaluating the robot personality and verbal behavior of domestic robots using video-based studies},
       publisher = {Taylor \& Francis},
            year = {2011},
         journal = {Advanced Robotics},
             doi = {10.1163/016918611X603800},
           pages = {2233--2254},
        keywords = {ARRAY(0x5568fba663d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6560/},
        abstract = {Robots are increasingly being used in domestic environments and should be able to interact with inexperienced users. Human-human interaction and human-computer interaction research findings are relevant, but often limited because robots are different from both humans and computers. Therefore, new human-robot interaction (HRI) research methods can inform the design of robots suitable for inexperienced users. A video-based HRI (VHRI) methodology was here used to carry out a multi-national HRI user study for the prototype domestic robot BIRON (BIelefeld RObot companioN). Previously, the VHRI methodology was used in constrained HRI situations, while in this study HRIs involved a series of events as part of a 'hometour' scenario. Thus, the present work is the first study of this methodology in extended HRI contexts with a multi-national approach. Participants watched videos of the robot interacting with a human actor and rated two robot behaviors (Extrovert and Introvert). Participants' perceptions and ratings of the robot's behaviors differed with regard to both verbal interactions and person following by the robot. The study also confirms that the VHRI methodology provides a valuable means to obtain early user feedback, even before fully working prototypes are available. This can usefully guide the future design work on robots, and associated verbal and non-verbal behaviors.}
}

@inproceedings{lincoln8314,
           month = {November},
          author = {Ruth S. Aylett and Ginevra Castellano and Bogdan Raducanu and Ana Paiva and Marc Hanheide},
            note = {Conference Code: 87685},
       booktitle = {Conference of 2011 ACM International Conference on Multimodal Interaction, ICMI'11},
           title = {Long-term socially perceptive and interactive robot companions: challenges and future perspective},
         address = {Alicante},
       publisher = {ACM},
            year = {2011},
         journal = {ICMI'11 - Proceedings of the 2011 ACM International Conference on Multimodal Interaction},
             doi = {10.1145/2070481.2070543},
           pages = {323--326},
        keywords = {ARRAY(0x5568fba11b60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8314/},
        abstract = {This paper gives a brief overview of the challenges for multi-model perception and generation applied to robot companions located in human social environments. It reviews the current position in both perception and generation and the immediate technical challenges and goes on to consider the extra issues raised by embodiment and social context. Finally, it briefly discusses the impact of systems that must function continually over months rather than just for a few hours. {\^A}{\copyright} 2011 ACM.}
}

@article{lincoln10329,
          volume = {62},
          number = {7},
           month = {October},
          author = {Shigang Yue and Hua-Liang Wei and Maozhen Li and Qilian Liang and Lipo Wang},
           title = {ICNC-FSKD 2010 special issue on computers \& mathematics in natural computation and knowledge discovery},
       publisher = {Elsevier},
            year = {2011},
         journal = {Computers and Mathematics with Applications},
             doi = {10.1016/j.camwa.2011.06.049},
           pages = {2683--2684},
        keywords = {ARRAY(0x5568fbb93f10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/10329/},
        abstract = {Natural computation, as an exciting and emerging interdisciplinary field, has been witnessing a surge of newly developed theories, methodologies and applications in recent years. These innovations have generated a huge impact in tackling complex and challenging real world problems. Not only are the well established intelligent techniques, such as neural networks, fuzzy systems, genetic and evolutionary algorithms, and cellular automata expanding to new application areas; the new forms of natural computation that have emerged recently, for example, swarm intelligence, artificial immune systems, bio-molecular computing and membrane computing, quantum computing, and granular computing, are also providing additional tools for various applications. One attractive area that natural computation has been playing a major role in is knowledge discovery. There are many success stories on natural computation and knowledge discovery, as you will find out in this special issue}
}

@inproceedings{lincoln40830,
           month = {September},
          author = {Gautham Das and Thomas M. McGinnity and Sonya A. Coleman and Laxmidhar Behera},
       booktitle = {2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
           title = {A fast distributed auction and consensus process using parallel task allocation and execution},
       publisher = {IEEE},
             doi = {10.1109/IROS.2011.6048635},
           pages = {4716--4721},
            year = {2011},
        keywords = {ARRAY(0x5568fba72478)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40830/},
        abstract = {In a multi-robot system, the coordination and cooperation among the robots determine the effectiveness of task execution. Different centralised and distributed task allocation algorithms have been proposed by researchers. Recently consensus based task allocation has been extensively researched because of its robustness in handling large teams of robots. We propose a new auction and consensus based algorithm for fast task allocation in parallel with task execution. The performance of the proposed algorithm under different conditions is analyzed and compared with other distributed consensus algorithms.}
}

@inproceedings{lincoln4662,
       booktitle = {Think Design Play: DiGRA Conference},
           month = {September},
           title = {From individual characters to large crowds: augmenting the believability of open-world games through exploring social emotion in pedestrian groups},
          author = {Oliver Szymanezyk and Patrick Dickinson and Tom Duckett},
       publisher = {ARA Digital Media Private Limited},
            year = {2011},
        keywords = {ARRAY(0x5568fbba15b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/4662/},
        abstract = {Crowds of non-player characters improve the game-play experiences of open-world video-games. Grouping is a common phenomenon of crowds and plays an important role in crowd behaviour. Recent crowd simulation research focuses on group modelling in pedestrian crowds and game-designers have argued that the design of non-player characters should capture and exploit the relationship between characters. The concepts of social groups and inter-character relationships are not new in social psychology, and on-going work addresses the social life of emotions and its behavioural consequences on individuals and groups alike. The aim of this paper is to provide an overview of current research in social psychology, and to use the findings as a source of inspiration to design a social network of non-player characters, with application to the problem of group modelling in simulated crowds in computer games.}
}

@incollection{lincoln4569,
          volume = {6682},
          number = {6682},
           month = {September},
          author = {Oliver Szymanezyk and Patrick Dickinson and Tom Duckett},
          series = {Lecture Notes in Computer Science},
       booktitle = {Agent and multi-agent systems: technologies and applications},
           title = {Towards agent-based crowd simulation in airports using games technology},
         address = {Berling Heidelberg},
       publisher = {Springer-Verlag},
            year = {2011},
             doi = {10.1007/978-3-642-22000-5\_54},
           pages = {524--533},
        keywords = {ARRAY(0x5568fba8f2b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/4569/},
        abstract = {We adapt popular video games technology for an agent-based crowd simulation in an airport terminal. To achieve this, we investigate the unique traits of airports and implement a virtual crowd by exploiting a scalable layered intelligence technique in combination with physics middleware and a socialforces approach. Our experiments show that the framework runs at interactive frame-rate and evaluate the scalability with increasing number of agents demonstrating
navigation behaviour.}
}

@inproceedings{lincoln37404,
          volume = {6856 L},
           month = {September},
          author = {B. Yeomans and C. Saaj},
            note = {cited By 0},
       booktitle = {Conference Towards Autonomous Robotic Systems},
           title = {Walking rover trafficability - Presenting a comprehensive analysis and prediction tool},
       publisher = {Springer},
            year = {2011},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-23232-9\_31},
           pages = {348--359},
        keywords = {ARRAY(0x5568fbb7a978)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37404/},
        abstract = {Although walking rovers perform well in rocky terrain, their performance over sands and other deformable materials has not been well studied. A better understanding of walking rover terramechanics will be essential if they are to be actually deployed on a space mission.

This paper presents a comprehensive walking rover terramechanics model incorporating slip and sinkage dependencies. In addition to quantifying the leg / soil forces, the superior trafficability potential of a walking rover in deformable terrain is demonstrated, and a control approach is described which can reduce the risk inherent in traversing soils with unknown physical parameters. This work enhances the state of the art of legged rover trafficability and highlights some potential benefits from deploying micro-legged rovers for future surface exploration missions.}
}

@article{lincoln46207,
          volume = {6},
          number = {3},
           month = {September},
          author = {M Calisti and M Giorelli and G Levy and B Mazzolai and B Hochner and C Laschi and P Dario},
           title = {An octopus-bioinspired solution to movement and manipulation for soft robots},
            year = {2011},
         journal = {Bioinspiration \& Biomimetics},
             doi = {10.1088/1748-3182/6/3/036002},
           pages = {036002},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46207/},
        abstract = {Soft robotics is a challenging and promising branch of robotics. It can drive significant improvements across various fields of traditional robotics, and contribute solutions to basic problems such as locomotion and manipulation in unstructured environments. A challenging task for soft robotics is to build and control soft robots able to exert effective forces. In recent years, biology has inspired several solutions to such complex problems. This study aims at investigating the smart solution that the Octopus vulgaris adopts to perform a crawling movement, with the same limbs used for grasping and manipulation. An ad hoc robot was designed and built taking as a reference a biological hypothesis on crawling. A silicone arm with cables embedded to replicate the functionality of the arm muscles of the octopus was built. This novel arm is capable of pushing-based locomotion and object grasping, mimicking the movements that octopuses adopt when crawling. The results support the biological observations and clearly show a suitable way to build a more complex soft robot that, with minimum control, can perform diverse tasks.}
}

@inproceedings{lincoln8313,
           month = {September},
          author = {R. Golombek and S. Wrede and Marc Hanheide and M. Heckmann},
            note = {Conference Code: 87712},
       booktitle = {Conference of 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems: Celebrating 50 Years of Robotics, IROS'11},
           title = {Online data-driven fault detection for robotic systems},
         address = {San Francisco, CA},
       publisher = {IEEE},
            year = {2011},
         journal = {IEEE International Conference on Intelligent Robots and Systems},
             doi = {10.1109/IROS.2011.6048683},
           pages = {3011--3016},
        keywords = {ARRAY(0x5568fbab1c10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8313/},
        abstract = {In this paper we demonstrate the online applicability of the fault detection and diagnosis approach which we previously developed and published in 1. In our former work we showed that a purely data driven fault detection approach can be successfully built based on monitored inter-component communication data of a robotic system and used for a-posteriori fault detection. Here we propose an extension to this approach which is capable of online learning of the fault model as well as for online fault detection. We evaluate the application of our approach in the context of a RoboCup task executed by our service robot BIRON in corporation with an expert user. {\^A}{\copyright} 2011 IEEE.}
}

@incollection{lincoln10338,
          volume = {6856},
           month = {August},
          author = {Feras Dayoub and Grzegorz Cielniak and Tom Duckett},
          series = {Lecture Notes in Computer Science},
            note = {12th Annual Conference, TAROS 2011, Sheffield, UK, August 31 ? September 2, 2011. Proceedings},
       booktitle = {Towards autonomous robotic systems},
           title = {Long-term experiment using an adaptive appearance-based map for visual navigation by mobile robots},
         address = {Sheffield},
       publisher = {Springer},
            year = {2011},
             doi = {10.1007/978-3-642-23232-9\_47},
           pages = {400--401},
        keywords = {ARRAY(0x5568fba971f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/10338/},
        abstract = {Building functional and useful mobile service robots means that these robots have to be able to share physical spaces with humans, and to update their internal representation of the world in response to changes in the arrangement of objects and appearance of the environment - changes that may be spontaneous and unpredictable - as a result of human activities. However, almost all past research on robot mapping addresses only the initial learning of an environment, a phase which will only be a short moment in the lifetime of a service robot that may be expected to operate for many years. {\copyright} 2011 Springer-Verlag Berlin Heidelberg.}
}

@inproceedings{lincoln6756,
           month = {July},
          author = {Marc Hanheide and Charles Gretton and Richard W. Dearden and Nick A. Hawes and Jeremy L. Wyatt and Moritz Goedelbecker and Andrzej Pronobis and Alper Aydemir and Hendrik Zender},
            note = {Robots must perform tasks efficiently and reli- ably while acting under uncertainty. One way to achieve efficiency is to give the robot common- sense knowledge about the structure of the world. Reliable robot behaviour can be achieved by mod- elling the uncertainty in the world probabilistically. We present a robot system that combines these two approaches and demonstrate the improvements in efficiency and reliability that result. Our first con- tribution is a probabilistic relational model integrat- ing common-sense knowledge about the world in general, with observations of a particular environ- ment. Our second contribution is a continual plan- ning system which is able to plan in the large prob- lems posed by that model, by automatically switch- ing between decision-theoretic and classical proce- dures. We evaluate our system on object search tasks in two different real-world indoor environ- ments. By reasoning about the trade-offs between possible courses of action with different informa- tional effects, and exploiting the cues and general structures of those environments, our robot is able to consistently demonstrate efficient and reliable goal-directed behaviour.},
       booktitle = {Twenty-Second International Joint Conference on Artificial Intelligence},
          editor = {B. Gottfried and H. Aghajan},
           title = {Exploiting probabilistic knowledge under uncertain sensing for efficient robot behaviour},
       publisher = {International Joint Conferences on Artiicial Intelligence},
            year = {2011},
             doi = {10.5591/978-1-57735-516-8/IJCAI11-407},
           pages = {2442--2449},
        keywords = {ARRAY(0x5568fbab9078)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6756/},
        abstract = {Robots must perform tasks efficiently and reli- ably while acting under uncertainty. One way to achieve efficiency is to give the robot common- sense knowledge about the structure of the world. Reliable robot behaviour can be achieved by mod- elling the uncertainty in the world probabilistically. We present a robot system that combines these two approaches and demonstrate the improvements in efficiency and reliability that result. Our first con- tribution is a probabilistic relational model integrat- ing common-sense knowledge about the world in general, with observations of a particular environ- ment. Our second contribution is a continual plan- ning system which is able to plan in the large prob- lems posed by that model, by automatically switch- ing between decision-theoretic and classical proce- dures. We evaluate our system on object search tasks in two different real-world indoor environ- ments. By reasoning about the trade-offs between possible courses of action with different informa- tional effects, and exploiting the cues and general structures of those environments, our robot is able to consistently demonstrate efficient and reliable goal-directed behaviour.}
}

@inproceedings{lincoln12818,
           month = {July},
          author = {Vladimir Belevskiy and Shigang Yue},
       booktitle = {2011 Seventh International Conference on Natural Computation},
           title = {Near range pedestrian collision detection using bio-inspired visual neural networks},
       publisher = {IEEE},
             doi = {10.1109/ICNC.2011.6022169},
           pages = {786--790},
            year = {2011},
        keywords = {ARRAY(0x5568fbaa1b38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/12818/},
        abstract = {New vehicular safety standards require the development of pedestrian collision detection systems that can trigger the deployment of active impact alleviation measures from the vehicle prior to a collision. In this paper, we propose a new vision-based system for near-range pedestrian collision detection. The low-level system uses a bio-inspired visual neural network, which emulates the visual system of the locust, to detect visual cues relevant to objects in front of a moving car. At a higher level, the system employs a neural-network classifier to identify dangerous pedestrian positions, triggering an alarm signal. The system was tuned via simulation and tested using recorded video sequences of real vehicle impacts. The experiment results demonstrate that the system is able to discriminate between pedestrians in dangerous and safe positions, triggering alarms accordingly.}
}

@article{lincoln37451,
          volume = {59},
          number = {8},
           month = {June},
          author = {T.P. Gouache and N. Patel and C. Brunskill and G.P. Scott and C. Saaj and M. Matthews and L. Cui},
            note = {cited By 16},
           title = {Soil simulant sourcing for the ExoMars rover testbed},
       publisher = {Elsevier},
            year = {2011},
         journal = {Planetary and Space Science},
             doi = {10.1016/j.pss.2011.03.006},
           pages = {779--787},
        keywords = {ARRAY(0x5568fbae6390)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37451/},
        abstract = {ExoMars is the European Space Agency (ESA) mission to Mars planned for launch in 2018, focusing on exobiology with the primary objective of searching for any traces of extant or extinct carbon-based micro-organisms. The on-surface mission is performed by a near-autonomous mobile robotic vehicle (also referred to as the rover) with a mission design life of 180 sols (Patel et al., 2010). In order to obtain useful data on the tractive performance of the ExoMars rover before flight, it is necessary to perform mobility tests on representative soil simulant materials producing a Martian terrain analogue under terrestrial laboratory conditions. Three individual types of regolith shown to be found extensively on the Martian surface were identified for replication using commercially available terrestrial materials, sourced from UK sites in order to ensure easy supply and reduce lead times for delivery. These materials (also referred to as the Engineering Soil (ES-x) simulants) are: a fine dust analogue (ES-1); a fine aeolian sand analogue (ES-2); and a coarse sand analogue (ES-3). Following a detailed analysis, three fine sand regolith types were identified from commercially available products. Each material was used in its off-the-shelf state, except for ES-2, where further processing methods were used to reduce the particle size range. These materials were tested to determine their physical characteristics, including the particle size distribution, particle density, particle shape (including angularity/sphericity) and moisture content. The results are analysed to allow comparative analysis with existing soil simulants and the published results regarding in situ analysis of Martian soil on previous NASA (National Aeronautics and Space Administration) missions. The findings have shown that in some cases material properties vary significantly from the specifications provided by material suppliers. This has confirmed the need for laboratory testing to determine the actual parameters to prove that standard geotechnical processes are indeed suitable. The outcomes have allowed the confirmation of each simulant material as suitable for replicating their respective regolith types.}
}

@inproceedings{lincoln25793,
       booktitle = {28th International Conference on Machine Learning (ICML-11)},
           month = {June},
           title = {Variational inference for policy search in changing situations},
          author = {Gerhard Neumann},
            year = {2011},
           pages = {817--824},
         journal = {Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
        keywords = {ARRAY(0x5568fba42898)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25793/},
        abstract = {Many policy search algorithms minimize the Kullback-Leibler (KL) divergence to a certain
target distribution in order to fit their policy. The commonly used KL-divergence forces the resulting
policy to be ?reward-attracted?. The policy tries to reproduce all positively rewarded experience
while negative experience is neglected. However, the KL-divergence is not symmetric
and we can also minimize the the reversed KL-divergence, which is typically used in variational
inference. The policy now becomes ?cost-averse?. It tries to avoid reproducing any negatively-rewarded experience while maximizing exploration. Due to this ?cost-averseness? of the policy, Variational Inference for Policy Search (VIP) has several interesting properties. It requires no kernelbandwith nor exploration rate, such settings are
determined automatically by the inference. The algorithm meets the performance of state-of-theart
methods while being applicable to simultaneously learning in multiple situations. We concentrate on using VIP for policy search in robotics. We apply our algorithm to learn dynamic counterbalancing of different kinds of
pushes with human-like 2-link and 4-link robots.}
}

@inproceedings{lincoln29362,
       booktitle = {IEEE World Haptics Conference 2011 (WHC'11)},
           month = {June},
           title = {Conveying intentions through haptics in human-computer collaboration},
          author = {Ayse Kucukyilmaz and Tevfik Metin Sezgin and Cagatay Basdogan},
            year = {2011},
           pages = {421--426},
             doi = {10.1109/WHC.2011.5945523},
        keywords = {ARRAY(0x5568fbb67030)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29362/},
        abstract = {Haptics has been used as a natural way for humans to communicate with computers in collaborative virtual environments. Human-computer collaboration is typically achieved by sharing control of the task between a human and a computer operator. An important research challenge in the field addresses the need to realize intention recognition and response, which involves a decision making process between the partners. In an earlier study, we implemented a dynamic role exchange mechanism, which realizes decision making by means of trading the parties' control levels on the task. This mechanism proved to show promise of a more intuitive and comfortable communication. Here, we extend our earlier work to further investigate the utility of a role exchange mechanism in dynamic collaboration tasks. An experiment with 30 participants was conducted to compare the utility of a role exchange mechanism with that of a shared control scheme where the human and the computer share control equally at all times. A no guidance condition is considered as a base case to present the benefits of these two guidance schemes more clearly. Our experiment show that the role exchange scheme maximizes the efficiency of the user, which is the ratio of the work done by the user within the task to the energy spent by her. Furthermore, we explored the added benefits of explicitly displaying the control state by embedding visual and vibrotactile sensory cues on top of the role exchange scheme. We observed that such cues decrease performance slightly, probably because they introduce an extra cognitive load, yet they improve the users' sense of collaboration and interaction with the computer. These cues also create a stronger sense of trust for the user towards her partner's control over the task.}
}

@inproceedings{lincoln4824,
       booktitle = {IEEE International Conference on Computer Science and information Technology (ICCSIT)},
           month = {June},
           title = {AltURI: a thin middleware for simulated robot vision applications},
          author = {Mark Smith and Marwan Shaker and Shigang Yue and Tom Duckett},
       publisher = {IEEE},
            year = {2011},
        keywords = {ARRAY(0x5568fb9f4550)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/4824/},
        abstract = {Fast software performance is often the focus when developing real-time vision-based control applications for robot simulators. In this paper we have developed a thin, high performance middleware for USARSim and other simulators designed for real-time vision-based control applications. It includes a fast image server providing images in OpenCV, Matlab or web formats and a simple command/sensor processor. The interface has been tested in USARSim with an Unmanned Aerial Vehicle using two control applications; landing using a reinforcement learning algorithm and altitude control using elementary motion detection. The middleware has been found to be fast enough to control the flying robot as well as very easy to set up and use.}
}

@incollection{lincoln36756,
           month = {June},
          author = {Mark Taylor and Charles Fox},
          series = {Lecture Notes in Business Information Processing},
       booktitle = {International Conference on Business Information Systems},
           title = {Inventory Management with Dynamic Bayesian Network Software Systems},
       publisher = {Springer},
            year = {2011},
             doi = {10.1007/978-3-642-21863-7\_25},
           pages = {290--300},
        keywords = {ARRAY(0x5568fbab23d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36756/},
        abstract = {Inventory management at a single or multiple levels of a supply chain is usually performed with computations such as Economic Order Quantity or Markov Decision Processes. The former makes many unrealistic assumptions and the later requires specialist Operations Research knowledge to implement. Dynamic Bayesian networks provide an alternative framework which is accessible to non-specialist managers through off-the-shelf graphical software systems. We show how such systems may be deployed to model a simple inventory problem, and learn an improved solution over EOQ. We discuss how these systems can allow managers to model additional risk factors throughout a supply chain through intuitive, incremental extensions to the Bayesian networks.}
}

@inproceedings{lincoln6764,
           month = {May},
          author = {Nick Hawes and Marc Hanheide and Jack Hargreaves and Ben Page and Hendrik Zender and Patric Jensfelt},
            note = {In this paper we present an account
of the problems faced by a mobile robot given
an incomplete tour of an unknown environment,
and introduce a collection of techniques which can
generate successful behaviour even in the presence
of such problems. Underlying our approach is the
principle that an autonomous system must be motivated
to act to gather new knowledge, and to validate
and correct existing knowledge. This principle is
embodied in Dora, a mobile robot which features
the aforementioned techniques: shared representations,
non-monotonic reasoning, and goal generation
and management. To demonstrate how well this
collection of techniques work in real-world situations
we present a comprehensive analysis of the Dora
system?s performance over multiple tours in an indoor
environment. In this analysis Dora successfully
completed 18 of 21 attempted runs, with all but
3 of these successes requiring one or more of the
integrated techniques to recover from problems.},
       booktitle = {2011 IEEE International Conference on Robotics and Automation (ICRA)},
          editor = {B. Gottfried and H. Aghajan},
           title = {Home alone: autonomous extension and correction of spatial
representations},
       publisher = {IEEE},
            year = {2011},
             doi = {10.1109/ICRA.2011.5980004},
           pages = {3907--3914},
        keywords = {ARRAY(0x5568fba2a568)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6764/},
        abstract = {In this paper we present an account
of the problems faced by a mobile robot given
an incomplete tour of an unknown environment,
and introduce a collection of techniques which can
generate successful behaviour even in the presence
of such problems. Underlying our approach is the
principle that an autonomous system must be motivated
to act to gather new knowledge, and to validate
and correct existing knowledge. This principle is
embodied in Dora, a mobile robot which features
the aforementioned techniques: shared representations,
non-monotonic reasoning, and goal generation
and management. To demonstrate how well this
collection of techniques work in real-world situations
we present a comprehensive analysis of the Dora
system?s performance over multiple tours in an indoor
environment. In this analysis Dora successfully
completed 18 of 21 attempted runs, with all but
3 of these successes requiring one or more of the
integrated techniques to recover from problems.}
}

@article{lincoln22209,
          volume = {7},
          number = {3},
           month = {May},
          author = {Heriberto Cuayahuitl},
           title = {Spatially-aware dialogue control using hierarchical reinforcement learning},
       publisher = {Association for Computing Machinery},
            year = {2011},
         journal = {ACM Transactions on Speech and Language Processing (TSLP)},
             doi = {10.1145/1966407.1966410},
        keywords = {ARRAY(0x5568fbb851b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22209/},
        abstract = {This article addresses the problem of scalable optimization for spatially-aware dialogue systems. These kinds of systems must perceive, reason, and act about the spatial environment where they are embedded. We formulate the problem in terms of Semi-Markov Decision Processes and propose a hierarchical reinforcement learning approach to optimize subbehaviors rather than full behaviors. Because of the vast number of policies that are required to control the interaction in a dynamic environment (e.g., a dialogue system assisting a user to navigate in a building from one location to another), our learning approach is based on two stages: (a) the first stage learns low-level behavior, in advance; and (b) the second stage learns high-level behavior, in real time. For such a purpose we extend an existing algorithm in the literature of reinforcement learning in order to support reusable policies and therefore to perform fast learning. We argue that our learning approach makes the problem feasible, and we report on a novel reinforcement learning dialogue system that performs a joint optimization between dialogue and spatial behaviors. Our experiments, using simulated and real environments, are based on a text-based dialogue system for indoor navigation. Experimental results in a realistic environment reported an overall user satisfaction result of 89\%, which suggests that our proposed approach is attractive for its application in real interactions as it combines fast learning with adaptive and reasonable behavior.}
}

@article{lincoln25794,
          volume = {104},
          number = {4-5},
           month = {May},
          author = {Helmut Hauser and Gerhard Neumann and Auke J. Ijspeert and Wolfgang Maass},
           title = {Biologically inspired kinematic synergies enable linear balance control of a humanoid robot},
       publisher = {Springer},
            year = {2011},
         journal = {Biological Cybernetics},
             doi = {10.1007/s00422-011-0430-1},
           pages = {235--249},
        keywords = {ARRAY(0x5568fb6704c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25794/},
        abstract = {Despite many efforts, balance control of humanoid robots in the presence of unforeseen external or internal forces has remained an unsolved problem. The difficulty of this problem is a consequence of the high dimensionality of the action space of a humanoid robot, due to its large number of degrees of freedom (joints), and of non-linearities in its kinematic chains. Biped biological organisms face similar difficulties, but have nevertheless solved this problem. Experimental data reveal that many biological organisms reduce the high dimensionality of their action space by generating movements through linear superposition of a rather small number of stereotypical combinations of simultaneous movements of many joints, to which we refer as kinematic synergies in this paper. We show that by constructing two suitable non-linear kinematic synergies for the lower part of the body of a humanoid robot, balance control can in fact be reduced to a linear control problem, at least in the case of relatively slow movements. We demonstrate for a variety of tasks that the humanoid robot HOAP-2 acquires through this approach the capability to balance dynamically against unforeseen disturbances that may arise from external forces or from manipulating unknown loads.}
}

@article{lincoln6046,
          volume = {59},
          number = {5},
           month = {May},
          author = {Feras Dayoub and Grzegorz Cielniak and Tom Duckett},
           title = {Long-term experiments with an adaptive spherical view representation for navigation in changing environments},
       publisher = {Elsevier},
            year = {2011},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2011.02.013},
           pages = {285--295},
        keywords = {ARRAY(0x5568fbaf9158)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6046/},
        abstract = {Real-world environments such as houses and offices change over time, meaning that a mobile robot?s map will become out of date. In this work, we introduce a method to update the reference views in a hybrid metric-topological map so that a mobile robot can continue to localize itself in a changing environment. The updating mechanism, based on the multi-store model of human memory, incorporates a spherical metric representation of the observed visual features for each node in the map, which enables the robot to estimate its heading and navigate using multi-view geometry, as well as representing the local 3D geometry of the environment. A series of experiments demonstrate the persistence performance of the proposed system in real changing environments, including analysis of the long-term stability.}
}

@inproceedings{lincoln8353,
           month = {May},
          author = {N. Hawes and Marc Hanheide and J. Hargreaves and B. Page and H. Zender and P. Jensfelt},
            note = {Conference of 2011 IEEE International Conference on Robotics and Automation, ICRA 2011; Conference Date: 9 May 2011 through 13 May 2011; Conference Code: 94261},
       booktitle = {Robotics and Automation (ICRA), 2011 IEEE International Conference on},
           title = {Home alone: autonomous extension and correction of spatial representations},
         address = {Shanghai},
       publisher = {IEEE},
            year = {2011},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
             doi = {10.1109/ICRA.2011.5980004},
           pages = {3907--3914},
        keywords = {ARRAY(0x5568fbab8c70)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8353/},
        abstract = {In this paper we present an account of the problems faced by a mobile robot given an incomplete tour of an unknown environment, and introduce a collection of techniques which can generate successful behaviour even in the presence of such problems. Underlying our approach is the principle that an autonomous system must be motivated to act to gather new knowledge, and to validate and correct existing knowledge. This principle is embodied in Dora, a mobile robot which features the aforementioned techniques: shared representations, non-monotonic reasoning, and goal generation and management. To demonstrate how well this collection of techniques work in real-world situations we present a comprehensive analysis of the Dora system's performance over multiple tours in an indoor environment. In this analysis Dora successfully completed 18 of 21 attempted runs, with all but 3 of these successes requiring one or more of the integrated techniques to recover from problems. {\^A}{\copyright} 2011 IEEE.}
}

@incollection{lincoln6714,
           month = {April},
          author = {Annika Peters and Thorsten P. Spexard and Marc Hanheide and Petra Weiss},
       booktitle = {Behaviour Monitoring and Interpretation - BMI Well-being},
          editor = {B. Gottfried and H. Aghajan},
           title = {Hey robot, get out of my way: survey on a spatial and situational movement concept in HRI},
       publisher = {IOS Press},
             doi = {10.3233/978-1-60750-731-4},
            year = {2011},
        keywords = {ARRAY(0x5568fba57208)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6714/},
        abstract = {Mobile robots are already applied in factories and hospitals, merely to do a distinct task. It is envisioned that robots assist in households soon. Those service robots will have to cope with several situations and tasks and of course with sophisticated human-robot interactions (HRI). Therefore, a robot has not only to consider social rules with respect to proxemics, it must detect in which (interaction) situation it is in and act accordingly. With respect to spatial HRI, we concentrate on the use of non-verbal communication. This chapter stresses the meaning of both, machine movements as signals towards a human and human body language. Considering these aspects will make interaction simpler and smoother. An observational study is presented to acquire a concept of spatial prompting by a robot and by a human. When a person and robot meet in a narrow hallway in order to pass by, they have to make room for each other. But how can a robot make sure that both really want to pass by instead of starting interaction? This especially concerns narrow, non-artificial surroundings. Which social signals are expected by the user and on the other side, can be generated or processed by a robot? The results will show what an appropriate passing behaviour is and how to distinguish between passage situations and others. The results shed light upon the readability of signals in spatial HRI.}
}

@inproceedings{lincoln39649,
       booktitle = {11th Symposium on Advanced Space Technologies in Robotics and Automation},
           month = {April},
           title = {Progress Towards Robust Mobility Analysis for a Legged Planetary Fetch Rover},
          author = {B. Yeomans and C. Saaj},
            year = {2011},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39649/}
}

@inproceedings{lincoln37418,
           month = {March},
          author = {B.G.R. Smith and C. Saaj and E. Allouis},
            note = {cited By 8},
       booktitle = {IEEE International Conference on Robotics and Biomimetics (ROBIO2010)},
           title = {Evolving legged robots using biologically inspired optimization strategies},
       publisher = {IEEE},
            year = {2011},
         journal = {2010 IEEE International Conference on Robotics and Biomimetics, ROBIO 2010},
             doi = {10.1109/ROBIO.2010.5723523},
           pages = {1335--1340},
        keywords = {ARRAY(0x5568fbb04df8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37418/},
        abstract = {When designing a legged robot a small change in one variable can have a significant effect on a number of the robot's characteristics, meaning that making tradeoffs can be difficult. The algorithm presented in this paper uses biologically inspired optimization techniques to identify the effects of changing various robot design variables and determine if there are any general rules which can be applied to the design of a legged robot. Designs produced by this simulation are also compared to existing robot designs and biological systems, showing that the algorithm produces results which require less power and torque than similar robots, and which share a number of characteristics with biological systems.}
}

@inproceedings{lincoln37446,
          volume = {9},
          author = {S. Chhaniyara and C. Saaj and B. Maediger and M. Althoff-Kotzias and B. Langpap and I. Ahrns},
            note = {cited By 4},
       booktitle = {62nd International Astronautical Congress},
           title = {SysML based system engineering: A case study for space robotics systems},
         journal = {62nd International Astronautical Congress 2011, IAC 2011},
           pages = {7271--7278},
            year = {2011},
        keywords = {ARRAY(0x5568fba56f38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37446/},
        abstract = {Space systems are similar to their terrestrial counterparts in many respects but the main distinction that makes space system unique are due to the harsh and low gravity environment that space systems needs to survive, requirements of system redundancy due to lack of on orbit maintenance or parts replacement and costs associated with those. These put extra emphasis on systems and requirement engineering from the very early stage of systems development lifecycle. Typical space missions comprise of many interconnected systems and systems of systems. Each of these systems need to be satisfied or adhered to thousands of requirements. Traditional System Engineering (SE) approaches require updating and tracking requirements against their functional or behavioural components manually. On top of that, during early design review stages, mission system engineers may also needs to carefully modify or delete requirements without compromising effects of that on other interconnected or sub systems. This is a very time consuming and complex procedure especially when multiple stakeholders and teams of engineers involved locally or globally. This paper introduces the implementation of Systems Modelling Language (SysML) for modelling complex space robotic systems in context of On-orbit Serving (OOS) missions. In this paper, the benefits of applying Object Management Group (OMG) System Modeling language (SysMLTM) to support the specification, analysis, design and verification to space robotic systems is being proposed}
}

@article{lincoln38471,
          volume = {175},
          number = {2},
          author = {P.E. Dunne and A. Hunter and P. McBurney and Simon Parsons and M. Wooldridge},
            note = {cited By 158},
           title = {Weighted argument systems: Basic definitions, algorithms, and complexity results},
            year = {2011},
         journal = {Artificial Intelligence},
             doi = {10.1016/j.artint.2010.09.005},
           pages = {457--486},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38471/}
}

@article{lincoln38464,
          volume = {6614 L},
          author = {C.D. Emele and T.J. Norman and F. Guerin and Simon Parsons},
            note = {cited By 2},
           title = {On the benefits of argumentation-derived evidence in learning policies},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-21940-5},
           pages = {86--104},
            year = {2011},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38464/}
}

@inproceedings{lincoln38472,
          volume = {2},
           title = {Argumentation strategies for plan resourcing},
          author = {C.D. Emele and T.J. Norman and Simon Parsons},
            year = {2011},
           pages = {857--864},
            note = {cited By 8},
         journal = {10th International Conference on Autonomous Agents and Multiagent Systems 2011, AAMAS 2011},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38472/}
}

@article{lincoln38470,
          volume = {26},
          number = {1},
          author = {P. Mcburney and Simon Parsons and M. Viroli},
            note = {cited By 1},
           title = {A quarter-century of the knowledge engineering review : Introduction to the special issue},
            year = {2011},
         journal = {Knowledge Engineering Review},
             doi = {10.1017/S0269888910000330},
           pages = {1--3},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38470/}
}

@inproceedings{lincoln38583,
          volume = {2},
           title = {Learning from demonstration in spatial exploration},
          author = {J.P. Munoz and A.T. Ozgelen and Elizabeth Sklar},
            year = {2011},
           pages = {1878--1879},
            note = {cited By 0},
         journal = {Proceedings of the National Conference on Artificial Intelligence},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38583/}
}

@inproceedings{lincoln38465,
          volume = {2},
           title = {Approaches to multi-robot exploration and localization},
          author = {A.T. Ozgelen and M. Costantino and A. Ishak and M. Kingston and D. Moore and S. Sanchez and J.P. Munoz and Simon Parsons and Elizabeth Sklar},
            year = {2011},
           pages = {1880--1881},
            note = {cited By 0},
         journal = {Proceedings of the National Conference on Artificial Intelligence},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38465/}
}

@article{lincoln38461,
          volume = {6614 L},
          author = {Simon Parsons and P. McBurney and Elizabeth Sklar},
            note = {cited By 4},
           title = {Reasoning about trust using argumentation: A position paper},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-21940-5},
           pages = {159--170},
            year = {2011},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38461/}
}

@article{lincoln38473,
          volume = {43},
          number = {2},
          author = {Simon Parsons and J.A. Rodriguez-Aguilar and M. Klein},
            note = {cited By 86},
           title = {Auctions and bidding: A guide for computer scientists},
         journal = {ACM Computing Surveys},
             doi = {10.1145/1883612.1883617},
            year = {2011},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38473/}
}

@inproceedings{lincoln38468,
          volume = {SS-11-},
           title = {A simple logical approach to reasoning with and about trust},
          author = {Simon Parsons and Elizabeth Sklar and P. McBurney},
            year = {2011},
           pages = {160--163},
            note = {cited By 1},
         journal = {AAAI Spring Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38468/}
}

@article{lincoln38467,
          volume = {6814 L},
          author = {Simon Parsons and Y. Tang and K. Cai and Elizabeth Sklar and P. McBurney},
            note = {cited By 0},
           title = {Some thoughts on using argumentation to handle trust},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-22359-4},
           pages = {1--12},
            year = {2011},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38467/}
}

@inproceedings{lincoln38475,
          volume = {2},
           title = {Argumentation-based reasoning in agents with varying degrees of trust},
          author = {Simon Parsons and Y. Tang and Elizabeth Sklar and P. McBurney and K. Cai},
            year = {2011},
           pages = {825--832},
            note = {cited By 24},
         journal = {10th International Conference on Autonomous Agents and Multiagent Systems 2011, AAMAS 2011},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38475/}
}

@article{lincoln38588,
          volume = {6532 L},
          author = {J. Salvit and Elizabeth Sklar},
            note = {cited By 6},
           title = {Toward a Myers-Briggs type indicator model of agent behavior in multiagent teams},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-18345-4},
           pages = {28--43},
            year = {2011},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38588/}
}

@inproceedings{lincoln38469,
          volume = {SS-11-},
           title = {A framework in which robots and humans help each other},
          author = {Elizabeth Sklar and S.L. Epstein and Simon Parsons and A.T. Ozgelen and J.P. Munoz and J. Gonzalez},
            year = {2011},
           pages = {54--59},
            note = {cited By 4},
         journal = {AAAI Spring Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38469/}
}

@inproceedings{lincoln38466,
           title = {Using semi-parametric clustering applied to electronic health record time series data},
          author = {S. Tamang and Simon Parsons},
            year = {2011},
           pages = {72--75},
             doi = {10.1145/2023582.2023596},
            note = {cited By 4},
         journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38466/}
}

@inproceedings{lincoln38474,
          volume = {2},
           title = {Probabilistic hierarchical planning over MDPs},
          author = {Y. Tang and F. Meneguzzi and K. Sycara and Simon Parsons},
            year = {2011},
           pages = {1075--1076},
            note = {cited By 3},
         journal = {10th International Conference on Autonomous Agents and Multiagent Systems 2011, AAMAS 2011},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38474/}
}

@article{lincoln38462,
          volume = {6614 L},
          author = {Y. Tang and T.J. Norman and Simon Parsons},
            note = {cited By 0},
           title = {Computing argumentation in polynomial number of BDD operations: A preliminary report},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-21940-5},
           pages = {268--285},
            year = {2011},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38462/}
}

@inproceedings{lincoln9709,
           month = {December},
          author = {K. Harmer and Shigang Yue and Kun Guo and Karen Adams and Andrew Hunter},
       booktitle = {2010 International Conference of Soft Computing and Pattern Recognition},
           title = {Automatic blush detection in "concealed information" test using visual stimuli},
       publisher = {IEEE / Institute of Electrical and Electronics Engineers Incorporated},
             doi = {10.1109/SOCPAR.2010.5686076},
           pages = {259--264},
            year = {2010},
        keywords = {ARRAY(0x5568fba48fd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/9709/},
        abstract = {Blushing has been identified as an indicator of deception, shame, anxiety and embarrassment. Although normally associated with the skin coloration of the face, a blush response also affects skin surface temperature. In this paper, an approach to detect a blush response automatically is presented using the Argus P7225 thermal camera from e2v. The algorithm was tested on a sample population of 51 subjects, while using visual stimuli to elicit a response, and achieved recognition rates of {\texttt{\char126}}77\% TPR and {\texttt{\char126}}60\% TNR.}
}

@inproceedings{lincoln8321,
           month = {December},
          author = {S. Gieselmann and Marc Hanheide and B. Wrede},
            note = {Conference Code: 83761},
       booktitle = {Conference of 2010 10th IEEE-RAS International Conference on Humanoid Robots, Humanoids 2010},
           title = {Remembering interaction episodes: an unsupervised learning approach for a humanoid robot},
         address = {Nashville, TN},
       publisher = {IEEE},
            year = {2010},
         journal = {2010 10th IEEE-RAS International Conference on Humanoid Robots, Humanoids 2010},
             doi = {10.1109/ICHR.2010.5686297},
           pages = {566--571},
        keywords = {ARRAY(0x5568fba3ae90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8321/},
        abstract = {In this paper we will present a new approach to give a robot the capability to recognize already seen people and to remember details about past interactions. These details are time, length, location(GPS) and involved people of one interaction. Furthermore all features of this system work unsupervised. This means that the robot itself decides e.g. when and which person is important to remember or when an interaction starts. Out of these collected data additional information can be learned. For example a social network is build up which contains how often different people were seen together in the same interaction. {\^A}{\copyright}2010 IEEE.}
}

@article{lincoln6699,
          volume = {2},
          number = {4},
           month = {December},
          author = {Jeremy L. Wyatt and Alper Aydemir and Michael Brenner and Marc Hanheide and Nick Hawes and Patric Jensfelt and Matej Kristan and Geert-Jan M. Kruijff and Pierre Lison and Andrzej Pronobis and Kristoffer Sjoo and Alen Vrecko and Hendrik Zender and Michael Zillich and Danijel Skocaj},
            note = {There are many different approaches to building a system that can engage in autonomous mental development. In this paper we present an approach based on what we term em self-understanding, by which we mean the use of explicit representation of and reasoning about what a system does and doesn't know, and how that understanding changes under action. We present a coherent architecture and a set of representations used in two robot systems that exhibit a limited degree of autonomous mental development, what we term em self-extension. The contributions include: representations of gaps and uncertainty for specific kinds of knowledge, and a motivational and planning system for setting and achieving learning goals},
           title = {Self-understanding and self-extension: a systems and representational approach},
       publisher = {IEEE},
            year = {2010},
         journal = {Autonomous Mental Development, IEEE Transactions on},
             doi = {10.1109/TAMD.2010.2090149},
           pages = {282--303},
        keywords = {ARRAY(0x5568fbb083a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6699/},
        abstract = {There are many different approaches to building a system that can engage in autonomous mental development. In this paper we present an approach based on what we term em self-understanding, by which we mean the use of explicit representation of and reasoning about what a system does and doesn't know, and how that understanding changes under action. We present a coherent architecture and a set of representations used in two robot systems that exhibit a limited degree of autonomous mental development, what we term em self-extension. The contributions include: representations of gaps and uncertainty for specific kinds of knowledge, and a motivational and planning system for setting and achieving learning goals}
}

@inproceedings{lincoln46208,
       booktitle = {2010 3rd IEEE RAS \& EMBS International Conference on Biomedical Robotics and Biomechatronics},
           month = {November},
           title = {Study and fabrication of bioinspired Octopus arm mockups tested on a multipurpose platform},
          author = {Marcello Calisti and Andrea Arienti and Maria Elena Giannaccini and Maurizio Follador and Michele Giorelli and Matteo Cianchetti and Barbara Mazzolai and Cecilia Laschi and Paolo Dario},
            year = {2010},
           pages = {461--466},
             doi = {10.1109/BIOROB.2010.5625959},
        keywords = {ARRAY(0x5568fb6d48b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46208/},
        abstract = {This paper illustrates a robotic approach to the study of the Octopus vulgaris arm. On the base of the embodied intelligence theory, a study on the interaction among materials, mechanisms and actuation systems has been conducted. Starting from the observation of the performances of the octopus and drawing inspiration by its functional anatomy, several mock-ups, made by different materials and actuated by different cable arrangements have been tested. For this purpose a versatile platform has been designed and built, where the various solutions have been mounted and compared. The final aim of the work is to replicate the main complex movements of the octopus in a robotic platform. In particular the reaching movement, which best represents the stereotyped motion pattern of the octopus arm, has been reproduced.}
}

@article{lincoln8317,
          volume = {6414 L},
           month = {November},
          author = {Patrick Holthaus and Ingo Lutkebohle and Marc Hanheide and Sven Wachsmuth},
            note = {Second International Conference on Social Robotics, ICSR 2010, Singapore, November 23-24, 2010. Conference Date: 23 November 2010 through 24 November 2010; Conference Code: 82714},
           title = {Can I help you? A spatial attention system for a receptionist robot},
         address = {Singapore},
       publisher = {Springer},
            year = {2010},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-17248-9},
           pages = {325--334},
        keywords = {ARRAY(0x5568fb67dbb0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8317/},
        abstract = {Social interaction between humans takes place in the spatial dimension on a daily basis. We occupy space for ourselves and respect the dynamics of spaces that are occupied by others. In human-robot interaction, the focus has been on other topics so far. Therefore, this work applies a spatial model to a humanoid robot and implements an attention system that is connected to it. The resulting behaviors have been verified in an on-line video study. The questionnaire revealed that these behaviors are applicable and result in a robot that has been perceived as more interested in the human and shows its attention and intentions to a higher degree. {\^A}{\copyright} 2010 Springer-Verlag.}
}

@inproceedings{lincoln10050,
           month = {November},
          author = {J. Li and B. Wang and Tom Duckett},
            note = {Conference Code:89095},
       booktitle = {IASTED International Conference on Robotics and Applications, RA 2010},
           title = {A data collection framework for learning from demonstration in mobile robotics},
         address = {Cambridge, MA},
       publisher = {IASTED},
            year = {2010},
             doi = {10.2316/P.2010.706-034},
           pages = {137--142},
        keywords = {ARRAY(0x5568fb9f92a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/10050/},
        abstract = {Robot learning from demonstration (LfD) requires data collection for mapping the sensory states to motion action, which plays a significant role in the learning efficiency and effectiveness. In this paper we present a data collection framework that allows a human demonstrator to teleoperate or to visually guide a mobile robot for the required behaviors, while the sensory-motor examples are simultaneously gathered. In the teleoperation mode, the human demonstrator can teleoperate the robot through a GUI that consists of the velocity control and sensory-motor recording commands with the monitoring windows for sonar, laser and visual image. In the visual-guided mode, the human demonstrator uses a green can as the command stick that is tracked by a pan-tilt-zoom (PTZ) camera. The framework is implemented on a Peoplebot robot. Experiments show that both demonstration modes of the framework provide an user-friendly interface of data collection for the subsequent learning process of the robot.}
}

@article{lincoln2315,
          volume = {114},
          number = {11},
           month = {November},
          author = {Hongying Meng and Kofi Appiah and Shigang Yue and Andrew Hunter and Mervyn Hobden and Nigel Priestley and Peter Hobden and Cy Pettit},
           title = {A modified model for the Lobula Giant Movement Detector and its FPGA implementation},
       publisher = {Elsevier},
            year = {2010},
         journal = {Computer vision and image understanding},
             doi = {10.1016/j.cviu.2010.03.017},
           pages = {1238--1247},
        keywords = {ARRAY(0x5568fba3ce80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2315/},
        abstract = {The Lobula Giant Movement Detector (LGMD) is a wide-field visual neuron located in the Lobula layer of the Locust nervous system. The LGMD increases its firing rate in response to both the velocity of an approaching object and the proximity of this object. It has been found that it can respond to looming stimuli very quickly and trigger avoidance reactions. It has been successfully applied in
visual collision avoidance systems for vehicles and robots. This paper introduces a modified neural model for LGMD that provides additional depth direction information for the movement. The proposed model retains the simplicity of the previous model by adding only a few new cells. It has been
simplified and implemented on a Field Programmable Gate Array (FPGA), taking advantage of the inherent parallelism exhibited by the LGMD, and tested on real-time video streams. Experimental results demonstrate the effectiveness as a fast motion detector.}
}

@inproceedings{lincoln3866,
       booktitle = {Workshop on Semantic Mapping and Autonomous Knowledge Acquisition},
           month = {October},
           title = {Toward an object-based semantic memory for long-term operation of mobile service robots},
          author = {Feras Dayoub and Tom Duckett and Grzegorz Cielniak},
            year = {2010},
            note = {Throughout a lifetime of operation, a mobile service robot needs to acquire, store and update its knowledge of a working environment. This includes the ability to identify and track objects in different places, as well as using this information for interaction with humans. This paper introduces a long-term updating mechanism, inspired by the modal model of human memory, to enable a mobile robot to maintain its knowledge of a changing environment. The memory model is integrated with a hybrid map that represents the global topology and local geometry of the environment, as well as the respective 3D location of objects. We aim to enable the robot to use this knowledge to help humans by suggesting the most likely locations of specific objects in its map. An experiment using omni-directional vision demonstrates the ability to track the movements of several objects in a dynamic environment over an extended period of time.},
        keywords = {ARRAY(0x5568fba87e40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/3866/},
        abstract = {Throughout a lifetime of operation, a mobile service robot needs to acquire, store and update its knowledge of a working environment. This includes the ability to identify and track objects in different places, as well as using this information for interaction with humans. This paper introduces a long-term updating mechanism, inspired by the modal model of human memory, to enable a mobile robot to maintain its knowledge of a changing environment. The memory model is integrated with a hybrid map that represents the global topology and local geometry of the environment, as well as the respective 3D location of objects. We aim to enable the robot to use this knowledge to help humans by suggesting the most likely locations of specific objects in its map. An experiment using omni-directional vision demonstrates the ability to track the movements of several objects in a dynamic environment over an extended period of time.}
}

@inproceedings{lincoln8322,
           month = {October},
          author = {R. Golombek and S. Wrede and M. Hanheide and M. Heckmann},
            note = {cited By (since 1996) 0; Conference of 23rd IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010; Conference Date: 18 October 2010 through 22 October 2010; Conference Code: 83389},
       booktitle = {2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           title = {Learning a probabilistic self-awareness model for robotic systems},
         address = {Taipei},
            year = {2010},
         journal = {IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010 - Conference Proceedings},
             doi = {10.1109/IROS.2010.5651095},
           pages = {2745--2750},
        keywords = {ARRAY(0x5568fba19398)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8322/},
        abstract = {In order to address the problem of failure detection in the robotics domain, we present in this contribution a so-called self-awareness model, based on the system's internal data exchange and the inherent dynamics of inter-component communication. The model is strongly data driven and provides an anomaly detector for robotics systems both applicable in-situ at runtime as well as a-posteriori in post-mortem analysis. Current architectures or methods for failure detection in autonomous robots are either implementations of watch dog concepts or are based on excessive amounts of domain-specific error detection code. The approach presented in this contribution provides an avenue for the detection of more subtle anomalies originating from external sources such as the environment itself or system failures such as resource starvation. Additionally, developers are alleviated from explicitly modeling and foreseeing every exceptional situation, instead training the presented probabilistic model with the known normal modes within the specification of the robot system. As we developed and evaluated the self-awareness model on a mobile robot platform featuring an event-driven software architecture, the presented method can easily be applied in other current robotics software architectures. {\^A}{\copyright}2010 IEEE.}
}

@inproceedings{lincoln10023,
          volume = {1},
           month = {October},
          author = {J. Li and A. Lilienthal and Tom Duckett},
            note = {Conference Code:82996},
       booktitle = {ICINA 2010 - 2010 International Conference on Information, Networking and Automation},
           title = {A visual-guided data collection system for learning from demonstration in mobile robotics},
         address = {Kunming},
            year = {2010},
         journal = {ICINA 2010 - 2010 International Conference on Information, Networking and Automation, Proceedings},
             doi = {10.1109/ICINA.2010.5636387},
           pages = {V1289--V1293},
        keywords = {ARRAY(0x5568fba863d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/10023/},
        abstract = {Robot learning from demonstration (LID) requires data collection for mapping the sensory states to motion action, which plays a significant role in the learning efficiency and effectiveness. This paper presents a visual-guided data collection system that allows a human demonstrator to teleoperate or to visually guide a mobile robot for the required behaviors, when simultaneously recording the sensory-motor training examples within LID. In the teleoperation mode, the human demonstrator can teleoperate the robot through a GUI that consists of the velocity control and sensory-motor recording commands with the monitoring windows for sonar, laser and visual image. In the visual-guided mode, the human demonstrator uses a green can as the command stick that is tracked by a pan-tilt-zoom (PTZ) camera. The system is implemented on a Peoplebot robot. Experiments show that both demonstration modes of the framework provide an user-friendly interface of data collection for the subsequent learning process of the robot. {\^A}{\copyright} 2010 IEEE.}
}

@inproceedings{lincoln8320,
           month = {October},
          author = {F. Yuan and L. Twardon and Marc Hanheide},
            note = {Conference Code: 83389},
       booktitle = {Conference of 23rd IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010},
           title = {Dynamic path planning adopting human navigation strategies for a domestic mobile robot},
         address = {Taipei},
       publisher = {IEEE},
            year = {2010},
         journal = {IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010 - Conference Proceedings},
             doi = {10.1109/IROS.2010.5650307},
           pages = {3275--3281},
        keywords = {ARRAY(0x5568fbb801e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8320/},
        abstract = {Mobile robots that are employed in people's homes need to safely navigate their environment. And natural human-inhabited environments still pose significant challenges for robots despite the impressive progress that has been achieved in the field of path planning and obstacle avoidance. These challenges mostly arise from the fact that (i) the perceptual abilities of a robot are limited, thus sometimes impeding its ability to see relevant obstacles (e.g. transparent objects), and (ii) the environment is highly dynamic being populated by humans. In this contribution we are making a case for an integrated solution to these challenges that builds upon the analysis and use of implicit human knowledge in path planning and a cascade of replanning approaches. We combine state of the art path planning and obstacle avoidance algorithms with the knowledge about how humans navigate in their very own environment. The approach results in a more robust and predictable navigation ability for domestic robots as is demonstrated in a number of experimental runs. {\^A}{\copyright}2010 IEEE.}
}

@inproceedings{lincoln5517,
           month = {September},
          author = {Michael Barnes and Grzegorz Cielniak and Tom Duckett},
            note = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
Volume 6374 LNCS, Issue PART 1, 2010, Pages 209-216},
       booktitle = {International Conference on Computer Vision and Graphics 2010},
           title = {Minimalist AdaBoost for blemish identification
in potatoes},
       publisher = {Springer},
            year = {2010},
             doi = {10.1007/978-3-642-15910-7\_23},
           pages = {209--216},
        keywords = {ARRAY(0x5568fbae1f90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/5517/},
        abstract = {We present a multi-class solution based on minimalist Ad-
aBoost for identifying blemishes present in visual images of potatoes.
Using training examples we use Real AdaBoost to rst reduce the fea-
ture set by selecting ve features for each class, then train binary clas-
siers for each class, classifying each testing example according to the
binary classier with the highest certainty. Against hand-drawn ground
truth data we achieve a pixel match of 83\% accuracy in white potatoes
and 82\% in red potatoes. For the task of identifying which blemishes
are present in each potato within typical industry dened criteria (10\%
coverage) we achieve accuracy rates of 93\% and 94\%, respectively.}
}

@inproceedings{lincoln3865,
       booktitle = {11th Conference Towards Autonomous Robotic Systems (TAROS'2010)},
           month = {September},
           title = {A vision-guided parallel parking system for a mobile robot using approximate policy iteration},
          author = {Marwan Shaker and Tom Duckett and Shigang Yue},
            year = {2010},
            note = {Reinforcement Learning (RL) methods enable autonomous robots to learn skills from scratch by interacting with the environment. However, reinforcement learning can be very time consuming. This paper focuses on accelerating the reinforcement learning process on a mobile robot in an unknown environment. The presented algorithm is based on approximate policy iteration with a continuous state space and a fixed number of actions. The action-value function is represented by a weighted combination of basis functions.
Furthermore, a complexity analysis is provided to show that the implemented approach is guaranteed to converge on an optimal policy with less computational time.
A parallel parking task is selected for testing purposes. In the experiments, the efficiency of the proposed approach is demonstrated and analyzed through a set of simulated and real robot experiments, with comparison drawn from two well known algorithms (Dyna-Q and Q-learning).},
        keywords = {ARRAY(0x5568fb96a1b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/3865/},
        abstract = {Reinforcement Learning (RL) methods enable autonomous robots to learn skills from scratch by interacting with the environment. However, reinforcement learning can be very time consuming. This paper focuses on accelerating the reinforcement learning process on a mobile robot in an unknown environment. The presented algorithm is based on approximate policy iteration with a continuous state space and a fixed number of actions. The action-value function is represented by a weighted combination of basis functions.
Furthermore, a complexity analysis is provided to show that the implemented approach is guaranteed to converge on an optimal policy with less computational time.
A parallel parking task is selected for testing purposes. In the experiments, the efficiency of the proposed approach is demonstrated and analyzed through a set of simulated and real robot experiments, with comparison drawn from two well known algorithms (Dyna-Q and Q-learning).}
}

@article{lincoln37432,
          volume = {14},
          number = {5},
           month = {August},
          author = {C. Saaj and V. Lappas and H. Schaub and D. Izzo},
            note = {cited By 12},
           title = {Hybrid propulsion system for formation flying using electrostatic forces},
       publisher = {Elsevier},
            year = {2010},
         journal = {Aerospace Science and Technology},
             doi = {10.1016/j.ast.2010.02.009},
           pages = {348--355},
        keywords = {ARRAY(0x5568fbb99180)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37432/},
        abstract = {Propulsion, path planning and control of spacecraft formations in Geostationary Earth Orbit (GEO) and other high Earth orbits present significant challenges to engineers. An innovative hybrid propulsion system for close-proximity ({\ensuremath{<}}50 m) formation flying is presented using electrostatic forces and standard electric/ion thrusters. The Sliding Mode Control (SMC) strategy generates the required inter-spacecraft forces based on the equivalent product of spacecraft surface charges. Collision-free aggregation and formation is realized using the Artificial Potential Field (APF) method. Simulation is performed to prove the efficacy of the proposed control, path planning and hybrid actuation schemes for close-proximity spacecraft formation flying in GEO and other high Earth orbits.}
}

@inproceedings{lincoln3867,
       booktitle = {International Symposium on Learning and Adaptive Behaviour in Robotics Systems (LAB-RS 2010)},
           month = {August},
           title = {Vision-based landing of a simulated unmanned aerial vehicle with fast reinforcement learning},
          author = {Marwan Shaker and Mark N. R. Smith and Shigang Yue and Tom Duckett},
            year = {2010},
             doi = {10.1109/EST.2010.14},
            note = {Also: Emerging Security Technologies (EST), 2010 International Conference on},
        keywords = {ARRAY(0x5568fb966868)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/3867/},
        abstract = {Landing is one of the difficult challenges for an unmanned
aerial vehicle (UAV). In this paper, we propose a vision-based landing approach for an autonomous UAV using reinforcement learning (RL). The autonomous UAV learns the landing skill from scratch by interacting with the environment. The reinforcement learning algorithm explored and extended in this study is Least-Squares Policy Iteration (LSPI) to gain a fast learning process and a smooth landing trajectory. The proposed approach has been tested with a simulated quadrocopter in an extended version of the USARSim Unified System for Automation and Robot Simulation) environment. Results showed that LSPI learned the landing skill very quickly, requiring less than 142 trials.}
}

@inproceedings{lincoln8319,
          volume = {WS-10-},
           month = {July},
          author = {N. Hawes and Marc Hanheide},
            note = {Conference Code: 85345},
       booktitle = {Conference of 2010 AAAI Workshop; Conference},
           title = {CAST: Middleware for memory-based architecture},
         address = {Atlanta, GA},
       publisher = {AAAI - Association for the Advancement of Artificial Intelligence},
            year = {2010},
         journal = {AAAI Workshop - Technical Report},
           pages = {11--12},
        keywords = {ARRAY(0x5568fba05ca8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8319/},
        abstract = {.}
}

@inproceedings{lincoln6913,
           month = {June},
          author = {Christian Lang and Sven Wachsmuth and Heiko Wersing and Marc Hanheide},
            note = {Facial expressions are one important nonverbal communication cue, as they can provide feedback in conversations between people and also in human-robot interaction. This paper presents an evaluation of three standard pattern recognition techniques (active appearance models, gabor energy filters, and raw images) for facial feedback interpretation in terms of valence (success and failure) and compares the results to the human performance. The used database contains videos of people interacting with a robot by teaching the names of several objects to it. After teaching, the robot should term the objects correctly. The subjects reacted to its answer while showing spontaneous facial expressions, which were classified in this work. One main result is that an automatic classification of facial expressions in terms of valence using simple standard pattern recognition techniques is possible with an accuracy comparable to the average human classification rate, but with a high variance between different subjects, likewise to the human performance.},
       booktitle = {Proc. IEEE Computer Society Conf. Computer Vision and Pattern Recognition Workshops (CVPRW)},
          editor = {B. Gottfried and H. Aghajan},
           title = {Facial expressions as feedback cue in human-robot interaction - a comparison between human and automatic recognition performances},
       publisher = {IEEE},
            year = {2010},
             doi = {10.1109/CVPRW.2010.5543264},
           pages = {79--85},
        keywords = {ARRAY(0x5568fb953cd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6913/},
        abstract = {Facial expressions are one important nonverbal communication cue, as they can provide feedback in conversations between people and also in human-robot interaction. This paper presents an evaluation of three standard pattern recognition techniques (active appearance models, gabor energy filters, and raw images) for facial feedback interpretation in terms of valence (success and failure) and compares the results to the human performance. The used database contains videos of people interacting with a robot by teaching the names of several objects to it. After teaching, the robot should term the objects correctly. The subjects reacted to its answer while showing spontaneous facial expressions, which were classified in this work. One main result is that an automatic classification of facial expressions in terms of valence using simple standard pattern recognition techniques is possible with an accuracy comparable to the average human classification rate, but with a high variance between different subjects, likewise to the human performance.}
}

@article{lincoln2206,
          volume = {98},
          number = {3},
           month = {June},
          author = {Michael Barnes and Tom Duckett and Grzegorz Cielniak and Graeme Stroud and Glyn Harper},
            note = {This paper introduces novel methods for detecting blemishes in potatoes using machine vision. After segmentation of the potato from the background, a pixel-wise classifier is trained to detect blemishes using features extracted from the image.
A very large set of candidate features, based on statistical information relating to the colour and texture of the region surrounding a given pixel, is first extracted.
Then an adaptive boosting algorithm (AdaBoost) is used to automatically select the best features for discriminating between blemishes and non-blemishes.
With this approach, different features can be selected for different potato varieties, while also handling the natural variation in fresh produce due to different seasons, lighting conditions, etc.
The results show that the method is able to build ``minimalist'' classifiers that optimise detection performance at low computational cost.
In experiments, blemish detectors were trained for both white and red potato varieties, achieving 89.6{$\backslash$}\% and 89.5{$\backslash$}\% accuracy, respectively.},
           title = {Visual detection of blemishes in potatoes using minimalist boosted classifiers},
       publisher = {Elsevier},
            year = {2010},
         journal = {Journal of Food Engineering},
             doi = {10.1016/j.jfoodeng.2010.01.010},
           pages = {339--346},
        keywords = {ARRAY(0x5568fbbb7bc0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2206/},
        abstract = {This paper introduces novel methods for detecting blemishes in potatoes using machine vision. After segmentation of the potato from the background, a pixel-wise classifier is trained to detect blemishes using features extracted from the image.
A very large set of candidate features, based on statistical information relating to the colour and texture of the region surrounding a given pixel, is first extracted.
Then an adaptive boosting algorithm (AdaBoost) is used to automatically select the best features for discriminating between blemishes and non-blemishes.
With this approach, different features can be selected for different potato varieties, while also handling the natural variation in fresh produce due to different seasons, lighting conditions, etc.
The results show that the method is able to build ``minimalist'' classifiers that optimise detection performance at low computational cost.
In experiments, blemish detectors were trained for both white and red potato varieties, achieving 89.6{$\backslash$}\% and 89.5{$\backslash$}\% accuracy, respectively.}
}

@article{lincoln2566,
          volume = {2},
          number = {2},
           month = {June},
          author = {Nicola Bellotto and Huosheng Hu},
            note = {A new generation of mobile service robots could be ready soon to operate in human environments if they can robustly estimate position and identity of surrounding people. Researchers in this field face a number of challenging problems, among which sensor uncertainties and real-time constraints.
In this paper, we propose a novel and efficient solution for simultaneous tracking and recognition of people within the observation range of a mobile robot. Multisensor techniques for legs and face detection are fused in a robust probabilistic framework to height, clothes and face recognition algorithms. The system is based on an efficient bank of Unscented Kalman Filters that keeps a multi-hypothesis estimate of the person being tracked, including the case where the latter is unknown to the robot.
Several experiments with real mobile robots are presented to validate the proposed approach. They show that our solutions can improve the robot's perception and recognition of humans, providing a useful contribution for the future application of service robotics.},
           title = {A bank of unscented Kalman filters for multimodal human perception with mobile service robots},
       publisher = {Springer},
            year = {2010},
         journal = {International Journal of Social Robotics},
             doi = {10.1007/s12369-010-0047-x},
           pages = {121--136},
        keywords = {ARRAY(0x5568fbb874e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2566/},
        abstract = {A new generation of mobile service robots could be ready soon to operate in human environments if they can robustly estimate position and identity of surrounding people. Researchers in this field face a number of challenging problems, among which sensor uncertainties and real-time constraints.
In this paper, we propose a novel and efficient solution for simultaneous tracking and recognition of people within the observation range of a mobile robot. Multisensor techniques for legs and face detection are fused in a robust probabilistic framework to height, clothes and face recognition algorithms. The system is based on an efficient bank of Unscented Kalman Filters that keeps a multi-hypothesis estimate of the person being tracked, including the case where the latter is unknown to the robot.
Several experiments with real mobile robots are presented to validate the proposed approach. They show that our solutions can improve the robot's perception and recognition of humans, providing a useful contribution for the future application of service robotics.}
}

@inproceedings{lincoln8323,
           month = {June},
          author = {C. Lang and S. Wachsmuth and H. Wersing and Marc Hanheide},
            note = {Conference Code: 81678},
       booktitle = {Conference of 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, CVPRW 2010},
           title = {Facial expressions as feedback cue in human-robot interaction: a comparison between human and automatic recognition performances},
         address = {San Francisco, CA},
            year = {2010},
         journal = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, CVPRW 2010},
             doi = {10.1109/CVPRW.2010.5543264},
           pages = {79--85},
        keywords = {ARRAY(0x5568fb9dccc0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8323/},
        abstract = {Facial expressions are one important nonverbal communication cue, as they can provide feedback in conversations between people and also in human-robot interaction. This paper presents an evaluation of three standard pattern recognition techniques (active appearance models, gabor energy filters, and raw images) for facial feedback interpretation in terms of valence (success and failure) and compares the results to the human performance. The used database contains videos of people interacting with a robot by teaching the names of several objects to it. After teaching, the robot should term the objects correctly. The subjects reacted to its answer while showing spontaneous facial expressions, which were classified in this work. One main result is that an automatic classification of facial expressions in terms of valence using simple standard pattern recognition techniques is possible with an accuracy comparable to the average human classification rate, but with a high variance between different subjects, likewise to the human performance. {\^A}{\copyright} 2010 IEEE.}
}

@article{lincoln2277,
          volume = {58},
          number = {5},
           month = {May},
          author = {Grzegorz Cielniak and Tom Duckett and Achim J. Lilienthal},
           title = {Data association and occlusion handling for vision-based people tracking by mobile robots},
       publisher = {Elsevier B.V.},
            year = {2010},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2010.02.004},
           pages = {435--443},
        keywords = {ARRAY(0x5568fb9f11c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2277/},
        abstract = {This paper presents an approach for tracking multiple persons on a mobile robot with a combination of colour and thermal vision sensors, using several new techniques. First, an adaptive colour model is incorporated into the measurement model of the tracker. Second, a new approach for detecting occlusions is introduced, using a machine learning classifier for pairwise comparison of persons (classifying which one is in front of the other). Third, explicit occlusion handling is incorporated into the tracker. The paper presents a comprehensive, quantitative evaluation of the whole system and its different components using several real world data sets.}
}

@article{lincoln2286,
          volume = {28},
          number = {4},
           month = {May},
          author = {Nicola Bellotto and Huosheng Hu},
           title = {Computationally efficient solutions for tracking people with a mobile robot: an experimental evaluation of Bayesian filters},
       publisher = {Springer},
            year = {2010},
         journal = {Autonomous Robots},
             doi = {10.1007/s10514-009-9167-2},
           pages = {425--438},
        keywords = {ARRAY(0x5568fbb58ea0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2286/},
        abstract = {Modern service robots will soon become an essential part of modern society. As they have to move and act in human environments, it is essential for them to be provided with a fast and reliable tracking system that localizes people in the neighbourhood. It is therefore important to select the most appropriate filter to estimate the position of these persons.
This paper presents three efficient implementations of multisensor-human tracking based on different Bayesian estimators: Extended Kalman Filter (EKF), Unscented Kalman Filter (UKF) and Sampling Importance Resampling (SIR) particle filter. The system implemented on a mobile robot is explained, introducing the methods used to detect and estimate the position of multiple people. Then, the solutions based on the three filters are discussed in detail. Several real experiments are conducted to evaluate their performance, which is compared in terms of accuracy, robustness and execution time of the estimation. The results show that a solution based on the UKF can perform as good as particle filters and can be often a better choice when computational efficiency is a key issue.}
}

@article{lincoln22208,
          volume = {24},
          number = {2},
           month = {April},
          author = {Heriberto Cuayahuitl and Steve Renals and Oliver Lemon and Hiroshi Shimodaira},
           title = {Evaluation of a hierarchical reinforcement learning spoken dialogue system},
       publisher = {Elsevier for International Speech Communication Association (ISCA)},
            year = {2010},
         journal = {Computer Speech \& Language},
             doi = {10.1016/j.csl.2009.07.001},
           pages = {395--429},
        keywords = {ARRAY(0x5568fb6790d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22208/},
        abstract = {We describe an evaluation of spoken dialogue strategies designed using hierarchical reinforcement learning agents. The dialogue strategies were learnt in a simulated environment and tested in a laboratory setting with 32 users. These dialogues were used to evaluate three types of machine dialogue behaviour: hand-coded, fully-learnt and semi-learnt. These experiments also served to evaluate the realism of simulated dialogues using two proposed metrics contrasted with ?Precision-Recall?. The learnt dialogue behaviours used the Semi-Markov Decision Process (SMDP) model, and we report the first evaluation of this model in a realistic conversational environment. Experimental results in the travel planning domain provide evidence to support the following claims: (a) hierarchical semi-learnt dialogue agents are a better alternative (with higher overall performance) than deterministic or fully-learnt behaviour; (b) spoken dialogue strategies learnt with highly coherent user behaviour and conservative recognition error rates (keyword error rate of 20\%) can outperform a reasonable hand-coded strategy; and (c) hierarchical reinforcement learning dialogue agents are feasible and promising for the (semi) automatic design of optimized dialogue behaviours in larger-scale systems.}
}

@inproceedings{lincoln10036,
           month = {March},
          author = {Feras Dayoub and Tom Duckett and Grzegorz Cielniak},
            note = {cConference of org.apache.xalan.xsltc.dom.DOMAdapter@47716bee ; Conference Date: org.apache.xalan.xsltc.dom.DOMAdapter@6764fae6 Through org.apache.xalan.xsltc.dom.DOMAdapter@16944712; Conference Code:90743},
       booktitle = {International Symposium on Remembering Who We Are - Human Memory for Artificial Agents - A Symposium at the AISB 2010 Convention},
         address = {Leicester},
           title = {Short- and long-term adaptation of visual place memories for mobile robots},
            year = {2010},
         journal = {Proceedings of the International Symposium on Remembering Who We Are - Human Memory for Artificial Agents - A Symposium at the AISB 2010 Convention},
           pages = {21--26},
        keywords = {ARRAY(0x5568fbb701e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/10036/},
        abstract = {This paper presents a robotic implementation of a human-inspired memory model for long-term adaptation of spatial maps for navigation in changing environments. The robot uses an appearance-based representation of its workplace as a map, where the current view and the map are used to estimate the robots current position in the environment. Due to the nature of real-world environments such as houses and offices, where the appearance keeps changing, the map may become out of date after some time. To solve this problem the robot needs to adapt the map continually in response to the changing appearance of the environment. In this work we use local features extracted from panoramic images to represent the appearance of the environment. Adopting concepts of short-term and long-term memory, our method updates the group of feature points for the image representation of a particular place. Experiments using robot sensor data collected over a period of 2 months show that the implemented model is able to adapt successfully to changes.}
}

@inproceedings{lincoln6295,
       booktitle = {The Thirty Sixth Annual Convention of the Society for the Study of Artificial Intelligence and Simulation of Behaviour (AISB{\"i}??10)},
           month = {March},
           title = {Group emotion modelling and the use of middleware for virtual crowds in video-games},
          author = {Oliver Szymanezyk and Grzegorz Cielniak},
       publisher = {AISB Daniela M. Romano and David C. Moffat},
            year = {2010},
            note = {In this paper we discuss the use of crowd
simulation in video-games to augment their realism. Using
previous works on emotion modelling and virtual crowds we
define a game world in an urban context. To achieve that, we
explore a biologically inspired human emotion model,
investigate the formation of groups in crowds, and examine
the use of physics middleware for crowds. Furthermore, we
assess the realism and computational performance of the
proposed approach. Our system runs at interactive frame-rate
and can generate large crowds which demonstrate complex
behaviour.},
        keywords = {ARRAY(0x5568fbbc2cb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6295/},
        abstract = {In this paper we discuss the use of crowd
simulation in video-games to augment their realism. Using
previous works on emotion modelling and virtual crowds we
define a game world in an urban context. To achieve that, we
explore a biologically inspired human emotion model,
investigate the formation of groups in crowds, and examine
the use of physics middleware for crowds. Furthermore, we
assess the realism and computational performance of the
proposed approach. Our system runs at interactive frame-rate
and can generate large crowds which demonstrate complex
behaviour.}
}

@inproceedings{lincoln29371,
           month = {March},
          author = {Salih Ozgur Oguz and Ayse Kucukyilmaz and Tevfik Metin Sezgin and Cagatay Basdogan},
       booktitle = {IEEE Haptics Symposium 2010},
           title = {Haptic negotiation and role exchange for collaboration in virtual environments},
       publisher = {IEEE},
             doi = {10.1109/HAPTIC.2010.5444628},
           pages = {371--378},
            year = {2010},
        keywords = {ARRAY(0x5568fba72568)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29371/},
        abstract = {We investigate how collaborative guidance can be realized in multi-modal virtual environments for dynamic tasks involving motor control. Haptic guidance in our context can be defined as any form of force/tactile feedback that the computer generates to help a user execute a task in a faster, more accurate, and subjectively more pleasing fashion. In particular, we are interested in determining guidance mechanisms that best facilitate task performance and arouse a natural sense of collaboration. We suggest that a haptic guidance system can be further improved if it is supplemented with a role exchange mechanism, which allows the computer to adjust the forces it applies to the user in response to his/her actions. Recent work on collaboration and role exchange presented new perspectives on defining roles and interaction. However existing approaches mainly focus on relatively basic environments where the state of the system can be defined with a few parameters. We designed and implemented a complex and highly dynamic multimodal game for testing our interaction model. Since the state space of our application is complex, role exchange needs to be implemented carefully. We defined a novel negotiation process, which facilitates dynamic communication between the user and the computer, and realizes the exchange of roles using a three-state finite state machine. Our preliminary results indicate that even though the negotiation and role exchange mechanism we adopted does not improve performance in every evaluation criteria, it introduces a more personal and human-like interaction model.}
}

@inproceedings{lincoln39651,
       booktitle = {International Conference on Control, Communication and Computing, Trivandrum},
           month = {February},
           title = {Collision Avoidance and Control of Multi-Agent Systems},
          author = {H. Ibrahim and C.M. Saaj},
            year = {2010},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39651/}
}

@article{lincoln2669,
          volume = {28},
          number = {2},
           month = {February},
          author = {Shigang Yue and Roger D. Santer and Yoshifumi Yamawaki and F. Claire Rind},
           title = {Reactive direction control for a mobile robot: A locust-like control of escape direction emerges when a bilateral pair of model locust visual neurons are integrated},
       publisher = {Springer Verlag},
            year = {2010},
         journal = {Autonomous Robots},
             doi = {10.1007/s10514-009-9157-4},
           pages = {151--167},
        keywords = {ARRAY(0x5568fba14250)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2669/},
        abstract = {Locusts possess a bilateral pair of uniquely identifiable visual neurons that respond vigorously to
the image of an approaching object. These neurons are called the lobula giant movement
detectors (LGMDs). The locust LGMDs have been extensively studied and this has lead to the
development of an LGMD model for use as an artificial collision detector in robotic applications.
To date, robots have been equipped with only a single, central artificial LGMD sensor, and this
triggers a non-directional stop or rotation when a potentially colliding object is detected. Clearly,
for a robot to behave autonomously, it must react differently to stimuli approaching from
different directions. In this study, we implement a bilateral pair of LGMD models in Khepera
robots equipped with normal and panoramic cameras. We integrate the responses of these LGMD
models using methodologies inspired by research on escape direction control in cockroaches.
Using ?randomised winner-take-all? or ?steering wheel? algorithms for LGMD model integration,
the khepera robots could escape an approaching threat in real time and with a similar
distribution of escape directions as real locusts. We also found that by optimising these
algorithms, we could use them to integrate the left and right DCMD responses of real jumping
locusts offline and reproduce the actual escape directions that the locusts took in a particular
trial. Our results significantly advance the development of an artificial collision detection and
evasion system based on the locust LGMD by allowing it reactive control over robot behaviour.
The success of this approach may also indicate some important areas to be pursued in future
biological research.}
}

@article{lincoln38481,
          volume = {31},
          number = {1},
          author = {R. Azevedo and T. Bench-Capon and G. Biswas and T. Carmichael and N. Green and M. Hadzikadic and O. Koyejo and U. Kurup and Simon Parsons and R. Pirrone and H. Prakken and A. Samsonovich and D. Scott and R. Souvenir},
            note = {cited By 1},
           title = {Reports on the AAAI 2009 fall symposia},
            year = {2010},
         journal = {AI Magazine},
             doi = {10.1609/aimag.v31i1.2289},
           pages = {88--94},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38481/}
}

@inproceedings{lincoln37417,
          volume = {7},
          author = {S. Bandyopadhyay and C. Saaj and B. Bandyopadhyay},
            note = {cited By 1},
       booktitle = {61st International Astronautical Congress 2010},
           title = {Development of sliding mode controller for small satellite in planetary orbital environment formation flying missions},
       publisher = {International Astronautical Federation},
            year = {2010},
         journal = {61st International Astronautical Congress 2010, IAC 2010},
           pages = {5992--5998},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37417/}
}

@article{lincoln38480,
          volume = {44 LNB},
          author = {K. Cai and J. Niu and Simon Parsons},
            note = {cited By 4},
           title = {On the economic effects of competition between double auction markets},
         journal = {Lecture Notes in Business Information Processing},
             doi = {10.1007/978-3-642-15237-5},
           pages = {88--102},
            year = {2010},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38480/}
}

@article{lincoln38479,
          volume = {40},
          number = {3},
          author = {S. Phelps and P. McBurney and Simon Parsons},
            note = {cited By 5},
           title = {A novel method for strategy acquisition and its application to a double-auction market game},
            year = {2010},
         journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
             doi = {10.1109/TSMCB.2009.2034731},
           pages = {668--674},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38479/}
}

@inproceedings{lincoln38478,
          volume = {WS-10-},
           title = {Developing a framework for team-based robotics research},
          author = {Elizabeth Sklar and Simon Parsons and S. Epstein and A.T. Ozgelen and G. Rabanca and S. Anzaroot and J. Gonzalez and J. Lopez and M. Lustig and L. Ma and M. Manashiro and J.P. Munoz and S.B. Salazar and M. Schwartz},
            year = {2010},
           pages = {25--26},
            note = {cited By 2},
         journal = {AAAI Workshop - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38478/}
}

@article{lincoln38591,
          volume = {25},
          number = {2},
          author = {Elizabeth Sklar and D. Richards},
            note = {cited By 16},
           title = {Agent-based systems for human learners},
            year = {2010},
         journal = {Knowledge Engineering Review},
             doi = {10.1017/S0269888910000044},
           pages = {111--135},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38591/}
}

@article{lincoln38476,
          volume = {6057 L},
          author = {Y. Tang and T.J. Norman and Simon Parsons},
            note = {cited By 7},
           title = {A model for integrating dialogue and the execution of joint plans},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-12805-9},
           pages = {60--78},
            year = {2010},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38476/}
}

@inproceedings{lincoln37431,
          volume = {8},
          author = {B. Yeomans and S. Murton and B. Smith and C. Saaj},
            note = {cited By 0},
       booktitle = {61st International Astronautical Congress},
           title = {Biologically inspired nanorovers - Sample return using lightweight hybrid actuation},
       publisher = {International Astronautical Federation},
            year = {2010},
         journal = {61st International Astronautical Congress 2010, IAC 2010},
           pages = {6820--6831},
        keywords = {ARRAY(0x5568fbaeda18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37431/},
        abstract = {This paper describes further progress in the design of a low mass, biologically inspired nanorover suitable for Mars surface exploration and sample return missions. An advanced legged vehicle is presented, incorporating a hybrid DC motor and Shape Memory Alloy (SMA) actuation system to minimise mass and conserve power. Previous work demonstrated that an ultra low mass vehicle could be designed using composite materials. Innovations in this new design include hybrid lightweight DC motor / SMA technology for high power / mass ratio whilst minimising power use, and steps to achieve proportional control of both DC motors and SMA actuators, although work on this area continues in order to resolve problems with proportional control of SMA. Agility is improved using legs with increased angular displacement, which facilitates attitude control over steep and uneven landscapes and enables implementation of biologicallyinspired locomotion techniques such as crawling and sideways walking, and adding a third degree of freedom which allows the rover to display an extensive array of gait and pose options. System control applies embedded systems technology running a Linux operating system, force sensors are installed on each leg to provide feedback of terrain interaction for gait management purposes, and power storage capacity and efficiency are improved, enabling the vehicle to carry sufficient power reserves for meaningful excursion durations. The vehicle incorporates an innovative lightweight sample collection arm which uses two servo motors and two SMA actuators. This allows it to collect approximately 2cm 3 of sample. Mass is minimised by using a combination of aluminium and Carbon Fibre Reinforced Polymer (CFRP). Total system mass is less than 1 kg, offering the opportunity for a swarm of rovers to form part of the overall Mars mission. These vehicles would take advantage of their superior agility and ability to traverse difficult landscapes, and complement the operation of a larger wheeled mother rover the mother vehicle would carry larger scale science and navigation equipment, as well as on board power resources, whereas the smaller vehicle can be dispatched to climb through rocky and steep terrain or deep into fissures to retrieve samples from the most interesting locations, returning to the mother rover for power and to deposit the sample}
}

@inproceedings{lincoln2134,
       booktitle = {Image and Vision Computing New Zealand},
           month = {November},
           title = {Boosting minimalist classifiers for blemish detection in potatoes},
          author = {Michael Barnes and Tom Duckett and Grzegorz Cielniak},
            year = {2009},
           pages = {397--402},
            note = {This paper introduces novel methods for detecting blemishes in potatoes using machine vision. After segmentation of the potato from the background, a pixel-wise classifier is trained to detect blemishes using features extracted from the image. A very large set of candidate features, based on statistical information relating to the colour and texture of the region surrounding a given pixel, is first extracted. Then an adaptive boosting algorithm (AdaBoost) is used to automatically select the best features for discriminating between blemishes and nonblemishes.
With this approach, different features can be selected
for different potato varieties, while also handling the natural variation in fresh produce due to different seasons, lighting conditions, etc. The results show that the method is able to build ?minimalist? classifiers that optimise detection performance at low computational cost. In experiments, minimalist blemish detectors were trained for both white and red potato varieties, achieving 89.6\% and 89.5\% accuracy respectively.},
        keywords = {ARRAY(0x5568fb9b5658)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2134/},
        abstract = {This paper introduces novel methods for detecting blemishes in potatoes using machine vision. After segmentation of the potato from the background, a pixel-wise classifier is trained to detect blemishes using features extracted from the image. A very large set of candidate features, based on statistical information relating to the colour and texture of the region surrounding a given pixel, is first extracted. Then an adaptive boosting algorithm (AdaBoost) is used to automatically select the best features for discriminating between blemishes and nonblemishes.
With this approach, different features can be selected
for different potato varieties, while also handling the natural variation in fresh produce due to different seasons, lighting conditions, etc. The results show that the method is able to build ?minimalist? classifiers that optimise detection performance at low computational cost. In experiments, minimalist blemish detectors were trained for both white and red potato varieties, achieving 89.6\% and 89.5\% accuracy respectively.}
}

@incollection{lincoln6715,
          number = {5436},
           month = {November},
          author = {Britte Wrede and Katharina J. Rohlfing and Marc Hanheide and Gerhard Sagerer},
          series = {Lecture Notes in Computer Science},
            note = {Abstract},
       booktitle = {Creating brain-like intelligence: from basic principles to complex intelligent systems},
          editor = {Bernhard Sendhoff and Edgar Korner and Olaf Sporns and Helge Ritter and Kenji Doya},
           title = {Towards learning by interacting},
       publisher = {Springer},
            year = {2009},
             doi = {10.1007/978-3-642-00616-6},
        keywords = {ARRAY(0x5568fbbc2190)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6715/},
        abstract = {Abstract}
}

@inproceedings{lincoln6925,
           month = {November},
          author = {Thorsten P. Spexard and Marc Hanheide},
            note = {Abstract With robotic systems entering our daily life, they have to become more flexible and subsuming a multitude of abilities in one single integrated system. Subsequently an increased extensibility of the robots? system architectures is needed. 
The goal is to facilitate a long-time evolution of the integrated system in-line with the scientific progress on the algorithmic level. In this paper we present an approach developed for an event-driven robot architecture, focussing on the coordination and interplay of new abilities and components. Appropriate timing, sequencing strategies, execution guaranties, and process flow synchronization are taken into account to allow appropriate arbitration and interaction between components as well as between the integrated system and the user. The presented approach features dynamic reconfiguration and global coordination based on simple production rules. These are applied fist time in conjunction with flexible representations in global memory spaces and an event-driven architecture. As a result a highly adaptive robot control compared to alternative approaches is achieved, allowing system modification during runtime even within complex interactive human-robot scenarios},
       booktitle = {Conference on Human Centered Robotic Systems},
          editor = {B. Gottfried and H. Aghajan},
           title = {System integration supporting evolutionary development and design},
       publisher = {Springer},
            year = {2009},
           pages = {1--9},
        keywords = {ARRAY(0x5568fbaee108)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6925/},
        abstract = {Abstract With robotic systems entering our daily life, they have to become more flexible and subsuming a multitude of abilities in one single integrated system. Subsequently an increased extensibility of the robots? system architectures is needed. 
The goal is to facilitate a long-time evolution of the integrated system in-line with the scientific progress on the algorithmic level. In this paper we present an approach developed for an event-driven robot architecture, focussing on the coordination and interplay of new abilities and components. Appropriate timing, sequencing strategies, execution guaranties, and process flow synchronization are taken into account to allow appropriate arbitration and interaction between components as well as between the integrated system and the user. The presented approach features dynamic reconfiguration and global coordination based on simple production rules. These are applied fist time in conjunction with flexible representations in global memory spaces and an event-driven architecture. As a result a highly adaptive robot control compared to alternative approaches is achieved, allowing system modification during runtime even within complex interactive human-robot scenarios}
}

@incollection{lincoln11964,
          number = {6},
           month = {November},
          author = {Thorsten P. Spexard and Marc Hanheide},
          series = {Cognitive Systems Monographs},
       booktitle = {Human centered robot systems: cognition, interaction, technology},
           title = {System integration supporting evolutionary development and design},
       publisher = {Springer Berlin Heidelberg},
            year = {2009},
             doi = {10.1007/978-3-642-10403-9},
           pages = {1--9},
        keywords = {ARRAY(0x5568fb670d78)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/11964/},
        abstract = {With robotic systems entering our daily life, they have to become more flexible and subsuming a multitude of abilities in one single integrated system. Sub- sequently an increased extensibility of the robots? system architectures is needed. The goal is to facilitate a long-time evolution of the integrated system in-line with the scientific progress on the algorithmic level. In this paper we present an approach developed for an event-driven robot architecture, focussing on the coordination and interplay of new abilities and components. Appropriate timing, sequencing strategies, execution guaranties, and process flow synchronisation are taken into account to allow appropriate arbitration and interaction between components as well as between the integrated system and the user. The presented approach features dynamic reconfiguration and global coordination based on simple production rules. These are applied first time in conjunction with flexible representations in global memory spaces and an event-driven architecture. As a result a highly adaptive robot control compared to alternative approaches is achieved, allowing system modification during runtime even within complex interactive human-robot scenarios.}
}

@inproceedings{lincoln6922,
       booktitle = {International Conference on Multimodal interfaces - ICMI-MLMI '09},
          editor = {B. Gottfried and H. Aghajan},
           month = {November},
           title = {Mediated attention with multimodal augmented reality},
          author = {Angelika Dierker and Christian Mertes and Thomas Hermann and Marc Hanheide and Gerhard Sagerer},
            year = {2009},
        keywords = {ARRAY(0x5568fb9d06a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6922/},
        abstract = {We present an Augmented Reality (AR) system to support
collaborative tasks in a shared real-world interaction space
by facilitating joint attention. The users are assisted by information about their interaction partner's field of view both visually and acoustically. In our study, the audiovisual improvements are compared with an AR system without these support mechanisms in terms of the participants' reaction times and error rates. The participants performed a simple object-choice task we call the gaze game to ensure controlled experimental conditions. Additionally, we asked the subjects to fill in a questionnaire to gain subjective feedback from them. We were able to show an improvement for both dependent variables as well as positive feedback for the visual augmentation in the questionnaire.}
}

@article{lincoln6704,
          volume = {10},
          number = {3},
           month = {October},
          author = {Manja Lohse and Marc Hanheide and Karola Pitsch and Katharina J. Rohlfing and Gerhard Sagerer},
            note = {.},
           title = {Improving HRI design by applying systemic interaction analysis (SInA)},
       publisher = {John Benjamins Publishing},
            year = {2009},
         journal = {Interaction Studies},
             doi = {10.1075/is.10.3.03loh},
           pages = {298--303},
        keywords = {ARRAY(0x5568fba2ace8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6704/},
        abstract = {Social robots are designed to interact with humans. That is why they need interaction models that take social behaviors into account. These usually influence many of a robot's abilities simultaneously. Hence, when designing robots that users will want to interact with, all components need to be tested in the system context, with real users and real tasks in real interactions. This requires methods that link the analysis of the robot's internal computations within and between components (system level) with the interplay between robot and user (interaction level). This article presents Systemic Interaction Analysis (SInA) as an integrated method to (a) derive prototypical courses of interaction based on system and interaction level, (b) identify deviations from these, (c) infer the causes of deviations by analyzing the system's operational sequences, and (d) improve the robot iteratively by adjusting models and implementations.}
}

@inproceedings{lincoln6919,
           month = {September},
          author = {Christian Lang and Marc Hanheide and Manja Lohse and Heiko Wersing and Gerhard Sagerer},
            note = {In everyday conversation besides speech people also communicate by means of nonverbal cues. Facial expressions are one important cue, as they can provide useful information about the conversation, for instance, whether the interlocutor seems to understand or appears to be puzzled. Similarly, in human-robot interaction facial expressions also give feedback about the interaction situation. We present a Wizard of Oz user study in an object-teaching scenario where subjects showed several objects to a robot and taught the objects' names. Afterward, the robot should term the objects correctly. In a first evaluation, we let other people watch short video sequences of this study. They decided by looking at the face of the human whether the answer of the robot was correct (unproblematic situation) or incorrect (problematic situation). We conducted the experiments under specific conditions by varying the amount of temporal and visual context information and compare the results with related experiments described in the literature.},
       booktitle = {The 18th IEEE International Symposium on Robot and Human Interactive Communication},
          editor = {B. Gottfried and H. Aghajan},
           title = {Feedback interpretation based on facial expressions in human-robot interaction},
       publisher = {IEEE},
            year = {2009},
             doi = {10.1109/ROMAN.2009.5326199},
           pages = {189--194},
        keywords = {ARRAY(0x5568fbaa2618)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6919/},
        abstract = {In everyday conversation besides speech people also communicate by means of nonverbal cues. Facial expressions are one important cue, as they can provide useful information about the conversation, for instance, whether the interlocutor seems to understand or appears to be puzzled. Similarly, in human-robot interaction facial expressions also give feedback about the interaction situation. We present a Wizard of Oz user study in an object-teaching scenario where subjects showed several objects to a robot and taught the objects' names. Afterward, the robot should term the objects correctly. In a first evaluation, we let other people watch short video sequences of this study. They decided by looking at the face of the human whether the answer of the robot was correct (unproblematic situation) or incorrect (problematic situation). We conducted the experiments under specific conditions by varying the amount of temporal and visual context information and compare the results with related experiments described in the literature.}
}

@inproceedings{lincoln6923,
           month = {September},
          author = {Julia Peltason and Ingo L{\"u}tkebohle and Britta Wrede and Marc Hanheide},
            note = {In learning tasks, interaction is mostly about the exchange
of knowledge. The interaction process shall be governed on the one hand by the knowledge the tutor wants to convey and on the other by the lacks of knowledge of the learner. In human-robot interaction (HRI), it is usually the human demonstrating or explicitly verbalizing her knowl-
edge and the robot acquiring a respective representation. The ultimate goal in interactive robot learning is thus to enable inexperienced, un- trained users to tutor robots in a most natural and intuitive manner.
This goal is often impeded by a lack of knowledge of the human about the internal processing and expectations of the robot and by the inflexibility of the robot to understand open-ended, unconstrained tutoring or demonstration. Hence, we propose mixed-initiative strategies to allow both to mutually contribute to the interactive learning process as
a bi-directional negotiation about knowledge. Along this line this paper discusses two initially different case studies on object manipulation and learning of spatial environments. We present different styles of mixed-
initiative in these scenarios and discuss the merits in each case.},
       booktitle = {Mixed Initiative Workshop on Improving Human-Robot Communication with Mixed-Initiative and Context-Awareness at the 18th IEEE International Symposium on Robot and Human Interactive Communication},
          editor = {B. Gottfried and H. Aghajan},
           title = {Mixed initiative in interactive robotic learning},
       publisher = {IEEE},
            year = {2009},
        keywords = {ARRAY(0x5568fbaf8bb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6923/},
        abstract = {In learning tasks, interaction is mostly about the exchange
of knowledge. The interaction process shall be governed on the one hand by the knowledge the tutor wants to convey and on the other by the lacks of knowledge of the learner. In human-robot interaction (HRI), it is usually the human demonstrating or explicitly verbalizing her knowl-
edge and the robot acquiring a respective representation. The ultimate goal in interactive robot learning is thus to enable inexperienced, un- trained users to tutor robots in a most natural and intuitive manner.
This goal is often impeded by a lack of knowledge of the human about the internal processing and expectations of the robot and by the inflexibility of the robot to understand open-ended, unconstrained tutoring or demonstration. Hence, we propose mixed-initiative strategies to allow both to mutually contribute to the interactive learning process as
a bi-directional negotiation about knowledge. Along this line this paper discusses two initially different case studies on object manipulation and learning of spatial environments. We present different styles of mixed-
initiative in these scenarios and discuss the merits in each case.}
}

@inproceedings{lincoln1960,
       booktitle = {4th European Conference on Mobile Robots ECMR-09},
           month = {September},
           title = {An adaptive spherical view representation for navigation in changing environments},
          author = {Feras Dayoub and Tom Duckett and Grzegorz Cielniak},
            year = {2009},
            note = {Real-world environments such as houses and offices change over time, meaning that a mobile robot?s map will become out of date. In previous work we introduced a method to update the reference views in a topological map so that a mobile robot could continue to localize itself in a changing environment using omni-directional vision. In this work we extend this longterm updating mechanism to incorporate a spherical metric representation of the observed visual features for each node in the topological map. Using multi-view geometry we are then able to estimate the heading of the robot, in order to enable navigation between the nodes of the map, and to simultaneously adapt the spherical view representation in response to environmental changes. The results demonstrate the persistent performance of the proposed system in a long-term experiment.},
         journal = {European Conference on Mobile Robots - ECMR 2009},
        keywords = {ARRAY(0x5568fbad04f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1960/},
        abstract = {Real-world environments such as houses and offices change over time, meaning that a mobile robot?s map will become out of date. In previous work we introduced a method to update the reference views in a topological map so that a mobile robot could continue to localize itself in a changing environment using omni-directional vision. In this work we extend this longterm updating mechanism to incorporate a spherical metric representation of the observed visual features for each node in the topological map. Using multi-view geometry we are then able to estimate the heading of the robot, in order to enable navigation between the nodes of the map, and to simultaneously adapt the spherical view representation in response to environmental changes. The results demonstrate the persistent performance of the proposed system in a long-term experiment.}
}

@inproceedings{lincoln6921,
       booktitle = {Workshop on Behavior Monitoring and Interpretation - Well Being},
          editor = {B. Gottfried and H. Aghajan},
           month = {September},
           title = {Make room for me: a spatial and situational movement concept in HRI},
          author = {Annika Peters and Thorsten P. Spexard and Petra Wei{\ss} and Marc Hanheide},
            year = {2009},
            note = {Mobile robots are already applied in factories and hospitals, merely to do a distinct task. It is envisioned that robots assist in households, soon. Those service robots will have to cope with several situations and tasks and of course with sophisticated Human-Robot Interaction (HRI)},
        keywords = {ARRAY(0x5568fb9b63c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6921/},
        abstract = {Mobile robots are already applied in factories and hospitals, merely to do a distinct task. It is envisioned that robots assist in households, soon. Those service robots will have to cope with several situations and tasks and of course with sophisticated Human-Robot Interaction (HRI)}
}

@inproceedings{lincoln39650,
       booktitle = {2009 2nd International Workshop on Nonlinear Dynamics and Synchronization},
           month = {September},
           title = {Vision Based Hazard Detection and Obstacle Avoidance for Planetary Landing},
          author = {W. Mahmood and S. Ali Shah and C. Saaj},
       publisher = {IEEE},
            year = {2009},
             doi = {https://doi.org/10.1109/INDS.2009.5227995},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39650/},
        abstract = {Current lunar and planetary missions aim for pinpoint landing accuracy. Landing a set of science instruments at the edge of a particular crater or critical life-supporting supplies in proximity of a lunar outpost is not possible with the kilometer level precision of past. To achieve this level of precise landing, accurate identification of potential hazards (like craters, boulders, steep slopes, etc.) is necessary. In this paper, a robust algorithm for autonomous hazard detection and avoidance (HDA) for a low cost, pinpoint planetary lander, Magnolia-1 is proposed. The algorithm requires no input from classical inertial sensors. The hazard assessment and navigation is done purely by using imaging camera. The primary algorithm incorporates different functions which include (a) Feature selection and hazard identification, (b) Feature transformation and hazard mapping, (c) Safe site selection and (d) Site tracking and retargeting. Implementation of each functional block and simulation results for the algorithm are presented in this paper.}
}

@article{lincoln6702,
          volume = {10},
          number = {S2},
           month = {September},
          author = {Annika Peters and Petra Weiss and Marc Hanheide},
            note = {In humanhuman interaction, social signals or unconscious cues are sent and received by interaction partners. These signals and cues influence the interaction partner wanted and unwantedsometimes to achieve a distinct goal. To be aware of those signals and especially of implicit cues is crucial when interaction between a robot and a human is modelled. This project aims to use implicit body and machine movements to make HRI smoother and simpler. A robot should not only consider social rules with respect to proxemics in communication or in encounter people. It should also be able to signal and understand certain spatial constraints. A first spatial and situational constraint, which this research project currently focuses on, is avoiding each other. This includes not only passing by but also especially making room for each other. Consider a narrow place, e.g. hallways, door frames or a small kitchen. A robot might block the way or drives towards you, pursuing its own goal like you. Humans do not even speak to each other in order to pass by and avoid bumping into each other even if the space is narrow. A first study is currently conducted to find out which behaviour is the most appropriate avoiding strategy and how participants express their wish to pass by. Therefore, a variety of defensive and more offensive avoiding strategies of the robot are applied in experiments. The results of the study will be used to equip the robot with spatial concepts to make interaction faster and more appropriate.},
           title = {Avoid me: a spatial movement concept in human-robot interaction},
       publisher = {Springer},
            year = {2009},
         journal = {Cognitive Processing},
             doi = {10.1007/s10339-009-0325-4},
           pages = {177--178},
        keywords = {ARRAY(0x5568fba5cf68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6702/},
        abstract = {In humanhuman interaction, social signals or unconscious cues are sent and received by interaction partners. These signals and cues influence the interaction partner wanted and unwantedsometimes to achieve a distinct goal. To be aware of those signals and especially of implicit cues is crucial when interaction between a robot and a human is modelled. This project aims to use implicit body and machine movements to make HRI smoother and simpler. A robot should not only consider social rules with respect to proxemics in communication or in encounter people. It should also be able to signal and understand certain spatial constraints. A first spatial and situational constraint, which this research project currently focuses on, is avoiding each other. This includes not only passing by but also especially making room for each other. Consider a narrow place, e.g. hallways, door frames or a small kitchen. A robot might block the way or drives towards you, pursuing its own goal like you. Humans do not even speak to each other in order to pass by and avoid bumping into each other even if the space is narrow. A first study is currently conducted to find out which behaviour is the most appropriate avoiding strategy and how participants express their wish to pass by. Therefore, a variety of defensive and more offensive avoiding strategies of the robot are applied in experiments. The results of the study will be used to equip the robot with spatial concepts to make interaction faster and more appropriate.}
}

@article{lincoln4262,
          volume = {12},
          number = {3},
           month = {September},
          author = {K. Walley and P. Custance and G. Orton and S. Parsons and A. Lindgreen and Martin Hingley},
            note = {Purpose ? The aim of this article is to consolidate the theory relating to longitudinal attitude
surveys, and supplement it with knowledge gained from the execution of an annual attitude survey of
consumers.
Design/methodology/approach ? First, the article presents a distillation of current knowledge
concerning longitudinal research; attitudes and behaviour; measurement of attitudes; and conduct of
attitude surveys. Following that, a case study is carried out to survey consumer attitudes. This survey,
which is intended to predict future behaviour and monitor changes in consumers? attitudes in response to
socio-political and economic changes in the food and agricultural market environment, is then discussed.
Findings ? The findings of a series of annual surveys of consumers? attitudes first conducted in 1997
and continued annually to 2004 include: British farmers are viewed as ?good food producers?; farms
are businesses, which whilst forming the financial backbone of the rural community are at present
members of a struggling industry; and there is agreement that the Government does not care for the
countryside.
Research limitations/implications ? The survey on which the findings and the best practices are
based upon relates to the consumers? attitudes in response to changes in the food and agricultural
market environment. Further research would be required to verify the findings in respect of other
market sections.
Practical implications ? The article presents a checklist of eight good practices relating to the
conduct of longitudinal attitude survey work.
Originality/value ? Attitude surveys are a popular means of gathering market research data. Much
has been written about attitudes and the conduct of ad hoc attitude surveys. However, much less has
been published concerning longitudinal attitude surveys. The study reports empirical findings in an
important context, that is: changes in consumers? attitudes in response to changes in the food and
agricultural market environment.},
           title = {Longitudinal attitude surveys in consumer research: a case study from the agrifood sector},
       publisher = {Emerald},
            year = {2009},
         journal = {Qualitative Market Research: An International Journal},
             doi = {10.1108/13522750910963791},
           pages = {260--278},
        keywords = {ARRAY(0x5568fba5cba8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/4262/},
        abstract = {Purpose ? The aim of this article is to consolidate the theory relating to longitudinal attitude
surveys, and supplement it with knowledge gained from the execution of an annual attitude survey of
consumers.
Design/methodology/approach ? First, the article presents a distillation of current knowledge
concerning longitudinal research; attitudes and behaviour; measurement of attitudes; and conduct of
attitude surveys. Following that, a case study is carried out to survey consumer attitudes. This survey,
which is intended to predict future behaviour and monitor changes in consumers? attitudes in response to
socio-political and economic changes in the food and agricultural market environment, is then discussed.
Findings ? The findings of a series of annual surveys of consumers? attitudes first conducted in 1997
and continued annually to 2004 include: British farmers are viewed as ?good food producers?; farms
are businesses, which whilst forming the financial backbone of the rural community are at present
members of a struggling industry; and there is agreement that the Government does not care for the
countryside.
Research limitations/implications ? The survey on which the findings and the best practices are
based upon relates to the consumers? attitudes in response to changes in the food and agricultural
market environment. Further research would be required to verify the findings in respect of other
market sections.
Practical implications ? The article presents a checklist of eight good practices relating to the
conduct of longitudinal attitude survey work.
Originality/value ? Attitude surveys are a popular means of gathering market research data. Much
has been written about attitudes and the conduct of ad hoc attitude surveys. However, much less has
been published concerning longitudinal attitude surveys. The study reports empirical findings in an
important context, that is: changes in consumers? attitudes in response to changes in the food and
agricultural market environment.}
}

@article{lincoln2666,
          volume = {3},
           month = {August},
          author = {Cinly Ooi and Edward Bullmore and Alle-Meije Wink and Levent Sendur and Anna Barnes and Sophie Achard and John Aspden and Sanja Abbott and Shigang Yue and Manfred Kitzbichler and David Meunier and Voichita Maxim and Raymond Salvador and Julian Henty and Roger Tait and Naresh Subramaniam and John Suckling},
            note = {CamBAfx is a workflow application designed for both researchers who use workflows to process data (consumers) and those who design them (designers). It provides a front-end (user
interface) optimized for data processing designed in a way familiar to consumers. The back-end
uses a pipeline model to represent workfl ows since this is a common and useful metaphor used
by designers and is easy to manipulate compared to other representations like programming
scripts. As an Eclipse Rich Client Platform application, CamBAfx?s pipelines and functions can
be bundled with the software or downloaded post-installation. The user interface contains all the
workfl ow facilities expected by consumers. Using the Eclipse Extension Mechanism designers
are encouraged to customize CamBAfx for their own pipelines. CamBAfx wraps a workfl ow
facility around neuroinformatics software without modifi cation. CamBAfx?s design, licensing
and Eclipse Branding Mechanism allow it to be used as the user interface for other software,
facilitating exchange of innovative computational tools between originating labs.},
           title = {CamBAfx: workflow design, implementation and application for neuroimaging},
       publisher = {Frontiers Research Foundation},
            year = {2009},
         journal = {Frontiers in Neuroinformatics},
             doi = {10.3389/neuro.11.027.2009},
           pages = {1--10},
        keywords = {ARRAY(0x5568fbbc3fc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2666/},
        abstract = {CamBAfx is a workflow application designed for both researchers who use workflows to process data (consumers) and those who design them (designers). It provides a front-end (user
interface) optimized for data processing designed in a way familiar to consumers. The back-end
uses a pipeline model to represent workfl ows since this is a common and useful metaphor used
by designers and is easy to manipulate compared to other representations like programming
scripts. As an Eclipse Rich Client Platform application, CamBAfx?s pipelines and functions can
be bundled with the software or downloaded post-installation. The user interface contains all the
workfl ow facilities expected by consumers. Using the Eclipse Extension Mechanism designers
are encouraged to customize CamBAfx for their own pipelines. CamBAfx wraps a workfl ow
facility around neuroinformatics software without modifi cation. CamBAfx?s design, licensing
and Eclipse Branding Mechanism allow it to be used as the user interface for other software,
facilitating exchange of innovative computational tools between originating labs.}
}

@article{lincoln2095,
          volume = {28},
          number = {1},
           month = {August},
          author = {Peter Biber and Tom Duckett},
           title = {Experimental analysis of sample-based maps for long-term SLAM},
       publisher = {SAGE},
            year = {2009},
         journal = {International Journal of Robotics Research},
             doi = {10.1177/0278364908096286},
           pages = {20--33},
        keywords = {ARRAY(0x5568fb67b430)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2095/},
        abstract = {This paper presents a system for long-term SLAM (simultaneous localization and mapping) by mobile service robots and its experimental evaluation in a real dynamic environment. To deal with the stability-plasticity dilemma (the trade-off between adaptation to new patterns and preservation of old patterns), the environment is represented at multiple timescales simultaneously (5 in our experiments). A sample-based representation is
proposed, where older memories fade at different rates depending on the timescale, and robust statistics are used to interpret the samples. The dynamics of this representation are analysed in a five week experiment, measuring the relative influence of short- and long-term memories over time, and further demonstrating the robustness of the approach.}
}

@inproceedings{lincoln39652,
       booktitle = {International Conference on Space Technology},
           month = {August},
           title = {Robot Assisted Satellite Servicing: Novel Motion Control Algorithm using Sliding Mode Control},
          author = {S. Seyyedi Parsa and C.M. Saaj and C. Underwood},
            year = {2009},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39652/}
}

@inproceedings{lincoln2670,
           month = {August},
          author = {Shigang Yue and F. Claire Rind},
          series = {2009 2nd IEEE International Conference on Computer Science and Information Technology, 2009},
            note = {(c) 2003 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other users},
       booktitle = {2009 2nd IEEE International Conference on Computer Science and Information Technology, 2009},
           title = {Near range path navigation using LGMD visual neural networks},
         address = {Beijing, China},
       publisher = {IEEE},
            year = {2009},
             doi = {10.1109/ICCSIT.2009.5234439},
        keywords = {ARRAY(0x5568fbb87630)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2670/},
        abstract = {In this paper, we proposed a method for near range path navigation for a mobile robot by using a pair of biologically
inspired visual neural network ? lobula giant movement detector (LGMD). In the proposed binocular style visual system, each LGMD processes images covering a part of the wide field of view and extracts relevant visual cues as its output. The outputs from the two LGMDs are compared and translated into executable motor commands to control the wheels of the robot in real time. Stronger signal from the LGMD in one side pushes the robot away from this side step by step; therefore, the robot can navigate in a visual environment naturally with the proposed vision system. Our experiments showed that this bio-inspired system worked well in different scenarios.}
}

@inproceedings{lincoln6918,
           month = {July},
          author = {Christian Mertes and Angelika Dierker and Thomas Hermann and Marc Hanheide and Gerhard Sagerer},
            note = {Humans naturally use an impressive variety of ways to com-
municate. In this work, we investigate the possibilities of complementing these natural communication channels with articial ones. For this, augmented reality is used as a technique to add synthetic visual and auditory stimuli to people's perception. A system for the mutual display
of the gaze direction of two interactants is presented and its acceptance is shown through a study. Finally, future possibilities of promoting this novel concept of articial communication channels are explored},
       booktitle = {Proceedings of the 13th International Conference on Human-Computer Interaction},
          editor = {B. Gottfried and H. Aghajan},
           title = {Enhancing human cooperation with multimodal augmented reality},
       publisher = {Springer},
            year = {2009},
           pages = {447--451},
        keywords = {ARRAY(0x5568fbb8c030)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6918/},
        abstract = {Humans naturally use an impressive variety of ways to com-
municate. In this work, we investigate the possibilities of complementing these natural communication channels with articial ones. For this, augmented reality is used as a technique to add synthetic visual and auditory stimuli to people's perception. A system for the mutual display
of the gaze direction of two interactants is presented and its acceptance is shown through a study. Finally, future possibilities of promoting this novel concept of articial communication channels are explored}
}

@inproceedings{lincoln37421,
           month = {July},
          author = {B.G.R. Smith and G.P. Scott and C. Saaj},
            note = {cited By 5},
       booktitle = {4th International Conference on Recent Advances in Space Technologies},
           title = {Biorobotics: Innovative and low cost technologies for next generation planetary rovers},
       publisher = {IEEE},
            year = {2009},
         journal = {RAST 2009 - Proceedings of 4th International Conference on Recent Advances Space Technologies},
             doi = {10.1109/RAST.2009.5158288},
           pages = {732--737},
        keywords = {ARRAY(0x5568fbbb4180)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37421/},
        abstract = {This paper details some of the various robotics projects which have been inspired by the natural world, and which the authors believe will have an impact on the future of robotic space exploration. This includes both hardware-centric projects such as RiSE, and projects which concentrate more on software and control such as Swarm-bots. The authors outline two of the biologically inspired planetary explorer robots currently under investigation at the University of Surrey.}
}

@inproceedings{lincoln1879,
       booktitle = {IEEE International Joint Conference on Neural Networks (IJCNN 2009), Atlanta, USA.},
           month = {June},
           title = {A modified sparse distributed memory model for extracting clean patterns from noisy inputs},
          author = {Hongying Meng and Kofi Appiah and Andrew Hunter and Shigang Yue and Mervyn Hobden and Nigel Priestley and Peter Hobden and Cy Pettit},
            year = {2009},
        keywords = {ARRAY(0x5568fb9d03d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1879/},
        abstract = {Abstract{--}The Sparse Distributed Memory (SDM) proposed by Kanerva provides a simple model for human long-term memory, with a strong underlying mathematical theory. However, there are problematic features in the original SDM model that affect its efficiency and performance in real world applications and for hardware implementation. In this paper, we propose modifications to the SDM model that improve its efficiency and performance in pattern recall. First, the address matrix is built using training samples rather than random binary sequences. This improves the recall performance significantly. Second, the content matrix is modified using a simple tri-state logic rule. This reduces the storage requirements of the SDM and simplifies the implementation logic, making it suitable for hardware implementation. The modified model has been tested using pattern recall experiments. It is found that the modified model can recall clean patterns very well from noisy inputs.}
}

@inproceedings{lincoln1971,
       booktitle = {IEEE International Joint Conference on Neural Networks (IJCNN 2009), Atlanta, USA.},
           month = {June},
           title = {A modified neural network model for Lobula Giant Movement Detector with additional depth movement feature},
          author = {Hongying Meng and Shigang Yue and Andrew Hunter and Kofi Appiah and Mervyn Hobden and Nigel Priestley and Peter Hobden and Cy Pettit},
            year = {2009},
            note = {The Lobula Giant Movement Detector (LGMD) is a wide-field visual neuron that is located in the Lobula layer of the Locust nervous system. The LGMD increases its firing rate in response to both the velocity of the approaching object and its proximity. It has been found that it can respond to looming stimuli very quickly and can trigger avoidance reactions whenever a rapidly approaching object is detected. It has been successfully applied in visual collision avoidance systems for vehicles and robots. This paper proposes a modified LGMD model that provides additional movement depth direction information. The proposed model retains the simplicity of the previous neural network model, adding only a few new cells. It has been tested on both simulated and recorded video data sets. The experimental results shows that the modified model can very efficiently provide stable information on the depth direction of movement.},
        keywords = {ARRAY(0x5568fbb6cc48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1971/},
        abstract = {The Lobula Giant Movement Detector (LGMD) is a wide-field visual neuron that is located in the Lobula layer of the Locust nervous system. The LGMD increases its firing rate in response to both the velocity of the approaching object and its proximity. It has been found that it can respond to looming stimuli very quickly and can trigger avoidance reactions whenever a rapidly approaching object is detected. It has been successfully applied in visual collision avoidance systems for vehicles and robots. This paper proposes a modified LGMD model that provides additional movement depth direction information. The proposed model retains the simplicity of the previous neural network model, adding only a few new cells. It has been tested on both simulated and recorded video data sets. The experimental results shows that the modified model can very efficiently provide stable information on the depth direction of movement.}
}

@inproceedings{lincoln25795,
       booktitle = {26th Annual International Conference on Machine Learning (ICML 2009)},
           month = {June},
           title = {Learning complex motions by sequencing simpler motion templates},
          author = {Gerhard Neumann and W. Maass and J. Peters},
            year = {2009},
           pages = {753--760},
         journal = {Proceedings of the 26th International Conference On Machine Learning, ICML 2009},
        keywords = {ARRAY(0x5568fb9d9888)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25795/},
        abstract = {Abstraction of complex, longer motor tasks into simpler elemental movements enables humans and animals to exhibit motor skills which have not yet been matched by robots. Humans intuitively decompose complex motions into smaller, simpler segments. For example when describing simple movements like drawing a triangle with a pen, we can easily name the basic steps of this movement.

Surprisingly, such abstractions have rarely been used in artificial motor skill learning algorithms. These algorithms typically choose a new action (such as a torque or a force) at a very fast time-scale. As a result, both policy and temporal credit assignment problem become unnecessarily complex - often beyond the reach of current machine learning methods.

We introduce a new framework for temporal abstractions in reinforcement learning (RL), i.e. RL with motion templates. We present a new algorithm for this framework which can learn high-quality policies by making only few abstract decisions.}
}

@inproceedings{lincoln1852,
       booktitle = {IEEE International Joint Conference on Neural Networks},
           month = {June},
           title = {A binary self-organizing map and its FPGA implementation},
          author = {Kofi Appiah and Andrew Hunter and Hongying Meng and Shigang Yue and Mervyn Hobden and Nigel Priestley and Peter Hobden and Cy Pettit},
            year = {2009},
        keywords = {ARRAY(0x5568fbb7e780)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1852/},
        abstract = {A binary Self Organizing Map (SOM) has been designed and
implemented on a Field Programmable Gate Array (FPGA) chip. A novel learning algorithm which takes binary inputs and maintains tri-state weights is presented. The binary SOM has the capability of recognizing binary input sequences after training. A novel tri-state rule is used in updating the network weights during the training phase. The rule implementation is highly suited to the FPGA architecture, and allows extremely rapid training. This architecture may be used in real-time for fast pattern clustering and classification of the binary features.}
}

@inproceedings{lincoln25796,
       booktitle = {Advances in Neural Information Processing Systems 22 (NIPS 2008)},
           month = {June},
           title = {Fitted Q-iteration by advantage weighted regression},
          author = {Gerhard Neumann and Jan Peters},
            year = {2009},
           pages = {1177--1184},
         journal = {Advances in Neural Information Processing Systems 21 - Proceedings of the 2008 Conference},
        keywords = {ARRAY(0x5568fbaa9b50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25796/},
        abstract = {Recently, fitted Q-iteration (FQI) based methods have become more popular due
to their increased sample efficiency, a more stable learning process and the higher
quality of the resulting policy. However, these methods remain hard to use for continuous
action spaces which frequently occur in real-world tasks, e.g., in robotics
and other technical applications. The greedy action selection commonly used for
the policy improvement step is particularly problematic as it is expensive for continuous
actions, can cause an unstable learning process, introduces an optimization
bias and results in highly non-smooth policies unsuitable for real-world systems.
In this paper, we show that by using a soft-greedy action selection the policy
improvement step used in FQI can be simplified to an inexpensive advantage weighted
regression. With this result, we are able to derive a new, computationally
efficient FQI algorithm which can even deal with high dimensional action spaces.}
}

@article{lincoln37407,
          volume = {62},
          number = {5},
           month = {May},
          author = {G.P. Scott and C Saaj},
            note = {cited By 1},
           title = {Biologically inspired robots to assist areonauts on the Martian surface},
       publisher = {The British Interplanetary Society},
            year = {2009},
         journal = {JBIS - Journal of the British Interplanetary Society},
           pages = {175--186},
        keywords = {ARRAY(0x5568fbb9d9a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37407/}
}

@inproceedings{lincoln6924,
           month = {May},
          author = {Julia Peltason and F. H. K. Siepmann and T. P. Spexard and Britta Wrede and Marc Hanheide and E. A. Topp},
            note = {In scenarios that require a close collaboration and
knowledge transfer between inexperienced users and robots,
the ?learning by interacting? paradigm goes hand in hand
with appropriate representations and learning methods. In this paper we discuss a mixed initiative strategy for robotic learning by interacting with a user in a joint map acquisition process.
We propose the integration of an environment representation
approach into our interactive learning framework. The environment representation and mapping system supports both
user driven and data driven strategies for the acquisition of spatial information, so that a mixed initiative strategy for the learning process is realised. We evaluate our system with test runs according to the scenario of a guided tour, extending the area of operation from structured laboratory environment to
less predictable domestic settings},
       booktitle = {IEEE International Conference on Robotics and Automation.},
          editor = {B. Gottfried and H. Aghajan},
           title = {Mixed-initiative in human augmented mapping},
       publisher = {IEEE},
            year = {2009},
             doi = {10.1109/ROBOT.2009.5152683},
           pages = {2146--2153},
        keywords = {ARRAY(0x5568fb67d430)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6924/},
        abstract = {In scenarios that require a close collaboration and
knowledge transfer between inexperienced users and robots,
the ?learning by interacting? paradigm goes hand in hand
with appropriate representations and learning methods. In this paper we discuss a mixed initiative strategy for robotic learning by interacting with a user in a joint map acquisition process.
We propose the integration of an environment representation
approach into our interactive learning framework. The environment representation and mapping system supports both
user driven and data driven strategies for the acquisition of spatial information, so that a mixed initiative strategy for the learning process is realised. We evaluate our system with test runs according to the scenario of a guided tour, extending the area of operation from structured laboratory environment to
less predictable domestic settings}
}

@inproceedings{lincoln7218,
           month = {May},
          author = {Fang Yuan and Agnes Swadzba and Roland Philippsen and Orhan Engin and Marc Hanheide and Sven Wachsmuth},
            note = {Navigation and obstacle avoidance in robotics using planar laser scans has matured over the last decades. They basically enable robots to penetrate highly dynamic and populated spaces, such as people's home, and move around smoothly. However, in an unconstrained environment the twodimensional perceptual space of a fixed mounted laser is not sufficient to ensure safe navigation. In this paper, we present an approach that pools a fast and reliable motion generation approach with modern 3D capturing techniques using a Timeof-Flight camera. Instead of attempting to implement full 3D motion control, which is computationally more expensive and simply not needed for the targeted scenario of a domestic robot, we introduce a \&quot;virtual laser\&quot;. For the originally solely laserbased motion generation the technique of fusing real laser measurements and 3D point clouds into a continuous data stream is 100\% compatible and transparent. The paper covers the general concept, the necessary extrinsic calibration of two very different types of sensors, and exemplarily illustrates the benefit which is to avoid obstacles not being perceivable in the original laser scan. {\^A}{\copyright} 2009 IEEE.},
       booktitle = {Conference of 2009 IEEE International Conference on Robotics and Automation, ICRA '09},
           title = {Laser-based navigation enhanced with 3D time-of-flight data},
         address = {Kobe},
       publisher = {IEEE},
            year = {2009},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
           pages = {2844--2850},
        keywords = {ARRAY(0x5568fbabd078)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/7218/},
        abstract = {Navigation and obstacle avoidance in robotics using planar laser scans has matured over the last decades. They basically enable robots to penetrate highly dynamic and populated spaces, such as people's home, and move around smoothly. However, in an unconstrained environment the twodimensional perceptual space of a fixed mounted laser is not sufficient to ensure safe navigation. In this paper, we present an approach that pools a fast and reliable motion generation approach with modern 3D capturing techniques using a Timeof-Flight camera. Instead of attempting to implement full 3D motion control, which is computationally more expensive and simply not needed for the targeted scenario of a domestic robot, we introduce a \&quot;virtual laser\&quot;. For the originally solely laserbased motion generation the technique of fusing real laser measurements and 3D point clouds into a continuous data stream is 100\% compatible and transparent. The paper covers the general concept, the necessary extrinsic calibration of two very different types of sensors, and exemplarily illustrates the benefit which is to avoid obstacles not being perceivable in the original laser scan. {\^A}{\copyright} 2009 IEEE.}
}

@article{lincoln6700,
          volume = {1},
          number = {1},
           month = {May},
          author = {Matthias Rolf and Marc Hanheide and Katharina J. Rohfling},
            note = {Infants learning about their environment are confronted with many stimuli of different modalities. Therefore, a crucial problem is how to discover which stimuli are related, for instance, in learning words. In making these multimodal ldquobindings,rdquo infants depend on social interaction with a caregiver to guide their attention towards relevant stimuli. The caregiver might, for example, visually highlight an object by shaking it while vocalizing the object's name. These cues are known to help structuring the continuous stream of stimuli. To detect and exploit them, we propose a model of bottom-up attention by multimodal signal-level synchrony. We focus on the guidance of visual attention from audio-visual synchrony informed by recent adult-infant interaction studies. Consequently, we demonstrate that our model is receptive to parental cues during child-directed tutoring. The findings discussed in this paper are consistent with recent results from developmental psychology but for the first time are obtained employing an objective, computational model. The presence of ldquomultimodal mothereserdquo is verified directly on the audio-visual signal. Lastly, we hypothesize how our computational model facilitates tutoring interaction and discuss its application in interactive learning scenarios, enabling social robots to benefit from adult-like tutoring.},
           title = {Attention via synchrony: making use of multimodal cues in social learning},
       publisher = {IEEE},
            year = {2009},
         journal = {Autonomous Mental Development, IEEE Transactions on},
             doi = {10.1109/TAMD.2009.2021091},
           pages = {55--67},
        keywords = {ARRAY(0x5568fbafcb00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6700/},
        abstract = {Infants learning about their environment are confronted with many stimuli of different modalities. Therefore, a crucial problem is how to discover which stimuli are related, for instance, in learning words. In making these multimodal ldquobindings,rdquo infants depend on social interaction with a caregiver to guide their attention towards relevant stimuli. The caregiver might, for example, visually highlight an object by shaking it while vocalizing the object's name. These cues are known to help structuring the continuous stream of stimuli. To detect and exploit them, we propose a model of bottom-up attention by multimodal signal-level synchrony. We focus on the guidance of visual attention from audio-visual synchrony informed by recent adult-infant interaction studies. Consequently, we demonstrate that our model is receptive to parental cues during child-directed tutoring. The findings discussed in this paper are consistent with recent results from developmental psychology but for the first time are obtained employing an objective, computational model. The presence of ldquomultimodal mothereserdquo is verified directly on the audio-visual signal. Lastly, we hypothesize how our computational model facilitates tutoring interaction and discuss its application in interactive learning scenarios, enabling social robots to benefit from adult-like tutoring.}
}

@inproceedings{lincoln6927,
           month = {April},
          author = {Matthias Rolf and Marc Hanheide and Katharina J. Rohlfing},
            note = {In our approach, we aim at an objective measurement of
synchrony in multimodal tutoring behavior. The use of signal
correlation provides a well formalized method that yields
gradual information about the degree of synchrony. For our
analysis, we used and extended an algorithm proposed by
Hershey \& Movellan (2000) that correlates single-pixel
values of a video signal with the loudness of the
corresponding audio track over time. The results of all pixels are integrated over the video to achieve a scalar estimate of synchrony.},
       booktitle = {SRCD 2009 Biennial Meeting},
          editor = {B. Gottfried and H. Aghajan},
           title = {The use of synchrony in parent-child interaction can be measured on a signal-level},
       publisher = {Society for Research in Child Development},
            year = {2009},
        keywords = {ARRAY(0x5568fbbc1238)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6927/},
        abstract = {In our approach, we aim at an objective measurement of
synchrony in multimodal tutoring behavior. The use of signal
correlation provides a well formalized method that yields
gradual information about the degree of synchrony. For our
analysis, we used and extended an algorithm proposed by
Hershey \& Movellan (2000) that correlates single-pixel
values of a video signal with the loudness of the
corresponding audio track over time. The results of all pixels are integrated over the video to achieve a scalar estimate of synchrony.}
}

@inproceedings{lincoln6926,
           month = {March},
          author = {Manja Lohse and Marc Hanheide and Katharina J. Rohlfing and Gerhard Sagerer},
            note = {Recent developments in robotics enable advanced human-robot interaction. Especially interactions of novice users with robots are often unpredictable and, therefore, demand for novel methods for the analysis of the interaction in systemic ways. We propose Systemic Interaction Analysis (SInA) as a method to jointly analyze system level and interaction level in an integrated manner using one tool. The approach allows us to trace back patterns that deviate from prototypical interaction sequences to the distinct system components of our autonomous robot. In this paper, we exemplarily apply the method to the analysis of the follow behavior of our domestic robot BIRON. The analysis is the basis to achieve our goal of improving human-robot interaction iteratively.},
       booktitle = {4th ACM/IEEE international conference on Human robot interaction - HRI '09},
          editor = {B. Gottfried and H. Aghajan},
           title = {Systemic interaction analysis (SInA) in HRI},
       publisher = {ACM / IEEE},
            year = {2009},
             doi = {10.1145/1514095.1514114},
           pages = {93--100},
        keywords = {ARRAY(0x5568fba93fe0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6926/},
        abstract = {Recent developments in robotics enable advanced human-robot interaction. Especially interactions of novice users with robots are often unpredictable and, therefore, demand for novel methods for the analysis of the interaction in systemic ways. We propose Systemic Interaction Analysis (SInA) as a method to jointly analyze system level and interaction level in an integrated manner using one tool. The approach allows us to trace back patterns that deviate from prototypical interaction sequences to the distinct system components of our autonomous robot. In this paper, we exemplarily apply the method to the analysis of the follow behavior of our domestic robot BIRON. The analysis is the basis to achieve our goal of improving human-robot interaction iteratively.}
}

@phdthesis{lincoln22207,
           month = {March},
           title = {Hierarchical reinforcement learning for spoken dialogue systems},
          school = {The University of Edinburgh},
          author = {Heriberto Cuay{\'a}huitl},
            year = {2009},
        keywords = {ARRAY(0x5568fba22898)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/22207/},
        abstract = {This thesis focuses on the problem of scalable optimization of dialogue behaviour in speech-based conversational systems using reinforcement learning. Most previous investigations in dialogue strategy learning have proposed flat reinforcement learning methods, which are more suitable for small-scale spoken dialogue systems. This research formulates the problem in terms of Semi-Markov Decision Processes (SMDPs), and proposes two hierarchical reinforcement learning methods to optimize sub-dialogues rather than full dialogues. The first method uses a hierarchy of SMDPs, where every SMDP ignores irrelevant state variables and actions in order to optimize a sub-dialogue. The second method extends the first one by constraining every SMDP in the hierarchy with prior expert knowledge. The latter method proposes a learning algorithm called 'HAM+HSMQ-Learning', which combines two existing algorithms in the literature of hierarchical reinforcement learning. Whilst the first method generates fully-learnt behaviour, the second one generates semi-learnt behaviour. In addition, this research proposes a heuristic dialogue simulation environment for automatic dialogue strategy learning. Experiments were performed on simulated and real environments based on a travel planning spoken dialogue system. Experimental results provided evidence to support the following claims: First, both methods scale well at the cost of near-optimal solutions, resulting in slightly longer dialogues than the optimal solutions. Second, dialogue strategies learnt with coherent user behaviour and conservative recognition error rates can outperform a reasonable hand-coded strategy. Third, semi-learnt dialogue behaviours are a better alternative (because of their higher overall performance) than hand-coded or fully-learnt dialogue behaviours. Last, hierarchical reinforcement learning dialogue agents are feasible and promising for the (semi) automatic design of adaptive behaviours in larger-scale spoken dialogue systems. This research makes the following contributions to spoken dialogue systems which learn their dialogue behaviour. First, the Semi-Markov Decision Process (SMDP) model was proposed to learn spoken dialogue strategies in a scalable way. Second, the concept of 'partially specified dialogue strategies' was proposed for integrating simultaneously hand-coded and learnt spoken dialogue behaviours into a single learning framework. Third, an evaluation with real users of hierarchical reinforcement learning dialogue agents was essential to validate their effectiveness in a realistic environment.}
}

@article{lincoln2096,
          volume = {39},
          number = {1},
           month = {February},
          author = {Nicola Bellotto and Huosheng Hu},
           title = {Multisensor-based human detection and tracking for mobile service robots},
       publisher = {IEEE Systems, Man and Cybernetics Society},
            year = {2009},
         journal = {IEEE Transactions on Systems, Man and Cybernetics, Part B},
             doi = {10.1109/TSMCB.2008.2004050},
           pages = {167--181},
        keywords = {ARRAY(0x5568fbb873f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2096/},
        abstract = {The one of fundamental issues for service robots is human-robot interaction. In order to perform such a task and provide the desired services, these robots need to detect and track people in the surroundings. In the present paper, we propose a solution for human tracking with a mobile robot that implements multisensor data fusion techniques. The system utilizes a new algorithm for laser-based legs detection using the on-board LRF. The approach is based on the recognition of typical leg patterns extracted from laser scans, which are shown to be very discriminative also in cluttered environments. These patterns can be used to localize both static and walking persons, even when the robot moves. Furthermore, faces are detected using the robot's camera and the information is fused to the legs position using a sequential implementation of Unscented Kalman Filter. The proposed solution is feasible for service robots with a similar device configuration and has been successfully implemented on two different mobile platforms.
Several experiments illustrate the effectiveness of our approach, showing that robust human tracking can be performed within complex indoor environments.}
}

@inproceedings{lincoln2097,
       booktitle = {3rd ACM/IEEE International Conference on Distributed Smart Cameras (ICDSC)},
           title = {A distributed camera system for multi-resolution surveillance},
          author = {Nicola Bellotto and Eric Sommerlade and Ben Benfold and Charles Bibby and Ian Reid and Daniel Roth and Carles Fenandez and Luc Van Gool and Jordi Gonzales},
            year = {2009},
            note = {We describe an architecture for a multi-camera, multi-resolution surveillance system. The aim is to support a set of distributed static and pan-tilt-zoom (PTZ) cameras and visual tracking algorithms, together with a central supervisor unit. Each camera (and possibly pan-tilt device) has a dedicated process and processor.
Asynchronous interprocess communications and archiving of data are achieved in a simple and effective way via a central repository, implemented using an SQL database.
Visual tracking data from static views are stored dynamically into tables in the database via client calls to the SQL server. A supervisor process running on the SQL server determines if active zoom cameras should be dispatched to observe a particular target, and this message is effected via writing demands into another database table.
We show results from a real implementation of the system comprising one static camera overviewing the environment under consideration and a PTZ camera operating
under closed-loop velocity control, which uses a fast and robust level-set-based region tracker. Experiments demonstrate the effectiveness of our approach and its feasibility to multi-camera systems for intelligent surveillance.},
        keywords = {ARRAY(0x5568fb9f92f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2097/},
        abstract = {We describe an architecture for a multi-camera, multi-resolution surveillance system. The aim is to support a set of distributed static and pan-tilt-zoom (PTZ) cameras and visual tracking algorithms, together with a central supervisor unit. Each camera (and possibly pan-tilt device) has a dedicated process and processor.
Asynchronous interprocess communications and archiving of data are achieved in a simple and effective way via a central repository, implemented using an SQL database.
Visual tracking data from static views are stored dynamically into tables in the database via client calls to the SQL server. A supervisor process running on the SQL server determines if active zoom cameras should be dispatched to observe a particular target, and this message is effected via writing demands into another database table.
We show results from a real implementation of the system comprising one static camera overviewing the environment under consideration and a PTZ camera operating
under closed-loop velocity control, which uses a fast and robust level-set-based region tracker. Experiments demonstrate the effectiveness of our approach and its feasibility to multi-camera systems for intelligent surveillance.}
}

@inproceedings{lincoln38483,
          volume = {FS-09-},
           title = {Association for the Advancement of Artificial Intelligence Fall Symposium - Technical Report: Preface},
          author = {T. Bench-Capon and Simon Parsons and H. Prakken},
            year = {2009},
            note = {cited By 0},
         journal = {AAAI Fall Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38483/}
}

@inproceedings{lincoln46205,
       booktitle = {Models and Analysis of Vocal Emissions for Biomedical Applications - 6th International Workshop, MAVEBA},
           title = {Automatic detection of post-apnoeic snore events from home and clinical full night sleep recordings},
          author = {M Calisti and L Bocchi and C Manfredi and I Romagnoli and F Gigliotti and G Donzelli},
            year = {2009},
           pages = {185--188},
        keywords = {ARRAY(0x5568fba9bc80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46205/},
        abstract = {{\copyright}2009 Firenze University Press. Snoring is the hallmark of the Obstructive Sleep Apnoea Syndrome and several studies explore possible correlations between them. In this work an improved methodology with respect to 4 is proposed, based on a proper energy threshold applied on audio recordings for sound/silence detection, and on a feature vector of 14 elements (13 Mel Frequency Cepstral Coefficient plus the number of zero crossings) for sound classification. This feature vector is obtained from a 62-elements one by applying a genetic algorithm, fitted to obtain the best classification of the training/validation sets. The feature vector is analyzed by means of a radial basis neural network to perform snore events identification. Finally, formant frequencies and time analysis are also investigated to split up post-apnoeic snores and normal ones. Audio data from 26 patients of different age and sex are used to test the methodology: 6 patients (3 male and 3 female) were used to train the nets (1800 snores) and 4 patients to validate the classification (600 snores). On the whole dataset of patients, a sensitivity between 69\{{$\backslash$}\%\} and 84\{{$\backslash$}\%\} is obtained in the detection of post-apnoeic snores.}
}

@inproceedings{lincoln38488,
          volume = {1},
           title = {Inconsistency tolerance in weighted argument systems},
          author = {P.E. Dunne and Simon Parsons and A. Hunter and P. McBurney and M. Wooldridge},
            year = {2009},
           pages = {616--623},
            note = {cited By 25},
         journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38488/}
}

@inproceedings{lincoln38484,
          volume = {FS-09-},
           title = {Learning policy constraints through dialogue},
          author = {C.D. Emele and T.J. Norman and F. Guerin and Simon Parsons},
            year = {2009},
           pages = {20--26},
            note = {cited By 1},
         journal = {AAAI Fall Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38484/}
}

@inproceedings{lincoln38487,
          volume = {2},
           title = {An evolutionary model of multi-agent learning with a varying exploration rate},
          author = {M. Kaisers and K. Tuyls and Simon Parsons and F. Thuijsman},
            year = {2009},
           pages = {1286--1287},
            note = {cited By 5},
         journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38487/}
}

@inproceedings{lincoln37420,
          volume = {2},
          author = {A. Khorram and S.S. Parsa and C. Saaj},
            note = {cited By 0},
       booktitle = {60th International Astronautical Congress},
           title = {Trajectory planning and control of robot arm for planetary surface sample missions},
       publisher = {International Astronautical Congress},
            year = {2009},
         journal = {60th International Astronautical Congress 2009, IAC 2009},
           pages = {1466--1471},
        keywords = {ARRAY(0x5568fbaf9110)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37420/},
        abstract = {The exploration of Mars for traces of past or present life and presence of water and minerals in the subsurface rocks remains one of the most challenging and exciting areas for the scientific community. Having an absolute control over the planetary manipulator for executing the assigned task is a vital requirement of any planetary mission design. In this paper a robust control method has been applied to the robot manipulator in the presence of uncertain and unknown disturbances. The simulation results illustrate the efficiency of the proposed method.}
}

@inproceedings{lincoln38485,
           title = {Learning to stabilize the head of a quadrupedal robot with an artificial vestibular system},
          author = {M. Marcinkiewicz and R. Kaushik and I. Labutov and Simon Parsons and T. Raphan},
            year = {2009},
           pages = {2512--2517},
             doi = {10.1109/ROBOT.2009.5152685},
            note = {cited By 9},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38485/}
}

@book{lincoln38482,
           title = {Dialogue games for agent argumentation},
          author = {P. McBurney and Simon Parsons},
            year = {2009},
           pages = {261--280},
             doi = {10.1007/978-0-387-98197-0{$_1$}{$_3$}},
            note = {cited By 75},
         journal = {Argumentation in Artificial Intelligence},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38482/}
}

@inproceedings{lincoln8325,
          volume = {1},
          author = {A. Rabie and B. Wrede and T. Vogt and M. Hanheide},
            note = {Conference Code: 79725},
       booktitle = {ICCEE '09. Second International Conference on Computer and Electrical Engineering},
           title = {Evaluation and discussion of multi-modal emotion recognition},
         address = {Dubai},
       publisher = {IEEE},
            year = {2009},
         journal = {2009 International Conference on Computer and Electrical Engineering, ICCEE 2009},
             doi = {10.1109/ICCEE.2009.192},
           pages = {598--602},
        keywords = {ARRAY(0x5568fbbc8000)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8325/},
        abstract = {Recognition of emotions from multimodal cues is of basic interest for the design of many adaptive interfaces in human-machine and human-robot interaction. It provides a means to incorporate non-verbal feedback in the interactional course. Humans express their emotional state rather unconsciously exploiting their different natural communication modalities. In this paper, we present a first study on multimodal recognition of emotions from auditive and visual cues for interaction interfaces. We recognize seven classes of basic emotions by means of visual analysis of talking faces. In parallel, the audio signal is analyzed on the basis of the intonation of the verbal articulation. We compare the performance of state of the art recognition systems on the DaFEx database for both complement modalities and discuss these results with regard to the theoretical background and possible fusion schemes in real-world multimodal interfaces. {\^A}{\copyright} 2009 IEEE.}
}

@inproceedings{lincoln37419,
          volume = {5},
          author = {C. Saaj and S. Bandyopadhyay and B. Bandyopadhyay},
            note = {cited By 1},
       booktitle = {60th International Astronautical Congress},
           title = {Robust control and path planning algorithms for small satellite formation flying missions},
         journal = {60th International Astronautical Congress 2009, IAC 2009},
           pages = {3786--3792},
            year = {2009},
        keywords = {ARRAY(0x5568fbbc1b50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37419/},
        abstract = {Recent advances in small, low cost satellite technology has generated a renewed interest in formation
flying missions. One challenging aspect of satellite formation flying missions is collision free navigation and
control. In this paper, novel robust control algorithm using Sliding Mode Control is presented for a threedimensional, high Earth orbit satellite formation scenario. The paper presents the comparison of results of three
types of Sliding Mode Controllers (SMC): the first one is a tan-hyperbolic SMC, the second one is a constant
plus proportional rate SMC and the third one is a power rate SMC. Hybrid propulsion system minimises the use
of on-board power for close formations. Artificial Potential Field method is used for collision-free path planning
of the satellites in the formation. Simulation results show that for the formation flying scenario considered in this
study, the constant plus proportional rate SMC and the power rate SMC gives better performance over the tanhyperbolic SMC. Simulation results prove that for the tetrahedron formation considered in this study, the total
control effort is less when the constant plus proportional rate controller and the power rate controller are used
compared to the tan-hyperbolic sliding mode controller. Very little formation center movement is observed for
the three SMCs.}
}

@inproceedings{lincoln37405,
          author = {G.P. Scott and C. Saaj},
            note = {cited By 13},
       booktitle = {AIAA Space 2009},
           title = {Measuring and simulating the effect of variations in soil properties on microrover trafficability},
       publisher = {Aerospace Research Central},
         journal = {AIAA Space 2009 Conference and Exposition},
             doi = {10.2514/6.2009-6468},
            year = {2009},
        keywords = {ARRAY(0x5568fb9dca50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37405/},
        abstract = {The authors of this paper build on many years of experience in planetary rover locomotion system design and validation at the University of Surrey. One of the key lessons learned from these systems is how little is accurately understood about the deformation of soil under microrover systems. As such, this paper examines some areas of soil mechanics and their effect on traditional vehicle locomotion. Then, moving beyond wheeled and tracked locomotion systems for planetary rovers, the authors evaluate legged locomotion as a viable option for future robotic explorers. As such, a methodology for determining the tractive capability of a legged robot in Martian soil will be presented. Mathematical models developed in MATLAB validate the terramechanic theory behind the soil deformation under each of these experimental conditions and new models for measuring microrover capability in soil are proposed. Finally a legged vehicle is proposed and simulated in the software under Martian soil conditions in order for the vehicle's performance to be measured.}
}

@inproceedings{lincoln2049,
       booktitle = {14th International Conference on Advanced Robotics (ICAR)},
           title = {Vision-based reinforcement learning using approximate policy
iteration},
          author = {Marwan Shaker and Shigang Yue and Tom Duckett},
            year = {2009},
           pages = {0--6},
            note = {A major issue for reinforcement learning (RL) applied to robotics is the time required to learn a new skill. While RL has been used to learn mobile robot control in many simulated domains, applications involving learning on real
robots are still relatively rare. In this paper, the Least-Squares Policy Iteration (LSPI) reinforcement learning algorithm and a new model-based algorithm Least-Squares Policy Iteration with Prioritized Sweeping (LSPI+), are implemented on a mobile robot to acquire new skills quickly and efficiently. LSPI+ combines the benefits of LSPI and prioritized sweeping, which uses all previous experience to focus the computational effort on the most ?interesting? or dynamic parts of the state space. 
The proposed algorithms are tested on a household vacuum
cleaner robot for learning a docking task using vision as the only sensor modality. In experiments these algorithms are compared to other model-based and model-free RL algorithms. The results show that the number of trials required to learn the docking task is significantly reduced using LSPI compared to the other RL algorithms investigated, and that LSPI+ further improves on the performance of LSPI.},
        keywords = {ARRAY(0x5568fb9d9030)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2049/},
        abstract = {A major issue for reinforcement learning (RL) applied to robotics is the time required to learn a new skill. While RL has been used to learn mobile robot control in many simulated domains, applications involving learning on real
robots are still relatively rare. In this paper, the Least-Squares Policy Iteration (LSPI) reinforcement learning algorithm and a new model-based algorithm Least-Squares Policy Iteration with Prioritized Sweeping (LSPI+), are implemented on a mobile robot to acquire new skills quickly and efficiently. LSPI+ combines the benefits of LSPI and prioritized sweeping, which uses all previous experience to focus the computational effort on the most ?interesting? or dynamic parts of the state space. 
The proposed algorithms are tested on a household vacuum
cleaner robot for learning a docking task using vision as the only sensor modality. In experiments these algorithms are compared to other model-based and model-free RL algorithms. The results show that the number of trials required to learn the docking task is significantly reduced using LSPI compared to the other RL algorithms investigated, and that LSPI+ further improves on the performance of LSPI.}
}

@article{lincoln38592,
          volume = {5269},
          author = {Elizabeth Sklar and I. Icke},
            note = {cited By 1},
           title = {Using simulation to evaluate data-driven agents},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-642-01991-3},
           pages = {85--96},
            year = {2009},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38592/}
}

@inproceedings{lincoln37406,
          volume = {2},
          author = {B.G.R. Smith and C. Saaj},
            note = {cited By 0},
       booktitle = {60th International Astronautical Congress},
           title = {Biologically inspired nanorovers: Innovative and low cost technologies using shape memory alloys},
         journal = {60th International Astronautical Congress 2009, IAC 2009},
           pages = {1482--1494},
            year = {2009},
        keywords = {ARRAY(0x5568fbb5c648)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37406/},
        abstract = {This paper details the design and construction of a biologically inspired nanorover prototype for exploring Mars. Although all Martian exploration vehicles to date have been wheeled, a six legged design was selected for this rover so as to improve its trafficability across rough terrains, since the main focus of this project was miniaturisation, with a goal of building a rover which weighed less than 1kg. To this end, shape memory alloy actuators were used instead of conventional rotary motors, due to their small size and mass, and carbon fibre was used as the main construction material. The rover was analysed using a combination of empirical results and computer simulation, in particular a simulation tool being developed at the University of Surrey called the Legged Performance and Traction Predicting Tool (LPTPT), with results suggesting that the design could be the basis of a successful planetary exploration vehicle.}
}

@inproceedings{lincoln6937,
       booktitle = {International Workshop on Cognition for Technical Systems},
          editor = {B. Gottfried and H. Aghajan},
           month = {December},
           title = {Spatial context-aware person-following for a domestic robot},
          author = {Fang Yuan and Marc Hanheide and Gerhard Sagerer},
            year = {2008},
            note = {Domestic robots are in the focus of research in
terms of service providers in households and even as robotic
companion that share the living space with humans. A major
capability of mobile domestic robots that is joint exploration
of space. One challenge to deal with this task is how could we
let the robots move in space in reasonable, socially acceptable
ways so that it will support interaction and communication
as a part of the joint exploration. As a step towards this
challenge, we have developed a context-aware following behav-
ior considering these social aspects and applied these together
with a multi-modal person-tracking method to switch between
three basic following approaches, namely direction-following,
path-following and parallel-following. These are derived from
the observation of human-human following schemes and are
activated depending on the current spatial context (e.g. free
space) and the relative position of the interacting human.
A combination of the elementary behaviors is performed in
real time with our mobile robot in different environments.
First experimental results are provided to demonstrate the
practicability of the proposed approach.},
        keywords = {ARRAY(0x5568fba3a758)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6937/},
        abstract = {Domestic robots are in the focus of research in
terms of service providers in households and even as robotic
companion that share the living space with humans. A major
capability of mobile domestic robots that is joint exploration
of space. One challenge to deal with this task is how could we
let the robots move in space in reasonable, socially acceptable
ways so that it will support interaction and communication
as a part of the joint exploration. As a step towards this
challenge, we have developed a context-aware following behav-
ior considering these social aspects and applied these together
with a multi-modal person-tracking method to switch between
three basic following approaches, namely direction-following,
path-following and parallel-following. These are derived from
the observation of human-human following schemes and are
activated depending on the current spatial context (e.g. free
space) and the relative position of the interacting human.
A combination of the elementary behaviors is performed in
real time with our mobile robot in different environments.
First experimental results are provided to demonstrate the
practicability of the proposed approach.}
}

@inproceedings{lincoln6936,
           month = {December},
          author = {Agnes Swadzba and Anna-Lisa Vollmer and Marc Hanheide and Sven Wachsmuth},
            note = {This paper presents a new method for detecting
and merging redundant points in registered range data.
Given a global representation from sequences of 3D
points, the points are projected onto a virtual image
plane computed from the intrinsic parameters of the
sensor. Candidates for redundancy are collected per
pixel which then are clustered locally via region growing and replaced by the cluster?s mean value. As data is
provided in a certain manner defined by camera characteristics, this processing step preserves the structural
information of the data. For evaluation, our approach is
compared to two other algorithms. Applied to two dif-
ferent sequences, it is shown that the presented method
gives smooth results within planar regions of the point
clouds by successfully reducing noise and redundancy
and thus improves registered range data.},
       booktitle = {19th International Conference on Pattern Recognition},
          editor = {B. Gottfried and H. Aghajan},
           title = {Reducing noise and redundancy in registered range data for planar surface extraction},
       publisher = {IEEE / The International Association for Pattern Recognition (IAPR)},
            year = {2008},
             doi = {10.1109/ICPR.2008.4761411},
        keywords = {ARRAY(0x5568fbbc7fe8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6936/},
        abstract = {This paper presents a new method for detecting
and merging redundant points in registered range data.
Given a global representation from sequences of 3D
points, the points are projected onto a virtual image
plane computed from the intrinsic parameters of the
sensor. Candidates for redundancy are collected per
pixel which then are clustered locally via region growing and replaced by the cluster?s mean value. As data is
provided in a certain manner defined by camera characteristics, this processing step preserves the structural
information of the data. For evaluation, our approach is
compared to two other algorithms. Applied to two dif-
ferent sequences, it is shown that the presented method
gives smooth results within planar regions of the point
clouds by successfully reducing noise and redundancy
and thus improves registered range data.}
}

@inproceedings{lincoln39653,
       booktitle = {10th ESA Workshop on Advanced Space Technologies for Robotics and Automation},
           month = {November},
           title = {On-Orbit Servicing: Novel Algorithms for Motion Control of Robot Manipulators},
          author = {S. Parsa and C.M. Saaj and R.M. Daniali Hamid and Reza Ghaderi},
            year = {2008},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39653/}
}

@inproceedings{lincoln46206,
       booktitle = {30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
           month = {October},
           title = {Voice quality monitoring: A portable device prototype},
          author = {C Manfredi and T Bruschi and A Dallai and A Ferri and P Tortoli and M Calisti},
            year = {2008},
             doi = {10.1109/IEMBS.2008.4649323},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46206/},
        abstract = {This paper addresses the important issue of voice monitoring throughout the day under a clinical perspective. This problem is of great concern, for rehabilitation and from the assistive technology point of view. A prototype for a new portable device is proposed, implementing basic voice quality indexes (fundamental frequency F 0 , jitter, relative average perturbation RAP, noise) by means of robust high-resolution techniques. The device is contact-less, as the transducer is a small microphone included in the device. A feedback for patients outside the clinic is provided, given by a led/audio unit that advices the patient for any abnormal vocal emission, to help patients with carryover of therapy goals outside the clinical environment. The device will collect audio recordings to be submitted to a PC for further analysis, to be performed off-line. Such device for self-diagnosis and vocal rehabilitation could give a valid support, both to clinicians and patients.}
}

@article{lincoln2094,
          volume = {24},
          number = {5},
           month = {October},
          author = {Henrik Andreasson and Tom Duckett and Achim Lilienthal},
           title = {A minimalistic approach to appearance-based visual SLAM},
       publisher = {IEEE},
            year = {2008},
         journal = {IEEE Transactions on Robotics},
             doi = {10.1109/TRO.2008.2004642},
           pages = {991--1001},
        keywords = {ARRAY(0x5568fbb70618)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2094/},
        abstract = {This paper presents a vision-based approach to SLAM in indoor / outdoor environments with minimalistic sensing and computational requirements. The approach is based on a graph representation of robot poses, using a relaxation algorithm to obtain a globally consistent map. Each link corresponds to a
relative measurement of the spatial relation between the two nodes it connects. The links describe the likelihood distribution of the relative pose as a Gaussian distribution. To estimate the covariance matrix for links obtained from an omni-directional vision sensor, a novel method is introduced based on the relative similarity of neighbouring images. This new method does not require determining distances to image features using multiple
view geometry, for example. Combined indoor and outdoor experiments demonstrate that the approach can handle qualitatively different environments (without modification of the parameters), that it can cope with violations of the ?flat floor assumption? to some degree, and that it scales well with increasing size of the environment, producing topologically correct and geometrically accurate maps at low computational cost. Further experiments demonstrate that the approach is also suitable for combining multiple overlapping maps, e.g. for solving the multi-robot SLAM problem with unknown initial poses.}
}

@inproceedings{lincoln1679,
           month = {September},
          author = {Feras Dayoub and Tom Duckett},
       booktitle = {International Conference on Intelligent Robots and Systems 2008},
           title = {An adaptive appearance-based map for long-term topological localization of mobile robots},
       publisher = {IEEE},
             doi = {10.1109/IROS.2008.4650701},
           pages = {3364--3369},
            year = {2008},
        keywords = {ARRAY(0x5568fb9f4358)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1679/},
        abstract = {This work considers a mobile service robot which uses an appearance-based representation of its workplace as a map, where the current view and the map are used to estimate the current position in the environment. Due to the nature of real-world environments such as houses and offices, where the appearance keeps changing, the internal representation may become out of date after some time. To solve this problem the robot needs to be able to adapt its internal representation continually to the changes in the environment. This paper presents a method for creating an adaptive map for long-term appearance-based localization of a mobile robot using long-term and short-term memory concepts, with omni-directional vision as the external sensor.}
}

@inproceedings{lincoln39655,
       booktitle = {AIAA SPACE 2008 Conference \& Exposition},
           month = {September},
           title = {The Interaction between Walking Robot Footprint Shapes and Planetary Soil Deformation},
          author = {G.P. Scoot and C.M. Saaj and E. Moxey},
            year = {2008},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39655/}
}

@inproceedings{lincoln39654,
       booktitle = {Towards Autonomous Robotic Systems Conference},
           month = {September},
           title = {Modelling Soil Traction for more Effective Control of Walking Planetary Rovers},
          author = {G.P. Scott and C.M. Saaj and E. Moxey},
            year = {2008},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39654/}
}

@inproceedings{lincoln6928,
           month = {August},
          author = {Marc Hanheide and Gerhard Sagerer},
            note = {Despite increasing efforts in the field of social
robotics and interactive systems integrated and fully autonomous
robots which are capable of learning from interaction
with inexperienced and non-expert users are still a rarity.
However, in order to tackle the challenge of learning by
interaction robots need to be equipped with a set of basic
behaviors and abilities which have to be coupled and combined
in a flexible manner. This paper presents how a recently
proposed information-driven integration concept termed ?active
memory? is adopted to realize learning-enabling behaviors for
a domestic robot. These behaviors enable it to (i) learn about its
environment, (ii) interact with several humans simultaneously,
and (iii) couple learning and interaction tightly. The basic
interaction strategies on the basis of information exchange
through the active memory are presented. A brief discussion
of results obtained from live user trials with inexperienced
users in a home tour scenario underpin the relevance and
appropriateness of the described concepts.},
       booktitle = {RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication},
          editor = {B. Gottfried and H. Aghajan},
           title = {Active memory-based interaction strategies for learning-enabling behaviors},
       publisher = {IEEE},
            year = {2008},
             doi = {10.1109/ROMAN.2008.4600650},
           pages = {101--106},
        keywords = {ARRAY(0x5568fbb64588)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6928/},
        abstract = {Despite increasing efforts in the field of social
robotics and interactive systems integrated and fully autonomous
robots which are capable of learning from interaction
with inexperienced and non-expert users are still a rarity.
However, in order to tackle the challenge of learning by
interaction robots need to be equipped with a set of basic
behaviors and abilities which have to be coupled and combined
in a flexible manner. This paper presents how a recently
proposed information-driven integration concept termed ?active
memory? is adopted to realize learning-enabling behaviors for
a domestic robot. These behaviors enable it to (i) learn about its
environment, (ii) interact with several humans simultaneously,
and (iii) couple learning and interaction tightly. The basic
interaction strategies on the basis of information exchange
through the active memory are presented. A brief discussion
of results obtained from live user trials with inexperienced
users in a home tour scenario underpin the relevance and
appropriateness of the described concepts.}
}

@inproceedings{lincoln6930,
           month = {August},
          author = {Manja Lohse and Marc Hanheide},
            note = {In a society that keeps getting closer in touch with social robots it is very important to include potential users throughout the design of the systems. This is an important rationale to build robots that provide services and assistance in a socially acceptable way and influence societies in a positive way. In the process, methods are needed to rate the robot interaction performance. We present a multimodal corpus of na{\"i}ve users interacting with an autonomously operating system. It comprises data that, to our conviction, reveal a lot about human-robot interaction (HRI) in general and social acceptance, in particular. In both, the evaluation and the design process we took into account Clarkson and Arkin's heuristics for HRI (developed by adapting Nielsen's and Scholtz' heuristics to robotics) 1. We discuss exemplary results to show the use of heuristics in the design of socially acceptable robots.},
       booktitle = {Robots as Social Actors Workshop: International Symposium on Robot and Human Interactive Communication (RO-MAN 08)},
          editor = {B. Gottfried and H. Aghajan},
           title = {Evaluating a social home tour robot applying heuristics},
           pages = {1584--1589},
            year = {2008},
        keywords = {ARRAY(0x5568fbbc85e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6930/},
        abstract = {In a society that keeps getting closer in touch with social robots it is very important to include potential users throughout the design of the systems. This is an important rationale to build robots that provide services and assistance in a socially acceptable way and influence societies in a positive way. In the process, methods are needed to rate the robot interaction performance. We present a multimodal corpus of na{\"i}ve users interacting with an autonomously operating system. It comprises data that, to our conviction, reveal a lot about human-robot interaction (HRI) in general and social acceptance, in particular. In both, the evaluation and the design process we took into account Clarkson and Arkin's heuristics for HRI (developed by adapting Nielsen's and Scholtz' heuristics to robotics) 1. We discuss exemplary results to show the use of heuristics in the design of socially acceptable robots.}
}

@inproceedings{lincoln6931,
           month = {August},
          author = {Manja Lohse and Marc Hanheide and Britta Wrede and Michael L. Walters and Kheng Lee Koay and Dag Sverre Syrdal and Anders Green and Helge Huttenrauch and Kerstin Dautenhahn and Gerhard Sagerer and Kerstin Severinson-Eklundh},
            note = {Human-robot interaction (HRI) research is here presented into social robots that have to be able to interact with inexperienced users. In the design of these robots many research findings of human-human interaction and human-computer interaction are adopted but the direct applicability of these theories is limited because a robot is different from both humans and computers. Therefore, new methods have to be developed in HRI in order to build robots that are suitable for inexperienced users. In this paper we present a video study we conducted employing our robot BIRON (Bielefeld robot companion) which is designed for use in domestic environments. Subjects watched the system during the interaction with a human and rated two different robot behaviours (extrovert and introvert). The behaviours differed regarding verbal output and person following of the robot. Aiming to improve human-robot interaction, participantspsila ratings of the behaviours were evaluated and compared.},
       booktitle = {The 17th IEEE International Symposium on Robot and Human Interactive Communication},
          editor = {B. Gottfried and H. Aghajan},
           title = {Evaluating extrovert and introvert behaviour of a domestic robot {--} a video study},
       publisher = {IEEE},
            year = {2008},
             doi = {10.1109/ROMAN.2008.4600714},
           pages = {488--493},
        keywords = {ARRAY(0x5568fb677c58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6931/},
        abstract = {Human-robot interaction (HRI) research is here presented into social robots that have to be able to interact with inexperienced users. In the design of these robots many research findings of human-human interaction and human-computer interaction are adopted but the direct applicability of these theories is limited because a robot is different from both humans and computers. Therefore, new methods have to be developed in HRI in order to build robots that are suitable for inexperienced users. In this paper we present a video study we conducted employing our robot BIRON (Bielefeld robot companion) which is designed for use in domestic environments. Subjects watched the system during the interaction with a human and rated two different robot behaviours (extrovert and introvert). The behaviours differed regarding verbal output and person following of the robot. Aiming to improve human-robot interaction, participantspsila ratings of the behaviours were evaluated and compared.}
}

@inproceedings{lincoln6933,
       booktitle = {Robotics: Science and Systems Workshop on Interactive Robot Learning},
          editor = {B. Gottfried and H. Aghajan},
           month = {June},
           title = {Moving from augmented to interactive mapping},
          author = {Olaf Booij and Ben Kr{\"o}se and Julia Peltason and Thorsten P. Spexard and Marc Hanheide},
            year = {2008},
            note = {Recently1 there has been a growing interest in human
augmented mapping[1, 2]. That is: a mobile robot builds
a low level spatial representation of the environment based
on its sensor readings while a human provides labels for
human concepts, such as rooms, which are then augmented
or anchored to this representation or map [3]. Given such an
augmented map the robot has the ability to communicate with
the human about spatial concepts using the labels that the
human understand. For instance, the robot could report it is
in the ?kitchen?, instead of a set Cartesian coordinates which
are probably meaningless to the human.},
        keywords = {ARRAY(0x5568fbaae000)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6933/},
        abstract = {Recently1 there has been a growing interest in human
augmented mapping[1, 2]. That is: a mobile robot builds
a low level spatial representation of the environment based
on its sensor readings while a human provides labels for
human concepts, such as rooms, which are then augmented
or anchored to this representation or map [3]. Given such an
augmented map the robot has the ability to communicate with
the human about spatial concepts using the labels that the
human understand. For instance, the robot could report it is
in the ?kitchen?, instead of a set Cartesian coordinates which
are probably meaningless to the human.}
}

@inproceedings{lincoln12853,
           month = {June},
          author = {Li Jun and Tom Duckett},
       booktitle = {2008 7th World Congress on Intelligent Control and Automation},
           title = {Some practical aspects on incremental training of RBF network for robot behavior learning},
       publisher = {IEEE},
             doi = {10.1109/WCICA.2008.4593231},
           pages = {2001--2006},
            year = {2008},
        keywords = {ARRAY(0x5568fb9d9900)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/12853/},
        abstract = {The radial basis function (RBF) neural network with Gaussian activation function and least- mean squares (LMS) learning algorithm is a popular function approximator widely used in many applications due to its simplicity, robustness, optimal approximation, etc.. In practice, however, making the RBF network (and other neural networks) work well can sometimes be more of an art than a science, especially concerning parameter selection and adjustment. In this paper, we address three issues, namely the normalization of raw sensory-motor data, the choice of receptive fields for the RBFs, and the adjustment of the learning rate when training the RBF network in incremental learning fashion for robot behavior learning, where the RBF network is used to map sensory inputs to motor outputs. Though these issues are less theoretical and scientific, they are more practical, and sometimes more crucial for the application of the RBF network to the problems at hand. We believe that being aware of these practical issues can enable a better use of the RBF network in the real-world application. 1Introduction The radial basis function (RBF) network [3, 16] has found a wide range of application due to its simplicity, local learning, robustness, optimal approximation, etc.. For example, in an autonomous robot control system, the RBF network can be applied to directly map the sensory inputs to motor outputs [23, 21, 9, 15] for acquiring the required behaviors. However, in these successful applications there has been much less description on how to choose and adjust the parameters and why they are adjusted so for the applications of interest. In this paper, we address three practical aspects for incremental training of the RBF network, namely normalizing the raw sensor input, choosing the receptive fields of RBFs, and adjusting the learning rate for robot behavior learning. We restrict our investigation of these issues to the following situations: First of all, for simplicity of notation, consider a multi-input and single-output (MISO) system in which x = [x1,x2,...,xm]Tis an m-dimensional input vector, and y the scalar output. The RBF neural network can be defined as: ? y = F(x) = K ? k=1 wk{\ensuremath{\phi}}k(x) + b,{\ensuremath{\phi}}k(x) = e? 1 ({\ensuremath{\gamma}}{\ensuremath{\sigma}}k)2?x??k?2 for k = 1,2,...,K, (1) where wkis the weight of k-th Gaussian function {\ensuremath{\phi}}k(x), ?k= [?k1,?k2,...,?km]Tis the m-dimensional position vector of k-th radial basis function, and {\ensuremath{\sigma}}kis receptive field of k-th radial basis function. In addition, K is the number of the RBFs, b is the bias, and {\ensuremath{\gamma}} is the optimal factor introduced for optimising the receptive field {\ensuremath{\sigma}}k, as in [20]. We assume that the number of RBFs K could either be designated in advance before training, thus clustering algorithms like McQueen?s K-means, or Kohonen?s SOM [10] can be used for determining the position vector ?k; or it could be automatically obtained in real time during the training process by using dynamically adaptive clustering algorithms such as GWR [14]. In both cases, the receptive field {\ensuremath{\sigma}}kcan be determined by some empirical estimation method (see section 3). We also assume that the RBF network?s weights wkand bias b are updated by the least mean squares (LMS) algorithm, as wk? wk+ {\ensuremath{\eta}}t(yt? ? y){\ensuremath{\phi}}k(xt), for k = 1,2,...,K,b ? b + {\ensuremath{\eta}}t(yp? ? y), (2) 1}
}

@inproceedings{lincoln1683,
       booktitle = {The Intelligent Vehicles 2008 Symposium  (IV08)},
           month = {June},
           title = {Learning visual docking for non-holonomic autonomous vehicles},
          author = {Tomas Martinez-Marin and Tom Duckett},
            year = {2008},
            note = {This paper presents a new method of learning visual docking skills for non-holonomic vehicles by direct interaction with the environment. The method is based on a reinforcement algorithm, which speeds up Q-learning by applying memorybased sweeping and enforcing the ?adjoining property?, a filtering mechanism to only allow transitions between states that satisfy a fixed distance. The method overcomes some limitations of reinforcement learning techniques when they are employed in applications with continuous non-linear systems, such as car-like vehicles. In particular, a good approximation to the optimal
behaviour is obtained by a small look-up table. The algorithm is tested within an image-based visual servoing framework on a docking task. The training time was less than 1 hour on the real vehicle. In experiments, we show the satisfactory performance of the algorithm.},
        keywords = {ARRAY(0x5568fba33938)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1683/},
        abstract = {This paper presents a new method of learning visual docking skills for non-holonomic vehicles by direct interaction with the environment. The method is based on a reinforcement algorithm, which speeds up Q-learning by applying memorybased sweeping and enforcing the ?adjoining property?, a filtering mechanism to only allow transitions between states that satisfy a fixed distance. The method overcomes some limitations of reinforcement learning techniques when they are employed in applications with continuous non-linear systems, such as car-like vehicles. In particular, a good approximation to the optimal
behaviour is obtained by a small look-up table. The algorithm is tested within an image-based visual servoing framework on a docking task. The training time was less than 1 hour on the real vehicle. In experiments, we show the satisfactory performance of the algorithm.}
}

@article{lincoln1682,
          volume = {56},
          number = {6},
           month = {June},
          author = {Martin Persson and Tom Duckett and Achim Lilienthal},
            note = {This work investigates the use of semantic information to link ground level occupancy maps and aerial images. A ground level semantic map, which shows open ground and indicates the probability of cells being occupied by walls of buildings, is obtained by a mobile robot equipped with an omnidirectional camera, GPS and a laser range finder. This semantic information is used for local and global segmentation of an aerial image. The result is a map where the semantic information has been extended beyond the range of the robot sensors and predicts where the mobile robot can find buildings and potentially driveable ground.},
           title = {Fusion of aerial images and sensor data from a ground vehicle for improved semantic mapping},
       publisher = {Elsevier},
            year = {2008},
         journal = {Robotics and autonomous systems},
             doi = {10.1016/j.robot.2008.03.002},
           pages = {483--492},
        keywords = {ARRAY(0x5568fbaf5a18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1682/},
        abstract = {This work investigates the use of semantic information to link ground level occupancy maps and aerial images. A ground level semantic map, which shows open ground and indicates the probability of cells being occupied by walls of buildings, is obtained by a mobile robot equipped with an omnidirectional camera, GPS and a laser range finder. This semantic information is used for local and global segmentation of an aerial image. The result is a map where the semantic information has been extended beyond the range of the robot sensors and predicts where the mobile robot can find buildings and potentially driveable ground.}
}

@inproceedings{lincoln6938,
           month = {May},
          author = {Marc Hanheide and Sebastian Wrede and Christian Lang and Gerhard Sagerer},
            note = {In order to provide personalized services and to
develop human-like interaction capabilities robots need to rec-
ognize their human partner. Face recognition has been studied
in the past decade exhaustively in the context of security systems
and with significant progress on huge datasets. However, these
capabilities are not in focus when it comes to social interaction
situations. Humans are able to remember people seen for a
short moment in time and apply this knowledge directly in
their engagement in conversation. In order to equip a robot with
capabilities to recall human interlocutors and to provide user-
aware services, we adopt human-human interaction schemes to
propose a face memory on the basis of active appearance models
integrated with the active memory architecture. This paper
presents the concept of the interactive face memory, the applied
recognition algorithms, and their embedding into the robot?s
system architecture. Performance measures are discussed for
general face databases as well as scenario-specific datasets.},
       booktitle = {IEEE International Conference on Robotics and Automation},
          editor = {B. Gottfried and H. Aghajan},
           title = {Who am I talking with? A face memory for social robots},
       publisher = {IEEE},
            year = {2008},
             doi = {10.1109/ROBOT.2008.4543772},
           pages = {3660--3665},
        keywords = {ARRAY(0x5568fb6747a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6938/},
        abstract = {In order to provide personalized services and to
develop human-like interaction capabilities robots need to rec-
ognize their human partner. Face recognition has been studied
in the past decade exhaustively in the context of security systems
and with significant progress on huge datasets. However, these
capabilities are not in focus when it comes to social interaction
situations. Humans are able to remember people seen for a
short moment in time and apply this knowledge directly in
their engagement in conversation. In order to equip a robot with
capabilities to recall human interlocutors and to provide user-
aware services, we adopt human-human interaction schemes to
propose a face memory on the basis of active appearance models
integrated with the active memory architecture. This paper
presents the concept of the interactive face memory, the applied
recognition algorithms, and their embedding into the robot?s
system architecture. Performance measures are discussed for
general face databases as well as scenario-specific datasets.}
}

@inproceedings{lincoln6935,
       booktitle = {ICRA Workshop on Social Interaction with Intelligent Indoor Robots (2008)},
          editor = {B. Gottfried and H. Aghajan},
           month = {May},
           title = {Oops, something is wrong - error detection and recovery for advanced human-robot-interaction},
          author = {Thorsten P. Spexard and Marc Hanheide and Shuyin Li and Britta Wrede},
            year = {2008},
            note = {A matter of course for the researchers and developers of state-of-the-art technology for human-computer- or human-robot-interaction is to create not only systems that can precisely fulfill a certain task. They must provide a strong robustness against internal and external errors or user-dependent application errors. Especially when creating service robots for a variety of applications or robots for accompanying humans in everyday situations sufficient error robustness is crucial for acceptance by users. But experience unveils that operating such systems under real world conditions with unexperienced users is an extremely challenging task which still is not solved satisfactorily. In this paper we will present an approach for handling both internal errors and application errors within an integrated system capable of performing extended HRI on different robotic platforms and in unspecified surroundings like a real world apartment. Based on the gathered experience from user studies and evaluating integrated systems in the real world, we implemented several ways to generalize and handle unexpected situations. Adding such a kind of error awareness to HRI systems in cooperation with the interaction partner avoids to get stuck in an unexpected situation or state and handle mode confusion. Instead of shouldering the enormous effort to account for all possible problems, this paper proposes a more general solution and underpins this with findings from naive user studies. This enhancement is crucial for the development of a new generation of robots as despite diligent preparations might be made, no one can predict how an interaction with a robotic system will develop and which kind of environment it has to cope with.},
        keywords = {ARRAY(0x5568fb6d1cd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6935/},
        abstract = {A matter of course for the researchers and developers of state-of-the-art technology for human-computer- or human-robot-interaction is to create not only systems that can precisely fulfill a certain task. They must provide a strong robustness against internal and external errors or user-dependent application errors. Especially when creating service robots for a variety of applications or robots for accompanying humans in everyday situations sufficient error robustness is crucial for acceptance by users. But experience unveils that operating such systems under real world conditions with unexperienced users is an extremely challenging task which still is not solved satisfactorily. In this paper we will present an approach for handling both internal errors and application errors within an integrated system capable of performing extended HRI on different robotic platforms and in unspecified surroundings like a real world apartment. Based on the gathered experience from user studies and evaluating integrated systems in the real world, we implemented several ways to generalize and handle unexpected situations. Adding such a kind of error awareness to HRI systems in cooperation with the interaction partner avoids to get stuck in an unexpected situation or state and handle mode confusion. Instead of shouldering the enormous effort to account for all possible problems, this paper proposes a more general solution and underpins this with findings from naive user studies. This enhancement is crucial for the development of a new generation of robots as despite diligent preparations might be made, no one can predict how an interaction with a robotic system will develop and which kind of environment it has to cope with.}
}

@inproceedings{lincoln6929,
           month = {May},
          author = {Ahmad Rabie and Christian Lang and Marc Hanheide and Modesto Castrillon-Santana and Gerhard Sagerer},
            note = {The human face plays an important role in communication as it allows to discern different interaction partners and provides non-verbal feedback. In this paper, we present a soft real-time vision system that enables an interactive robot to analyze faces of interaction partners not only to identify them, but also to recognize their respective facial expressions as a dialog-controlling non-verbal cue. In order to assure applicability in real world environments, a robust detection scheme is presented which detects faces and basic facial features such as the position of the mouth, nose, and eyes. Based on these detected features, facial parameters are extracted using active appearance models (AAMs) and conveyed to support vector machine (SVM) classifiers to identify both persons and facial expressions. This paper focuses on four different initialization methods for determining the initial shape for the AAM algorithm and their particular performance in two different classification tasks with respect to either the facial expression DaFEx database and to the real world data obtained from a robot?s point of view.},
       booktitle = {6th International Conference, ICVS 2008},
          editor = {B. Gottfried and H. Aghajan},
           title = {Automatic initialization for facial analysis in interactive robotics},
       publisher = {Springer},
            year = {2008},
             doi = {10.1007/978-3-540-79547-6\_50},
           pages = {517--526},
        keywords = {ARRAY(0x5568fba06068)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6929/},
        abstract = {The human face plays an important role in communication as it allows to discern different interaction partners and provides non-verbal feedback. In this paper, we present a soft real-time vision system that enables an interactive robot to analyze faces of interaction partners not only to identify them, but also to recognize their respective facial expressions as a dialog-controlling non-verbal cue. In order to assure applicability in real world environments, a robust detection scheme is presented which detects faces and basic facial features such as the position of the mouth, nose, and eyes. Based on these detected features, facial parameters are extracted using active appearance models (AAMs) and conveyed to support vector machine (SVM) classifiers to identify both persons and facial expressions. This paper focuses on four different initialization methods for determining the initial shape for the AAM algorithm and their particular performance in two different classification tasks with respect to either the facial expression DaFEx database and to the real world data obtained from a robot?s point of view.}
}

@article{lincoln37440,
          volume = {61},
          number = {3},
           month = {April},
          author = {C. Saaj and C.I. Underwood and C. Noakes and D.W.G. Park and T. Moore},
            note = {cited By 0},
           title = {The science and technology behind galileo - Europe's GPS},
       publisher = {British Interplanetary Society},
            year = {2008},
         journal = {JBIS - Journal of the British Interplanetary Society},
           pages = {91--97},
        keywords = {ARRAY(0x5568fbb70a80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37440/}
}

@inproceedings{lincoln40831,
       booktitle = {2008 IEEE/PES Transmission and Distribution Conference and Exposition},
           month = {April},
           title = {Hydro thermal scheduling using particle swarm optimization},
          author = {Chandrasekar Samudi and Gautham Das and Piyush C. Ojha and T. S. Sreeni and Sushil Cherian},
            year = {2008},
           pages = {1--5},
             doi = {10.1109/TDC.2008.4517221},
        keywords = {ARRAY(0x5568fba1b328)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40831/},
        abstract = {This paper presents a new approach of particle swarm optimization (PSO) algorithm for short term Hydro Thermal Scheduling (HTS) problems. Various possible particle selections have been studied and its effects on the global optima have been discussed. The effectiveness and stochastic nature of proposed algorithm has been tested with standard test case and the results have been compared with earlier works. This paper also describes software developed for short term hydro-thermal scheduling by considering hydro economic dispatch and thermal unit commitment. The proposed algorithm is ideally suitable for hydro-thermal co-ordination problems, hydro economic dispatch problems with unit commitment, thermal economic dispatch with unit commitment problems and scheduling of hydraulically coupled plants.}
}

@inproceedings{lincoln6932,
           month = {April},
          author = {Kai J{\"u}ngling and Michael Arens and Marc Hanheide and Gerhard Sagerer},
            note = {This paper introduces a generic architecture for the fusion of perceptual processes and its application in real-time object tracking. In this architecture, the well known anchoring approach is, by integrating techniques from information fusion, extended to multi-modal anchoring so as to be applicable in a multi-process environment. The system architecture is designed to be applicable in a generic way, independent of specific application domains and of the characteristics of the underlying sensory processes. It is shown that, by combining multiple independent video-based detection methods, the generic multi-modal anchoring approach can be successfully employed for real-time person tracking in difficult environments},
       booktitle = {11th International Conference on Information Fusion},
          editor = {B. Gottfried and H. Aghajan},
           title = {Fusion of perceptual processes for real-time object tracking},
       publisher = {IEEE},
            year = {2008},
           pages = {1--8},
        keywords = {ARRAY(0x5568fba9bb30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6932/},
        abstract = {This paper introduces a generic architecture for the fusion of perceptual processes and its application in real-time object tracking. In this architecture, the well known anchoring approach is, by integrating techniques from information fusion, extended to multi-modal anchoring so as to be applicable in a multi-process environment. The system architecture is designed to be applicable in a generic way, independent of specific application domains and of the characteristics of the underlying sensory processes. It is shown that, by combining multiple independent video-based detection methods, the generic multi-modal anchoring approach can be successfully employed for real-time person tracking in difficult environments}
}

@article{lincoln6710,
          volume = {26},
          number = {1},
           month = {January},
          author = {Christian Bauckhage and Sven Wachsmuth and Marc Hanheide and S. Wrede and Gerhard Sagerer and G. Heidemann and H. Ritter},
            note = {Object recognition is the ability of a system to relate visual stimuli to its knowledge of the world. Although humans perform this task effortlessly and without thinking about it, a general algorithmic solution has not yet been found. Recently, a shift from devising isolated recognition techniques towards integrated systems could be observed [Y. Aloimonos, Active vision revisited, in: Y. Aloimonos (Ed.), Active Perception, Lawrence Efibaum, 1993, pp. 1?18; H. Christensen, Cognitive (vision) systems, ERCIM News (April, 2003). 17?18]. The visual active memory (VAM) perspective refines this system view towards an interactive computational framework for recognition systems in human everyday environments. VAM is in line with the recently emerged Cognitive Vision paradigm [H. Christensen, Cognitive (vision) systems, ERCIM News (April, 2003). 17?18] which is concerned with vision systems that evaluate, gather and integrate contextual knowledge for visual analysis. It consists of active processes that generate knowledge by means of a tight cooperation of perception, reasoning, learning and prior models. In addition, VAM emphasizes the dynamic representation of gathered knowledge. The memory is assumed to be structured in a hierarchy of successive memory systems that mediate the modularly defined processing components of the recognition system. Recognition and learning take place in the stress field of objects, actions, activities, scene context, and user interaction. In this paper, we exemplify the VAM perspective by means of existing demonstrator systems. Assuming three different perspectives (biological foundation, system engineering, and computer vision), we will show that the VAM concept is central to the cognitive capabilities of the system and that it leads to a more general object recognition framework.},
           title = {The visual active memory perspective on integrated recognition systems},
       publisher = {elsevier},
            year = {2008},
         journal = {Image and Vision Computing},
             doi = {10.1016/j.imavis.2005.08.008},
           pages = {5--14},
        keywords = {ARRAY(0x5568fbb49a48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6710/},
        abstract = {Object recognition is the ability of a system to relate visual stimuli to its knowledge of the world. Although humans perform this task effortlessly and without thinking about it, a general algorithmic solution has not yet been found. Recently, a shift from devising isolated recognition techniques towards integrated systems could be observed [Y. Aloimonos, Active vision revisited, in: Y. Aloimonos (Ed.), Active Perception, Lawrence Efibaum, 1993, pp. 1?18; H. Christensen, Cognitive (vision) systems, ERCIM News (April, 2003). 17?18]. The visual active memory (VAM) perspective refines this system view towards an interactive computational framework for recognition systems in human everyday environments. VAM is in line with the recently emerged Cognitive Vision paradigm [H. Christensen, Cognitive (vision) systems, ERCIM News (April, 2003). 17?18] which is concerned with vision systems that evaluate, gather and integrate contextual knowledge for visual analysis. It consists of active processes that generate knowledge by means of a tight cooperation of perception, reasoning, learning and prior models. In addition, VAM emphasizes the dynamic representation of gathered knowledge. The memory is assumed to be structured in a hierarchy of successive memory systems that mediate the modularly defined processing components of the recognition system. Recognition and learning take place in the stress field of objects, actions, activities, scene context, and user interaction. In this paper, we exemplify the VAM perspective by means of existing demonstrator systems. Assuming three different perspectives (biological foundation, system engineering, and computer vision), we will show that the VAM concept is central to the cognitive capabilities of the system and that it leads to a more general object recognition framework.}
}

@article{lincoln2103,
          volume = {56},
          number = {2},
          author = {Nicola Bellotto and Kevin Burn and Eric Fletcher and Stefan Wermter},
           title = {Appearance-based localization for mobile robots using digital zoom and visual compass},
       publisher = {Elsevier},
            year = {2008},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2007.07.001},
           pages = {143--156},
        keywords = {ARRAY(0x5568fb9f4538)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2103/},
        abstract = {This paper describes a localization system for mobile robots moving in dynamic indoor environments, which uses probabilistic integration of visual appearance and odometry information. The approach is based on a novel image matching algorithm for appearance-based place recognition that integrates digital zooming, to extend the area of application, and a visual compass. Ambiguous information used for recognizing places is resolved with multiple hypothesis tracking and a selection procedure inspired by Markov localization. This enables the system to deal with perceptual aliasing or absence of reliable sensor data. It has been implemented on a robot operating in an office scenario and the robustness of the approach demonstrated experimentally.}
}

@inproceedings{lincoln38495,
          volume = {13 LNB},
          author = {J. Collins and P. Faratin and Simon Parsons and J.A. Rodriguez-Aguilar and N. Sadeh and O. Shehory and Elizabeth Sklar},
            note = {cited By 0},
       booktitle = {5th Workshop on Trading Agent Design and Analysis, TADA 2007, Co-located with the 22nd AAAI Conference on Artificial Intelligence, AAAI 2007},
           title = {Preface},
         journal = {Lecture Notes in Business Information Processing},
           pages = {v--vii},
            year = {2008},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38495/}
}

@inproceedings{lincoln38594,
          volume = {WS-08-},
           title = {Using surveyor SRV-1 robots to motivate CS1 students},
          author = {J. Cummins and M.Q. Aznar and Elizabeth Sklar},
            year = {2008},
           pages = {23--27},
            note = {cited By 1},
         journal = {AAAI Workshop - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38594/}
}

@inproceedings{lincoln38490,
           title = {Discovering the game in auctions},
          author = {M. Kaisers and K. Tuyls and F. Thuijsman and Simon Parsons},
            year = {2008},
           pages = {113--120},
            note = {cited By 0},
         journal = {Belgian/Netherlands Artificial Intelligence Conference},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38490/}
}

@inproceedings{lincoln38494,
          volume = {2},
           title = {Characterizing effective auction mechanisms: Insights from the 2007 tac Market Design competition},
          author = {J. Niu and K. Cai and Simon Parsons and E. Gerding and P. McBurney},
            year = {2008},
           pages = {1061--1068},
            note = {cited By 35},
         journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38494/}
}

@inproceedings{lincoln38496,
          volume = {3},
           title = {JCAT: A platform for the TAC market design competition},
          author = {J. Niu and K. Cai and Simon Parsons and E. Gerding and P. McBurney and T. Moyaux and S. Phelps and D. Shield},
            year = {2008},
           pages = {1603--1604},
            note = {cited By 16},
         journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38496/}
}

@article{lincoln38493,
          volume = {13 LNB},
           title = {On the behavior of competing markets populated by automated traders},
          author = {J. Niu and K. Cai and Simon Parsons and Elizabeth Sklar},
            year = {2008},
           pages = {200--216},
            note = {cited By 0},
         journal = {Lecture Notes in Business Information Processing},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38493/}
}

@article{lincoln38491,
          volume = {4946 L},
          author = {Simon Parsons and P. McBurney and Elizabeth Sklar and M. Wooldridge},
            note = {cited By 1},
           title = {On the relevance of utterances in formal inter-agent dialogues},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-540-78915-4-4},
           pages = {47--62},
            year = {2008},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38491/}
}

@article{lincoln38599,
          volume = {4865 L},
          author = {S. Phelps and K. Cai and P. McBurney and J. Niu and Simon Parsons and Elizabeth Sklar},
            note = {cited By 12},
           title = {Auctions, evolution, and multi-agent learning},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-540-77949-0},
           pages = {188--210},
            year = {2008},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38599/}
}

@inproceedings{lincoln37433,
          author = {G.P. Scott and G.N. Meirion-Griffith and C. Saaj and E. Moxey},
            note = {cited By 8},
       booktitle = {AIAA SPACE 2008 Conference \& Exposition},
           title = {A Comparative study of the deformation of planetary soils under tracked and legged rovers},
       publisher = {Aerospace Research Central},
         journal = {Space 2008 Conference},
             doi = {10.2514/6.2008-7897},
            year = {2008},
        keywords = {ARRAY(0x5568fbb02160)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37433/}
}

@inproceedings{lincoln37422,
       booktitle = {16th International Conference of the International Society for Terrain Vehicle Systems 2008},
           title = {Walking micro-rovers for planetary exploration: Investigation into the mechanics of soil-footprint interaction},
          author = {G.P. Scott and C. Saaj and E. Moxey},
            year = {2008},
           pages = {265--275},
            note = {cited By 2},
         journal = {16th International Conference of the International Society for Terrain Vehicle Systems 2008, ISTVS 2008},
        keywords = {ARRAY(0x5568fb9e8720)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37422/}
}

@inproceedings{lincoln38596,
          volume = {SS-08-},
           title = {Using artificial intelligence to help bridge students from high school to college},
          author = {Elizabeth Sklar and Simon Parsons and S. Tejada and S. Lowes and M.Q. Azhar and S. Chopra and R. Jansen and I. Rudowsky},
            year = {2008},
           pages = {80--85},
            note = {cited By 1},
         journal = {AAAI Spring Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38596/}
}

@article{lincoln38598,
          volume = {5003 L},
          author = {M. Spoelstra and Elizabeth Sklar},
            note = {cited By 4},
           title = {Agent-based simulation of group learning},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-540-70916-9},
           pages = {69--83},
            year = {2008},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38598/}
}

@inproceedings{lincoln38492,
          volume = {1},
           title = {A dialogue mechanism for public argumentation using conversation policies},
          author = {Y. Tang and Simon Parsons},
            year = {2008},
           pages = {438--445},
            note = {cited By 2},
         journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38492/}
}

@article{lincoln38597,
          volume = {5003 L},
          author = {Y. Tang and Simon Parsons and Elizabeth Sklar},
            note = {cited By 0},
           title = {An agent-based model that relates investment in education to economic prosperity},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-540-70916-9},
           pages = {84--95},
            year = {2008},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38597/}
}

@article{lincoln8339,
          volume = {25},
          number = {12},
           month = {December},
          author = {H. Siegl and Marc Hanheide and S. Wrede and A. Pinz},
           title = {An augmented reality human-computer interface for object localization in a cognitive vision system},
       publisher = {Elsevier},
            year = {2007},
         journal = {Image and Vision Computing},
             doi = {10.1016/j.imavis.2006.04.027},
           pages = {1895--1903},
        keywords = {ARRAY(0x5568fba56ae8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8339/},
        abstract = {The European Cognitive Vision project VAMPIRE uses mobile AR-kits to interact with a visual active memory for teaching and retrieval purposes. This paper describes concept and technical realization of the used mobile AR-kits and discusses interactive learning and retrieval in office environments, and the active memory infrastructure. The focus is on 3D interaction for pointing in a scene coordinate system. This is achieved by 3D augmented pointing, which combines inside-out tracking for head pose recovery and 3D stereo human-computer interaction. Experimental evaluation shows that the accuracy of this 3D cursor is within a few centimeters, which is sufficient to point at an object in an office. Finally, an application of the cursor in VAMPIRE is presented, where in addition to the mobile system, at least one stationary active camera is used to obtain different views of an object. There are many potential applications, for example an improved view-based object recognition. {\^A}{\copyright} 2006 Elsevier B.V. All rights reserved.}
}

@article{lincoln6712,
          volume = {25},
          number = {12},
           month = {December},
          author = {H. Siegl and Marc Hanheide and S. Wrede and A. Pinz},
            note = {The European Cognitive Vision project VAMPIRE uses mobile AR-kits to interact with a visual active memory for teaching and retrieval purposes. This paper describes concept and technical realization of the used mobile AR-kits and discusses interactive learning and retrieval in office environments, and the active memory infrastructure. The focus is on 3D interaction for pointing in a scene coordinate system. This is achieved by 3D augmented pointing, which combines inside-out tracking for head pose recovery and 3D stereo human?computer interaction. Experimental evaluation shows that the accuracy of this 3D cursor is within a few centimeters, which is sufficient to point at an object in an office. Finally, an application of the cursor in VAMPIRE is presented, where in addition to the mobile system, at least one stationary active camera is used to obtain different views of an object. There are many potential applications, for example an improved view-based object recognition.},
           title = {An augmented reality human?computer interface for object localization in a cognitive vision system},
       publisher = {Elsevier},
            year = {2007},
         journal = {Image and Vision Computing},
             doi = {10.1016/j.imavis.2006.04.027},
           pages = {1895--1903},
        keywords = {ARRAY(0x5568fbb89348)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6712/},
        abstract = {The European Cognitive Vision project VAMPIRE uses mobile AR-kits to interact with a visual active memory for teaching and retrieval purposes. This paper describes concept and technical realization of the used mobile AR-kits and discusses interactive learning and retrieval in office environments, and the active memory infrastructure. The focus is on 3D interaction for pointing in a scene coordinate system. This is achieved by 3D augmented pointing, which combines inside-out tracking for head pose recovery and 3D stereo human?computer interaction. Experimental evaluation shows that the accuracy of this 3D cursor is within a few centimeters, which is sufficient to point at an object in an office. Finally, an application of the cursor in VAMPIRE is presented, where in addition to the mobile system, at least one stationary active camera is used to obtain different views of an object. There are many potential applications, for example an improved view-based object recognition.}
}

@inproceedings{lincoln1848,
           month = {October},
          author = {Grzegorz Cielniak and Tom Duckett and J. Achim Lilienthal},
            note = {This paper presents an approach for tracking multiple persons using a combination of colour and thermal vision sensors on a mobile robot. First, an adaptive colour model is incorporated into the measurement model of the tracker. Second, a new approach for detecting occlusions is introduced, using a machine learning classifier for pairwise comparison of persons (classifying which one is in front of the other). Third, explicit occlusion handling is then incorporated into the tracker.},
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           title = {Improved data association and occlusion handling for vision-based people tracking by mobile robots},
       publisher = {IEEE},
            year = {2007},
             doi = {10.1016/j.robot.2006.04.013},
           pages = {3436--3441},
        keywords = {ARRAY(0x5568fbaf2830)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1848/},
        abstract = {This paper presents an approach for tracking multiple persons using a combination of colour and thermal vision sensors on a mobile robot. First, an adaptive colour model is incorporated into the measurement model of the tracker. Second, a new approach for detecting occlusions is introduced, using a machine learning classifier for pairwise comparison of persons (classifying which one is in front of the other). Third, explicit occlusion handling is then incorporated into the tracker.}
}

@article{lincoln6741,
          volume = {23},
          number = {5},
           month = {October},
          author = {Thorsten P. Spexard and Marc Hanheide and Gerhard Sagerer},
            note = {A very important aspect in developing robots capable of human-robot interaction (HRI) is the research in natural, human-like communication, and subsequently, the development of a research platform with multiple HRI capabilities for evaluation. Besides a flexible dialog system and speech understanding, an anthropomorphic appearance has the potential to support intuitive usage and understanding of a robot, e.g., human-like facial expressions and deictic gestures can as well be produced and also understood by the robot. As a consequence of our effort in creating an anthropomorphic appearance and to come close to a human- human interaction model for a robot, we decided to use human-like sensors, i.e., two cameras and two microphones only, in analogy to human perceptual capabilities too. Despite the challenges resulting from these limits with respect to perception, a robust attention system for tracking and interacting with multiple persons simultaneously in real time is presented. The tracking approach is sufficiently generic to work on robots with varying hardware, as long as stereo audio data and images of a video camera are available. To easily implement different interaction capabilities like deictic gestures, natural adaptive dialogs, and emotion awareness on the robot, we apply a modular integration approach utilizing XML-based data exchange. The paper focuses on our efforts to bring together different interaction concepts and perception capabilities integrated on a humanoid robot to achieve comprehending human-oriented interaction.},
           title = {Human-oriented interaction with an anthropomorphic robot},
       publisher = {IEEE},
            year = {2007},
         journal = {Robotics, IEEE Transactions on},
             doi = {10.1109/TRO.2007.904903},
           pages = {852--862},
        keywords = {ARRAY(0x5568fb9b6408)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6741/},
        abstract = {A very important aspect in developing robots capable of human-robot interaction (HRI) is the research in natural, human-like communication, and subsequently, the development of a research platform with multiple HRI capabilities for evaluation. Besides a flexible dialog system and speech understanding, an anthropomorphic appearance has the potential to support intuitive usage and understanding of a robot, e.g., human-like facial expressions and deictic gestures can as well be produced and also understood by the robot. As a consequence of our effort in creating an anthropomorphic appearance and to come close to a human- human interaction model for a robot, we decided to use human-like sensors, i.e., two cameras and two microphones only, in analogy to human perceptual capabilities too. Despite the challenges resulting from these limits with respect to perception, a robust attention system for tracking and interacting with multiple persons simultaneously in real time is presented. The tracking approach is sufficiently generic to work on robots with varying hardware, as long as stereo audio data and images of a video camera are available. To easily implement different interaction capabilities like deictic gestures, natural adaptive dialogs, and emotion awareness on the robot, we apply a modular integration approach utilizing XML-based data exchange. The paper focuses on our efforts to bring together different interaction concepts and perception capabilities integrated on a humanoid robot to achieve comprehending human-oriented interaction.}
}

@article{lincoln6701,
          volume = {108},
          number = {1-2},
           month = {October},
          author = {Sven Wachsmuth and Sebastian Wrede and Marc Hanheide},
            note = {Most of the research conducted in human-computer interaction (HCI) focuses on a seamless interface between a user and an application that is separated from the user in terms of working space and/or control, like navigation in image databases, instruction of robots, or information retrieval systems. The interaction paradigm of cognitive assistance goes one step further in that the application consists of assisting the user performing everyday tasks in his or her own environment and in that the user and the system share the control of such tasks. This kind of tight bidirectional interaction in realistic environments demands cognitive system skills like context awareness, attention, learning, and reasoning about the external environment. Therefore, the system needs to integrate a wide variety of visual functions, like localization, object tracking and recognition, action recognition, interactive object learning, etc. In this paper we show how different kinds of system behaviors are realized using the Active Memory Infrastructure that provides the technical basis for distributed computation and a data- and event-driven integration approach. A running augmented reality system for cognitive assistance is presented that supports users in mixing beverages. The flexibility and generality of the system framework provides an ideal testbed for studying visual cues in human-computer interaction. We report about results from first user studies.},
           title = {Coordinating interactive vision behaviors for cognitive assistance},
       publisher = {Springer},
            year = {2007},
         journal = {Computer Vision and Image Understanding},
             doi = {10.1016/j.cviu.2006.10.018},
           pages = {135--149},
        keywords = {ARRAY(0x5568fbb804f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6701/},
        abstract = {Most of the research conducted in human-computer interaction (HCI) focuses on a seamless interface between a user and an application that is separated from the user in terms of working space and/or control, like navigation in image databases, instruction of robots, or information retrieval systems. The interaction paradigm of cognitive assistance goes one step further in that the application consists of assisting the user performing everyday tasks in his or her own environment and in that the user and the system share the control of such tasks. This kind of tight bidirectional interaction in realistic environments demands cognitive system skills like context awareness, attention, learning, and reasoning about the external environment. Therefore, the system needs to integrate a wide variety of visual functions, like localization, object tracking and recognition, action recognition, interactive object learning, etc. In this paper we show how different kinds of system behaviors are realized using the Active Memory Infrastructure that provides the technical basis for distributed computation and a data- and event-driven integration approach. A running augmented reality system for cognitive assistance is presented that supports users in mixing beverages. The flexibility and generality of the system framework provides an ideal testbed for studying visual cues in human-computer interaction. We report about results from first user studies.}
}

@mastersthesis{lincoln29373,
           month = {August},
           title = {Modelling and animation of brittle fracture in three dimensions},
          school = {Bilkent University},
          author = {Ayse Kucukyilmaz},
            year = {2007},
        keywords = {ARRAY(0x5568fb9e7958)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29373/},
        abstract = {This thesis describes a system for simulating fracture in brittle objects. The system combines rigid body simulation methods with a constraint-based model to animate fracturing of arbitrary polyhedral shaped objects under impact. The objects are represented as sets of masses, where pairs of adjacent masses are connected by a distance-preserving linear constraint. The movement of the objects are normally realized by unconstrained rigid body dynamics. The fracture calculations are only done at discrete collision events. In case of an impact, the forces acting on the constraints are calculated. These forces determine how and where the object will break.

The problem with most of the existing fracture systems is that they only allow simulations to be done offline, either because the utilized techniques are computationally expensive or they require many small steps for accuracy. This work presents a near-real-time solution to the problem of brittle fracture and a graphical user interface to create realistic animations.}
}

@inproceedings{lincoln6940,
           month = {August},
          author = {Thorsten Spexard and Shuyin Li and Britta Wrede and Marc Hanheide and Elin A. Topp and Helge Huttenrauch},
            note = {An important goal for research on service robots
is the cooperation of a human and a robot as team. A
service robot in a domestic environment needs to build a
representation of its future workspace that corresponds to
the human user's understanding of these surroundings. But
it also needs to apply this model about the "where" and
"what" in its current interaction to allow communication about
objects and places in a human-adequate way. In this paper
we present the integration of a hierarchical robotic mapping
system into an interactive framework controlled by a dialog
system. The goal is to use interactively acquired environment
models to implement a robot with interaction aware behaviors.
A major contribution of this work is a three-level hierarchy of
spatial representation affecting three different communication
dimensions. This hierarchy is consequently applied in the design
of the grounding-based dialog, laser-based topological mapping,
and an objects attention system. We demonstrate the benefits
of this integration for learning and tour guiding in a humancomprehensible
interaction between a robot and its user in
a home-tour scenario. The enhanced interaction capabilities
are crucial for developing a new generation of robots that
will be accepted not only as service robots but also as robot
companions.},
       booktitle = {RO-MAN 2007 - The 16th IEEE International Symposium on Robot and Human Interactive Communication},
          editor = {B. Gottfried and H. Aghajan},
           title = {Interaction awareness for joint environment exploration},
            year = {2007},
             doi = {10.1109/ROMAN.2007.4415146},
           pages = {546--551},
        keywords = {ARRAY(0x5568fbbbd5d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6940/},
        abstract = {An important goal for research on service robots
is the cooperation of a human and a robot as team. A
service robot in a domestic environment needs to build a
representation of its future workspace that corresponds to
the human user's understanding of these surroundings. But
it also needs to apply this model about the "where" and
"what" in its current interaction to allow communication about
objects and places in a human-adequate way. In this paper
we present the integration of a hierarchical robotic mapping
system into an interactive framework controlled by a dialog
system. The goal is to use interactively acquired environment
models to implement a robot with interaction aware behaviors.
A major contribution of this work is a three-level hierarchy of
spatial representation affecting three different communication
dimensions. This hierarchy is consequently applied in the design
of the grounding-based dialog, laser-based topological mapping,
and an objects attention system. We demonstrate the benefits
of this integration for learning and tour guiding in a humancomprehensible
interaction between a robot and its user in
a home-tour scenario. The enhanced interaction capabilities
are crucial for developing a new generation of robots that
will be accepted not only as service robots but also as robot
companions.}
}

@article{lincoln28026,
          volume = {55},
          number = {7},
           month = {July},
          author = {Henrik Andreasson and Andr{\'e} Treptow and Tom Duckett},
           title = {Self-localization in non-stationary environments using omni-directional vision},
       publisher = {Elsevier},
            year = {2007},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2007.02.002},
           pages = {541--551},
        keywords = {ARRAY(0x5568fb672778)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28026/},
        abstract = {This paper presents an image-based approach for localization in non-static environments using local feature descriptors, and its experimental evaluation in a large, dynamic, populated environment where the time interval between the collected data sets is up to two months. By using local features together with panoramic images, robustness and invariance to large changes in the environment can be handled. Results from global place recognition with no evidence accumulation and a Monte Carlo localization method are shown. To test the approach even further, experiments were conducted with up to 90\% virtual occlusion in addition to the dynamic changes in the environment.}
}

@article{lincoln37434,
          volume = {60},
          number = {7},
           month = {July},
          author = {M.A. Peck and B. Streetman and C. Saaj and V. Lappas},
            note = {cited By 67},
           title = {Spacecraft formation flying using Lorentz forces},
       publisher = {British Interplanetary Society},
            year = {2007},
         journal = {JBIS - Journal of the British Interplanetary Society},
           pages = {263--267},
        keywords = {ARRAY(0x5568fbabd720)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37434/},
        abstract = {The Lorentz Augmented Orbit (LAO) concept is an electromagnetic propulsion system without a tether that uses the interaction between an electrostatically charged spacecraft and the Earth's magnetic field to provide a useful thrust. In Low Earth Orbit (LEO), the Lorentz force acting on a charged spacecraft flying relative to Earth's magnetic field causes acceleration in a direction perpendicular to both its velocity and the magnetic field. In this paper, the concept of spacecraft propulsion using Lorentz force is investigated for LEO formation flying. A triangular spacecraft formation configuration is used to simulate and validate the advantages and disadvantages of the proposed concept. It is illustrated that simple formation manoeuvres can be performed solely using the Lorentz force.}
}

@article{lincoln37441,
          volume = {60},
          number = {7},
           month = {July},
          author = {C. Saaj and V. Lappas and D. Richie and H. Schaub and D. Izzo},
            note = {cited By 2},
           title = {Hybrid propulsion system for spacecraft swarm aggregation using coulomb force},
       publisher = {British Interplanetary Society},
            year = {2007},
         journal = {JBIS - Journal of the British Interplanetary Society},
           pages = {268--274},
        keywords = {ARRAY(0x5568fbb5a468)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37441/},
        abstract = {Current studies are examining challenges involved in the deployment of micro-spacecraft swarms in Geostationary Earth Orbit (GEO) and other high Earth orbits for astronomical imaging, interferometry and various other applications. There are several ongoing studies on spacecraft charging issue in GEO and great progress has been made in recent years to develop efficient propulsion system using the Coulomb forces. This paper presents an overview of Coulomb forces for propulsion of micro-spacecraft in swarms and reports the first results of a novel hybrid propulsion system recently developed for close- proximity motion. This hybrid propulsion system takes advantage of Coulomb spacecraft charging, saving on fuel consumed from the conventional electric/ion thrusters on-board the spacecraft. This would reduce the spacecraft mass, launch cost and enhance the life of the mission. The other advantages of the system are reduced payload contamination and improved spacecraft positioning. The results of extensive simulation studies for swarm aggregation using ten and forty spacecraft is presented to demonstrate the effectiveness of the proposed hybrid propulsion.}
}

@article{lincoln28022,
          volume = {55},
          number = {5},
           month = {May},
          author = {Martin Persson and Tom Duckett and Achim Lilienthal},
           title = {Virtual sensors for human concepts{--}Building detection by an outdoor mobile robot},
       publisher = {Elsevier},
            year = {2007},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2006.12.002},
           pages = {383--390},
        keywords = {ARRAY(0x5568fbb6da20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28022/},
        abstract = {In human?robot communication it is often important to relate robot sensor readings to concepts used by humans. We suggest the use of a virtual sensor (one or several physical sensors with a dedicated signal processing unit for the recognition of real world concepts) and a method with which the virtual sensor can learn from a set of generic features. The virtual sensor robustly establishes the link between sensor data and a particular human concept. In this work, we present a virtual sensor for building detection that uses vision and machine learning to classify the image content in a particular direction as representing buildings or non-buildings. The virtual sensor is trained on a diverse set of image data, using features extracted from grey level images. The features are based on edge orientation, the configurations of these edges, and on grey level clustering. To combine these features, the AdaBoost algorithm is applied. Our experiments with an outdoor mobile robot show that the method is able to separate buildings from nature with a high classification rate, and to extrapolate well to images collected under different conditions. Finally, the virtual sensor is applied on the mobile robot, combining its classifications of sub-images from a panoramic view with spatial information (in the form of location and orientation of the robot) in order to communicate the likely locations of buildings to a remote human operator.}
}

@inproceedings{lincoln29849,
           month = {April},
          author = {Henrik Andreasson and Tom Duckett and Achim Lilienthal},
       booktitle = {Proceedings 2007 IEEE International Conference on Robotics and Automation},
           title = {Mini-SLAM: minimalistic visual SLAM in large-scale environments based on a new interpretation of image similarity},
       publisher = {IEEE},
             doi = {10.1109/ROBOT.2007.364108},
           pages = {4096--4101},
            year = {2007},
        keywords = {ARRAY(0x5568fbb75a50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29849/},
        abstract = {This paper presents a vision-based approach to SLAM in large-scale environments with minimal sensing and
computational requirements. The approach is based on a graphical representation of robot poses and links between the poses. Links between the robot poses are established based on odomety and image similarity, then a relaxation algorithm is used to generate a globally consistent map. To estimate the covariance matrix for links obtained from the vision sensor, a novel method is introduced based on the relative similarity of neighbouring images, without requiring distances to image features or multiple view geometry. Indoor and outdoor experiments demonstrate that the approach scales well to large-scale environments, producing topologically correct and geometrically accurate maps at minimal computational cost. Mini-SLAM was found to produce consistent maps in an unstructured, large-scale environment (the total path length was 1.4 km) containing indoor and outdoor passages.}
}

@inproceedings{lincoln1685,
       booktitle = {Proceedings of ICRA-2007, IEEE International Conference on Robotics and Automation},
           month = {March},
           title = {Incremental spectral clustering and its application to topological mapping},
          author = {Christoffer Valgren and Tom Duckett and Achim Lilienthal},
            year = {2007},
            note = {This paper presents a novel use of spectral clustering algorithms to support cases where the entries in the affinity matrix are costly to compute. The method is incremental ? the
spectral clustering algorithm is applied to the affinity matrix after each row/column is added ? which makes it possible to inspect the clusters as new data points are added. The method is well suited to the problem of appearance-based, on-line topological mapping for mobile robots. In this problem domain, we show that we can reduce environment-dependent parameters of the clustering algorithm to just a single, intuitive parameter. Experimental results in large outdoor and indoor environments
show that we can close loops correctly by computing only a fraction of the entries in the affinity matrix. The accompanying video clip shows how an example map is produced by the
algorithm.},
        keywords = {ARRAY(0x5568fbb94498)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1685/},
        abstract = {This paper presents a novel use of spectral clustering algorithms to support cases where the entries in the affinity matrix are costly to compute. The method is incremental ? the
spectral clustering algorithm is applied to the affinity matrix after each row/column is added ? which makes it possible to inspect the clusters as new data points are added. The method is well suited to the problem of appearance-based, on-line topological mapping for mobile robots. In this problem domain, we show that we can reduce environment-dependent parameters of the clustering algorithm to just a single, intuitive parameter. Experimental results in large outdoor and indoor environments
show that we can close loops correctly by computing only a fraction of the entries in the affinity matrix. The accompanying video clip shows how an example map is produced by the
algorithm.}
}

@article{lincoln1218,
          volume = {13},
          number = {2},
           month = {March},
          author = {Shigang Yue and F. Claire Rind},
            note = {Reliably recognizing objects approaching on a collision course is extremely important. A synthetic vision system is proposed to tackle the problem of collision recognition in dynamic environments. The system combines the outputs of four whole-field motion-detecting neurons, each receiving inputs from a network of neurons employing asymmetric lateral inhibition to suppress their responses to one direction of motion. An evolutionary algorithm is then used to adjust the weights between the four motion-detecting neurons to tune the system to detect collisions in two test environments. To do this, a population of agents, each representing a proposed synthetic visual system, either were shown images generated by a mobile Khepera robot navigating in a simplified laboratory environment or were shown images videoed outdoors from a moving vehicle. The agents had to cope with the local environment correctly in order to survive. After 400 generations, the best agent recognized imminent collisions reliably in the familiar environment where it had evolved. However, when the environment was swapped, only the agent evolved to cope in the robotic environment still signaled collision reliably. This study suggests that whole-field direction-selective neurons, with selectivity based on asymmetric lateral inhibition, can be organized into a synthetic vision system, which can then be adapted to play an important role in collision detection in complex dynamic scenes.},
           title = {A synthetic vision system using directionally selective motion detectors to recognize collision},
       publisher = {MIT Press},
            year = {2007},
         journal = {Artificial life},
             doi = {10.1162/artl.2007.13.2.93},
           pages = {93--122},
        keywords = {ARRAY(0x5568fbbb4810)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1218/},
        abstract = {Reliably recognizing objects approaching on a collision course is extremely important. A synthetic vision system is proposed to tackle the problem of collision recognition in dynamic environments. The system combines the outputs of four whole-field motion-detecting neurons, each receiving inputs from a network of neurons employing asymmetric lateral inhibition to suppress their responses to one direction of motion. An evolutionary algorithm is then used to adjust the weights between the four motion-detecting neurons to tune the system to detect collisions in two test environments. To do this, a population of agents, each representing a proposed synthetic visual system, either were shown images generated by a mobile Khepera robot navigating in a simplified laboratory environment or were shown images videoed outdoors from a moving vehicle. The agents had to cope with the local environment correctly in order to survive. After 400 generations, the best agent recognized imminent collisions reliably in the familiar environment where it had evolved. However, when the environment was swapped, only the agent evolved to cope in the robotic environment still signaled collision reliably. This study suggests that whole-field direction-selective neurons, with selectivity based on asymmetric lateral inhibition, can be organized into a synthetic vision system, which can then be adapted to play an important role in collision detection in complex dynamic scenes.}
}

@article{lincoln1684,
          volume = {78},
          number = {1},
           month = {January},
          author = {Per Munkevik and Gunnar Hall and Tom Duckett},
           title = {A computer vision system for appearance-based descriptive sensory evaluation of meals},
       publisher = {Elsevier},
            year = {2007},
         journal = {Journal of Food Engineering},
           pages = {246--256},
        keywords = {ARRAY(0x5568fbaf5b08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1684/},
        abstract = {This paper presents a complete machine vision system for automatic descriptive sensory evaluation of meals. A human sensory panel
first developed a set of 72 sensory attributes describing the appearance of a prototypical meal, and then evaluated the intensities of those attributes on a data set of 58 images of example meals. This data was then used both to train and validate the performance of the artificial system. This system covers all stages of image analysis from pre-processing to pattern recognition, including novel techniques for enhancing the segmentation of meal components and extracting image features that mimic the attributes developed by the panel. Artificial neural networks were used to learn the mapping from image features to attribute intensity values. The results showed that the new system was extremely good in learning and reproducing the opinion of the human sensory experts, achieving almost the same performance as the panel members themselves.}
}

@inproceedings{lincoln2099,
       booktitle = {IEEE Int. Conf. on Robotics and Biomimetics (ROBIO)},
           title = {Multisensor data fusion for joint people tracking and identification with a service robot},
          author = {Nicola Bellotto and Huosheng Hu},
            year = {2007},
           pages = {1494--1499},
            note = {Tracking and recognizing people are essential skills modern service robots have to be provided with. The two tasks are generally performed independently, using ad-hoc solutions that first estimate the location of humans and then proceed with their identification. The solution presented in this paper, instead, is a general framework for tracking and recognizing people simultaneously with a mobile robot, where the estimates of the human location and identity are fused using probabilistic techniques. Our approach takes inspiration from recent implementations of joint tracking and classification, where the considered targets are mainly vehicles and aircrafts in military and civilian applications. We illustrate how people can be robustly tracked and recognized with a service robot using an improved histogram-based detection and multisensor data fusion. Some experiments in real challenging scenarios show the good performance of our solution.},
        keywords = {ARRAY(0x5568fbaa0270)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/2099/},
        abstract = {Tracking and recognizing people are essential skills modern service robots have to be provided with. The two tasks are generally performed independently, using ad-hoc solutions that first estimate the location of humans and then proceed with their identification. The solution presented in this paper, instead, is a general framework for tracking and recognizing people simultaneously with a mobile robot, where the estimates of the human location and identity are fused using probabilistic techniques. Our approach takes inspiration from recent implementations of joint tracking and classification, where the considered targets are mainly vehicles and aircrafts in military and civilian applications. We illustrate how people can be robustly tracked and recognized with a service robot using an improved histogram-based detection and multisensor data fusion. Some experiments in real challenging scenarios show the good performance of our solution.}
}

@article{lincoln38608,
          volume = {4434 L},
           title = {From RoboLab to aibo: A behavior-based interface for educational robotics},
          author = {R. Goldman and M.Q. Aznar and Elizabeth Sklar},
            year = {2007},
           pages = {122--133},
            note = {cited By 1},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38608/}
}

@inproceedings{lincoln38602,
          volume = {SS-07-},
           title = {Extra-curricular robotics: Entry-level soccer for undergraduates},
          author = {S. Imberman and A. Barkan and Elizabeth Sklar},
            year = {2007},
           pages = {59--64},
            note = {cited By 1},
         journal = {AAAI Spring Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38602/}
}

@inproceedings{lincoln37447,
          volume = {127 PA},
          author = {V. Lappas and C. Saaj and D. Richie and M. Peck and B. Streetman and H. Schaub},
            note = {cited By 13},
       booktitle = {30th Annual AAS Guidance and Control Conference},
           title = {Spacecraft formation flying and reconfiguration with electrostatic forces},
         journal = {Advances in the Astronautical Sciences},
           pages = {217--225},
            year = {2007},
        keywords = {ARRAY(0x5568fba18dc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37447/}
}

@article{lincoln1615,
          volume = {24},
          number = {10},
          author = {Martin Magnusson and Achim Lilienthals and Tom Duckett},
            note = {Scan registration is an essential subtask when building maps based on range finder data from mobile robots. The problem is to deduce how the robot has moved between consecutive scans, based on the shape of overlapping portions of the scans. This paper presents a new algorithm for registration of 3D data. The algorithm is a generalization and improvement of the normal distributions transform (NDT) for 2D data developed by Biber and Strasser, which allows for accurate registration using a memory-efficient representation of the scan surface. A detailed quantitative and qualitative comparison of the new algorithm with the 3D version of the popular ICP (iterative closest point) algorithm is presented. Results with actual mine data, some of which were collected with a new prototype 3D laser scanner, show that the presented algorithm is faster and slightly more reliable than the standard ICP algorithm for 3D registration, while using a more memory efficient scan surface representation.},
           title = {Scan registration for autonomous mining vehicles using 3D-NDT},
       publisher = {Wiley Periodicals, Inc.},
            year = {2007},
         journal = {Journal of Field Robotics},
             doi = {10.1002/rob.20204},
           pages = {803--827},
        keywords = {ARRAY(0x5568fb67f810)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1615/},
        abstract = {Scan registration is an essential subtask when building maps based on range finder data from mobile robots. The problem is to deduce how the robot has moved between consecutive scans, based on the shape of overlapping portions of the scans. This paper presents a new algorithm for registration of 3D data. The algorithm is a generalization and improvement of the normal distributions transform (NDT) for 2D data developed by Biber and Strasser, which allows for accurate registration using a memory-efficient representation of the scan surface. A detailed quantitative and qualitative comparison of the new algorithm with the 3D version of the popular ICP (iterative closest point) algorithm is presented. Results with actual mine data, some of which were collected with a new prototype 3D laser scanner, show that the presented algorithm is faster and slightly more reliable than the standard ICP algorithm for 3D registration, while using a more memory efficient scan surface representation.}
}

@article{lincoln38613,
          volume = {4434 L},
           title = {Towards a methodology for stabilizing the gaze of a quadrupedal robot},
          author = {M. Marcinkiewicz and M. Kunin and Simon Parsons and Elizabeth Sklar and T. Raphan},
            year = {2007},
           pages = {540--547},
            note = {cited By 2},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38613/}
}

@inproceedings{lincoln38610,
          volume = {WS-07-},
           title = {Some preliminary results on competition between markets for automated traders},
          author = {J. Niu and K. Cai and Simon Parsons and Elizabeth Sklar},
            year = {2007},
           pages = {19--26},
            note = {cited By 15},
         journal = {AAAI Workshop - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38610/}
}

@article{lincoln38607,
          volume = {4434 L},
           title = {Automatic acquisition of robot motion and sensor models},
          author = {A.T. Ozgelen and Elizabeth Sklar and Simon Parsons},
            year = {2007},
           pages = {548--555},
            note = {cited By 0},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38607/}
}

@inproceedings{lincoln37435,
          author = {C. Saaj and V. Lappas and D. Richie and H. Schaub},
            note = {cited By 0},
       booktitle = {2007 European Control Conference (ECC)},
           title = {Hybrid propulsion using electrostatic forces for spacecraft swarms},
       publisher = {IEEE},
            year = {2007},
         journal = {2007 European Control Conference, ECC 2007},
             doi = {10.23919/ecc.2007.7068704},
           pages = {3187--3194},
        keywords = {ARRAY(0x5568fbb64630)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37435/},
        abstract = {In high Earth orbits, spacecraft surface charging due to ambient plasma and the photoelectric effect can produce disruptive electrostatic forces to the order of 10-1000 micro-Newtons between close-flying spacecraft flying with separation distances up to 100 meters. Rather than fighting them, these forces could be utilized to propel spacecraft to form a swarm. In this paper, a novel hybrid propulsion system for spacecraft swarms in geostationary or other high Earth orbits is investigated using Coulomb forces and standard electric thrusters. This novel hybrid approach can provide fuel-efficient propulsion over a range of separation distances, reduce spacecraft mass and eliminate differential perturbations found in Geostationary Earth Orbit (GEO). Moreover, the application of artificial potential-field method for path planning combined with sliding mode control, for spacecraft swarm aggregation is demonstrated. The performance of the proposed hybrid propulsion system is illustrated using an example of thirty spacecraft in aggregation.}
}

@inproceedings{lincoln6939,
          author = {Falk Schubert and Thorsten P. Spexard and Marc Hanheide and Sven Wachsmuth},
            note = {Self-Localization is a crucial task for mobile robots. It is not only a requirement
for auto navigation but also provides contextual information to support
human robot interaction (HRI). In this paper we present an active vision-based
localization method for integration in a complex robot system to work in human
interaction scenarios (e.g. home-tour) in a real world apartment. The holistic
features used are robust to illumination and structural changes in the scene. The
system uses only a single pan-tilt camera shared between different vision applications
running in parallel to reduce the number of sensors. Additional information
from other modalities (like laser scanners) can be used, profiting of an integration
into an existing system. The camera view can be actively adapted and the
evaluation showed that different rooms can be discerned.},
       booktitle = {5th International Conference on Computer Vision Systems (ICVS 2007)},
          editor = {B. Gottfried and H. Aghajan},
           title = {Active vision-based localization for robots in a home-tour scenario},
       publisher = {Applied Computer Science Group, Bielefeld University, Germany},
             doi = {10.2390/biecoll-icvs2007-101},
            year = {2007},
        keywords = {ARRAY(0x5568fba11728)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6939/},
        abstract = {Self-Localization is a crucial task for mobile robots. It is not only a requirement
for auto navigation but also provides contextual information to support
human robot interaction (HRI). In this paper we present an active vision-based
localization method for integration in a complex robot system to work in human
interaction scenarios (e.g. home-tour) in a real world apartment. The holistic
features used are robust to illumination and structural changes in the scene. The
system uses only a single pan-tilt camera shared between different vision applications
running in parallel to reduce the number of sensors. Additional information
from other modalities (like laser scanners) can be used, profiting of an integration
into an existing system. The camera view can be actively adapted and the
evaluation showed that different rooms can be discerned.}
}

@article{lincoln38614,
          volume = {13},
          number = {3},
          author = {Elizabeth Sklar},
            note = {cited By 112},
           title = {Software review: NetLogo, a multi-agent simulation environment},
            year = {2007},
         journal = {Artificial Life},
             doi = {10.1162/artl.2007.13.3.303},
           pages = {303--311},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38614/}
}

@inproceedings{lincoln38604,
          volume = {SS-07-},
           title = {Robotics across the curriculum},
          author = {Elizabeth Sklar and Simon Parsons and M.Q. Azhar},
            year = {2007},
           pages = {141--146},
            note = {cited By 17},
         journal = {AAAI Spring Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38604/}
}

@inproceedings{lincoln38605,
          volume = {WS-06-},
           title = {Educational robotics in Brooklyn},
          author = {Elizabeth Sklar and Simon Parsons and M.Q. Azhar and V. Andrewlevich},
            year = {2007},
           pages = {63--69},
            note = {cited By 2},
         journal = {AAAI Workshop - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38605/}
}

@inproceedings{lincoln38612,
           title = {An agent-based methodology for analyzing and visualizing educational assessment data},
          author = {Elizabeth Sklar and J. Salvit and V. Andrewlevich and C. Camacho and W. Liu},
            year = {2007},
           pages = {376--378},
             doi = {10.1145/1329125.1329440},
            note = {cited By 2},
         journal = {Proceedings of the International Conference on Autonomous Agents},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38612/}
}

@article{lincoln38603,
          volume = {4442 L},
           title = {Modeling human education data: From equation-based modeling to agent-based modeling},
          author = {Y. Tang and Simon Parsons and Elizabeth Sklar},
            year = {2007},
           pages = {41--56},
            note = {cited By 3},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38603/}
}

@article{lincoln13378,
          volume = {6},
          number = {11},
           month = {November},
          author = {Achim {\ensuremath{|}}J. Lilienthal and Amy Loutfi and Tom Duckett},
            note = {This article belongs to the Special Issue Gas Sensors},
           title = {Airborne chemical sensing with mobile robots},
       publisher = {MDPI},
            year = {2006},
         journal = {Sensors},
             doi = {10.3390/s6111616},
           pages = {1616--1678},
        keywords = {ARRAY(0x5568fbb80990)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13378/},
        abstract = {Airborne chemical sensing with mobile robots has been an active research areasince the beginning of the 1990s. This article presents a review of research work in this field,including gas distribution mapping, trail guidance, and the different subtasks of gas sourcelocalisation. Due to the difficulty of modelling gas distribution in a real world environmentwith currently available simulation techniques, we focus largely on experimental work and donot consider publications that are purely based on simulations.}
}

@inproceedings{lincoln28035,
           month = {October},
          author = {Christoffer Valgren and Achim Lilienthal and Tom Duckett},
       booktitle = {2006 IEEE/RSJ International Conference on Intelligent Robots and Systems},
           title = {Incremental topological mapping using omnidirectional vision},
       publisher = {IEEE},
             doi = {10.1109/IROS.2006.282583},
           pages = {3441--3447},
            year = {2006},
        keywords = {ARRAY(0x5568fba49300)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28035/},
        abstract = {This paper presents an algorithm that builds topological maps, using omnidirectional vision as the only sensor modality. Local features are extracted from images obtained in sequence, and are used both to cluster the images into nodes and to detect links between the nodes. The algorithm is incremental, reducing the computational requirements of the corresponding batch algorithm. Experimental results in a complex, indoor environment show that the algorithm produces topologically correct maps, closing loops without suffering from perceptual aliasing or false links. Robustness to lighting variations was further demonstrated by building correct maps from combined multiple datasets collected over a period of 2 months}
}

@phdthesis{lincoln6743,
           month = {October},
           title = {A cognitive ego-vision system for interactive assistance},
          school = {Universitat Bielefeld},
          author = {Marc Hanheide},
            year = {2006},
            note = {With increasing computational power and decreasing size, computers nowadays are already wearable and mobile. They become attendant of peoples' everyday life. Personal digital assistants and mobile phones equipped with adequate software gain a lot of interest in public, although the functionality they provide in terms of assistance is little more than a mobile databases for appointments, addresses, to-do lists and photos. Compared to the assistance a human can provide, such systems are hardly to call real assistants. The motivation to construct more human-like assistance systems that develop a certain level of cognitive capabilities leads to the exploration of two central paradigms in this work. The first paradigm is termed cognitive vision systems. Such systems take human cognition as a design principle of underlying concepts and develop learning and adaptation capabilities to be more flexible in their application. They are embodied, active, and situated. Second, the ego-vision paradigm is introduced as a very tight interaction scheme between a user and a computer system that especially eases close collaboration and assistance between these two. Ego-vision systems (EVS) take a user's (visual) perspective and integrate the human in the system's processing loop by means of a shared perception and augmented reality. EVSs adopt techniques of cognitive vision to identify objects, interpret actions, and understand the user's visual perception. And they articulate their knowledge and interpretation by means of augmentations of the user's own view. These two paradigms are studied as rather general concepts, but always with the goal in mind to realize more flexible assistance systems that closely collaborate with its users. This work provides three major contributions. First, a definition and explanation of ego-vision as a novel paradigm is given. Benefits and challenges of this paradigm are discussed as well. Second, a configuration of different approaches that permit an ego-vision system to perceive its environment and its user is presented in terms of object and action recognition, head gesture recognition, and mosaicing. These account for the specific challenges identified for ego-vision systems, whose perception capabilities are based on wearable sensors only. Finally, a visual active memory (VAM) is introduced as a flexible conceptual architecture for cognitive vision systems in general, and for assistance systems in particular. It adopts principles of human cognition to develop a representation for information stored in this memory. So-called memory processes continuously analyze, modify, and extend the content of this VAM. The functionality of the integrated system emerges from their coordinated interplay of these memory processes. An integrated assistance system applying the approaches and concepts outlined before is implemented on the basis of the visual active memory. The system architecture is discussed and some exemplary processing paths in this system are presented and discussed. It assists users in object manipulation tasks and has reached a maturity level that allows to conduct user studies. Quantitative results of different integrated memory processes are as well presented as an assessment of the interactive system by means of these user studies.},
        keywords = {ARRAY(0x5568fb6abd58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6743/},
        abstract = {With increasing computational power and decreasing size, computers nowadays are already wearable and mobile. They become attendant of peoples' everyday life. Personal digital assistants and mobile phones equipped with adequate software gain a lot of interest in public, although the functionality they provide in terms of assistance is little more than a mobile databases for appointments, addresses, to-do lists and photos. Compared to the assistance a human can provide, such systems are hardly to call real assistants. The motivation to construct more human-like assistance systems that develop a certain level of cognitive capabilities leads to the exploration of two central paradigms in this work. The first paradigm is termed cognitive vision systems. Such systems take human cognition as a design principle of underlying concepts and develop learning and adaptation capabilities to be more flexible in their application. They are embodied, active, and situated. Second, the ego-vision paradigm is introduced as a very tight interaction scheme between a user and a computer system that especially eases close collaboration and assistance between these two. Ego-vision systems (EVS) take a user's (visual) perspective and integrate the human in the system's processing loop by means of a shared perception and augmented reality. EVSs adopt techniques of cognitive vision to identify objects, interpret actions, and understand the user's visual perception. And they articulate their knowledge and interpretation by means of augmentations of the user's own view. These two paradigms are studied as rather general concepts, but always with the goal in mind to realize more flexible assistance systems that closely collaborate with its users. This work provides three major contributions. First, a definition and explanation of ego-vision as a novel paradigm is given. Benefits and challenges of this paradigm are discussed as well. Second, a configuration of different approaches that permit an ego-vision system to perceive its environment and its user is presented in terms of object and action recognition, head gesture recognition, and mosaicing. These account for the specific challenges identified for ego-vision systems, whose perception capabilities are based on wearable sensors only. Finally, a visual active memory (VAM) is introduced as a flexible conceptual architecture for cognitive vision systems in general, and for assistance systems in particular. It adopts principles of human cognition to develop a representation for information stored in this memory. So-called memory processes continuously analyze, modify, and extend the content of this VAM. The functionality of the integrated system emerges from their coordinated interplay of these memory processes. An integrated assistance system applying the approaches and concepts outlined before is implemented on the basis of the visual active memory. The system architecture is discussed and some exemplary processing paths in this system are presented and discussed. It assists users in object manipulation tasks and has reached a maturity level that allows to conduct user studies. Quantitative results of different integrated memory processes are as well presented as an assessment of the interactive system by means of these user studies.}
}

@article{lincoln1220,
          volume = {104},
          number = {1},
           month = {October},
          author = {Shigang Yue and F. Claire Rind},
            note = {Detecting colliding objects in complex dynamic scenes is a difficult task for conventional computer vision techniques. However, visual processing mechanisms in animals such as insects may provide very simple and effective solutions for detecting colliding objects in complex dynamic scenes. In this paper, we propose a robust collision detecting system, which consists of a lobula giant movement detector (LGMD) based neural network and a translating sensitive neural network (TSNN), to recognise objects on a direct collision course in complex dynamic scenes. The LGMD based neural network is specialized for recognizing looming objects that are on a direct collision course. The TSNN, which fuses the extracted visual motion cues from several whole field direction selective neural networks, is only sensitive to translating movements in the dynamic scenes. The looming cue and translating cue revealed by the two specialized visual motion detectors are fused in the present system via a decision making mechanism. In the system, the LGMD plays a key role in detecting imminent collision; the decision from TSNN becomes useful only when a collision alarm has been issued by the LGMD network. Using driving scenarios as an example, we showed that the bio-inspired system can reliably detect imminent colliding objects in complex driving scenes.},
           title = {Visual motion pattern extraction and fusion for collision detection in complex dynamic scenes},
       publisher = {Elsevier},
            year = {2006},
         journal = {Computer vision and image understanding},
             doi = {10.1016/j.cviu.2006.07.002},
           pages = {48--60},
        keywords = {ARRAY(0x5568fb9f46b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1220/},
        abstract = {Detecting colliding objects in complex dynamic scenes is a difficult task for conventional computer vision techniques. However, visual processing mechanisms in animals such as insects may provide very simple and effective solutions for detecting colliding objects in complex dynamic scenes. In this paper, we propose a robust collision detecting system, which consists of a lobula giant movement detector (LGMD) based neural network and a translating sensitive neural network (TSNN), to recognise objects on a direct collision course in complex dynamic scenes. The LGMD based neural network is specialized for recognizing looming objects that are on a direct collision course. The TSNN, which fuses the extracted visual motion cues from several whole field direction selective neural networks, is only sensitive to translating movements in the dynamic scenes. The looming cue and translating cue revealed by the two specialized visual motion detectors are fused in the present system via a decision making mechanism. In the system, the LGMD plays a key role in detecting imminent collision; the decision from TSNN becomes useful only when a collision alarm has been issued by the LGMD network. Using driving scenarios as an example, we showed that the bio-inspired system can reliably detect imminent colliding objects in complex driving scenes.}
}

@article{lincoln28030,
          volume = {54},
          number = {9},
           month = {September},
          author = {Hashem Tamimi and Henrik Andreasson and Andr{\'e} Treptow and Tom Duckett and Andreas Zell},
           title = {Localization of mobile robots with omnidirectional vision using Particle Filter and iterative SIFT},
       publisher = {Elsevier},
            year = {2006},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2006.04.018},
           pages = {758--765},
        keywords = {ARRAY(0x5568fbb5a930)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28030/},
        abstract = {The Scale Invariant Feature Transform, SIFT, has been successfully applied to robot localization. Still, the number of features extracted with this approach is immense, especially when dealing with omnidirectional vision. In this work, we propose a new approach that reduces the number of features generated by SIFT as well as their extraction and matching time. With the help of a Particle Filter, we demonstrate that we can still localize the mobile robot accurately with a lower number of features.}
}

@article{lincoln1201,
          volume = {54},
          number = {9},
           month = {September},
          author = {Andre Treptow and Grzegorz Cielniak and Tom Duckett},
            note = {This paper presents a vision-based approach for tracking people on a mobile robot using thermal images. The approach combines a particle filter with two alternative measurement models that are suitable for real-time tracking. With this approach a person can be detected independently from current light conditions and in situations where no skin colour is visible. In addition, the paper presents a comprehensive, quantitative evaluation of the different methods on a mobile robot in an office environment, for both single and multiple persons. The results show that the measurement model that was learned from local grey-scale features could improve on the performance of the elliptic contour model, and that both models could be combined to further improve performance with minimal extra computational cost},
           title = {Real-time people tracking for mobile robots using thermal vision},
            year = {2006},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2006.04.013},
           pages = {729--729},
        keywords = {ARRAY(0x5568fbba5e08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1201/},
        abstract = {This paper presents a vision-based approach for tracking people on a mobile robot using thermal images. The approach combines a particle filter with two alternative measurement models that are suitable for real-time tracking. With this approach a person can be detected independently from current light conditions and in situations where no skin colour is visible. In addition, the paper presents a comprehensive, quantitative evaluation of the different methods on a mobile robot in an office environment, for both single and multiple persons. The results show that the measurement model that was learned from local grey-scale features could improve on the performance of the elliptic contour model, and that both models could be combined to further improve performance with minimal extra computational cost}
}

@inproceedings{lincoln39656,
       booktitle = {Advanced Space Vehicle Control Workshop},
           month = {September},
           title = {Spacecraft Formation Flying and Aggregation using Electrostatic Forces},
          author = {C.M. Saaj and V. Lappas and D. Richie and M. Peck and B. Streetman and H. Schaub},
            year = {2006},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39656/}
}

@inproceedings{lincoln6941,
           month = {August},
          author = {Marc Hanheide and Nils Hofemann and Gerhard Sagerer},
            note = {Enabling artificial systems to recognize human actions
is a requisite to develop intelligent assistance systems that
are able to instruct and supervise users in accomplishing
tasks. In order to enable an assistance system to be wearable,
head-mounted cameras allow to perceive a scene visually
from a user?s perspective. But realizing action recognition
without any static sensors causes special challenges.
The movement of the camera is directly related to the user?s
head motion and not controlled by the system. In this paper
we present how a trajectory-based action recognition can
be combined with object recognition, visual tracking, and a
background motion compensation to be applicable in such
a wearable assistance system. The suitability of our approach
is proved by user studies in an object manipulation
scenario.},
       booktitle = {18th International Conference on Pattern Recognition (ICPR'06)},
          editor = {B. Gottfried and H. Aghajan},
           title = {Action recognition in a wearable assistance system},
       publisher = {IEEE Computer Society},
            year = {2006},
           pages = {1254--1258},
        keywords = {ARRAY(0x5568fbba9e08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6941/},
        abstract = {Enabling artificial systems to recognize human actions
is a requisite to develop intelligent assistance systems that
are able to instruct and supervise users in accomplishing
tasks. In order to enable an assistance system to be wearable,
head-mounted cameras allow to perceive a scene visually
from a user?s perspective. But realizing action recognition
without any static sensors causes special challenges.
The movement of the camera is directly related to the user?s
head motion and not controlled by the system. In this paper
we present how a trajectory-based action recognition can
be combined with object recognition, visual tracking, and a
background motion compensation to be applicable in such
a wearable assistance system. The suitability of our approach
is proved by user studies in an object manipulation
scenario.}
}

@article{lincoln1219,
          volume = {17},
          number = {3},
           month = {May},
          author = {Shigang Yue and F. C. Rind},
            note = {The lobula giant movement detector (LGMD) is an identified neuron in the locust brain that responds most strongly to the images of an approaching object such as a predator. Its computational model can cope with unpredictable environments without using specific object recognition algorithms. In this paper, an LGMD-based neural network is proposed with a new feature enhancement mechanism to enhance the expanded edges of colliding objects via grouped excitation for collision detection with complex backgrounds. The isolated excitation caused by background detail will be filtered out by the new mechanism. Offline tests demonstrated the advantages of the presented LGMD-based neural network in complex backgrounds. Real time robotics experiments using the LGMD-based neural network as the only sensory system showed that the system worked reliably in a wide range of conditions; in particular, the robot was able to navigate in arenas with structured surrounds and complex backgrounds.},
           title = {Collision detection in complex dynamic scenes using an LGMD-based visual neural network with feature enhancement},
            year = {2006},
         journal = {IEEE transactions on neural networks},
             doi = {10.1109/TNN.2006.873286},
           pages = {705--716},
        keywords = {ARRAY(0x5568fb9b7d90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1219/},
        abstract = {The lobula giant movement detector (LGMD) is an identified neuron in the locust brain that responds most strongly to the images of an approaching object such as a predator. Its computational model can cope with unpredictable environments without using specific object recognition algorithms. In this paper, an LGMD-based neural network is proposed with a new feature enhancement mechanism to enhance the expanded edges of colliding objects via grouped excitation for collision detection with complex backgrounds. The isolated excitation caused by background detail will be filtered out by the new mechanism. Offline tests demonstrated the advantages of the presented LGMD-based neural network in complex backgrounds. Real time robotics experiments using the LGMD-based neural network as the only sensory system showed that the system worked reliably in a wide range of conditions; in particular, the robot was able to navigate in arenas with structured surrounds and complex backgrounds.}
}

@article{lincoln8443,
          volume = {134},
          number = {2-3},
           month = {April},
          author = {S. D. C. Parsons and B. L. Penzhorn and Fred Reyers and J. C. A. Steyl and P. J. Becker},
           title = {Erythrocyte morphology and haemoglobin types of neonatal roan antelopes (Hippotragus equinus) with hypochromic poikilocytic anaemia},
       publisher = {Elsevier},
            year = {2006},
         journal = {Journal of Comparative Pathology},
             doi = {10.1016/j.jcpa.2005.09.008},
           pages = {152--160},
        keywords = {ARRAY(0x5568fb9f9aa0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8443/},
        abstract = {Neonatal, poikilocytic anaemia in some members of the Hippotragini has previously been documented but not fully investigated. This study was undertaken to describe the erythrocyte morphology of roan antelopes (Hippotragus equinus) during the first 4 weeks after birth and to identify aspects of haemoglobin (Hb) production that might be implicated in this syndrome. Twenty-nine roan antelope calves were sampled on, or close to, 1, 7, 14 and 28 days after birth. Erythrocyte morphology was characterized, and microhaematocrit values and Hb parameters determined, for each sampling occasion. Findings indicated a significant change in erythrocyte morphology during the neonatal period and two haemoglobin types, fetal and adult, were identified. The perinatal onset of adult Hb synthesis was delayed relative to the termination of fetal Hb production, resulting in the observed anaemia. Haemoglobin concentration and erythrocyte morphology were significantly correlated. These findings suggest an intimate relationship between Hb synthesis and the observed poikilocytosis. An imbalance in the synthesis of the {\^I}{$\pm$}- and {\~A}?-globin chains of Hb (a thalassaemia) may prove to be the underlying pathophysiology of this syndrome. {\^A}{\copyright} 2005 Elsevier Ltd. All rights reserved.}
}

@inproceedings{lincoln6942,
           month = {January},
          author = {Frank Lomker and Sebastian Wrede and Marc Hanheide and Jannik Fritsch},
            note = {With the increasing interest in computer vision for interactive
systems, the challenges of the development process
involving many researchers are becoming more prominent.
Issues like reuse of algorithms, modularity, and distributed
processing are getting more important in the endeavor of
building complex vision systems. We present a framework
that allows independent development of enclosed components
and supports interactive optimization of algorithmic
parameters in an online fashion. The communication between
components is performed nearly without any slow
down compared to a monolithic system. Through the modular
concept, all components can be flexibly distributed and
reused in other application domains. The suitability of the
approach is demonstrated with an example system.},
       booktitle = {Fourth IEEE International Conference on Computer Vision Systems (ICVS'06)},
          editor = {B. Gottfried and H. Aghajan},
           title = {Building modular vision systems with a graphical plugin environment},
       publisher = {IEEE Computer Society},
            year = {2006},
             doi = {10.1109/ICVS.2006.18},
        keywords = {ARRAY(0x5568fbba1078)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6942/},
        abstract = {With the increasing interest in computer vision for interactive
systems, the challenges of the development process
involving many researchers are becoming more prominent.
Issues like reuse of algorithms, modularity, and distributed
processing are getting more important in the endeavor of
building complex vision systems. We present a framework
that allows independent development of enclosed components
and supports interactive optimization of algorithmic
parameters in an online fashion. The communication between
components is performed nearly without any slow
down compared to a monolithic system. Through the modular
concept, all components can be flexibly distributed and
reused in other application domains. The suitability of the
approach is demonstrated with an example system.}
}

@inproceedings{lincoln6943,
           month = {January},
          author = {Sebastian Wrede and Marc Hanheide and Sven Wachsmuth and Gerhard Sagerer},
            note = {In this paper, we present a case study that exemplifies
general ideas of system integration and coordination.
The application field of assistant technology provides an
ideal test bed for complex computer vision systems including
real-time components, human-computer interaction, dynamic
3-d environments, and information retrieval aspects.
In our scenario the user is wearing an augmented reality device
that supports her/him in everyday tasks by presenting
information that is triggered by perceptual and contextual
cues. The system integrates a wide variety of visual functions
like localization, object tracking and recognition, action
recognition, interactive object learning, etc. We show
how different kinds of system behavior are realized using
the Active Memory Infrastructure that provides the technical
basis for distributed computation and a data- and eventdriven
integration approach.},
       booktitle = {Computer Vision Systems, 2006 ICVS '06. IEEE International Conference on},
          editor = {B. Gottfried and H. Aghajan},
           title = {Integration and coordination in a cognitive vision system},
       publisher = {IEEE},
            year = {2006},
             doi = {10.1109/ICVS.2006.36},
        keywords = {ARRAY(0x5568fba71d28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6943/},
        abstract = {In this paper, we present a case study that exemplifies
general ideas of system integration and coordination.
The application field of assistant technology provides an
ideal test bed for complex computer vision systems including
real-time components, human-computer interaction, dynamic
3-d environments, and information retrieval aspects.
In our scenario the user is wearing an augmented reality device
that supports her/him in everyday tasks by presenting
information that is triggered by perceptual and contextual
cues. The system integrates a wide variety of visual functions
like localization, object tracking and recognition, action
recognition, interactive object learning, etc. We show
how different kinds of system behavior are realized using
the Active Memory Infrastructure that provides the technical
basis for distributed computation and a data- and eventdriven
integration approach.}
}

@article{lincoln38500,
          volume = {144},
           title = {An Application of Formal Argumentation: Fusing Bayes Nets in MAS},
          author = {S.H. Nielsen and Simon Parsons},
            year = {2006},
           pages = {33--44},
            note = {cited By 4},
         journal = {Frontiers in Artificial Intelligence and Applications},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38500/}
}

@article{lincoln38499,
          volume = {144},
           title = {Computing Preferred Extensions for Argumentation Systems with Sets of Attacking Arguments},
          author = {S.H. Nielsen and Simon Parsons},
            year = {2006},
           pages = {97--108},
            note = {cited By 11},
         journal = {Frontiers in Artificial Intelligence and Applications},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38499/}
}

@inproceedings{lincoln38617,
          volume = {2006},
          author = {J. Niu and K. Cai and Simon Parsons and Elizabeth Sklar},
            note = {cited By 20},
           title = {Reducing price fluctuation in continuous double auctions through pricing policy and shout improvement},
         journal = {Proceedings of the International Conference on Autonomous Agents},
             doi = {10.1145/1160633.1160841},
           pages = {1143--1150},
            year = {2006},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38617/}
}

@article{lincoln38620,
          volume = {4049 L},
          author = {Simon Parsons and Elizabeth Sklar},
            note = {cited By 9},
           title = {How agents alter their beliefs after an argumentation-based dialogue},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/11794578},
           pages = {297--312},
            year = {2006},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38620/}
}

@inproceedings{lincoln38497,
          volume = {2006},
          author = {S. Phelps and M. Marcinkiewicz and Simon Parsons and P. McBurney},
            note = {cited By 25},
           title = {A novel method for automatic strategy acquisition in n-player Non-zero-sum games},
         journal = {Proceedings of the International Conference on Autonomous Agents},
             doi = {10.1145/1160633.1160760},
           pages = {705--712},
            year = {2006},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38497/}
}

@inproceedings{lincoln38498,
           title = {Reinforcement learning interfaces for biomedical database systems},
          author = {I. Rudowsky and O. Kulyba and M. Kunin and Simon Parsons and T. Raphan},
            year = {2006},
           pages = {6269--6272},
             doi = {10.1109/IEMBS.2006.260484},
            note = {cited By 1},
         journal = {Annual International Conference of the IEEE Engineering in Medicine and Biology - Proceedings},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38498/}
}

@inproceedings{lincoln37423,
          author = {C. Saaj and V. Lappas and V. Gazi},
            note = {cited By 26},
       booktitle = {2006 IEEE International Conference on Industrial Technology},
           title = {Spacecraft swarm navigation and control using artificial potential field and sliding mode control},
       publisher = {IEEE},
            year = {2006},
         journal = {Proceedings of the IEEE International Conference on Industrial Technology},
             doi = {10.1109/ICIT.2006.372712},
           pages = {2646--2651},
        keywords = {ARRAY(0x5568fbb0b4b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37423/},
        abstract = {The artificial potential field (APF) method provides simple and effective path planners for practical terrestrial robotics control. Sliding mode control (SMC) strategy together with artificial potential field has been used for control of multi-agent systems or swarms. The aim of this work is to examine for the first time the applicability of APF and SMC for spacecraft swarm navigation and control. This paper demonstrates that spacecraft formation flying can be successfully achieved using SMC for closed loop feedback and APF method for path planning.}
}

@techreport{lincoln39657,
           title = {Electrostatic forces for satellite swarm navigation and reconfiguration},
          author = {C.M. Saaj and V. Lappas and D. Richie and M. Peck and B. Streetman},
            year = {2006},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39657/},
        abstract = {Final report for Ariadna Study Id. AO 4919 05}
}

@inproceedings{lincoln38615,
          volume = {2006},
          author = {Elizabeth Sklar and D. Richards},
            note = {cited By 23},
           title = {The use of agents in human learning systems},
         journal = {Proceedings of the International Conference on Autonomous Agents},
             doi = {10.1145/1160633.1160768},
           pages = {767--774},
            year = {2006},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38615/}
}

@inproceedings{lincoln38619,
          volume = {SS-06-},
           title = {Exploring coordination properties within populations of distributed agents},
          author = {Elizabeth Sklar and M. Schut and K. Diwold and Simon Parsons},
            year = {2006},
           pages = {121--127},
            note = {cited By 1},
         journal = {AAAI Spring Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38619/}
}

@inproceedings{lincoln38616,
          volume = {2006},
          author = {Y. Tang and Simon Parsons and Elizabeth Sklar},
            note = {cited By 3},
           title = {Agent-based modeling of human education data},
         journal = {Proceedings of the International Conference on Autonomous Agents},
             doi = {10.1145/1160633.1160654},
           pages = {129--131},
            year = {2006},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38616/}
}

@incollection{lincoln6717,
          number = {3540},
           month = {December},
          author = {Marc M. Ellenrieder and Lars Kruger and Dirk Stoessel and Marc Hanheide},
          series = {Lecture Notes in Computer Science},
            note = {In this paper, we introduce a novel model-based visibility measure for geometric primitives called visibility map. It is simple to calculate, memory efficient, accurate for viewpoints outside the convex hull of the object and versatile in terms of possible applications. Several useful properties of visibility maps that show their superiority to existing visibility measures are derived. Various example applications from the automotive industry where the presented measure is used successfully conclude the paper.},
       booktitle = {Image Analysis},
          editor = {Heikki Kalviainen and Jussi Parkinnen and Arto Kaarna},
           title = {A versatile model-based visibility measure for geometric primitives},
       publisher = {Springer},
            year = {2005},
             doi = {10.1007/11499145\_68},
           pages = {669--678},
        keywords = {ARRAY(0x5568fbb6ce20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6717/},
        abstract = {In this paper, we introduce a novel model-based visibility measure for geometric primitives called visibility map. It is simple to calculate, memory efficient, accurate for viewpoints outside the convex hull of the object and versatile in terms of possible applications. Several useful properties of visibility maps that show their superiority to existing visibility measures are derived. Various example applications from the automotive industry where the presented measure is used successfully conclude the paper.}
}

@article{lincoln29364,
          volume = {3733},
           month = {October},
          author = {Ayse Kucukyilmaz and Bulent Ozguc},
          series = {Lecture Notes in Computer Science},
       booktitle = {Computer and Information Sciences - ISCIS 2005: 20th International Symposium, Istanbul, Turkey, October 26 -- 28, 2005, Proceedings},
          editor = {P. Yolum and T. Gungor and F. Gurgen and C. Ozturan},
           title = {An animation system for fracturing of rigid objects},
       publisher = {Springer},
            year = {2005},
         journal = {In: Yolum ., G{\"u}ng{\"o}r T., G{\"u}rgen F., {\"O}zturan C. (eds) Computer and Information Sciences - ISCIS 2005. ISCIS 2005. Lecture Notes in Computer Science},
             doi = {10.1007/11569596\_71},
        keywords = {ARRAY(0x5568fbb6cd50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29364/},
        abstract = {This paper describes a system for the animation of fracturing brittle objects. The system combines rigid body simulation methods with a constraint-based model to animate fracturing of arbitrary polyhedral shaped objects under impact. The objects are represented as sets of masses, where pairs of adjacent masses are connected via a distance-preserving linear constraint. Lagrange multipliers are used to compute the forces exerted by those constraints, where these forces determine how and where the object will break. However, a problem with existing systems is that the initial body models exhibit well-defined uniformity, which makes the generated animations unrealistic. This work introduces a method for generating more realistic cracks without any performance loss. This method is easy to implement and applicable on different models.

Computer and Information Sciences - ISCIS 2005, 20th International Symposium, Istanbul, Turkey, October 26-28, 2005, Proceedings}
}

@inproceedings{lincoln6944,
           month = {October},
          author = {Marc Hanheide and Christian Bauckhage and Gerhard Sagerer},
            note = {As wearable sensors and computing hardware are becoming a reality,
new and unorthodox approaches to seamless human-computer
interaction can be explored. This paper presents the prototype of a
wearable, head-mounted device for advanced human-machine interaction
that integrates speech recognition and computer vision
with head gesture analysis based on inertial sensor data. We will
focus on the innovative idea of integrating visual and inertial data
processing for interaction. Fusing head gestures with results from
visual analysis of the environment provides rich vocabularies for
human-machine communication because it renders the environment
into an interface: if objects or items in the surroundings are
being associated with system activities, head gestures can trigger
commands if the corresponding object is being looked at. We will
explain the algorithmic approaches applied in our prototype and
present experiments that highlight its potential for assistive technology.
Apart from pointing out a new direction for seamless interaction
in general, our approach provides a new and easy to use
interface for disabled and paralyzed users in particular.},
       booktitle = {7th international conference on Multimodal interfaces},
          editor = {B. Gottfried and H. Aghajan},
           title = {Combining environmental cues \& head gestures to interact with wearable devices},
       publisher = {ACM Association of Computing Machinery},
            year = {2005},
             doi = {10.1145/1088463.1088471},
           pages = {25--31},
        keywords = {ARRAY(0x5568fbaee870)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6944/},
        abstract = {As wearable sensors and computing hardware are becoming a reality,
new and unorthodox approaches to seamless human-computer
interaction can be explored. This paper presents the prototype of a
wearable, head-mounted device for advanced human-machine interaction
that integrates speech recognition and computer vision
with head gesture analysis based on inertial sensor data. We will
focus on the innovative idea of integrating visual and inertial data
processing for interaction. Fusing head gestures with results from
visual analysis of the environment provides rich vocabularies for
human-machine communication because it renders the environment
into an interface: if objects or items in the surroundings are
being associated with system activities, head gestures can trigger
commands if the corresponding object is being looked at. We will
explain the algorithmic approaches applied in our prototype and
present experiments that highlight its potential for assistive technology.
Apart from pointing out a new direction for seamless interaction
in general, our approach provides a new and easy to use
interface for disabled and paralyzed users in particular.}
}

@inproceedings{lincoln29844,
          volume = {3},
           month = {September},
          author = {P. Biber and S. Fleck and T. Duckett},
       booktitle = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops},
           title = {3D modeling of indoor environments for a robotic security guard},
       publisher = {IEEE},
            year = {2005},
             doi = {10.1109/CVPR.2005.381},
           pages = {124--124},
        keywords = {ARRAY(0x5568fbb7dee0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29844/},
        abstract = {Autonomous mobile robots will play a major role in future security and surveillance tasks for large scale environments
such as shopping malls, airports, hospitals and museums. Robotic security guards will autonomously survey such environments, unless a remote human operator takes over control. In this context a 3D model can convey much more useful information than the typical 2D maps used in many robotic applications today, both for visualisation of information and as human machine interface for remote control.

This paper addresses the challenge of building such a model of a large environment (50m x 60m) using data from the robot?s own sensors: a 2D laser scanner and a panoramic camera. The data are processed in a pipeline that comprises automatic, semi-automatic and manual stages. The user can interact with the reconstruction process where necessary to ensure robustness and completeness of the model. A hybrid representation, tailored to the application, has been chosen: floors and walls are represented efficiently by textured planes. Non-planar structures like stairs
and tables, which are represented by point clouds, can be added if desired. Our methods to extract these structures include: simultaneous localization and mapping in 2D and wall extraction based on laser scanner range data, building textures from multiple omni-directional images using multi-resolution blending, and calculation of 3D geometry by a graph cut stereo technique. Various renderings illustrate the usability of the model for visualising the security guard?s position and environment.}
}

@inproceedings{lincoln6945,
           month = {September},
          author = {Sven Wachsmuth and Marc Hanheide and Sebastian Wrede and Christian Bauckhage},
            note = {Systems that perform in real environments need to bind the internal state to externally
perceived objects, events, or complete scenes. How to learn this correspondence has been a long
standing problem in computer vision as well as artificial intelligence. Augmented Reality provides
an interesting perspective on this problem because a human user can directly relate displayed
system results to real environments. In the following we present a system that is able to bootstrap
internal models from user-system interactions. Starting from pictorial representations it learns
symbolic object labels that provide the basis for storing observed episodes. In a second step, more
complex relational information is extracted from stored episodes that enables the system to react
on specific scene contexts.},
       booktitle = {KI 2005 Workshop on Mixed-reality as a Challenge to Image Understanding and Artificial Intelligence},
          editor = {B. Gottfried and H. Aghajan},
           title = {From images via symbols to contexts: using augmented reality for interactive model acquisition},
           pages = {41--46},
            year = {2005},
        keywords = {ARRAY(0x5568fbad44e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6945/},
        abstract = {Systems that perform in real environments need to bind the internal state to externally
perceived objects, events, or complete scenes. How to learn this correspondence has been a long
standing problem in computer vision as well as artificial intelligence. Augmented Reality provides
an interesting perspective on this problem because a human user can directly relate displayed
system results to real environments. In the following we present a system that is able to bootstrap
internal models from user-system interactions. Starting from pictorial representations it learns
symbolic object labels that provide the basis for storing observed episodes. In a second step, more
complex relational information is extracted from stored episodes that enables the system to react
on specific scene contexts.}
}

@inproceedings{lincoln12824,
       booktitle = {13th European Signal Processing Conference (EUSIPCO 2005)},
           month = {September},
           title = {3D modeling of indoor environments by a mobile platform with a laser scanner and panoramic camera},
          author = {Peter Biber and Sven Fleck and Florian Busch and Michael Wand and Tom Duckett and Wolfgang Strasser},
            year = {2005},
            note = {Proceedings published by Curran Associates, Inc. ( Dec 2007 )},
        keywords = {ARRAY(0x5568fbb64cd8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/12824/},
        abstract = {One major challenge of 3DTV is content acquisition. Here, we present a method to acquire a realistic, visually convincing D model of indoor environments based on a mobile platform that is equipped with a laser range scanner and a panoramic camera. The data of the 2D laser scans are used to solve the simultaneous lo- calization and mapping problem and to extract walls. Textures for walls and floor are built from the images of a calibrated panoramic camera. Multiresolution blending is used to hide seams in the gen- erated textures. The scene is further enriched by 3D-geometry cal- culated from a graph cut stereo technique. We present experimental results from a moderately large real environment. 1}
}

@article{lincoln6744,
          volume = {14},
           month = {August},
          author = {Christian Bauckhage and Marc Hanheide and Sebastian Wrede and Thomas Kaster and Michael Pfeiffer and Gerhard Sagerer},
            note = {The emerging cognitive vision paradigm deals with vision systems that apply machine learning and automatic reasoning in order to learn from what they perceive. Cognitive vision systems can rate the relevance and consistency of newly acquired knowledge, they can adapt to their environment and thus will exhibit high robustness. This contribution presents vision systems that aim at flexibility and robustness. One is tailored for content-based image retrieval, the others are cognitive vision systems that constitute prototypes of visual active memories which evaluate, gather, and integrate contextual knowledge for visual analysis. All three systems are designed to interact with human users. After we will have discussed adaptive content-based image retrieval and object and action recognition in an office environment, the issue of assessing cognitive systems will be raised. Experiences from psychologically evaluated human-machine interactions will be reported and the promising potential of psychologically-based usability experiments will be stressed.},
           title = {Vision systems with the human in the loop},
       publisher = {Hindawi Publishing Corp},
            year = {2005},
         journal = {EURASIP Journal on Applied Signal Processing},
             doi = {10.1155/ASP.2005.2375},
           pages = {2375--2390},
        keywords = {ARRAY(0x5568fbbc5058)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6744/},
        abstract = {The emerging cognitive vision paradigm deals with vision systems that apply machine learning and automatic reasoning in order to learn from what they perceive. Cognitive vision systems can rate the relevance and consistency of newly acquired knowledge, they can adapt to their environment and thus will exhibit high robustness. This contribution presents vision systems that aim at flexibility and robustness. One is tailored for content-based image retrieval, the others are cognitive vision systems that constitute prototypes of visual active memories which evaluate, gather, and integrate contextual knowledge for visual analysis. All three systems are designed to interact with human users. After we will have discussed adaptive content-based image retrieval and object and action recognition in an office environment, the issue of assessing cognitive systems will be raised. Experiences from psychologically evaluated human-machine interactions will be reported and the promising potential of psychologically-based usability experiments will be stressed.}
}

@inproceedings{lincoln29078,
           month = {August},
          author = {A. Treptow and G. Cielniak and T. Duckett},
       booktitle = {2005 IEEE/RSJ International Conference on Intelligent Robots and Systems},
           title = {Active people recognition using thermal and grey images on a mobile security robot},
       publisher = {IEEE},
             doi = {10.1109/IROS.2005.1545530},
           pages = {2103--2108},
            year = {2005},
        keywords = {ARRAY(0x5568fba33428)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29078/},
        abstract = {In this paper we present a vision-based approach to detect, track and identify people on a mobile robot in real time. While most vision systems for tracking people on mobile robots use skin color information, we present an approach using thermal images and a fast contour model together with a particle filter. With this method a person can be detected independently from current light conditions and in situations where no skin color is visible (the person is not close or does not face the robot). Tracking in thermal images is used as an attention system to get an estimate of the position of a person. Based on this estimate we use a pan-tilt camera to zoom to the expected face region and apply a fast face tracker in combination with face recognition to identify the person.}
}

@inproceedings{lincoln29843,
           month = {June},
          author = {M. Persson and M. Sandvall and T. Duckett},
       booktitle = {2005 International Symposium on Computational Intelligence in Robotics and Automation},
           title = {Automatic building detection from aerial images for mobile robot mapping},
       publisher = {IEEE},
             doi = {10.1109/CIRA.2005.1554289},
           pages = {273--278},
            year = {2005},
        keywords = {ARRAY(0x5568fbaae4f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29843/},
        abstract = {To improve mobile robot outdoor mapping, information about the shape and location of buildings is of
interest. This paper describes a system for automatic detection of buildings in aerial images taken from a nadir view. The system builds two types of independent hypotheses based on the image contents. A segmentation process implemented as an ensemble of SOMs (Self Organizing Maps) is trained and used to create a segmented image showing different types of roofs, vegetation and sea. A second type of hypotheses is based on an edge image produced from the aerial photo. A line extraction process uses the edge image as input and extracts lines from it. From these edges, corners and rectangles that represent buildings are constructed. A classification process uses the information from both hypotheses to determine whether the rectangles are buildings, unsure buildings or unknown objects.}
}

@inproceedings{lincoln8346,
          volume = {3540},
           month = {June},
          author = {M. M. Ellenrieder and L. Kr{\"u}ger and D. St{\~A}{\P}{\~A}?e and M. Hanheide},
            note = {Conference Code: 65718},
       booktitle = {14th Scandinavian Conference on Image Analysis, SCIA 2005},
           title = {A versatile model-based visibility measure for geometric primitive},
         address = {Joensuu},
       publisher = {Springer Verlag},
            year = {2005},
         journal = {Lecture Notes in Computer Science},
           pages = {669--678},
        keywords = {ARRAY(0x5568fbb69318)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/8346/},
        abstract = {In this paper, we introduce a novel model-based visibility measure for geometric primitives called visibility map. It is simple to calculate, memory efficient, accurate for viewpoints outside the convex hull of the object and versatile in terms of possible applications. Several useful properties of visibility maps that show their superiority to existing visibility measures are derived. Various example applications from the automotive industry where the presented measure is used successfully conclude the paper. {\^A}{\copyright} Springer-Verlag Berlin Heidelberg 2005.}
}

@inproceedings{lincoln29074,
           month = {April},
          author = {H. Andreasson and A. Treptow and T. Duckett},
       booktitle = {Proceedings of the 2005 IEEE International Conference on Robotics and Automation},
           title = {Localization for mobile robots using panoramic vision, local features and particle filter},
       publisher = {IEEE},
             doi = {10.1109/ROBOT.2005.1570627},
           pages = {3348--3353},
            year = {2005},
        keywords = {ARRAY(0x5568fb9d8ee0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29074/},
        abstract = {In this paper we present a vision-based approach to self-localization that uses a novel scheme to integrate feature-based matching of panoramic images with Monte Carlo localization. A specially modified version of Lowe?s SIFT algorithm is used to match features extracted from local interest points in the image, rather than using global features calculated from the whole image. Experiments conducted in a large, populated indoor environment (up to 5 persons visible) over a period of several months demonstrate the robustness of the approach, including kidnapping and occlusion of up to 90\% of the robot?s field of view.}
}

@inproceedings{lincoln29077,
           month = {April},
          author = {T. Martinez-Marin and T. Duckett},
       booktitle = {Proceedings of the 2005 IEEE International Conference on Robotics and Automation},
           title = {Fast reinforcement learning for vision-guided mobile robots},
       publisher = {IEEE},
             doi = {10.1109/ROBOT.2005.1570760},
           pages = {4170--4175},
            year = {2005},
        keywords = {ARRAY(0x5568fbaf8e88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29077/},
        abstract = {This paper presents a new reinforcement learning algorithm for accelerating acquisition of new skills by real mobile robots, without requiring simulation. It speeds up Q-learning by applying memory-based sweeping and enforcing the ?adjoining property?, a technique that exploits the natural ordering of sensory state spaces in many robotic applications by only allowing transitions between neighbouring states. The algorithm is tested within an image-based visual servoing framework on a docking task, in which the robot has to position its gripper at a desired configuration relative to an object on a table. In experiments, we compare the performance of the new algorithm with a hand-designed linear controller and a scheme using the linear controller as a bias to further accelerate the learning. By analysis of the controllability and docking time, we show that the biased learner could improve on the performance of the linear controller, while requiring substantially lower training time than unbiased learning (less than 1 hour on the real robot).}
}

@inproceedings{lincoln1204,
          volume = {21},
          number = {2},
           month = {April},
          author = {Peter Biber and Tom Duckett},
            note = {This paper introduces a dynamic map for mobile robots that adapts continuously over time. It resolves the stability plasticity dilemma (the tradeoff between adaptation to new patterns and preservation of old patterns) by representing the environment over multiple time scales simultaneously (five in our experiments). A sample-based representation is proposed, where older memories fade at different rates depending on the time scale. Robust statistics are used to interpret the samples. It is shown that this approach can track both stationary and non-stationary elements of the environment, covering the full spectrum of variations from moving objects to structural changes. The method was evaluated in a five-week experiment in a real dynamic environment. Experimental results show that the resulting map is stable, improves its quality over time and adapts to changes.},
       booktitle = {Robotics: Science and Systems 2005 Massachusetts Institute of Technology, Cambridge, Massachusetts},
           title = {Dynamic maps for long-term operation of mobile service robots},
            year = {2005},
         journal = {Robotics, IEEE Transactions on [see also Robotics and Automation, IEEE Transactions on]},
             doi = {10.1109/TRO.2004.839220},
           pages = {196--207},
        keywords = {ARRAY(0x5568fba449e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1204/},
        abstract = {This paper introduces a dynamic map for mobile robots that adapts continuously over time. It resolves the stability plasticity dilemma (the tradeoff between adaptation to new patterns and preservation of old patterns) by representing the environment over multiple time scales simultaneously (five in our experiments). A sample-based representation is proposed, where older memories fade at different rates depending on the time scale. Robust statistics are used to interpret the samples. It is shown that this approach can track both stationary and non-stationary elements of the environment, covering the full spectrum of variations from moving objects to structural changes. The method was evaluated in a five-week experiment in a real dynamic environment. Experimental results show that the resulting map is stable, improves its quality over time and adapts to changes.}
}

@article{lincoln1203,
          volume = {21},
          number = {2},
           month = {April},
          author = {U. Frese and P. Larsson and Tom Duckett},
            note = {This paper addresses the problem of simultaneous localization and mapping (SLAM) by a mobile robot. An incremental SLAM algorithm is introduced that is derived from multigrid methods used for solving partial differential equations. The approach improves on the performance of previous relaxation methods for robot mapping, because it optimizes the map at multiple levels of resolution. The resulting algorithm has an update time that is linear in the number of estimated features for typical indoor environments, even when closing very large loops, and offers advantages in handling nonlinearities compared with other SLAM algorithms. Experimental comparisons with alternative algorithms using two well-known data sets and mapping results on a real robot are also presented.},
           title = {A multilevel relaxation algorithm for simultaneous localization and mapping},
            year = {2005},
         journal = {Robotics, IEEE Transactions on [see also Robotics and Automation, IEEE Transactions on]},
             doi = {10.1109/TRO.2004.839220},
           pages = {196--207},
        keywords = {ARRAY(0x5568fba1a878)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1203/},
        abstract = {This paper addresses the problem of simultaneous localization and mapping (SLAM) by a mobile robot. An incremental SLAM algorithm is introduced that is derived from multigrid methods used for solving partial differential equations. The approach improves on the performance of previous relaxation methods for robot mapping, because it optimizes the map at multiple levels of resolution. The resulting algorithm has an update time that is linear in the number of estimated features for typical indoor environments, even when closing very large loops, and offers advantages in handling nonlinearities compared with other SLAM algorithms. Experimental comparisons with alternative algorithms using two well-known data sets and mapping results on a real robot are also presented.}
}

@article{lincoln6742,
          volume = {19},
          number = {2},
           month = {March},
          author = {Sven Wachsmuth and Sebastian Wrede and Marc Hanheide and Christian Bauckhage},
            note = {Computer vision is becoming an integral part in human-machine interfaces as research increasingly aims at a seamless
and natural interaction between a user and an application system. Gesture recognition, context awareness, and grounding
concepts in the commonly perceived environment as well as in the interaction history are key abilities of such systems.
Simultaneously, recent computer vision research has indicated that integrated systems which are embedded in the world
and interact with their environment seem a prerequisite for solving more general vision tasks. Cognitive computer vision
systems which enable the generation of knowledge on the basis of perception, reasoning, and extension of prior models
are a major step towards this goal. For these, the integration, interaction and organization of memory becomes a key
issue in system design. In this article we will present a computational framework for integrated vision systems that is
centered around an active memory component. It supports a fast integration and substitution of system components,
various means of interaction patterns, and enables a system to reason about its own memory content. This framework
will be exemplified by means of a cognitive human-machine interface in an Augmented Reality scenario. The system is
able to acquire new concepts from interaction and provides a context aware scene augmentation for the user.},
           title = {An active memory model for cognitive computer vision systems},
       publisher = {Springer for Fachbereiches KI in der Gesellschaft f{\"u}r Informatik},
            year = {2005},
         journal = {KI - K{\"u}nstliche Intelligenz},
           pages = {25--31},
        keywords = {ARRAY(0x5568fbb0ad90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6742/},
        abstract = {Computer vision is becoming an integral part in human-machine interfaces as research increasingly aims at a seamless
and natural interaction between a user and an application system. Gesture recognition, context awareness, and grounding
concepts in the commonly perceived environment as well as in the interaction history are key abilities of such systems.
Simultaneously, recent computer vision research has indicated that integrated systems which are embedded in the world
and interact with their environment seem a prerequisite for solving more general vision tasks. Cognitive computer vision
systems which enable the generation of knowledge on the basis of perception, reasoning, and extension of prior models
are a major step towards this goal. For these, the integration, interaction and organization of memory becomes a key
issue in system design. In this article we will present a computational framework for integrated vision systems that is
centered around an active memory component. It supports a fast integration and substitution of system components,
various means of interaction patterns, and enables a system to reason about its own memory content. This framework
will be exemplified by means of a cognitive human-machine interface in an Augmented Reality scenario. The system is
able to acquire new concepts from interaction and provides a context aware scene augmentation for the user.}
}

@article{lincoln1221,
          volume = {22},
          number = {2},
           month = {February},
          author = {Shigang Yue and Dominik Henrich},
            note = {The vibration of a deformable object is often problematic during automatic handling by robot manipulators. However, humans can often handle and damp the vibration of deformable objects with ease. This paper presents force/torque sensor-based skills for handling deformable linear objects in a manner suitable to reduce acute vibration with simple human skill inspired strategies that consist of one or two adjustment motions. The adjustment motion is a simple open-loop motion that can be attached to the end of any arbitrary end-effector's trajectory. As an ordinary industrial robot's simple action, it has three periods, i.e., acceleration, constant speed, and deceleration period; it starts from a predicted time tightly close to a force/moment maximum. The predicted time for the adjustment action is generated automatically on-line based on the vibration rhythm and the data sensed by a force/torque sensor mounted on the robot's wrist. To find the matching point between the vibrational signal of the deformable object and a template, template matching techniques including cross-correlation and minimum squared error methods are used and compared. Experiments are conducted with an industrial robot to test the new skills under various conditions. The results demonstrate that an industrial robot could perform effective vibration reduction skills with simple strategies.},
           title = {Manipulating deformable linear objects: Sensor-based skills of adjustment motions for vibration reduction},
       publisher = {Wiley},
            year = {2005},
         journal = {Journal of robotic systems},
             doi = {10.1002/rob.20049},
           pages = {67--85},
        keywords = {ARRAY(0x5568fbb856a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1221/},
        abstract = {The vibration of a deformable object is often problematic during automatic handling by robot manipulators. However, humans can often handle and damp the vibration of deformable objects with ease. This paper presents force/torque sensor-based skills for handling deformable linear objects in a manner suitable to reduce acute vibration with simple human skill inspired strategies that consist of one or two adjustment motions. The adjustment motion is a simple open-loop motion that can be attached to the end of any arbitrary end-effector's trajectory. As an ordinary industrial robot's simple action, it has three periods, i.e., acceleration, constant speed, and deceleration period; it starts from a predicted time tightly close to a force/moment maximum. The predicted time for the adjustment action is generated automatically on-line based on the vibration rhythm and the data sensed by a force/torque sensor mounted on the robot's wrist. To find the matching point between the vibrational signal of the deformable object and a template, template matching techniques including cross-correlation and minimum squared error methods are used and compared. Experiments are conducted with an industrial robot to test the new skills under various conditions. The results demonstrate that an industrial robot could perform effective vibration reduction skills with simple strategies.}
}

@article{lincoln1202,
          volume = {24},
          number = {1},
          author = {Maren Bennewitz and Wolfram Burgard and Grzegorz Cielniak and Sebastian Thrun},
            note = {Whenever people move through their environments they do not move randomly. Instead, they usually follow specific trajectories or motion patterns corresponding to their intentions. Knowledge about such patterns enables a mobile robot to robustly keep track of persons in its environment and to improve its behavior. In this paper we propose a technique for learning collections of trajectories that characterize typical motion patterns of persons. Data recorded with laser-range finders are clustered using the expectation maximization algorithm. Based on the result of the clustering process, we derive a hidden Markov model that is applied to estimate the current and future positions of persons based on sensory input. We also describe how to incorporate the probabilistic belief about the potential trajectories of persons into the path planning process of a mobile robot. We present several experiments carried out in different environments with a mobile robot equipped with a laser-range scanner and a camera system. The results demonstrate that our approach can reliably learn motion patterns of persons, can robustly estimate and predict positions of persons, and can be used to improve the navigation behavior of a mobile robot.},
           title = {Learning motion patterns of people for compliant robot motion},
            year = {2005},
         journal = {The International Journal of Robotics Research},
             doi = {10.1177/0278364904048962},
           pages = {31--48},
        keywords = {ARRAY(0x5568fbb640a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1202/},
        abstract = {Whenever people move through their environments they do not move randomly. Instead, they usually follow specific trajectories or motion patterns corresponding to their intentions. Knowledge about such patterns enables a mobile robot to robustly keep track of persons in its environment and to improve its behavior. In this paper we propose a technique for learning collections of trajectories that characterize typical motion patterns of persons. Data recorded with laser-range finders are clustered using the expectation maximization algorithm. Based on the result of the clustering process, we derive a hidden Markov model that is applied to estimate the current and future positions of persons based on sensory input. We also describe how to incorporate the probabilistic belief about the potential trajectories of persons into the path planning process of a mobile robot. We present several experiments carried out in different environments with a mobile robot equipped with a laser-range scanner and a camera system. The results demonstrate that our approach can reliably learn motion patterns of persons, can robustly estimate and predict positions of persons, and can be used to improve the navigation behavior of a mobile robot.}
}

@inproceedings{lincoln38624,
          volume = {3276},
           title = {Exploring auction mechanisms for role assignment in teams of autonomous robots},
          author = {V. Frias-Martinez and Elizabeth Sklar and Simon Parsons},
            year = {2005},
           pages = {532--539},
            note = {cited By 11},
         journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38624/}
}

@book{lincoln38501,
           title = {The use of expert systems for toxicology risk prediction},
          author = {Simon Parsons and P. McBurney},
            year = {2005},
           pages = {135--175},
            note = {cited By 10},
         journal = {Predictive Toxicology},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38501/}
}

@inproceedings{lincoln38621,
           title = {Multiagent simulation of learning environments},
          author = {Elizabeth Sklar and M. Davies},
            year = {2005},
           pages = {1085--1091},
            note = {cited By 6},
         journal = {Proceedings of the International Conference on Autonomous Agents},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38621/}
}

@inproceedings{lincoln38623,
          volume = {3276},
           title = {RoboCupJunior - Four years later},
          author = {Elizabeth Sklar and A. Eguchi},
            year = {2005},
           pages = {172--183},
            note = {cited By 3},
         journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38623/}
}

@inproceedings{lincoln38622,
          volume = {3366},
           title = {When is it okay to lie? A simple model of contradiction in agent-based dialogues},
          author = {Elizabeth Sklar and Simon Parsons and M. Davies},
            year = {2005},
           pages = {251--261},
            note = {cited By 3},
         journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38622/}
}

@incollection{lincoln6719,
          number = {3175},
           month = {December},
          author = {Nicholas Gorges and Marc Hanheide and William Christmas and Christian Bauckhage and Gerhard Sagerer and Joseph Kittler},
          series = {Lecture Notes in Computer Science},
            note = {lthough mosaics are well established as a compact and non-redundant representation of image sequences, their application still suffers from restrictions of the camera motion or has to deal with parallax errors. We present an approach that allows construction of mosaics from arbitrary motion of a head-mounted camera pair. As there are no parallax errors when creating mosaics from planar objects, our approach first decomposes the scene into planar sub-scenes from stereo vision and creates a mosaic for each plane individually. The power of the presented mosaicing technique is evaluated in an office scenario, including the analysis of the parallax error.},
       booktitle = {Pattern recognition},
          editor = {Carl Edward Rasmussen and Heinrich H. Buelthoff and Bernhard Schoelkopf and Martin Giese},
           title = {Mosaics from arbitrary stereo video sequences},
       publisher = {Springer},
            year = {2004},
             doi = {10.1007/978-3-540-28649-3\_42},
           pages = {342--349},
        keywords = {ARRAY(0x5568fbafd310)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6719/},
        abstract = {lthough mosaics are well established as a compact and non-redundant representation of image sequences, their application still suffers from restrictions of the camera motion or has to deal with parallax errors. We present an approach that allows construction of mosaics from arbitrary motion of a head-mounted camera pair. As there are no parallax errors when creating mosaics from planar objects, our approach first decomposes the scene into planar sub-scenes from stereo vision and creates a mosaic for each plane individually. The power of the presented mosaicing technique is evaluated in an office scenario, including the analysis of the parallax error.}
}

@incollection{lincoln6718,
          number = {3175},
           month = {December},
          author = {Dirk Stoessel and Marc Hanheide and Gerhard Sagerer and Lars Kruger},
          series = {Lecture Notes in Computer Science},
            note = {Abstract. Quality assurance programs of today?s car manufacturers show increasing demand for automated visual inspection tasks. A typical example is just-in-time checking of assemblies along production lines. Since high throughput must be achieved, object recognition and pose estimation heavily rely on offline preprocessing stages of available CAD data. In this paper, we propose a complete, universal framework for CAD model feature extraction and entropy index based viewpoint selection that is developed in cooperation with a major german car manufacturer.},
       booktitle = {Pattern recognition},
          editor = {Carl Edward Rasmussen and Heinrich H. B{\"u}lthoff and Bernhard Sch{\"o}lkopf and Martin A. Giese},
           title = {Feature and viewpoint selection for industrial car assembly},
       publisher = {Springer},
            year = {2004},
             doi = {10.1007/978-3-540-28649-3\_65},
           pages = {528--535},
        keywords = {ARRAY(0x5568fbb691c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6718/},
        abstract = {Abstract. Quality assurance programs of today?s car manufacturers show increasing demand for automated visual inspection tasks. A typical example is just-in-time checking of assemblies along production lines. Since high throughput must be achieved, object recognition and pose estimation heavily rely on offline preprocessing stages of available CAD data. In this paper, we propose a complete, universal framework for CAD model feature extraction and entropy index based viewpoint selection that is developed in cooperation with a major german car manufacturer.}
}

@inproceedings{lincoln29079,
          volume = {4},
           month = {September},
          author = {P. Biber and H. Andreasson and T. Duckett and A. Schilling},
       booktitle = {2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)},
           title = {3D modeling of indoor environments by a mobile robot with a laser scanner and panoramic camera},
       publisher = {IEEE},
            year = {2004},
             doi = {10.1109/IROS.2004.1389947},
           pages = {3430--3435},
        keywords = {ARRAY(0x5568fbaedaa8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29079/},
        abstract = {We present a method to acquire a realistic, visually convincing 3D model of indoor office environments based on a mobile robot that is equipped with a laser range scanner and a panoramic camera. The data of the 2D laser scans are used to solve the SLAM problem and to extract walls. Textures for walls and floor are built from the images of a calibrated panoramic camera. Multi-resolution blending is used to hide seams in the generated textures.}
}

@inproceedings{lincoln39658,
       booktitle = {8th IEEE International Workshop on Variable Structure Systems},
           month = {September},
           title = {Algorithm for Computing Sliding Mode Control and Switching Surface from Output Samples},
          author = {B. Bandyopadhyay and V. Thakar and C.M. Saaj and S. Janardhanan},
            year = {2004},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39658/},
        abstract = {Paper No. 04}
}

@inproceedings{lincoln39659,
       booktitle = {6th IFAC Symposium on Nonlinear Control Systems},
           month = {September},
           title = {Output Feedback Variable Structure Control of Non-linear Systems by Feedback Linearization},
          author = {C.M. Saaj and B. Bandyopadhyay},
            year = {2004},
           pages = {771--776},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39659/}
}

@article{lincoln657,
          volume = {48},
          number = {1},
           month = {August},
          author = {Achim Lilienthal and Tom Duckett},
            note = {This paper addresses the problem of mapping the structure of a gas distribution by creating concentration gridmaps from the data collected by a mobile robot equipped with gas sensors. By contrast to metric gridmaps extracted from sonar or laser range scans, a single measurement from a gas sensor provides information about a comparatively small area. To overcome this problem, a mapping technique is introduced that uses a Gaussian weighting function to model the decreasing likelihood that a particular reading represents the true concentration with respect to the distance from the point of measurement. This method is evaluated in terms of its suitability regarding the slow response and recovery of the gas sensors, and experimental comparisons of different exploration strategies are presented. The stability of the mapped structures and the capability to use concentration gridmaps to locate a gas source are also discussed},
           title = {Building gas concentration gridmaps with a mobile robot},
            year = {2004},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2004.05.002},
           pages = {3--16},
        keywords = {ARRAY(0x5568fbba4f60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/657/},
        abstract = {This paper addresses the problem of mapping the structure of a gas distribution by creating concentration gridmaps from the data collected by a mobile robot equipped with gas sensors. By contrast to metric gridmaps extracted from sonar or laser range scans, a single measurement from a gas sensor provides information about a comparatively small area. To overcome this problem, a mapping technique is introduced that uses a Gaussian weighting function to model the decreasing likelihood that a particular reading represents the true concentration with respect to the distance from the point of measurement. This method is evaluated in terms of its suitability regarding the slow response and recovery of the gas sensors, and experimental comparisons of different exploration strategies are presented. The stability of the mapped structures and the capability to use concentration gridmaps to locate a gas source are also discussed}
}

@inproceedings{lincoln6948,
           month = {August},
          author = {Marc Hanheide and Christian Bauckhage and Gerhard Sagerer},
            note = {Information fusion is a mandatory prerequisite for
cognitive vision systems. These are vision systems that apply reasoning and learning on different levels of abstraction and correspondingly have to deal with hypotheses from different categorical domains. Following some principles of human cognition, we
present an approach to information fusion that closely couples
reasoning and representation. We will discuss how processes like
probabilistic contextual reasoning as well as functional and nonfunctional requirements in storing data from different sources can
be integrated by a uni?ed XML based data representation. Due
to the interaction between active processes and data storage, we
call our approach an active memory. Performance results of an
implemented system as well as an evaluation of data fusion from
contextual inference will be presented},
       booktitle = {17th International Conference on Pattern Recognition},
          editor = {B. Gottfried and H. Aghajan},
           title = {Memory consistency validation in a cognitive vision system},
       publisher = {IEEE},
            year = {2004},
             doi = {10.1109/ICPR.2004.1334260},
           pages = {459--462},
        keywords = {ARRAY(0x5568fba14e50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6948/},
        abstract = {Information fusion is a mandatory prerequisite for
cognitive vision systems. These are vision systems that apply reasoning and learning on different levels of abstraction and correspondingly have to deal with hypotheses from different categorical domains. Following some principles of human cognition, we
present an approach to information fusion that closely couples
reasoning and representation. We will discuss how processes like
probabilistic contextual reasoning as well as functional and nonfunctional requirements in storing data from different sources can
be integrated by a uni?ed XML based data representation. Due
to the interaction between active processes and data storage, we
call our approach an active memory. Performance results of an
implemented system as well as an evaluation of data fusion from
contextual inference will be presented}
}

@inproceedings{lincoln6947,
           month = {June},
          author = {Sebastian Wrede and Marc Hanheide and Christian Bauckhage and Gerhard Sagerer},
            note = {Information fusion is a mandatory prerequisite for
cognitive vision systems. These are vision systems that apply rea-
soning and learning on different levels of abstraction and corre-
spondingly have to deal with hypotheses from different categori-
cal domains. Following some principles of human cognition, we
present an approach to information fusion that closely couples
reasoning and representation. We will discuss how processes like
probabilistic contextual reasoning as well as functional and non-
functional requirements in storing data from different sources can
be integrated by a unified XML based data representation. Due
to the interaction between active processes and data storage, we
call our approach an active memory. Performance results of an
implemented system as well as an evaluation of data fusion from
contextual inference will be presented.},
       booktitle = {International Conference on Information Fusion},
          editor = {B. Gottfried and H. Aghajan},
           title = {An active memory as a model for information fusion},
           pages = {198--205},
            year = {2004},
        keywords = {ARRAY(0x5568fb9d9228)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6947/},
        abstract = {Information fusion is a mandatory prerequisite for
cognitive vision systems. These are vision systems that apply rea-
soning and learning on different levels of abstraction and corre-
spondingly have to deal with hypotheses from different categori-
cal domains. Following some principles of human cognition, we
present an approach to information fusion that closely couples
reasoning and representation. We will discuss how processes like
probabilistic contextual reasoning as well as functional and non-
functional requirements in storing data from different sources can
be integrated by a unified XML based data representation. Due
to the interaction between active processes and data storage, we
call our approach an active memory. Performance results of an
implemented system as well as an evaluation of data fusion from
contextual inference will be presented.}
}

@article{lincoln28031,
          volume = {18},
          number = {8},
           month = {April},
          author = {Achim Lilienthal and Tom Duckett},
           title = {Experimental analysis of gas-sensitive Braitenberg vehicles},
       publisher = {Taylor \& Francis},
            year = {2004},
         journal = {Advanced Robotics},
             doi = {10.1163/1568553041738103},
           pages = {817--834},
        keywords = {ARRAY(0x5568fbb91ec8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28031/},
        abstract = {This article addresses the problem of localizing a static gas source in an indoor environment by a mobile robot. In contrast to previous works, the environment is not artificially ventilated to produce a strong unidirectional airflow. Here, the dominant transport mechanisms of gas molecules are turbulence and convection flow rather than diffusion, which results in a patchy, chaotically fluctuating gas distribution. Two Braitenberg-type strategies (positive and negative tropotaxis) based on the instantaneously measured spatial concentration gradient were investigated. Both strategies were shown to be of potential use for gas source localization. As a possible solution to the problem of gas source declaration (the task of determining with certainty that the gas source has been found), an indirect localization strategy based on exploration and concentration peak avoidance is suggested. Here, a gas source is located by exploiting the fact that local concentration maxima occur more frequently near the gas source compared to distant regions.}
}

@inproceedings{lincoln6946,
           month = {April},
          author = {Christian Bauckhage and Marc Hanheide and Sebastian Wrede and Gerhard Sagerer},
            note = {The emerging cognitive vision paradigm is concerned
with vision systems that evaluate, gather and integrate con-
textual knowledge for visual analysis. In reasoning about
events and structures, cognitive vision systems should rely
on multiple computations in order to perform robustly even
in noisy domains. Action recognition in an unconstrained
office environment thus provides an excellent testbed for re-
search on cognitive computer vision. In this contribution,
we present a system that consists of several computational
modules for object and action recognition. It applies atten-
tion mechanisms, visual learning and contextual as well as
probabilistic reasoning to fuse individual results and verify
their consistency. Database technologies are used for infor-
mation storage and an XML based communication frame-
work integrates all modules into a consistent architecture.},
       booktitle = {2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004},
          editor = {B. Gottfried and H. Aghajan},
           title = {A cognitive vision system for action recognition in office environments},
       publisher = {IEEE},
            year = {2004},
             doi = {10.1109/CVPR.2004.1315250},
           pages = {827--833},
        keywords = {ARRAY(0x5568fbb0e028)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6946/},
        abstract = {The emerging cognitive vision paradigm is concerned
with vision systems that evaluate, gather and integrate con-
textual knowledge for visual analysis. In reasoning about
events and structures, cognitive vision systems should rely
on multiple computations in order to perform robustly even
in noisy domains. Action recognition in an unconstrained
office environment thus provides an excellent testbed for re-
search on cognitive computer vision. In this contribution,
we present a system that consists of several computational
modules for object and action recognition. It applies atten-
tion mechanisms, visual learning and contextual as well as
probabilistic reasoning to fuse individual results and verify
their consistency. Database technologies are used for infor-
mation storage and an XML based communication frame-
work integrates all modules into a consistent architecture.}
}

@article{lincoln37424,
          volume = {51},
          number = {1},
           month = {February},
          author = {C. Saaj and B. Bandyopadhyay and H. Unbehauen},
            note = {cited By 1},
           title = {A Minor Correction to "A New Algorithm for Discrete-Time Sliding Mode Control Using Fast Output Sampling Feedback"},
       publisher = {IEEE},
            year = {2004},
         journal = {IEEE Transactions on Industrial Electronics},
             doi = {10.1109/TIE.2003.821899},
           pages = {244--247},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37424/},
        abstract = {The purpose of this letter is to show that the recently proposed fast output sampling sliding-mode control method in an earlier paper by the authors needs a small correction in the expression for the control law. The results or the corrected algorithm is illustrated by the same example considered in the earlier paper.}
}

@inproceedings{lincoln38634,
          volume = {3020},
           title = {Toward an undergraduate league for RoboCup},
          author = {J. Anderson and J. Baltes and D. Livingston and Elizabeth Sklar and J. Tower},
            year = {2004},
           pages = {670--677},
            note = {cited By 2},
         journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38634/}
}

@inproceedings{lincoln38627,
          volume = {1},
           title = {Teaching with RoboCup},
          author = {J. Baltes and Elizabeth Sklar and J. Anderson},
            year = {2004},
           pages = {146--151},
            note = {cited By 8},
         journal = {AAAI Spring Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38627/}
}

@article{lincoln38635,
          volume = {3020},
           title = {RoboCup: Yesterday, today, and tomorrow workshop of the executive committee in Blaubeuren, october 2003},
          author = {H.-D. Burkhard and M. Asada and A. Bonarini and A. Jacoff and D. Nardi and M. Riedmiller and C. Sammut and Elizabeth Sklar and M. Veloso},
            year = {2004},
           pages = {15--34},
            note = {cited By 0},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38635/}
}

@article{lincoln38632,
          volume = {25},
          number = {2},
          author = {E. Pagello and E. Menegatti and A. Bredenfel and P. Costa and T. Christaller and A. Jacoff and D. Polani and M. Riedmiller and A. Saffiotti and Elizabeth Sklar and T. Tomoichi},
            note = {cited By 6},
           title = {RoboCup-2003 new scientific and technical advances},
         journal = {AI Magazine},
           pages = {81--98},
            year = {2004},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38632/}
}

@inproceedings{lincoln38625,
          volume = {1},
           title = {Teaching AI using LEGO Mindstorms},
          author = {Simon Parsons and Elizabeth Sklar},
            year = {2004},
           pages = {8--13},
            note = {cited By 10},
         journal = {AAAI Spring Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38625/}
}

@inproceedings{lincoln13473,
       booktitle = {IEEE International Workshop on Safety, Security, and Rescue Robotics (SSRR-04)},
           title = {A system for vision based human-robot interaction (Short Paper)},
          author = {Alessandro Saffiotti and Dimiter Driankov and Tom Duckett},
       publisher = {IEEE},
            year = {2004},
        keywords = {ARRAY(0x5568fbaa0288)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13473/},
        abstract = {We describe our initial steps toward the realization of a robotic system for assisting fir e-fighting and rescue ser- vices. The system implements the concept of shared auton- omy between the robot and the human operator: the mo- bile robot performslocal navigation, sensing and mapping, while the operator interprets the sensor data and provides strategic navigation goals.}
}

@inproceedings{lincoln38630,
          volume = {2004},
          number = {3},
          author = {Elizabeth Sklar},
            note = {cited By 9},
           title = {A long-term approach to improving human-robot interaction: RoboCupJunior Rescue},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
           pages = {2321--2326},
            year = {2004},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38630/}
}

@inproceedings{lincoln38629,
          volume = {3},
           title = {SimEd: Simulating education as a multi agent system},
          author = {Elizabeth Sklar and M. Davies and M.S.T. Co},
            year = {2004},
           pages = {998--1005},
            note = {cited By 12},
         journal = {Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS 2004},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38629/}
}

@inproceedings{lincoln38626,
          volume = {1},
           title = {Learning while teaching robotics},
          author = {Elizabeth Sklar and A. Eguchi},
            year = {2004},
           pages = {102--105},
            note = {cited By 10},
         journal = {AAAI Spring Symposium - Technical Report},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38626/}
}

@inproceedings{lincoln38628,
          volume = {3},
           title = {Towards the application of argumentation-based dialogues for education},
          author = {Elizabeth Sklar and Simon Parsons},
            year = {2004},
           pages = {1420--1421},
            note = {cited By 13},
         journal = {Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS 2004},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38628/}
}

@inproceedings{lincoln38503,
          volume = {3020},
           title = {RoboCup in higher education: A preliminary report},
          author = {Elizabeth Sklar and Simon Parsons and P. Stone},
            year = {2004},
           pages = {296--307},
            note = {cited By 2},
         journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38503/}
}

@article{lincoln38502,
          volume = {4},
          number = {2},
          author = {Elizabeth Sklar and Simon Parsons and P. Stone},
            note = {cited By 17},
           title = {Using RoboCup in University-Level Computer Science Education},
            year = {2004},
         journal = {ACM Journal on Educational Resources in Computing},
             doi = {10.1145/1071620.1071624},
           pages = {4},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38502/}
}

@inproceedings{lincoln29846,
          volume = {1},
           month = {October},
          author = {A. Lilienthal and T. Duckett},
       booktitle = {Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453)},
           title = {Creating gas concentration gridmaps with a mobile robot},
       publisher = {IEEE},
            year = {2003},
             doi = {10.1109/IROS.2003.1250615},
           pages = {118--123},
        keywords = {ARRAY(0x5568fb678ac0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29846/},
        abstract = {This paper addresses the problem of mapping the features of a gas distribution by creating concentration gridmaps
from the data collected by a mobile robot equipped with an electronic nose. By contrast to metric gridmaps extracted
from sonar or laser range scans, a single measurement of the electronic nose provides information about a comparatively small area. To overcome this problem, a mapping technique is introduced that uses a Gaussian density function to model the decreasing likelihood that a particular reading represents the true concentration with respect to
the distance from the point of measurement. This method is evaluated in terms of its suitability regarding the slow
response and recovery of the gas sensors. The stability of the mapped features and the capability to use concentration
gridmaps to locate a gas source are also discussed.}
}

@inproceedings{lincoln29845,
          volume = {1},
           month = {September},
          author = {Tom Duckett},
       booktitle = {2003 IEEE International Conference on Robotics and Automation (Cat. No.03CH37422)},
           title = {A genetic algorithm for simultaneous localization and mapping},
       publisher = {IEEE},
            year = {2003},
             doi = {10.1109/ROBOT.2003.1241633},
           pages = {434--439},
        keywords = {ARRAY(0x5568fbba9f58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29845/},
        abstract = {This paper addresses the problem of simultaneous localization and mapping (SLAM) by a mobile robot. The SLAM problem is defined as a global optimization problem in which the objective is to search the space of possible robot maps. A genetic algorithm is described for solving this problem, in which a population of candidate solutions is progressively refined in order to find a globally optimal solution. The fitness values in the genetic algorithm are obtained with a heuristic function that measures the consistency and compactness of the candidate maps. The results show that the maps obtained are very accurate, though the approach is computationally expensive. Directions for future research are also discussed.}
}

@article{lincoln38641,
          volume = {24},
          number = {2},
          author = {M. Asada and O. Obst and D. Polani and B. Browning and A. Bonarini and M. Fujita and T. Christaller and T. Takahashi and S. Tadokoro and Elizabeth Sklar and G.A. Kaminka},
            note = {cited By 14},
           title = {An overview of RoboCup-2002 Fukuoka/Busan},
         journal = {AI Magazine},
           pages = {21--40},
            year = {2003},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38641/}
}

@inproceedings{lincoln12823,
       booktitle = {1st International Workshop on Robotic Sensing, 2003. ROSE' 03.},
           title = {A stereo electronic nose for a mobile inspection robot},
          author = {A. Lilienthal and T. Duckett},
       publisher = {IEEE},
            year = {2003},
           pages = {6},
             doi = {10.1109/ROSE.2003.1218709},
        keywords = {ARRAY(0x5568fba57748)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/12823/},
        abstract = {This paper describes the design of a gas-sensitive system ("mobile nose") that is suitable for use on a mobile robot. The stereo architecture comprises of two equivalent sets of gas sensors mounted inside separated ventilated tubes (or "nostrils"). To characterise the dynamic response, the whole system is modelled as a first-order sensor. The corresponding parameters, including the response and recovery time, can be obtained by fitting this model to the values recorded during a simple experiment described in this paper. Our experiments confirmed the suitability of the applied model and permitted a quantitative comparison of different set-ups. It is shown that using suction fans lowers the recovery time of the metal oxide gas sensors by a factor of two, while a solid separation between the tubes ("septum") is necessary to maintain the sensitivity of the mobile nose to concentration gradients.}
}

@inproceedings{lincoln13442,
       booktitle = {First European Conference on Mobile Robots (ECMR 2003},
           title = {Gas source localisation by constructing concentration gridmaps with a mobile robot},
          author = {Achim Lilienthal and Tom Duckett},
            year = {2003},
         journal = {Proceedings of the European Conference on Mobile Robots (ECMR 2003)},
        keywords = {ARRAY(0x5568fb9b8438)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/13442/},
        abstract = {This paper addresses the problem of mapping the features of a gas distribution by creating concentration gridmaps with a mobile robot equipped with a gas-sensitive system ("mobile nose"). By contrast to metric gridmaps extracted from sonar or laser range scans, a gas sensor measurement provides information about a comparatively small area. To overcome this problem, a mapping technique is introduced that uses a Gaussian density function to model the decreasing likelihood that a particular reading represents the true concentration with respect to the distance from the point of measurement. The structure of the mapped features is discussed with respect to the parameters of the applied density function, the evolution of the gas distribution over time, and the capability to locate a gas source.}
}

@inproceedings{lincoln38639,
          volume = {2},
           title = {Applying Genetic Programming to Economic Mechanism Design: Evolving a Pricing Rule for a Continuous Double Auction},
          author = {S. Phelps and P. McBurney and Simon Parsons and Elizabeth Sklar},
            year = {2003},
           pages = {1096--1097},
            note = {cited By 5},
         journal = {Proceedings of the Interantional Conference on Autonomous Agents},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38639/}
}

@inproceedings{lincoln37409,
          author = {C. Saaj and B. Bandyopadhyay},
            note = {cited By 0},
       booktitle = {2003 European Control Conference (ECC)},
           title = {Discrete sliding mode control using fast output sampling feedback},
       publisher = {IEEE},
            year = {2003},
         journal = {European Control Conference, ECC 2003},
             doi = {10.23919/ECC.2003.7085076},
           pages = {922--926},
        keywords = {ARRAY(0x5568fbb44868)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37409/},
        abstract = {In this paper a new algorithm for discrete-time sliding mode control using only output samples is proposed. It is shown that the output feedback gain can be directly obtained using the reaching law of discrete-time sliding mode control. The main contribution of this work is that instead of using the system states, the output samples are used for designing the controller.}
}

@article{lincoln37408,
          volume = {76},
          number = {13},
          author = {C. Saaj and B. Bandyopadhyay},
            note = {cited By 5},
           title = {Variable structure model following controller using non-dynamic multirate output feedback},
       publisher = {Taylor \& Francis},
            year = {2003},
         journal = {International Journal of Control},
             doi = {10.1080/0020717031000147502},
           pages = {1263--1271},
        keywords = {ARRAY(0x5568fbacc3b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37408/},
        abstract = {The paper presents a new algorithm for a variable structure model following controller (VSMFC) design for discrete time systems using a fast output sampling technique. The reaching law approach is used to guarantee the sliding mode motion. This methodology is easy to implement since the method is based on output feedback. It is shown that the proposed fast output sampling variable structure model following controller (FOS VSMFC) gives the same results as obtained by state feedback VSMFC. To demonstrate the design technique a VSMFC is designed for the tip position control of a single flexible link. The simulation results show the effectiveness of the proposed method.}
}

@inproceedings{lincoln38637,
          volume = {2},
           title = {Agents for Education: When too Much Intelligence is a Bad Thing},
          author = {Elizabeth Sklar},
            year = {2003},
           pages = {1118--1119},
            note = {cited By 10},
         journal = {Proceedings of the Interantional Conference on Autonomous Agents},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38637/}
}

@inproceedings{lincoln38636,
          volume = {2752},
           title = {RoboCupJunior 2002: The state of the league},
          author = {Elizabeth Sklar},
            year = {2003},
           pages = {489--495},
            note = {cited By 1},
         journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38636/}
}

@inproceedings{lincoln38638,
          volume = {2752},
           title = {RoboCupJunior: Learning with educational robotics},
          author = {Elizabeth Sklar and A. Eguchi and J. Johnson},
            year = {2003},
           pages = {238--253},
            note = {cited By 19},
         journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38638/}
}

@article{lincoln37410,
          volume = {149},
          number = {6},
           month = {November},
          author = {B. Bandyopadhyay and C. Saaj},
            note = {cited By 17},
           title = {Algorithm on robust sliding mode control for discrete-time system using fast output sampling feedback},
       publisher = {IEEE},
            year = {2002},
         journal = {IEE Proceedings: Control Theory and Applications},
             doi = {10.1049/ip-cta:20020703},
           pages = {497--503},
        keywords = {ARRAY(0x5568fba72100)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37410/},
        abstract = {A robust fast output sampling sliding mode control (FOSSMC) method for discrete-time systems with uncertainty is presented. Recently a FOSSMC was designed for a constant discrete-time system, however, this control law does not ensure the robustness of the system to parameter uncertainty and external disturbances. The authors present a FOSSMC that for known parameter variations and external disturbances does guarantee the robustness of the sliding mode motion.}
}

@inproceedings{lincoln28023,
       booktitle = {Second Swedish Workshop on Autonomous Robotics},
           month = {September},
           title = {Reactive localisation of an odour source by a learning mobile robot},
          author = {Ahmed Mohamod Farah and Tom Duckett},
            year = {2002},
        keywords = {ARRAY(0x5568fbacc5f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28023/},
        abstract = {The goal of this work was to enable a mobile robot to navigate autonomously towards a stationary odour source with the help of a sense of smell. Two electronic noses, each containing a set of gas sensors, mounted on top of a Koala mobile robot were used for detection of the odour. The sensing strategy used for data collection was investigated in order to reduce the influence of air turbulences on the sample handling process. Then a multi-layer artificial neural network was used to learn both the direction to the source and the required turning speed of the robot. An experimental validation was carried out to evaluate the performance of the complete system.}
}

@inproceedings{lincoln39660,
       booktitle = {Proc. 7th IEEE International Workshop on Variable Structure Systems},
           month = {July},
           title = {Discrete Sliding Mode Control by Non-Dynamic Multirate Output Feedback},
          author = {B. Bandyopadhyay and C.M. Saaj},
            year = {2002},
           pages = {145--152},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39660/}
}

@article{lincoln37425,
          volume = {49},
          number = {3},
           month = {June},
          author = {C. Saaj and B. Bandyopadhyay and H. Unbehauen},
            note = {cited By 90},
           title = {A new algorithm for discrete-time sliding-mode control using fast output sampling feedback},
       publisher = {IEEE},
            year = {2002},
         journal = {IEEE Transactions on Industrial Electronics},
             doi = {10.1109/TIE.2002.1005376},
           pages = {518--523},
        keywords = {ARRAY(0x5568fbab24f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37425/},
        abstract = {This paper presents a new approach for sliding-mode control (SMC) of discrete-time systems using the reaching law approach together with the fast output sampling (FOS) feedback technique. This method does not need the system states for feedback as it makes use of only the output samples for designing the controller. Thus, this methodology is more practical and easy to implement. A numerical example demonstrates the design technique. Simulation results show that the proposed FOS SMC technique produces the same results as obtained by state feedback SMC technique.}
}

@article{lincoln1207,
          volume = {12},
          number = {3},
           month = {May},
          author = {Tom Duckett and S. Marsland and J. Shapiro},
            note = {To navigate in unknown environments, mobile robots require the ability to build their own maps. A major problem for robot map building is that odometry-based dead reckoning cannot be used to assign accurate global position information to a map because of cumulative drift errors. This paper introduces a fast, on-line algorithm for learning geometrically consistent maps using only local metric information. The algorithm works by using a relaxation technique to minimize an energy function over many small steps. The approach differs from previous work in that it is computationally cheap, easy to implement and is proven to converge to a globally optimal solution. Experiments are presented in which large, complex environments were successfully mapped by a real robot.},
       booktitle = {Robotics: Science and Systems 2005 Massachusetts Institute of Technology, Cambridge, Massachusetts},
           title = {Fast, on-line learning of globally consistent maps},
            year = {2002},
         journal = {Autonomous Robots},
             doi = {10.1023/A\%3A1015269615729},
           pages = {287--300},
        keywords = {ARRAY(0x5568fbbc4370)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/1207/},
        abstract = {To navigate in unknown environments, mobile robots require the ability to build their own maps. A major problem for robot map building is that odometry-based dead reckoning cannot be used to assign accurate global position information to a map because of cumulative drift errors. This paper introduces a fast, on-line algorithm for learning geometrically consistent maps using only local metric information. The algorithm works by using a relaxation technique to minimize an energy function over many small steps. The approach differs from previous work in that it is computationally cheap, easy to implement and is proven to converge to a globally optimal solution. Experiments are presented in which large, complex environments were successfully mapped by a real robot.}
}

@article{lincoln38505,
          volume = {2333 L},
           title = {Agent dialogues with conflicting preferences},
          author = {L. Amgoud and Simon Parsons},
            year = {2002},
           pages = {190--205},
            note = {cited By 16},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38505/}
}

@article{lincoln38504,
          volume = {2424 L},
          author = {L. Amgoud and Simon Parsons},
            note = {cited By 11},
           title = {An argumentation framework for merging conflicting knowledge bases},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/3-540-45757-7-3},
           pages = {27--37},
            year = {2002},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38504/}
}

@article{lincoln38507,
          volume = {2403},
           title = {Agent specification using multi-context systems},
          author = {Simon Parsons and N.R. Jennings and J. Sabater and C. Sierra},
            year = {2002},
           pages = {205--226},
            note = {cited By 11},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38507/}
}

@article{lincoln38508,
          volume = {2531},
           title = {Co-evolutionary auction mechanism design: A preliminary report},
          author = {S. Phelps and P. McBurney and Simon Parsons and Elizabeth Sklar},
            year = {2002},
           pages = {123--142},
            note = {cited By 29},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38508/}
}

@inproceedings{lincoln37411,
          volume = {15},
          number = {1},
          author = {C. Saaj and B. Bandyopadhyay},
            note = {cited By 1},
       booktitle = {15th IFAC World Congress on Automatic Control},
           title = {Output feedback sliding mode control for MIMO discrete time systems},
       publisher = {Elsevier},
            year = {2002},
         journal = {IFAC Proceedings Volumes (IFAC-PapersOnline)},
             doi = {10.3182/20020721-6-ES-1901.01076},
           pages = {31--35},
        keywords = {ARRAY(0x5568fbb6ccc0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37411/},
        abstract = {In this paper we present a new algorithm for discrete sliding mode control of linear multivariable systems using fast output sampling feedback. Here we make use of a single switching surface regardless of the number of inputs. The main contribution of this work is that instead of using the system states, the output samples are used for designing the controller. Numerical example demonstrates the design technique.}
}

@article{lincoln38506,
          volume = {2403},
           title = {On partially observable MDPs and BDI models},
          author = {M. Schut and M. Wooldridge and Simon Parsons},
            year = {2002},
           pages = {243--259},
            note = {cited By 13},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38506/}
}

@article{lincoln38509,
          volume = {2222},
          author = {W. Vasconcelos and D. Robertson and J. Agust{\'i} and C. Sierra and M. Wooldridge and Simon Parsons and C. Walton and J. Sabater},
            note = {cited By 10},
           title = {A lifecycle for models of large multi-agent Systems},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/3-540-70657-7},
           pages = {297--317},
            year = {2002},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38509/}
}

@inproceedings{lincoln39661,
       booktitle = {Int. Conf. on Control, Instrumentation and Information Communication},
           month = {December},
           title = {A New Three Level Output Feedback Sliding Mode Control For Discrete System},
          author = {B. Bandyopadhyay and C.M. Saaj},
            year = {2001},
           pages = {13--17},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39661/}
}

@phdthesis{lincoln6748,
           month = {July},
           title = {Objektbezogene 3D-Erkennung automatisch generierter Konturmodelle in Intensit{\"a}tsbildern},
          school = {Universitat Bielefeld},
          author = {Marc Hanheide},
            year = {2001},
            note = {Abstract},
        keywords = {ARRAY(0x5568fba5f2a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/6748/},
        abstract = {Abstract}
}

@inproceedings{lincoln28663,
          volume = {4},
           month = {May},
          author = {T. Duckett and M. Axelsson and A. Saffiotti},
       booktitle = {Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164)},
           title = {Learning to locate an odour source with a mobile robot},
       publisher = {IEEE},
            year = {2001},
             doi = {10.1109/ROBOT.2001.933245},
           pages = {4017--4022},
        keywords = {ARRAY(0x5568fba74dd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28663/},
        abstract = {We address the problem of enabling a mobile robot to locate a stationary odour source using an electronic nose constructed from gas sensors. On the hardware side, we use a stereo nose architecture consisting of two parallel chambers, each containing an identical set of sensors. On the software side, we use a recurrent artificial neural network to learn the direction to a stationary source from a time series of sensor readings. This contrasts with previous approaches, that rely on the existence of a model of the sensor's dynamics. The complete system is able to orient and turn towards the source. An experimental validation was carried out to evaluate the performance of the system.}
}

@article{lincoln38513,
          volume = {2253},
           title = {Chance discovery using dialectical argumentation},
          author = {P. McBurney and Simon Parsons},
            year = {2001},
           pages = {414--424},
            note = {cited By 33},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38513/}
}

@article{lincoln38514,
          volume = {10},
          number = {1},
          author = {P. McBurney and Simon Parsons},
            note = {cited By 12},
           title = {Intelligent systems to support deliberative democracy in environmental regulation},
            year = {2001},
         journal = {Information and Communications Technology Law},
             doi = {10.1080/13600830123217},
           pages = {79--89},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38514/}
}

@inproceedings{lincoln38510,
           title = {Context-specific sign-propagation in qualitative probabilistic networks},
          author = {S. Renooij and Simon Parsons and L.C. Van Der Gaag},
            year = {2001},
           pages = {667--672},
            note = {cited By 3},
         journal = {IJCAI International Joint Conference on Artificial Intelligence},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38510/}
}

@article{lincoln37412,
          volume = {27},
          number = {3},
          author = { Saaj and B. Bandyopadhyay},
            note = {cited By 2},
           title = {Discrete output feedback Sliding Mode Control of second order Systems - A moving switching line approach},
         journal = {Systems Science},
           pages = {20--21},
            year = {2001},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37412/},
        abstract = {In this paper a new algorithm for discrete-time sliding mode control using only output samples is proposed. It is shown that the output feedback gain can be directly obtained using the reaching law of discrete-time sliding mode control. The main contribution of this work is that instead of using the system states, the output samples are used for designing the controller.}
}

@article{lincoln38515,
          volume = {2143},
           title = {Reasoning about intentions in uncertain domains},
          author = {M. Schut and M. Wooldridge and Simon Parsons},
            year = {2001},
           pages = {84--95},
            note = {cited By 13},
         journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38515/}
}

@inproceedings{lincoln38512,
          volume = {2143},
           title = {Argumentation and qualitative probabilistic reasoning using the kappa calculus},
          author = {V. Tamma and Simon Parsons},
            year = {2001},
           pages = {680--691},
            note = {cited By 2},
         journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38512/}
}

@article{lincoln38511,
          volume = {2003},
           title = {Issues in the design of negotiation protocols for logic-based agent communication languages},
          author = {M. Wooldridge and Simon Parsons},
            year = {2001},
           pages = {70--83},
            note = {cited By 3},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38511/}
}

@inproceedings{lincoln28033,
       booktitle = {Seventeenth National Conference on Artificial Intelligence (AAAI 2000)},
           month = {July},
           title = {Performance comparison of landmark recognition systems for navigating mobile robots},
          author = {Tom Duckett and Ulrich Nehmzow},
       publisher = {AAAI Press},
            year = {2000},
           pages = {826--831},
        keywords = {ARRAY(0x5568fbb6dd38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28033/},
        abstract = {Self-localisation is an essential competence for mobile robot navigation. Due to the fundamental unreliability of dead reckoning, a robot must depend on its perception of external environmental features or landmarks to localise itself. A key question is how to evaluate landmark recognition systems for mobile robots. This paper answers this question by means of quantitative performance measures. An empirical study is presented in which a number of algorithms are
compared in four environments. The results of this analysis are then applied to the development of a novel landmark recognition system for a Nomad{\texttt{\char126}}200 robot. Subsequent experiments demonstrate that the new system obtains a similar level of performance to the best alternative method, but at a much lower computational cost.}
}

@inproceedings{lincoln28666,
          volume = {4},
           month = {April},
          author = {T. Duckett and S. Marsland and J. Shapiro},
       booktitle = {Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065)},
           title = {Learning globally consistent maps by relaxation},
       publisher = {IEEE},
            year = {2000},
             doi = {10.1109/ROBOT.2000.845330},
           pages = {3841--3846},
        keywords = {ARRAY(0x5568fb9e7f28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28666/},
        abstract = {Mobile robots require the ability to build their own maps to operate in unknown environments. A fundamental problem is that odometry-based dead reckoning cannot be used to assign accurate global position information to a map because of drift errors caused by wheel slippage. The paper introduces a fast, online method of learning globally consistent maps, using only local metric information. The approach differs from previous work in that it is computationally cheap, easy to implement and is guaranteed to find a globally optimal solution. Experiments are presented in which large, complex environments were successfully mapped by a real robot, and quantitative performance measures are used to assess the quality of the maps obtained.}
}

@inproceedings{lincoln38516,
           title = {Modelling dialogues using argumentation},
          author = {L. Amgoud and N. Maudet and Simon Parsons},
            year = {2000},
           pages = {31--38},
             doi = {10.1109/ICMAS.2000.858428},
            note = {cited By 190},
         journal = {Proceedings - 4th International Conference on MultiAgent Systems, ICMAS 2000},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38516/}
}

@article{lincoln38517,
          volume = {1757},
           title = {Using multi-context systems to engineer executable agents},
          author = {J. Sabater and C. Sierra and Simon Parsons and N.R. Jennings},
            year = {2000},
           pages = {260--276},
            note = {cited By 6},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38517/}
}

@article{lincoln38643,
          volume = {3},
          number = {3},
          author = {Elizabeth Sklar and J. Pollack},
            note = {cited By 8},
           title = {A framework for enabling an internet learning community},
         journal = {Educational Technology and Society},
           pages = {393--408},
            year = {2000},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38643/}
}

@inproceedings{lincoln28032,
           month = {November},
          author = {Tom Duckett and Ulrich Nehmzow},
       booktitle = {IEEE International Symposium on Computational Intelligence in Robotics and Automation, CIRA '99.},
           title = {Exploration of unknown environments using a compass, topological map and neural network},
       publisher = {IEEE},
             doi = {10.1109/CIRA.1999.810067},
           pages = {312--317},
            year = {1999},
        keywords = {ARRAY(0x5568fbae9298)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28032/},
        abstract = {This paper addresses the problem of autonomous exploration and mapping of unknown environments by a mobile
robot. A map-based exploration system is presented, in which a topological map of the environment is acquired incrementally by the robot, using an artificial neural network to detect new areas of unexplored territory. Using
this approach, no manual intervention in the map acquisition process is required, and all computation is carried
out in real-time on board the robot. Experiments are presented in which a Nomad 200 robot successfully mapped
and navigated complex, real world environments containing transient changes such as moving people.}
}

@inproceedings{lincoln38644,
          volume = {1},
          author = {A.D. Blair and Elizabeth Sklar},
            note = {cited By 2},
           title = {Exploring evolutionary learning in a simulated hockey environment},
         journal = {Proceedings of the 1999 Congress on Evolutionary Computation, CEC 1999},
             doi = {10.1109/CEC.1999.781926},
           pages = {197--203},
            year = {1999},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38644/}
}

@article{lincoln38521,
          volume = {1638},
           title = {Connecting lexicographic with maximum entropy entailment},
          author = {R.A. Bourne and Simon Parsons},
            year = {1999},
           pages = {80--91},
            note = {cited By 2},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38521/}
}

@inproceedings{lincoln38518,
          volume = {1},
           title = {Maximum entropy and variable strength defaults},
          author = {R.A. Bourne and Simon Parsons},
            year = {1999},
           pages = {50--55},
            note = {cited By 17},
         journal = {IJCAI International Joint Conference on Artificial Intelligence},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38518/}
}

@inproceedings{lincoln38520,
          volume = {1638},
          author = {A. Hunter and Simon Parsons},
            note = {cited By 0},
       booktitle = {5th European Conference on Symbolic and Quantitative Approaches to Reasoning and Uncertainty, ECSQARU 1999},
           title = {Preface},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
           pages = {V--VI},
            year = {1999},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38520/}
}

@article{lincoln38522,
          volume = {1638},
           title = {Argumentation and qualitative decision making},
          author = {Simon Parsons and S. Green},
            year = {1999},
           pages = {328--339},
            note = {cited By 8},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38522/}
}

@article{lincoln38519,
          volume = {1555},
           title = {Intention reconsideration reconsidered},
          author = {M. Wooldridge and Simon Parsons},
            year = {1999},
           pages = {63--79},
            note = {cited By 28},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38519/}
}

@article{lincoln38523,
          volume = {1365},
           title = {A framework for argumentation-based negotiation},
          author = {C. Sierra and N.R. Jennings and P. Noriega and Simon Parsons},
            year = {1998},
           pages = {177--192},
            note = {cited By 136},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38523/}
}

@article{lincoln38524,
          volume = {1244},
           title = {Normative argumentation and qualitative probability},
          author = {Simon Parsons},
            year = {1997},
           pages = {466--480},
            note = {cited By 13},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38524/}
}

@article{lincoln38526,
          volume = {3},
           title = {Softening constraints in constraint-based protein topology prediction},
          author = {Simon Parsons},
            year = {1995},
           pages = {268--276},
            note = {cited By 2},
         journal = {Proceedings / ... International Conference on Intelligent Systems for Molecular Biology ; ISMB. International Conference on Intelligent Systems for Molecular Biology},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38526/}
}

@article{lincoln38525,
          volume = {946},
           title = {Using qualitative uncertainty in protein topology prediction},
          author = {Simon Parsons},
            year = {1995},
           pages = {337--343},
            note = {cited By 0},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38525/}
}

@article{lincoln38528,
          volume = {7},
          number = {2},
          author = {Simon Parsons and M. Kubat and M. Dohnal},
            note = {cited By 14},
           title = {A rough set approach to reasoning under uncertainty},
            year = {1995},
         journal = {Journal of Experimental and Theoretical Artificial Intelligence},
             doi = {10.1080/09528139508953805},
           pages = {175--193},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38528/}
}

@article{lincoln38527,
          volume = {10},
          number = {1},
          author = {Simon Parsons and A. Saffiotti},
            note = {cited By 0},
           title = {Information processing and the management of uncertainty},
            year = {1995},
         journal = {The Knowledge Engineering Review},
             doi = {10.1017/S0269888900007311},
           pages = {83--88},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38527/}
}

@article{lincoln38530,
          volume = {2},
           title = {Prototyping a genetics deductive database},
          author = {C. Hearne and Z. Cui and S. Parsons and S. Hajnal},
            year = {1994},
           pages = {170--178},
            note = {cited By 1},
         journal = {Proceedings / ... International Conference on Intelligent Systems for Molecular Biology ; ISMB. International Conference on Intelligent Systems for Molecular Biology},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38530/},
        abstract = {We are developing a laboratory notebook system known as the Genetics Deductive Database. Currently our prototype provides storage for biological facts and rules with flexible access via an interactive graphical display. We have introduced a formal basis for the representation and reasoning necessary to order genome map data and handle the uncertainty inherent in biological data. We aim to support laboratory activities by introducing an experiment planner into our prototype. The Genetics Deductive Database is built using new database technology which provides an object-oriented conceptual model, a declarative rule language, and a procedural update language. This combination of features allows the implementation of consistency maintenance, automated reasoning, and data verification.}
}

@article{lincoln38529,
          volume = {9},
          number = {5},
          author = {A. Saffiotti and E. Umkehrer and S. Parsons},
            note = {cited By 0},
           title = {Comparing Uncertainty Management Techniques},
            year = {1994},
         journal = {Computer?Aided Civil and Infrastructure Engineering},
             doi = {10.1111/j.1467-8667.1994.tb00344.x},
           pages = {367--383},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38529/},
        abstract = {Several formalisms for representing and reasoning with uncertain knowledge have been proposed in the artificial intelligence literature. Unfortunately, analyses of the adequacy of each formalism to different types of problems have seldom appeared, and designers are often forced to make arbitrary choices about how to model uncertainty in their domain. In this paper, we present an experimental approach to comparing uncertainty management techniques in the light of a specific problem to solve. We model a problem tailored on a real?world application using three major techniques, namely, probability theory, Dempster?Shafer's theory, and possibility theory, and discuss the results. We also propose a new qualitative way of analyzing the behavior of the three techniques that highlights some interesting assumptions. The experiment has been performed using PULCINELLA, a tool for propagating uncertainty based on the local computation technique of Shafer and Shenoy that can be specialized to each of our target uncertainty formalisms.}
}

@article{lincoln38534,
          volume = {32},
          number = {2},
          author = {M. Dohnal and M. Starzak and M. Kerkovsky and J. Dohnalova and J. Vystrcil and R. Koivisto and M. Pokorny and M. Vanis and S. Parsons},
            note = {cited By 6},
           title = {A fuzzy upgrading of integrated vague managerial and engineering knowledge},
            year = {1993},
         journal = {International Journal of Production Economics},
             doi = {10.1016/0925-5273(93)90069-W},
           pages = {209--228},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38534/},
        abstract = {In reality it is not possible to separate managerial and engineering knowledge without a considerable information loss. Realistic integrated conventional managerial/engineering files are rather vague and very sparse. They are not suitable for direct applications of fuzzy reasoning algorithms. A fuzzy upgrading is a retrospective application of the knowledge of engineering methods and integration of large set of specific and rather isolated detailed information items. Any upgrading is highly subjective and ad hoc in nature. The upgrading objectivity can be increased by a set of upgrading algorithms. Two of them (discriminative power evaluation and fractal analysis) are described. The fractal analysis gives a trade-off between general and specific knowledge items and is presented separately as Appendix. A case study (an upgrading of sugar-cane-plant knowledge base) is presented.}
}

@article{lincoln38531,
          volume = {20},
          number = {4},
          author = {M. Hurme and M. J{\"a}rvel{\"a}inen and S. Parsons and M. Dohnal},
            note = {cited By 8},
           title = {A qualitative commonsense method for optimization of complex engineering systems},
            year = {1993},
         journal = {Engineering Optimization},
             doi = {10.1080/03052159308941288},
           pages = {323--339},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38531/},
        abstract = {A commonsense approach to optimization is needed especially during the early stages of research and design projects. A qualitative interpretation of classical optimization is used to formalize and systematize commonsense. The qualitative algebra can use only three different values ( + 0, ?). The degradation of conventional models (objective functions, constraints) eliminates the need for numerical values of constants. The result of qualitative optimization is a list of all possible behaviours (scenarios). Therefore the complete list of all possible ways of increasing or decreasing objective functions are identified. Two problems, the linear optimization of safety improvements and the nonlinear optimization of anaerobic fermentation are presented}
}

@inproceedings{lincoln38533,
          volume = {1},
           title = {Blackboard-based decision support system for the configuration of telecommunications services},
          author = {Simon Parsons and T. Brown and T. Chau and E.H. Mamdani},
            year = {1993},
           pages = {537--550},
            note = {cited By 0},
         journal = {Applications of Artificial Intelligence in Engineering},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38533/}
}

@article{lincoln38532,
          volume = {747 LN},
           title = {Integrating uncertainty handling formalisms in distributed artificial intelligence},
          author = {Simon Parsons and A. Saffiotti},
            year = {1993},
           pages = {304--309},
            note = {cited By 1},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38532/}
}

@inproceedings{lincoln38535,
           title = {A robust logic for rule-based reasoning under uncertainty},
          author = {Simon Parsons and M. Kubat and M. Dohnal},
            year = {1992},
           pages = {119--120},
             doi = {10.1109/CMPEUR.1992.218473},
            note = {cited By 1},
         journal = {Proceedings - Computer Systems and Software Engineering: 6th Annual European Computer Conference, CompEuro 1992},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38535/}
}

@article{lincoln38536,
          volume = {548 LN},
           title = {Advance prototyping},
          author = {Simon Parsons},
            year = {1991},
           pages = {86--90},
             doi = {10.1007/3-5},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38536/}
}

@article{lincoln38645,
           title = {Co-evolution, determinism and robustness},
          author = {A.D. Blair and Elizabeth Sklar and P. Funes},
         journal = {Lecture Notes in Computer Science (including s},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38645/}
}

@inproceedings{lincoln39648,
       booktitle = {11th Symposium on Advanced Space Technologies in Robotics and Automation},
           title = {Model based system engineering for space robotic systems},
          author = {S. Chhaniyara and C. Saaj and B. Maediger and M. Althoff-Kotzias and I. Ahrns},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39648/}
}

@article{lincoln53193,
           title = {Attention and Prediction-Guided Motion Detection for Low-Contrast Small Moving Targets},
          author = {Hongxin Wang and Jiannan Zhao and Huatian Wang and Cheng Hu and Jigen Peng and Shigang Yue},
       publisher = {IEEE},
             doi = {10.1109/TCYB.2022.3170699},
         journal = {IEEE Transactions on Cybernetics},
        keywords = {ARRAY(0x5568fba492a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53193/},
        abstract = {Small target motion detection within complex natural environments is an extremely challenging task for autonomous robots. Surprisingly, the visual systems of insects have evolved to be highly efficient in detecting mates and tracking prey, even though targets occupy as small as a few degrees of their visual fields. The excellent sensitivity to small target motion relies on a class of specialized neurons called small target motion detectors (STMDs). However, existing STMD-based models are heavily
dependent on visual contrast and perform poorly in complex natural environments where small targets generally exhibit extremely low contrast against neighbouring backgrounds. In this
paper, we develop an attention and prediction guided visual system to overcome this limitation. The developed visual system comprises three main subsystems, namely, an attention module, an STMD-based neural network, and a prediction module. The attention module searches for potential small targets in the predicted areas of the input image and enhances their contrast against complex background. The STMD-based neural network receives the contrast-enhanced image and discriminates small moving targets from background false positives. The prediction module foresees future positions of the detected targets and generates a prediction map for the attention module. The three subsystems are connected in a recurrent architecture allowing information to be processed sequentially to activate specific areas for small target detection. Extensive experiments on synthetic and real-world datasets demonstrate the effectiveness and superiority of the proposed visual system for detecting small, low-contrast moving targets against complex natural environments.}
}

