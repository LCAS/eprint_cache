@article{lincoln37397,
          volume = {33},
          number = {6},
           month = {December},
          author = {F.J. Comin and C. M. Saaj},
            note = {cited By 0},
           title = {Models for slip estimation and soft terrain characterization with multilegged wheel-legs},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Transactions on Robotics},
             doi = {10.1109/TRO.2017.2723904},
           pages = {1438--1452},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37397/},
        abstract = {Successful operation of off-road mobile robots faces the challenge of mobility hazards posed by soft, deformable terrain, e.g., sand traps. The slip caused by these hazards has a significant impact on tractive efficiency, leading to complete immobilization in extreme circumstances. This paper addresses the interaction between dry frictional soil and the multilegged wheel-leg concept, with the aim of exploiting its enhanced mobility for safe, in situ terrain sensing. The influence of multiple legs and different foot designs on wheel-leg-soil interaction is analyzed by incorporating these aspects to an existing terradynamics model. In addition, new theoretical models are proposed and experimentally validated to relate wheel-leg slip to both motor torque and stick-slip vibrations. These models, which are capable of estimating wheel-leg slip from purely proprioceptive sensors, are then applied in combination with detected wheel-leg sinkage to successfully characterize the load bearing and shear strength properties of different types of deformable soil. The main contribution of this paper enables nongeometric hazard detection based on detected wheel-leg slip and sinkage.}
}

@article{lincoln33057,
          volume = {4},
          number = {1},
           month = {December},
          author = {Khaled Goher and Abdullah Almeshal and Saad Agouri and Ahmed Nasir and Osman Tokhi and Mohamed Alenizi and Talal Alzanki and Sulaiman Fadlallah},
            note = {This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.},
           title = {Hybrid spiral-dynamic bacteria-chemotaxis algorithm with application to control two-wheeled machines},
       publisher = {Springer},
            year = {2017},
         journal = {Robotics and Biomimetics},
             doi = {10.1186/s40638-017-0059-1},
           pages = {3},
        keywords = {ARRAY(0x5649bb256048)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33057/},
        abstract = {This paper presents the implementation of the hybrid spiral-dynamic bacteria-chemotaxis (HSDBC) approach to control two different configurations of a two-wheeled vehicle. The HSDBC is a combination of bacterial chemotaxis used in bacterial forging algorithm (BFA) and the spiral-dynamic algorithm (SDA). BFA provides a good exploration strategy due to the chemotaxis approach. However, it endures an oscillation problem near the end of the search process when using a large step size. Conversely; for a small step size, it affords better exploitation and accuracy with slower convergence. SDA provides better stability when approaching an optimum point and has faster convergence speed. This may cause the search agents to get trapped into local optima which results in low accurate solution. HSDBC exploits the chemotactic strategy of BFA and fitness accuracy and convergence speed of SDA so as to overcome the problems associated with both the SDA and BFA algorithms alone. The HSDBC thus developed is evaluated in optimizing the performance and energy consumption of two highly nonlinear platforms, namely single and double inverted pendulum-like vehicles with an extended rod. Comparative results with BFA and SDA show that the proposed algorithm is able to result in better performance of the highly nonlinear systems.}
}

@article{lincoln27022,
          volume = {18},
          number = {12},
           month = {December},
          author = {Dongdong Wang and Xinwen Hou and Jiawei Xu and Shigang Yue and Cheng-Lin Liu},
           title = {Traffic sign detection using a cascade method with fast feature extraction and saliency test},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Transactions on Intelligent Transportation Systems},
             doi = {10.1109/tits.2017.2682181},
           pages = {3290--3302},
        keywords = {ARRAY(0x5649bb260b78)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27022/},
        abstract = {Automatic traffic sign detection is challenging due to the complexity of scene images, and fast detection is required in real applications such as driver assistance systems. In this paper, we propose a fast traffic sign detection method based on a cascade method with saliency test and neighboring scale awareness. In the cascade method, feature maps of several channels are extracted efficiently using approximation techniques. Sliding windows are pruned hierarchically using coarse-to-fine classifiers and the correlation between neighboring scales. The cascade system has only one free parameter, while the multiple thresholds are selected by a data-driven approach. To further increase speed, we also use a novel saliency test based on mid-level features to pre-prune background windows. Experiments on two public traffic sign data sets show that the proposed method achieves competing performance and runs 27 times as fast as most of the state-of-the-art methods.}
}

@article{lincoln28284,
          volume = {42},
          number = {4},
           month = {December},
          author = {Nina Dethlefs and Maarten Milders and Heriberto Cuay{\'a}huitl and Turkey Al-Salkini and Lorraine Douglas},
           title = {A natural language-based presentation of cognitive stimulation to people with dementia in assistive technology: a pilot study},
       publisher = {Taylor \& Francis: STM},
            year = {2017},
         journal = {Informatics for Health and Social Care},
             doi = {10.1080/17538157.2016.1255627},
           pages = {349--360},
        keywords = {ARRAY(0x5649bb001308)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28284/},
        abstract = {Currently, an estimated 36 million people worldwide are affected by Alzheimer?s disease or related dementias. In the absence of a cure, non-pharmacological interventions, such as cognitive stimulation, which slow down the rate of deterioration can benefit people with dementia and their caregivers. Such interventions have shown to improve well-being and slow down the rate of cognitive decline. It has further been shown that cognitive stimulation in interaction with a computer is as effective as with a human. However, the need to operate a computer often represents a difficulty for the elderly and stands in the way of widespread adoption. A possible solution to this obstacle is to provide a spoken natural language interface that allows people with dementia to interact with the cognitive stimulation software in the same way as they would interact with a human caregiver. This makes the assistive technology accessible to users regardless of their technical skills and provides a fully intuitive user experience. This article describes a pilot study that evaluated the feasibility of computer-based cognitive stimulation through a spoken natural language interface. Prototype software was evaluated with 23 users, including healthy elderly people and people with dementia. Feedback was overwhelmingly positive.}
}

@inproceedings{lincoln37349,
          volume = {694},
           month = {December},
          author = {Maria Teresa Lazaro and G. Grisetti and Luca Iocchi and Jaime Pulido Fentanes and Marc Hanheide},
       booktitle = {Iberian Robotics conference},
           title = {A Lightweight Navigation System for Mobile Robots},
             doi = {10.1007/978-3-319-70836-2\_25},
           pages = {295--306},
            year = {2017},
        keywords = {ARRAY(0x5649baff0138)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37349/},
        abstract = {{\copyright} Springer International Publishing AG 2018. In this paper, we describe a navigation system requiring very few computational resources, but still providing performance comparable with commonly used tools in the ROS universe. This lightweight navigation system is thus suitable for robots with low computational resources and provides interfaces for both ROS and NAOqi middlewares. We have successfully evaluated the software on different robots and in different situations, including SoftBank Pepper robot for RoboCup@Home SSPL competitions and on small home-made robots for RoboCup@Home Education workshops. The developed software is well documented and easy to understand. It is released open-source and as Debian package to facilitate ease of use, in particular for the young researchers participating in robotic competitions and for educational activities.}
}

@inproceedings{lincoln29946,
       booktitle = {UK-RAS Conference on Robotics and Autonomous Systems},
           month = {December},
           title = {Active human detection with a mobile robot},
          author = {Mohamed Heshmat and Manuel Fernandez-Carmona and Zhi Yan and Nicola Bellotto},
            year = {2017},
        keywords = {ARRAY(0x5649bb02f888)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29946/},
        abstract = {The problem of active human detection with a mobile robot equipped with an RGB-D camera is considered in this work. Traditional human detection algorithms for indoor mobile robots face several challenges, including occlusions due to cluttered dynamic environments, changing backgrounds, and large variety of human movements. Active human detection aims to improve classic detection systems by actively selecting new and potentially better observation points of the person. In this preliminary work, we present a system that actively guides a mobile robot towards high-confidence human detections, including initial simulation tests that highlight pros and cons of the proposed approach.}
}

@inproceedings{lincoln31053,
       booktitle = {UK-RAS Network Conference},
           month = {December},
           title = {Modelling and predicting rhythmic flow patterns in dynamic environments},
          author = {Sergi Molina Mellado and Grzegorz Cielniak and Tomas Krajnik and Tom Duckett},
            year = {2017},
        keywords = {ARRAY(0x5649bb15d070)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31053/},
        abstract = {In this paper, we introduce a time-dependent probabilistic map able to model and predict future flow patterns of people in indoor environments. The proposed representation models the likelihood of motion direction by a set of harmonic functions, which efficiently capture long-term (hours to months) variations of crowd movements over time, so from a robotics perspective, this model could be useful to add the predicted human behaviour into the control loop to influence the actions of the robot. Our approach is evaluated with data collected from a real environment and initial qualitative results are presented.}
}

@inproceedings{lincoln31547,
       booktitle = {UK-RAS Conference on Robotics and Autonomous Systems},
           month = {December},
           title = {Navigation testing for continuous integration in robotics},
          author = {Jaime Pulido Fentanes and Christian Dondrup and Marc Hanheide},
       publisher = {UK-RAS Conference on Robotics and Autonomous Systems (RAS 2017)},
            year = {2017},
        keywords = {ARRAY(0x5649bb0148f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31547/},
        abstract = {Robots working in real-world applications need to be robust and reliable. However, ensuring robust software in an academic development environment with dozens of developers poses a significant challenge. This work presents a testing framework, successfully employed in a large-scale integrated robotics project, based on continuous integration and the fork-and-pull model of software development, implementing automated system regression testing for robot navigation. It presents a framework suitable for both regression testing and also providing processes for parameter optimisation and benchmarking.}
}

@incollection{lincoln28879,
           month = {December},
          author = {Qinbing Fu and Shigang Yue},
            note = {{\copyright} 2017 IEEE},
       booktitle = {2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)},
           title = {Mimicking fly motion tracking and fixation behaviors with a hybrid visual neural network},
       publisher = {IEEE},
           pages = {1636--1641},
            year = {2017},
        keywords = {ARRAY(0x5649bb01c9e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28879/},
        abstract = {How do animals, e.g. insects, detect meaningful visual motion cues involving directional and locational information of moving objects in visual clutter accurately and efficiently? This open question has been very attractive for decades. In this paper, with respect to latest biological research progress made on motion detection circuitry, we conduct a novel hybrid visual neural network, combining the functionality of two bio-plausible, namely motion and position pathways explored in fly visual system, for mimicking the tracking and fixation behaviors. This modeling study extends a former direction selective neurons model to the higher level of behavior. The motivated algorithms can be used to guide a system that extracts location information on moving objects in a scene regardless of background clutter, using entirely low-level visual processing. We tested it against translational movements in synthetic and real-world scenes. The results demonstrated the following contributions: (1) Compared to conventional computer vision techniques, it turns out the computational simplicity of this model may benefit the utility in small robots for real time fixating. (2) The hybrid neural network structure fulfills the characteristics of a putative signal tuning map in physiology. (3) It also satisfies with a profound implication proposed by biologists: visual fixation behaviors could be simply tuned via only the position pathway; nevertheless, the motion-detecting pathway enhances the tracking precision.}
}

@article{lincoln29511,
          volume = {13},
          number = {2},
           month = {December},
          author = {Claire Keeble and Peter Adam Thwaites and Stuart Barber and Graham Richard Law and Paul David Baxter},
           title = {Adaptation of chain event graphs for use with case-Control studies in epidemiology},
       publisher = {De Gruyter},
            year = {2017},
         journal = {The International Journal of Biostatistics},
             doi = {10.1515/ijb-2016-0073},
        keywords = {ARRAY(0x5649baf9dce0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29511/},
        abstract = {Case-control studies are used in epidemiology to try to uncover the causes of diseases, but are a retrospective study design known to suffer from non-participation and recall bias, which may explain their decreased popularity in recent years. Traditional analyses report usually only the odds ratio for given exposures and the binary disease status. Chain event graphs are a graphical representation of a statistical model derived from event trees which have been developed in artificial intelligence and statistics, and only recently introduced to the epidemiology literature. They are a modern Bayesian technique which enable prior knowledge to be incorporated into the data analysis using the agglomerative hierarchical clustering algorithm, used to form a suitable chain event graph. Additionally, they can account for missing data and be used to explore missingness mechanisms. Here we adapt the chain event graph framework to suit scenarios often encountered in case-control studies, to strengthen this study design which is time and financially efficient. We demonstrate eight adaptations to the graphs, which consist of two suitable for full case-control study analysis, four which can be used in interim analyses to explore biases, and two which aim to improve the ease and accuracy of analyses. The adaptations are illustrated with complete, reproducible, fully-interpreted examples, including the event tree and chain event graph. Chain event graphs are used here for the first time to summarise non-participation, data collection techniques, data reliability, and disease severity in case-control studies. We demonstrate how these features of a case-control study can be incorporated into the analysis to provide further insight, which can help to identify potential biases and lead to more accurate study results.}
}

@article{lincoln26734,
          volume = {36},
          number = {13-14},
           month = {December},
          author = {Guilherme Maeda and Marco Ewerton and Gerhard Neumann and Rudolf Lioutikov and Jan Peters},
           title = {Phase estimation for fast action recognition and trajectory generation in human?robot collaboration},
       publisher = {SAGE},
            year = {2017},
         journal = {The International Journal of Robotics Research},
             doi = {10.1177/0278364917693927},
           pages = {1579--1594},
        keywords = {ARRAY(0x5649baf9dcc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26734/},
        abstract = {This paper proposes a method to achieve fast and fluid human?robot interaction by estimating the progress of the movement of the human. The method allows the progress, also referred to as the phase of the movement, to be estimated even when observations of the human are partial and occluded; a problem typically found when using motion capture systems in cluttered environments. By leveraging on the framework of Interaction Probabilistic Movement Primitives, phase estimation makes it possible to classify the human action, and to generate a corresponding robot trajectory before the human finishes his/her movement. The method is therefore suited for semi-autonomous robots acting as assistants and coworkers. Since observations may be sparse, our method is based on computing the probability of different phase candidates to find the phase that best aligns the Interaction Probabilistic Movement Primitives with the current observations. The method is fundamentally different from approaches based on Dynamic Time Warping that must rely on a consistent stream of measurements at runtime. The resulting framework can achieve phase estimation, action recognition and robot trajectory coordination using a single probabilistic representation. We evaluated the method using a seven-degree-of-freedom lightweight robot arm equipped with a five-finger hand in single and multi-task collaborative experiments. We compare the accuracy achieved by phase estimation with our previous method based on dynamic time warping.}
}

@article{lincoln30636,
          volume = {18},
          number = {136},
           month = {December},
          author = {Christian Wirth and Riad Akrour and Gerhard Neumann and Johannes F{\"u}rnkranz},
           title = {A survey of preference-based reinforcement learning methods},
       publisher = {Journal of Machine Learning Research / Massachusetts Institute of Technology Press (MIT Press) / Microtome},
            year = {2017},
         journal = {Journal of Machine Learning Research},
           pages = {1--46},
        keywords = {ARRAY(0x5649baf9dcb0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30636/},
        abstract = {Reinforcement learning (RL) techniques optimize the accumulated long-term reward of a suitably chosen reward function. However, designing such a reward function often requires a lot of task- specific prior knowledge. The designer needs to consider different objectives that do not only influence the learned behavior but also the learning progress. To alleviate these issues, preference-based reinforcement learning algorithms (PbRL) have been proposed that can directly learn from an expert's preferences instead of a hand-designed numeric reward. PbRL has gained traction in recent years due to its ability to resolve the reward shaping problem, its ability to learn from non numeric rewards and the possibility to reduce the dependence on expert knowledge. We provide a unified framework for PbRL that describes the task formally and points out the different design principles that affect the evaluation task for the human as well as the computational complexity. The design principles include the type of feedback that is assumed, the representation that is learned to capture the preferences, the optimization problem that has to be solved as well as how the exploration/exploitation problem is tackled. Furthermore, we point out shortcomings of current algorithms, propose open research questions and briefly survey practical tasks that have been solved using PbRL.}
}

@article{lincoln24936,
          volume = {28},
          number = {11},
           month = {November},
          author = {Bin Hu and Shigang Yue and Zhuhong Zhang},
           title = {A rotational motion perception neural network based on asymmetric spatiotemporal visual information processing},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
             doi = {10.1109/TNNLS.2016.2592969},
           pages = {2803--2821},
        keywords = {ARRAY(0x5649bafa7180)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24936/},
        abstract = {All complex motion patterns can be decomposed into several elements, including translation, expansion/contraction, and rotational motion. In biological vision systems, scientists have found that specific types of visual neurons have specific preferences to each of the three motion elements. There are computational models on translation and expansion/contraction perceptions; however, little has been done in the past to create computational models for rotational motion perception. To fill this gap, we proposed a neural network that utilizes a specific spatiotemporal arrangement of asymmetric lateral inhibited direction selective neural networks (DSNNs) for rotational motion perception. The proposed neural network consists of two parts-presynaptic and postsynaptic parts. In the presynaptic part, there are a number of lateral inhibited DSNNs to extract directional visual cues. In the postsynaptic part, similar to the arrangement of the directional columns in the cerebral cortex, these direction selective neurons are arranged in a cyclic order to perceive rotational motion cues. In the postsynaptic network, the delayed excitation from each direction selective neuron is multiplied by the gathered excitation from this neuron and its unilateral counterparts depending on which rotation, clockwise (cw) or counter-cw (ccw), to perceive. Systematic experiments under various conditions and settings have been carried out and validated the robustness and reliability of the proposed neural network in detecting cw or ccw rotational motion. This research is a critical step further toward dynamic visual information processing.}
}

@article{lincoln46152,
          volume = {13},
          number = {1},
           month = {November},
          author = {Marcello Calisti and Cecilia Laschi},
           title = {Morphological and control criteria for self-stable underwater hopping},
            year = {2017},
         journal = {Bioinspiration \& Biomimetics},
             doi = {10.1088/1748-3190/aa90f6},
           pages = {016001},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46152/},
        abstract = {This paper presents the self-stabilisation features of a hopping gait during underwater legged locomotion. We used a bio-inspired fundamental model of this gait, the underwater spring-loaded inverted pendulum model, to numerically derive quantitative (dimension of the basin of attraction, Floquet multipliers, mean horizontal speed) and qualitative (shape of the basin) features which characterise the self-stability of the system. Furthermore, we compared the results obtained with a terrestrial self-stable running model (i.e. the spring-loaded inverted pendulum with swing-leg retraction) to highlight the role of water-related components in relation to dynamic legged locomotion. The analysis revealed fundamental morphological and actuation parameters that could be used to design self-stabilising underwater hopping machines, as well as elucidating their role with respect to stability and speed. Underwater hopping is a simple and reliable locomotion, as it does not require complex control feedback to reject significant disturbances. Thanks to its high self-stabilising property, underwater hopping appears to be a reliable alternative locomotion for underwater robots}
}

@incollection{lincoln39232,
           month = {November},
          author = {Claus G. S{\o}rensen and Efthymios Rodias and Dionysis Bochtis},
       booktitle = {Precision Agriculture: Technology and Economic Perspectives},
           title = {Auto-Steering and Controlled Traffic Farming ? Route Planning and Economics},
       publisher = {Springer},
             doi = {doi:10.1007/978-3-319-68715-5\_6},
           pages = {129--145},
            year = {2017},
        keywords = {ARRAY(0x5649bafa71f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39232/},
        abstract = {Agriculture nowadays includes automation systems that contribute significantly to many levels of the food production process. Such systems include GPS based systems like auto-steering and Controlled Traffic Farming (CTF). These systems have led to many innovations in agricultural field area coverage design. Integrating these advancements, two different route planning designs, a traditional and an optimised one, are outlined and explained in this chapter. Four different machinery scenarios were tested in four fields each, and the main aim was to compare the two different route planning systems under economic criteria and identify the best operational route coverage design criterion. The results show that there are significant reductions in operational costs varying from 9 to 20\%, depending on the specific machinery and field configurations. Such results show the considerable potential of advanced route planning designs and further optimization measures. They indicate the need for research efforts that quantify the operational and economic benefits by optimising field coverage designs in the headlands, turnings or obstacles avoidance according to the actual configuration to minimize the non-working activities and, as a consequence, the overall operational cost.}
}

@inproceedings{lincoln29060,
       booktitle = {IEEE RAS International Conference on Humanoid Robots},
           month = {November},
           title = {Deep reinforcement learning for conversational robots playing games},
          author = {Heriberto Cuayahuitl},
       publisher = {IEEE},
            year = {2017},
        keywords = {ARRAY(0x5649bafe53e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29060/},
        abstract = {Deep reinforcement learning for interactive multimodal robots is attractive for endowing machines with trainable skill acquisition. But this form of learning still represents several challenges. The challenge that we focus in this paper is effective policy learning. To address that, in this paper we compare the Deep Q-Networks (DQN) method against a variant that aims for stronger decisions than the original method by avoiding decisions with the lowest negative rewards. We evaluated our baseline and proposed algorithms in agents playing the game of Noughts and Crosses with two grid sizes (3x3 and 5x5). Experimental results show evidence that our proposed method can lead to more effective policies than the baseline DQN method, which can be used for training interactive social robots.}
}

@article{lincoln26599,
          volume = {186},
          number = {10},
           month = {November},
          author = {C. Keeble and P. A. Thwaites and P. D. Baxter and S. Barber and R. C. Parslow and G. R. Law},
           title = {Learning Through Chain Event Graphs: The Role of Maternal Factors in Childhood Type 1 Diabetes},
       publisher = {Oxford University Press},
            year = {2017},
         journal = {American Journal of Epidemiology},
             doi = {10.1093/aje/kwx171},
           pages = {1204--1208},
        keywords = {ARRAY(0x5649baf9dd28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26599/},
        abstract = {Chain event graphs (CEGs) are a graphical representation of a statistical model derived from event trees. They have previously been applied to cohort studies but not to case-control studies. In this paper, we apply the CEG framework to a Yorkshire, United Kingdom, case-control study of childhood type 1 diabetes (1993?1994) in order to examine 4 exposure variables associated with the mother, 3 of which are fully observed (her school-leaving-age, amniocenteses during pregnancy, and delivery type) and 1 with missing values (her rhesus factor), while incorporating previous type 1 diabetes knowledge. We conclude that the unknown rhesus factor values were likely to be missing not at random and were mainly rhesus-positive. The mother?s school-leaving-age and rhesus factor were not associated with the diabetes status of the child, whereas having at least 1 amniocentesis procedure and, to a lesser extent, birth by cesarean delivery were associated; the combination of both procedures further increased the probability of diabetes. This application of CEGs to case-control data allows for the inclusion of missing data and prior knowledge, while investigating associations in the data. Communication of the analysis with the clinical expert is more straightforward than with traditional modeling, and this approach can be applied retrospectively or when assumptions for traditional analyses are not held.}
}

@inproceedings{lincoln30193,
           month = {November},
          author = {Emmanuel Senft and Severin Lemaignan and Paul Baxter and Tony Belpaeme},
       booktitle = {4th AAAI FSS on Artificial Intelligence for Social Human-Robot Interaction (AI-HRI)},
         address = {Arlington, Virginia, U.S.A.},
           title = {Toward supervised reinforcement learning with partial states for social HRI},
       publisher = {AAAI Press},
           pages = {109--113},
            year = {2017},
        keywords = {ARRAY(0x5649bafa9ad8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30193/},
        abstract = {Social interacting is a complex task for which machine learning holds particular promise. However, as no sufficiently accurate simulator of human interactions exists today, the learning of social interaction strategies has to happen online in the real world. Actions executed by the robot impact on humans, and as such have to be carefully selected, making it impossible to rely on random exploration. Additionally, no clear reward function exists for social interactions. This implies that traditional approaches used for Reinforcement Learning cannot be directly applied for learning how to interact with the social world. As such we argue that robots will profit from human expertise and guidance to learn social interactions. However, as the quantity of input a human can provide is limited, new methods have to be designed to use human input more efficiently. In this paper we describe a setup in which we combine a framework called Supervised Progressively Autonomous Robot Competencies (SPARC), which allows safer online learning with Reinforcement Learning, with the use of partial states rather than full states to accelerate generalisation and obtain a usable action policy more quickly.}
}

@article{lincoln27782,
          volume = {34},
          number = {8},
           month = {November},
          author = {Keerthy Kusumam and Tomas Krajnik and Simon Pearson and Tom Duckett and Grzegorz Cielniak},
           title = {3D-vision based detection, localization, and sizing of broccoli heads in the field},
       publisher = {Wiley Periodicals, Inc.},
            year = {2017},
         journal = {Journal of Field Robotics},
             doi = {10.1002/rob.21726},
           pages = {1505--1518},
        keywords = {ARRAY(0x5649bafa1ac8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27782/},
        abstract = {This paper describes a 3D vision system for robotic harvesting of broccoli using low-cost RGB-D sensors, which was developed and evaluated using sensory data collected under real-world field conditions in both the UK and Spain. The presented method addresses the tasks of detecting mature broccoli heads in the field and providing their 3D locations relative to the vehicle. The paper evaluates different 3D features, machine learning, and temporal filtering methods for detection of broccoli heads. Our experiments show that a combination of Viewpoint Feature Histograms, Support Vector Machine classifier, and a temporal filter to track the detected heads results in a system that detects broccoli heads with high precision. We also show that the temporal filtering can be used to generate a 3D map of the broccoli head positions in the field. Additionally, we present methods for automatically estimating the size of the broccoli heads, to determine when a head is ready for harvest. All of the methods were evaluated using ground-truth data from both the UK and Spain, which we also make available to the research community for subsequent algorithm development and result comparison. Cross-validation of the system trained on the UK dataset on the Spanish dataset, and vice versa, indicated good generalization capabilities of the system, confirming the strong potential of low-cost 3D imaging for commercial broccoli harvesting.}
}

@article{lincoln26857,
          volume = {99},
           month = {November},
          author = {Emmanuel Senft and Paul Baxter and James Kennedy and Severin Lemaignan and Tony Belpaeme},
           title = {Supervised autonomy for online learning in human-robot interaction},
       publisher = {Elsevier / North Holland for International Association for Pattern Recognition},
            year = {2017},
         journal = {Pattern Recognition Letters},
             doi = {10.1016/j.patrec.2017.03.015},
           pages = {77--86},
        keywords = {ARRAY(0x5649bafcef98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26857/},
        abstract = {When a robot is learning it needs to explore its environment and how its environment responds on its
actions. When the environment is large and there are a large number of possible actions the robot can
take, this exploration phase can take prohibitively long. However, exploration can often be optimised
by letting a human expert guide the robot during its learning. Interactive machine learning, in which a
human user interactively guides the robot as it learns, has been shown to be an effective way to teach a
robot. It requires an intuitive control mechanism to allow the human expert to provide feedback on
the robot?s progress. This paper presents a novel method which combines Reinforcement Learning
and Supervised Progressively Autonomous Robot Competencies (SPARC). By allowing the user to
fully control the robot and by treating rewards as implicit, SPARC aims to learn an action policy
while maintaining human supervisory oversight of the robot?s behaviour. This method is evaluated and
compared to Interactive Reinforcement Learning in a robot teaching task. Qualitative and quantitative
results indicate that SPARC allows for safer and faster learning by the robot, whilst not placing a high
workload on the human teacher.}
}

@unpublished{lincoln39630,
       booktitle = {29th Conference of the International Society for Medical Innovation and Technology},
           month = {November},
           title = {From concept to design: A new flexible robotic uterine elevator},
          author = {Chakravarthini M. Saaj and Seri Mustaza and Kavitha Madhuri},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39630/}
}

@article{lincoln39222,
          volume = {9},
          number = {11},
           month = {October},
          author = {Efthymios Rodias and Remigio Berruto and Patrizia Busato and Dionysis Bochtis and Claus S{\o}rensen and Kun Zhou},
           title = {Energy Savings from Optimised In-Field Route Planning for Agricultural Machinery},
            year = {2017},
         journal = {Sustainability},
             doi = {10.3390/su9111956},
           pages = {1956},
        keywords = {ARRAY(0x5649bb104f68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39222/},
        abstract = {Various types of sensors technologies, such as machine vision and global positioning system (GPS) have been implemented in navigation of agricultural vehicles. Automated navigation systems have proved the potential for the execution of optimised route plans for field area coverage. This paper presents an assessment of the reduction of the energy requirements derived from the implementation of optimised field area coverage planning. The assessment regards the analysis of the energy requirements and the comparison between the non-optimised and optimised plans for field area coverage in the whole sequence of operations required in two different cropping systems: Miscanthus and Switchgrass production. An algorithmic approach for the simulation of the executed field operations by following both non-optimised and optimised field-work patterns was developed. As a result, the corresponding time requirements were estimated as the basis of the subsequent energy cost analysis. Based on the results, the optimised routes reduce the fuel energy consumption up to 8\%, the embodied energy consumption up to 7\%, and the total energy consumption from 3\% up to 8\%}
}

@inproceedings{lincoln46159,
       booktitle = {OCEANS 2017 - Aberdeen},
           month = {October},
           title = {A rotating polarizing filter approach for image enhancement},
          author = {Marcello Calisti and Gaetano Carbonara and Cecilia Laschi},
            year = {2017},
           pages = {1--4},
             doi = {10.1109/OCEANSE.2017.8084722},
        keywords = {ARRAY(0x5649bb104f50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46159/},
        abstract = {This paper presents a polarization-based enhancing system consisting of a rotating polarizing filter and an image fusion algorithm. A prototype was developed and tested in different light conditions, from early morning to late afternoon, and recordings of underwater scenes were taken in a sea stretch of the Mediterranean sea. Several images within the polarization range of 0? to 180? were used in an image fusion algorithm to obtain a restored image. With respect to common image quality measure metrics, our approach has similar performance of previous systems. Conversely to current solutions, our approach benefits from the light selection properties of polarizing filters, without assumptions on the polarization angle, meanwhile it provides a generic implementation which could be easily adapted to existing cameras.}
}

@article{lincoln25279,
          volume = {9},
          number = {3},
           month = {September},
          author = {Cheng Hu and Farshad Arvin and Caihua Xiong and Shigang Yue},
           title = {A bio-inspired embedded vision system for autonomous micro-robots: the LGMD case},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Transactions on Cognitive and Developmental Systems},
             doi = {10.1109/TCDS.2016.2574624},
           pages = {241--254},
        keywords = {ARRAY(0x5649bb0d1e00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25279/},
        abstract = {In this paper, we present a new bio-inspired vision system embedded for micro-robots. The vision system takes inspiration from locusts in detecting fast approaching objects. Neurophysiological research suggested that locusts use a wide-field visual neuron called lobula giant movement detector (LGMD) to respond to imminent collisions. In this work, we present the implementation of the selected neuron model by a low-cost ARM processor as part of a composite vision module. As the first embedded LGMD vision module fits to a micro-robot, the developed system performs all image acquisition and processing independently. The vision module is placed on top of a microrobot to initiate obstacle avoidance behaviour autonomously. Both simulation and real-world experiments were carried out to test the reliability and robustness of the vision system. The results of the experiments with different scenarios demonstrated the potential of the bio-inspired vision system as a low-cost embedded module for autonomous robots.}
}

@inproceedings{lincoln27675,
       booktitle = {IEEE/RSJ International Conference on Itelligent Robots and Systems (IROS)},
           month = {September},
           title = {Online learning for human classification in 3D LiDAR-based tracking},
          author = {Zhi Yan and Tom Duckett and Nicola Bellotto},
       publisher = {IEEE},
            year = {2017},
             doi = {10.1109/IROS.2017.8202247},
        keywords = {ARRAY(0x5649bb0e6de8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27675/},
        abstract = {Human detection and tracking is one of the most important aspects to be considered in service robotics, as the robot often shares its workspace and interacts closely with humans. This paper presents an online learning framework for human classification in 3D LiDAR scans, taking advantage of robust multi-target tracking to avoid the need for data annotation by a human expert. The system learns iteratively by retraining a classifier online with the samples collected by the robot over time. A novel aspect of our approach is that errors in training data can be corrected using the information provided by the 3D LiDAR-based tracking. In order to do this, an efficient 3D cluster detector of potential human targets has been implemented. We evaluate the framework using a new 3D LiDAR dataset of people moving in a large indoor public space, which is made available to the research community. The experiments analyse the real-time performance of the cluster detector and show that our online-trained human classifier matches and in some cases outperforms its offline version.}
}

@inproceedings{lincoln28481,
       booktitle = {International Conference on Intelligent Robots and Systems (IROS)},
           month = {September},
           title = {Semantic-assisted 3D Normal Distributions Transform for scan registration in environments with limited structure},
          author = {Anestis Zaganidis and Martin Magnusson and Tom Duckett and Grzegorz Cielniak},
       publisher = {IEEE/RSJ},
            year = {2017},
        keywords = {ARRAY(0x5649bb10fee8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28481/},
        abstract = {Point cloud registration is a core problem of many robotic applications, including simultaneous localization and mapping. The Normal Distributions Transform (NDT) is a method that fits a number of Gaussian distributions to the data points, and then uses this transform as an approximation of the real data, registering a relatively small number of distributions as opposed to the full point cloud. This approach contributes to NDT?s registration robustness and speed but leaves room for improvement in environments of limited structure. 
To address this limitation we propose a method for the introduction of semantic information extracted from the point clouds into the registration process. The paper presents a large scale experimental evaluation of the algorithm against NDT on two publicly available benchmark data sets. For the purpose of this test a measure of smoothness is used for the semantic partitioning of the point clouds. The results indicate that the proposed method improves the accuracy, robustness and speed of NDT registration, especially in unstructured environments, making NDT suitable for a wider range of applications.}
}

@article{lincoln27834,
           month = {September},
          author = {Qinbing Fu and Cheng Hu and Tian liu and Shigang Yue},
            note = {{\copyright} 2017 IEEE},
       booktitle = {2017 IEEE/RSJ International Conference on Intelligent Robots and Systems},
           title = {Collision selective LGMDs neuron models research benefits from a vision-based autonomous micro robot},
       publisher = {IEEE},
            year = {2017},
         journal = {2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
             doi = {10.1109/IROS.2017.8206254},
           pages = {3996--4002},
        keywords = {ARRAY(0x5649bb10ff30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27834/},
        abstract = {The developments of robotics inform research across a broad range of disciplines. In this paper, we will study and compare two collision selective neuron models via a vision-based autonomous micro robot. In the locusts' visual brain, two Lobula Giant Movement Detectors (LGMDs), i.e. LGMD1 and LGMD2, have been identified as looming sensitive neurons responding to rapidly expanding objects, yet with different collision selectivity. Both neurons have been built for perceiving potential collisions in an efficient and reliable manner; a few modeling works have also demonstrated their effectiveness for robotic implementations. In this research, for the first time, we set up binocular neuronal models, combining the functionalities of LGMD1 and LGMD2 neurons, in the visual modality of a ground mobile robot. The results of systematic on-line experiments demonstrated three contributions: (1) The arena tests involving multiple robots verified the robustness and efficiency of a reactive motion control strategy via integrating a bilateral pair of LGMD1 and LGMD2 models for collision detection in dynamic scenarios. (2) We pinpointed the different collision selectivity between LGMD1 and LGMD2 neuron models fulfilling corresponded biological research results. (3) The low-cost robot may also shed lights on similar bio-inspired embedded vision systems and swarm robotics applications.}
}

@inproceedings{lincoln28257,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {September},
           title = {Hybrid control trajectory optimization under uncertainty},
          author = {J. Pajarinen and V. Kyrki and M. Koval and S Srinivasa and J. Peters and G. Neumann},
            year = {2017},
        keywords = {ARRAY(0x5649bb10fed0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28257/},
        abstract = {Trajectory optimization is a fundamental problem in robotics. While optimization of continuous control trajectories is well developed, many applications require both discrete and continuous, i.e. hybrid controls. Finding an optimal sequence of hybrid controls is challenging due to the exponential explosion of discrete control combinations. Our method, based on Differential Dynamic Programming (DDP), circumvents this problem by incorporating discrete actions inside DDP: we first optimize continuous mixtures of discrete actions, and, subsequently force the mixtures into fully discrete actions. Moreover, we show how our approach can be extended to partially observable Markov decision processes (POMDPs) for trajectory planning under uncertainty. We validate the approach in a car driving problem where the robot has to switch discrete gears and in a box pushing application where the robot can switch the side of the box to push. The pose and the friction parameters of the pushed box are initially unknown and only indirectly observable.}
}

@article{lincoln33039,
          volume = {4},
          number = {5},
           month = {September},
          author = {Khaled Goher and Nazanin Mansouri and Fadlallah Sulaiman},
            note = {This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.},
           title = {Assessment of personal care and medical robots from older adults? perspective},
       publisher = {Springer},
            year = {2017},
         journal = {Robotics and Biomimetics},
             doi = {10.1186/s40638-017-0061-7},
        keywords = {ARRAY(0x5649bb0f9168)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33039/},
        abstract = {Demographic reports indicate that population of older adults is growing significantly over the world and in particular in developed nations. Consequently, there are a noticeable number of demands for certain services such as health-care systems and assistive medical robots and devices. In today?s world, different types of robots play substantial roles specifically in medical sector to facilitate human life, especially older adults. Assistive medical robots and devices are created in various designs to fulfill specific needs of older adults. Though medical robots are utilized widely by senior citizens, it is dramatic to find out into what extent assistive robots satisfy their needs and expectations. This paper reviews various assessments of assistive medical robots from older adults? perspectives with the purpose of identifying senior citizen?s needs, expectations, and preferences. On the other hand, these kinds of assessments inform robot designers, developers, and programmers to come up with robots fulfilling elderly?s needs while improving their life quality.}
}

@inproceedings{lincoln31052,
       booktitle = {Student Conference on Planning in Artificial Intelligence and Robotics (PAIR)},
           month = {September},
           title = {Spatiotemporal models for motion planning in human populated environments},
          author = {Tomas Vintr and Sergi Molina Mellado and Grzegorz Cielniak and Tom Duckett and Tomas Krajnik},
       publisher = {Czech Technical University in Prague, Faculty of Electrical Engineering},
            year = {2017},
        keywords = {ARRAY(0x5649baf409d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31052/},
        abstract = {In this paper we present an effective spatio-temporal model for motion planning computed using a novel representation known as the temporary warp space-hypertime continuum. Such a model is suitable for robots that are expected to be helpful to humans in their natural environments. This method allows to capture natural periodicities of human behavior by adding additional time dimensions. The model created thus represents the temporal structure of the human habits within a given space and can be analyzed using regular analytical methods. We visualize the results on a real-world dataset using heatmaps.}
}

@article{lincoln40526,
          volume = {24},
          number = {3},
           month = {September},
          author = {Nick Hawes and Christopher Burbridge and Ferdian Jovan and Lars Kunze and Bruno Lacerda and Lenka Mudrova and Jay Young and Jeremy Wyatt and Denise Hebesberger and Tobias Kortner and Rares Ambrus and Nils Bore and John Folkesson and Patric Jensfelt and Lucas Beyer and Alexander Hermans and Bastian Leibe and Aitor Aldoma and Thomas Faulhammer and Michael Zillich and Markus Vincze and Eris Chinellato and Muhannad Al-Omari and Paul Duckworth and Yiannis Gatsoulis and David C. Hogg and Anthony G. Cohn and Christian Dondrup and Jaime Pulido Fentanes and Tomas Krajnik and Joao M. Santos and Tom Duckett and Marc Hanheide},
           title = {The STRANDS Project: Long-Term Autonomy in Everyday Environments},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Robotics \& Automation Magazine},
             doi = {10.1109/MRA.2016.2636359},
           pages = {146--156},
        keywords = {ARRAY(0x5649baf25a60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40526/},
        abstract = {Thanks to the efforts of the robotics and autonomous systems community, the myriad applications and capacities of robots are ever increasing. There is increasing demand from end users for autonomous service robots that can operate in real environments for extended periods. In the Spatiotemporal Representations and Activities for Cognitive Control in Long-Term Scenarios (STRANDS) project (http://strandsproject.eu), we are tackling this demand head-on by integrating state-of-the-art artificial intelligence and robotics research into mobile service robots and deploying these systems for long-term installations in security and care environments. Our robots have been operational for a combined duration of 104 days over four deployments, autonomously performing end-user-defined tasks and traversing 116 km in the process. In this article, we describe the approach we used to enable long-term autonomous operation in everyday environments and how our robots are able to use their long run times to improve their own performance.}
}

@article{lincoln29678,
          volume = {17},
          number = {3},
           month = {September},
          author = {Peter Lightbody and Marc Hanheide and Tomas Krajnik},
            note = {Copyright is held by the authors. This work is based on an earlier work: SAC?17 Proceedings of the 2017 ACM Symposium on Applied Computing, Copyright 2017 ACM 978-1-4503-4486-9. http://dx.doi.org/10. 1145/3019612.3019709},
           title = {An efficient visual fiducial localisation system},
       publisher = {ACM},
            year = {2017},
         journal = {Applied Computing Review},
             doi = {10.1145/3161534.3161537},
           pages = {28--37},
        keywords = {ARRAY(0x5649bb0f0748)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29678/},
        abstract = {With use cases that range from external localisation of single robots or robotic swarms to self-localisation in marker-augmented environments and simplifying perception by tagging objects in a robot's surrounding, fiducial markers have a wide field of application in the robotic world.
We propose a new family of circular markers which allow for both computationally efficient detection, tracking and identification and full 6D position estimation.
At the core of the proposed approach lies the separation of the detection and identification steps, with the former using computationally efficient circular marker detection and the latter utilising an open-ended `necklace encoding', allowing scalability to a large number of individual markers.
While the proposed algorithm achieves similar accuracy to other state-of-the-art methods, its experimental evaluation in realistic conditions demonstrates that it can detect markers from larger distances while being up to two orders of magnitude faster than other state-of-the-art fiducial marker detection methods. In addition, the entire system is available as an open-source package at {$\backslash$}url\{https://github.com/LCAS/whycon\}.}
}

@inproceedings{lincoln43301,
           month = {September},
           title = {The Pi-puck extension board:
a Raspberry Pi interface for the e-puck robot platform},
          author = {Alan Millard and Russel Joyce and James A. Hilder and Cristian Fleseriu and Leonard Newbrook and Wei Li and Liam J. McDaid and Halliday David M.},
       publisher = {IEEE},
            year = {2017},
             doi = {10.1109/IROS.2017.8202233},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43301/},
        abstract = {This paper presents the Pi-puck extension board ? an interface between the e-puck robot platform and a Raspberry Pi single-board computer that enhances the processing power, memory capacity, and networking capabilities of the robot at a low cost. It allows high-level control algorithms, wireless communication, and computationally expensive operations such as real-time image processing to be handled by a Raspberry Pi, while the e-puck?s microcontroller deals with low-level motor control and sensor interfacing. Although two similar extension boards for the e-puck robot platform already exist, they are now out-dated and expensive in comparison. Our open-source hardware design and supporting software infrastructure offer an inexpensive upgrade to the e-puck robot, transforming it into the Pi-puck ? a modern and flexible new platform for mobile robotics research.}
}

@article{lincoln26196,
          volume = {33},
          number = {4},
           month = {August},
          author = {Tomas Krajnik and Jaime Pulido Fentanes and Joao Santos and Tom Duckett},
           title = {FreMEn: Frequency map enhancement for long-term mobile robot autonomy in changing environments},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Transactions on Robotics},
             doi = {10.1109/TRO.2017.2665664},
           pages = {964--977},
        keywords = {ARRAY(0x5649bac4c450)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26196/},
        abstract = {We present a new approach to long-term mobile robot mapping in dynamic indoor environments. Unlike traditional world models that are tailored to represent static scenes, our approach explicitly models environmental dynamics. We assume that some of the hidden processes that influence the dynamic environment states are periodic and model the uncertainty of the estimated state variables by their frequency spectra. The spectral model can represent arbitrary timescales of environment dynamics with low memory requirements. Transformation of the spectral model to the time domain allows for the prediction of the future environment states, which improves the robot's long-term performance in dynamic environments. Experiments performed over time periods of months to years demonstrate that the approach can efficiently represent large numbers of observations and reliably predict future environment states. The experiments indicate that the model's predictive capabilities improve mobile robot localisation and navigation in changing environments.}
}

@article{lincoln28020,
          volume = {18},
          number = {73},
           month = {August},
          author = {Herke van Hoof and Gerhard Neumann and Jan Peters},
           title = {Non-parametric policy search with limited information loss},
       publisher = {Journal of Machine Learning Research},
            year = {2017},
         journal = {Journal of Machine Learning Research},
           pages = {1--46},
        keywords = {ARRAY(0x5649baf46cc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28020/},
        abstract = {Learning complex control policies from non-linear and redundant sensory input is an important challenge for reinforcement learning algorithms. Non-parametric methods that approximate values functions or transition models can address this problem, by adapting to the complexity of the dataset. Yet, many current non-parametric approaches rely on
unstable greedy maximization of approximate value functions, which might lead to poor convergence or oscillations in the policy update. A more robust policy update can be obtained by limiting the information loss between successive state-action distributions. In this paper, we develop a policy search algorithm with policy updates that are both robust and non-parametric. Our method can learn non-parametric control policies for infinite horizon continuous Markov decision processes with non-linear and redundant sensory representations. We investigate how we can use approximations of the kernel function to reduce the time requirements of the demanding non-parametric computations. In our experiments, we show the strong performance of the proposed method, and how it can be approximated efficiently. Finally, we show that our algorithm can learn a real-robot underpowered swing-up task directly from image data.}
}

@inproceedings{lincoln27676,
       booktitle = {International Conference of the Speech Communication Association (INTERSPEECH)},
           month = {August},
           title = {Deep reinforcement learning of dialogue policies with less weight updates},
          author = {Heriberto Cuayahuitl and Seunghak Yu},
            year = {2017},
        keywords = {ARRAY(0x5649bac42038)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27676/},
        abstract = {Deep reinforcement learning dialogue systems are attractive because they can jointly learn their feature representations and policies without manual feature engineering. But its application is challenging due to slow learning. We propose a two-stage method for accelerating the induction of single or multi-domain dialogue policies. While the first stage reduces the amount of weight updates over time, the second stage uses very limited minibatches (of as much as two learning experiences) sampled from experience replay memories. The former frequently updates the weights of the neural nets at early stages of training, and decreases the amount of updates as training progresses by performing updates during exploration and by skipping updates during exploitation. The learning process is thus accelerated
through less weight updates in both stages. An empirical evaluation in three domains (restaurants, hotels and tv guide) confirms that the proposed method trains policies 5 times faster than a baseline without the proposed method. Our findings are useful for training larger-scale neural-based spoken dialogue systems.}
}

@inproceedings{lincoln28141,
       booktitle = {International Joint Conference on Artificial Intelligence (IJCAI)},
           month = {August},
           title = {Contextual CMA-ES},
          author = {A. Abdolmaleki and B. Price and N. Lau and P. Reis and G. Neumann},
            year = {2017},
        keywords = {ARRAY(0x5649bac52178)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28141/},
        abstract = {Many stochastic search algorithms are designed to optimize a fixed objective function to learn a task, i.e., if the objective function changes slightly, for example, due to a change in the situation or context of the task, relearning is required to adapt to the new context. For instance, if we want to learn a kicking movement for a soccer robot, we have to relearn the movement for different ball locations. Such relearning is undesired as it is highly inefficient and many applications require a fast adaptation to a new context/situation. Therefore, we investigate contextual stochastic search algorithms
that can learn multiple, similar tasks simultaneously. Current contextual stochastic search methods are based on policy search algorithms and suffer from premature convergence and the need for parameter tuning. In this paper, we extend the well known CMA-ES algorithm to the contextual setting and illustrate its performance on several contextual
tasks. Our new algorithm, called contextual CMAES, leverages from contextual learning while it preserves all the features of standard CMA-ES such as stability, avoidance of premature convergence, step size control and a minimal amount of parameter tuning.}
}

@article{lincoln32031,
          volume = {140},
           month = {August},
          author = {Adam Binch and Charles Fox},
           title = {Controlled comparison of machine vision algorithms for Rumex and Urtica detection in grassland},
       publisher = {Elsevier},
            year = {2017},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2017.05.018},
           pages = {123--138},
        keywords = {ARRAY(0x5649bac52190)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32031/},
        abstract = {Automated robotic weeding of grassland will improve the productivity of dairy and sheep farms
7 while helping to conserve their environments. Previous studies have reported results of machine
8 vision methods to separate grass from grassland weeds but each use their own datasets and
9 report only performance of their own algorithm, making it impossible to compare them. A
10 definitive, large-scale independent study is presented of all major known grassland weed detec-
11 tion methods evaluated on a new standardised data set under a wider range of environment
12 conditions. This allows for a fair, unbiased, independent and statistically significant comparison
13 of these and future methods for the first time. We test features including linear binary pat-
14 terns, BRISK, Fourier and Watershed; and classifiers including support vector machines, linear
15 discriminants, nearest neighbour, and meta-classifier combinations. The most accurate method
16 is found to use linear binary patterns together with a support vector machine}
}

@inproceedings{lincoln27902,
       booktitle = {International Conference on Machine Learning (ICML)},
           month = {August},
           title = {Local Bayesian optimization of motor skills},
          author = {R. Akrour and D. Sorokin and J. Peters and G. Neumann},
            year = {2017},
        keywords = {ARRAY(0x5649bac521c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27902/},
        abstract = {Bayesian optimization is renowned for its sample
efficiency but its application to higher dimensional
tasks is impeded by its focus on global
optimization. To scale to higher dimensional
problems, we leverage the sample efficiency of
Bayesian optimization in a local context. The
optimization of the acquisition function is restricted
to the vicinity of a Gaussian search distribution
which is moved towards high value areas
of the objective. The proposed informationtheoretic
update of the search distribution results
in a Bayesian interpretation of local stochastic
search: the search distribution encodes prior
knowledge on the optimum?s location and is
weighted at each iteration by the likelihood of
this location?s optimality. We demonstrate the
effectiveness of our algorithm on several benchmark
objective functions as well as a continuous
robotic task in which an informative prior is obtained
by imitation learning.}
}

@article{lincoln26922,
          volume = {249},
           month = {August},
          author = {Daqi Liu and Shigang Yue},
           title = {Fast unsupervised learning for visual pattern recognition using spike timing dependent plasticity},
       publisher = {Elsevier},
            year = {2017},
         journal = {Neurocomputing},
             doi = {10.1016/j.neucom.2017.04.003},
           pages = {212--224},
        keywords = {ARRAY(0x5649bac3bc10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26922/},
        abstract = {Real-time learning needs algorithms operating in a fast speed comparable to human or animal, however this is a huge challenge in processing visual inputs. Research shows a biological brain can process complicated real-life recognition scenarios at milliseconds scale. Inspired by biological system, in this paper, we proposed a novel real-time learning method by combing the spike timing-based feed-forward spiking neural network (SNN) and the fast unsupervised spike timing dependent plasticity learning method with dynamic post-synaptic thresholds. Fast cross-validated experiments using MNIST database showed the high e?ciency of the proposed method at an acceptable accuracy.}
}

@inproceedings{lincoln40823,
           month = {August},
          author = {Anu B. Titus and Thejas Narayanan and Gautham Das},
       booktitle = {2017 IEEE International Conference on Smart Technologies and Management for Computing, Communication, Controls, Energy and Materials (ICSTM)},
           title = {Vision system for coconut farm cable robot},
       publisher = {IEEE},
             doi = {10.1109/ICSTM.2017.8089201},
           pages = {443--450},
            year = {2017},
        keywords = {ARRAY(0x5649baf2d8c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40823/},
        abstract = {In many countries, robots and automation techniques are being introduced in agriculture farms to reduce the human labour and to improve the yield. However, such technological initiatives are still lacking in India, although it is the leading producer of many vegetables and fruits, for example, coconuts. Some of the activities carried out in a coconut farm that requires human labor are coconut dehusking, loading and unloading of coconuts. Automating these activities in a coconut farm would require a robotic system to pick and transport coconuts, for which the primary need would be to detect coconuts in those environments under natural lighting conditions. Towards this, the work in this paper tests for the applicability of three most used computer vision based object detection approaches namely, Local Binary Pattern (LBP) cascade, Histogram of Oriented Gradients (HOG) cascade and Haar - like cascade in coconut detection. This vision system would enable any field robot to automate the tasks in coconut farms without human assistance. A comparative analysis using confusion matrix is carried on these three approaches. It is observed that Haar-like features provided comparably better results among all the three features, in terms of hit rate and precision.}
}

@inproceedings{lincoln44700,
       booktitle = {2017 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)},
           month = {July},
           title = {A one-class Clustering technique for Novelty Detection and Isolation in sensor networks},
          author = {Sepehr Maleki and Chris Bingham},
            year = {2017},
           pages = {1--6},
             doi = {10.1109/CIVEMSA.2017.7995292},
        keywords = {ARRAY(0x5649baf3fee0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44700/},
        abstract = {A new Cluster-based methodology for real-time Novelty Detection and Isolation (NDI) in sensor networks, is presented. The proposed algorithm enables uniform clustering across time-frames to indicate the presence of a ?healthy? network. In the event of novelty, the associated sensor is seen to be clustered in a non-uniform manner with respect other sensors in the network, thereby facilitating fault isolation. Moreover, a statistical approach is proposed to determine a noise tolerance level for reducing false alarms. Performance of the proposed algorithm is examined using datasets obtained from a number of industrial case studies, and the significance for fault detection for such systems is demonstrated. Specifically, it is shown that through a correct selection of the noise tolerance level, an emerging failure is successfully isolated in presence of other abrupt changes that visually might be perceived as indication of a failure.}
}

@article{lincoln35378,
           month = {July},
          author = {Ashiqur Rahman and Amr Ahmed and Shigang Yue},
       booktitle = {The 2017 International Conference of Data Mining and Knowledge Engineering},
           title = {Classification of Tongue - Glossitis Abnormality},
       publisher = {International Association of Engineers (IAENG)},
         journal = {Lecture Notes in Engineering and Computer Science: Proceedings of The World Congress on Engineering},
           pages = {1--4},
            year = {2017},
        keywords = {ARRAY(0x5649baf25a30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35378/},
        abstract = {Glossitis abnormality is a tongue abnormality affecting patients suffering from Diabetes Mellitus (DM). The novelty of the proposed approach is attributed to utilising visual signs that appear on the tongue due to Glossitis abnormality caused by the high blood sugar level in the human body. The clinical test for the blood sugar level is inconvenient for some patients in rural and poor areas where medical services are minimal or may not be available at all.

This paper presents an approach to classifying a tongue abnormality related to Diabetes Mellitus (DM) following Western Medicine. To screen and monitor human organ effectively, the proposed computer-aided model predicts and classifies abnormality appears on the tongue or tongue surface using visual signs caused by the Glossitis abnormality. The visual signs extracted following a coherent diagnosis procedure complying with Western Medicine (WM) in practice.  The experimental result has shown a promising accuracy of 95.8\% for the Glossitis abnormality by applying Random Forest classifier on the extracted visual signs from 572 tongue samples of 166 patients.}
}

@inproceedings{lincoln37437,
          volume = {10454},
           month = {July},
          author = {C. Lekakou and S.M. Mustaza and T. Crisp and Y. Elsayed and Mini Saaj},
            note = {cited By 1},
       booktitle = {Annual Conference Towards Autonomous Robotic Systems},
           title = {A material-based model for the simulation and control of soft robot actuator},
       publisher = {Springer},
            year = {2017},
         journal = {Proc. 18th Towards Autonomous Robotics Systems Conference},
             doi = {10.1007/978-3-319-64107-2\_45},
           pages = {557--569},
        keywords = {ARRAY(0x5649baf2dfb0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37437/},
        abstract = {An innovative material-based model is described for a three-pneumatic channel, soft robot actuator and implemented in simulations and control. Two types of material models are investigated: a soft, hyperelastic material model and a novel visco-hyperelastic material model are presented and evaluated in simulations of one-channel operation. The advanced visco-hyperelastic model is further demonstrated in control under multi-channel actuation. Finally, a soft linear elastic material model was used in finite element analysis of the soft three-pneumatic channel actuator within SOFA, moving inside a pipe and interacting with its rigid wall or with a soft hemispherical object attached to that wall. A collision model was used for these interactions and the simulations yielded ?virtual haptic? 3d-force profiles at monitored nodes at the free- and fixed-end of the actuator.}
}

@inproceedings{lincoln27056,
       booktitle = {The Genetic and Evolutionary Computation Conference (GECCO 2017)},
           month = {July},
           title = {Deriving and improving CMA-ES with Information geometric trust regions},
          author = {Abbas Abdolmaleki and Bob Price and Nuno Lau and Luis Paulo Reis and Gerhard Neumann},
            year = {2017},
        keywords = {ARRAY(0x5649baf409c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27056/},
        abstract = {CMA-ES is one of the most popular stochastic search algorithms.
It performs favourably in many tasks without the need of extensive
parameter tuning. The algorithm has many beneficial properties,
including automatic step-size adaptation, efficient covariance updates
that incorporates the current samples as well as the evolution
path and its invariance properties. Its update rules are composed
of well established heuristics where the theoretical foundations of
some of these rules are also well understood. In this paper we
will fully derive all CMA-ES update rules within the framework of
expectation-maximisation-based stochastic search algorithms using
information-geometric trust regions. We show that the use of the trust
region results in similar updates to CMA-ES for the mean and the
covariance matrix while it allows for the derivation of an improved
update rule for the step-size. Our new algorithm, Trust-Region Covariance
Matrix Adaptation Evolution Strategy (TR-CMA-ES) is
fully derived from first order optimization principles and performs
favourably in compare to standard CMA-ES algorithm.}
}

@article{lincoln27901,
          volume = {PP},
          number = {99},
           month = {July},
          author = {Alexandros Paraschos and Rudolf Lioutikov and Jan Peters and Gerhard Neumann},
       booktitle = {, Proceedings of the International Conference on Intelligent Robot Systems, and IEEE Robotics and Automation Letters (RA-L)},
           title = {Probabilistic prioritization of movement primitives},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2017.2725440},
        keywords = {ARRAY(0x5649baf40990)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27901/},
        abstract = {Movement prioritization is a common approach
to combine controllers of different tasks for redundant robots,
where each task is assigned a priority. The priorities of the
tasks are often hand-tuned or the result of an optimization,
but seldomly learned from data. This paper combines Bayesian
task prioritization with probabilistic movement primitives to
prioritize full motion sequences that are learned from demonstrations.
Probabilistic movement primitives (ProMPs) can
encode distributions of movements over full motion sequences
and provide control laws to exactly follow these distributions.
The probabilistic formulation allows for a natural application of
Bayesian task prioritization. We extend the ProMP controllers
with an additional feedback component that accounts inaccuracies
in following the distribution and allows for a more
robust prioritization of primitives. We demonstrate how the
task priorities can be obtained from imitation learning and
how different primitives can be combined to solve even unseen
task-combinations. Due to the prioritization, our approach can
efficiently learn a combination of tasks without requiring individual
models per task combination. Further, our approach can
adapt an existing primitive library by prioritizing additional
controllers, for example, for implementing obstacle avoidance.
Hence, the need of retraining the whole library is avoided in
many cases. We evaluate our approach on reaching movements
under constraints with redundant simulated planar robots and
two physical robot platforms, the humanoid robot ?iCub? and
a KUKA LWR robot arm.}
}

@inproceedings{lincoln26622,
       booktitle = {International Joint Conference on Neural Networks (IJCNN)},
           month = {July},
           title = {Scaling up deep reinforcement learning for multi-domain dialogue systems},
          author = {Heriberto Cuayahuitl and Seunghak Yu and Ashley Williamson and Jacob Carse},
       publisher = {IEEE},
            year = {2017},
             doi = {10.1109/IJCNN.2017.7966275},
        keywords = {ARRAY(0x5649baf521a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26622/},
        abstract = {Standard deep reinforcement learning methods such as Deep Q-Networks (DQN) for multiple tasks (domains) face scalability problems due to large search spaces. This paper proposes a three-stage method for multi-domain dialogue policy learning{--}termed NDQN, and applies it to an information-seeking spoken dialogue system in the domains of restaurants and hotels. In this method, the first stage does multi-policy learning via a network of DQN agents; the second makes use of compact state representations by compressing raw inputs; and the third stage applies a pre-training phase for bootstraping the behaviour of agents in the network. Experimental results comparing DQN
(baseline) versus NDQN (proposed) using simulations report that the proposed method exhibits better scalability and is
promising for optimising the behaviour of multi-domain dialogue systems. An additional evaluation reports that the NDQN agents outperformed a K-Nearest Neighbour baseline in task success and dialogue length, yielding more efficient and successful dialogues.}
}

@article{lincoln28021,
          volume = {36},
          number = {8},
           month = {July},
          author = {Rudolf Lioutikov and Gerhard Neumann and Guilherme Maeda and Jan Peters},
           title = {Learning movement primitive libraries through probabilistic segmentation},
       publisher = {SAGE},
            year = {2017},
         journal = {International Journal of Robotics Research (IJRR)},
             doi = {10.1177/0278364917713116},
           pages = {879--894},
        keywords = {ARRAY(0x5649bafe3ec8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28021/},
        abstract = {Movement primitives are a well established approach for encoding and executing movements. While the primitives
themselves have been extensively researched, the concept of movement primitive libraries has not received similar
attention. Libraries of movement primitives represent the skill set of an agent. Primitives can be queried and sequenced
in order to solve specific tasks. The goal of this work is to segment unlabeled demonstrations into a representative
set of primitives. Our proposed method differs from current approaches by taking advantage of the often neglected,
mutual dependencies between the segments contained in the demonstrations and the primitives to be encoded. By
exploiting this mutual dependency, we show that we can improve both the segmentation and the movement primitive
library. Based on probabilistic inference our novel approach segments the demonstrations while learning a probabilistic
representation of movement primitives. We demonstrate our method on two real robot applications. First, the robot
segments sequences of different letters into a library, explaining the observed trajectories. Second, the robot segments
demonstrations of a chair assembly task into a movement primitive library. The library is subsequently used to assemble the chair in an order not present in the demonstrations.}
}

@inproceedings{lincoln31513,
       booktitle = {IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications},
           month = {June},
           title = {A one-class clustering technique for novelty detection and Isolation in sensor networks},
          author = {Sepehr Maleki and Chris Bingham},
       publisher = {IEEE},
            year = {2017},
        keywords = {ARRAY(0x5649bafbe5f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/31513/},
        abstract = {A new Cluster-based methodology for real-time Novelty Detection and Isolation (NDI) in sensor networks, is presented. The proposed algorithm enables uniform clustering across time-frames to indicate the presence of a ?healthy? network. In the event of novelty, the associated sensor is seen to be clustered in a non-uniform manner with respect other sensors in the network, thereby facilitating fault isolation. Moreover, a statistical approach is proposed to determine a noise tolerance level for reducing false alarms. Performance of the proposed algorithm is examined using datasets obtained from a number of industrial case studies, and the significance for fault detection for such systems is demonstrated. Specifically, it is shown that through a correct selection of the noise tolerance level, an emerging failure is successfully isolated in presence of other abrupt changes that visually might be perceived as indication of a failure.}
}

@inproceedings{lincoln27055,
       booktitle = {Proceedings of the International Conference on Automated Planning and Scheduling (ICAPS)},
           month = {June},
           title = {State-regularized policy search for linearized dynamical systems},
          author = {Hany Abdulsamad and Oleg Arenz and Jan Peters and Gerhard Neumann},
            year = {2017},
        keywords = {ARRAY(0x5649bafbe640)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27055/},
        abstract = {Trajectory-Centric Reinforcement Learning and Trajectory
Optimization methods optimize a sequence of feedbackcontrollers
by taking advantage of local approximations of
model dynamics and cost functions. Stability of the policy update
is a major issue for these methods, rendering them hard
to apply for highly nonlinear systems. Recent approaches
combine classical Stochastic Optimal Control methods with
information-theoretic bounds to control the step-size of the
policy update and could even be used to train nonlinear deep
control policies. These methods bound the relative entropy
between the new and the old policy to ensure a stable policy
update. However, despite the bound in policy space, the
state distributions of two consecutive policies can still differ
significantly, rendering the used local approximate models invalid.
To alleviate this issue we propose enforcing a relative
entropy constraint not only on the policy update, but also on
the update of the state distribution, around which the dynamics
and cost are being approximated. We present a derivation
of the closed-form policy update and show that our approach
outperforms related methods on two nonlinear and highly dynamic
simulated systems.}
}

@article{lincoln39221,
          volume = {10},
          number = {7},
           month = {June},
          author = {Efthymios Rodias and Remigio Berruto and Dionysis Bochtis and Patrizia Busato and Alessandro Sopegno},
           title = {A Computational Tool for Comparative Energy Cost Analysis of Multiple-Crop Production Systems},
            year = {2017},
         journal = {Energies},
             doi = {10.3390/en10070831},
           pages = {831},
        keywords = {ARRAY(0x5649bafa9910)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39221/},
        abstract = {Various crops can be considered as potential bioenergy and biofuel production feedstocks. The selection of the crops to be cultivated for that purpose is based on several factors. For an objective comparison between different crops, a common framework is required to assess their economic or energetic performance. In this paper, a computational tool for the energy cost evaluation of multiple-crop production systems is presented. All the in-field and transport operations are considered, providing a detailed analysis of the energy requirements of the components that contribute to the overall energy consumption. A demonstration scenario is also described. The scenario is based on three selected energy crops, namely Miscanthus, Arundo donax and Switchgrass. The tool can be used as a decision support system for the evaluation of different agronomical practices (such as fertilization and agrochemicals application), machinery systems, and management practices that can be applied in each one of the individual crops within the production system}
}

@inproceedings{lincoln28054,
       booktitle = {2017 IEEE International Conference on Prognostics and Health Management (ICPHM)},
           month = {June},
           title = {Performance analysis of a twin shaft Industrial Gas Turbine at fouling conditions},
          author = {Samuel Cruz-Manzo and Sepehr Maleki and Yu Zhang and Vili Panov and Anthony Latimer},
            year = {2017},
        keywords = {ARRAY(0x5649bafa9958)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28054/},
        abstract = {In this study, the performance of a twin-shaft Industrial Gas Turbine (IGT) at fouling conditions is simulated through a Simulink model based on fundamental thermodynamics. Engine measurements across a twin-shaft IGT system during compressor fouling conditions were considered to validate this study. By implementing correlation coefficients in the compressor model, it is possible to predict the performance of the IGT system during compressor fouling conditions. The change of compressor air flow and the compressor efficiency in the twin-shaft IGT during fouling conditions is estimated. The results show that the reduction of air flow rate is the dominating parameter in the decrease of power generation in an IGT under fouled conditions. The model can provide an insight into the effect of compressor fouling conditions on system IGT performance.}
}

@article{lincoln18592,
          volume = {247},
           month = {June},
          author = {Marc Hanheide and Moritz G{\"o}belbecker and Graham S. Horn and Andrzej Pronobis and Kristoffer Sj{\"o}{\"o} and Alper Aydemir and Patric Jensfelt and Charles Gretton and Richard Dearden and Miroslav Janicek and Hendrik Zender and Geert-Jan Kruijff and Nick Hawes and Jeremy L. Wyatt},
           title = {Robot task planning and explanation in open and uncertain worlds},
       publisher = {Elsevier},
            year = {2017},
         journal = {Artificial Intelligence},
             doi = {10.1016/j.artint.2015.08.008},
           pages = {119--150},
        keywords = {ARRAY(0x5649bafdb790)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/18592/},
        abstract = {A long-standing goal of AI is to enable robots to plan in the face of uncertain and incomplete information, and to handle task failure intelligently. This paper shows how to achieve this. There are two central ideas. The first idea is to organize the robot's knowledge into three layers: instance knowledge at the bottom, commonsense knowledge above that, and diagnostic knowledge on top. Knowledge in a layer above can be used to modify knowledge in the layer(s) below. The second idea is that the robot should represent not just how its actions change the world, but also what it knows or believes. There are two types of knowledge effects the robot's actions can have: epistemic effects (I believe X because I saw it) and assumptions (I'll assume X to be true). By combining the knowledge layers with the models of knowledge effects, we can simultaneously solve several problems in robotics: (i) task planning and execution under uncertainty; (ii) task planning and execution in open worlds; (iii) explaining task failure; (iv) verifying those explanations. The paper describes how the ideas are implemented in a three-layer architecture on a mobile robot platform. The robot implementation was evaluated in five different experiments on object search, mapping, and room categorization.}
}

@article{lincoln25774,
          volume = {247},
           month = {June},
          author = {A. Kupcsik and M. P. Deisenroth and J. Peters and A. P. Loh and P. Vadakkepat and G. Neumann},
           title = {Model-based contextual policy search for data-efficient generalization of robot skills},
       publisher = {Elsevier},
            year = {2017},
         journal = {Artificial Intelligence},
             doi = {10.1016/j.artint.2014.11.005},
           pages = {415--439},
        keywords = {ARRAY(0x5649bafdb7d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25774/},
        abstract = {In robotics, lower-level controllers are typically used to make the robot solve a specific task in a fixed context. For example, the lower-level controller can encode a hitting movement while the context defines the target coordinates to hit. However, in many learning problems the context may change between task executions. To adapt the policy to a new context, we utilize a hierarchical approach by learning an upper-level policy that generalizes the lower-level controllers to new contexts. A common approach to learn such upper-level policies is to use policy search. However, the majority of current contextual policy search approaches are model-free and require a high number of interactions with the robot and its environment. Model-based approaches are known to significantly reduce the amount of robot experiments, however, current model-based techniques cannot be applied straightforwardly to the problem of learning contextual upper-level policies. They rely on specific parametrizations of the policy and the reward function, which are often unrealistic in the contextual policy search formulation. In this paper, we propose a novel model-based contextual policy search algorithm that is able to generalize lower-level controllers, and is data-efficient. Our approach is based on learned probabilistic forward models and information theoretic policy search. Unlike current algorithms, our method does not require any assumption on the parametrization of the policy or the reward function. We show on complex simulated robotic tasks and in a real robot experiment that the proposed learning framework speeds up the learning process by up to two orders of magnitude in comparison to existing methods, while learning high quality policies.}
}

@inproceedings{lincoln39636,
       booktitle = {25th International Congress of the European Association of Endoscopic Surgeons},
           month = {June},
           title = {Gynaecological ENdoscopic uTerine eLEvatoR (GENTLER)},
          author = {S. Mustaza and C.M. Saaj},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39636/}
}

@article{lincoln46161,
          volume = {14},
          number = {130},
           month = {May},
          author = {M. Calisti and G. Picardi and C. Laschi},
           title = {Fundamentals of soft robot locomotion},
            year = {2017},
         journal = {Journal of The Royal Society Interface},
             doi = {10.1098/rsif.2017.0101},
           pages = {20170101},
        keywords = {ARRAY(0x5649bafb8208)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46161/},
        abstract = {Soft robotics and its related technologies enable robot abilities in several robotics domains including, but not exclusively related to, manipulation, manufacturing, human?robot interaction and locomotion. Although field applications have emerged for soft manipulation and human?robot interaction, mobile soft robots appear to remain in the research stage, involving the somehow conflictual goals of having a deformable body and exerting forces on the environment to achieve locomotion. This paper aims to provide a reference guide for researchers approaching mobile soft robotics, to describe the underlying principles of soft robot locomotion with its pros and cons, and to envisage applications and further developments for mobile soft robotics.}
}

@article{lincoln38546,
          volume = {69},
           month = {May},
          author = {S. Zhang and E. Grave and Elizabeth Sklar and N. Elhadad},
            note = {cited By 10},
           title = {Longitudinal analysis of discussion topics in an online breast cancer community using convolutional neural networks},
            year = {2017},
         journal = {Journal of Biomedical Informatics},
             doi = {10.1016/j.jbi.2017.03.012},
           pages = {1--9},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38546/}
}

@article{lincoln27582,
          volume = {12},
          number = {5},
           month = {May},
          author = {Paul Baxter and Emily Ashurst and Robin Read and James Kennedy and Tony Belpaeme},
           title = {Robot education peers in a situated primary school study: personalisation promotes child learning},
       publisher = {Public Library of Science},
            year = {2017},
         journal = {PLoS One},
             doi = {10.1371/journal.pone.0178126},
           pages = {e0178126},
        keywords = {ARRAY(0x5649bb2bd390)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27582/},
        abstract = {The benefit of social robots to support child learning in an educational context over an extended period of time is evaluated. Specifically, the effect of personalisation and adaptation of robot social behaviour is assessed. Two autonomous robots were embedded within two matched classrooms of a primary school for a continuous two week period without experimenter supervision to act as learning companions for the children for familiar and novel subjects. Results suggest that while children in both personalised and non-personalised conditions learned, there was increased child learning of a novel subject exhibited when interacting with a robot that personalised its behaviours, with indications that this benefit extended to other class-based performance. Additional evidence was obtained suggesting that there is increased acceptance of the personalised robot peer over a non-personalised version. These results provide the first evidence in support of peer-robot behavioural personalisation having a positive influence on learning when embedded in a learning environment for an extended period of time.}
}

@inproceedings{lincoln26619,
       booktitle = {The 2017 International Joint Conference on Neural Networks (IJCNN 2017)},
           month = {May},
           title = {Modeling direction selective visual neural network with ON and OFF pathways for extracting motion cues from cluttered background},
          author = {Qinbing Fu and Shigang Yue},
            year = {2017},
        keywords = {ARRAY(0x5649bb2b5f90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26619/},
        abstract = {The nature endows animals robustvision systems for extracting and recognizing differentmotion cues, detectingpredators, chasing preys/mates in dynamic and cluttered environments. Direction selective neurons (DSNs), with preference to certain orientation visual stimulus, have been found in both vertebrates and invertebrates for decades. In thispaper, with respectto recent biological research progress in motion-detecting circuitry, we propose a novel way to model DSNs for recognizing movements on four cardinal directions. It is based on an architecture of ON and OFF visual pathways underlies a theory of splitting motion signals into parallel channels, encoding brightness increments and decrements separately. To enhance the edge selectivity and speed response to moving objects, we put forth a bio-plausible spatial-temporal network structure with multiple connections of same polarity ON/OFF cells. Each pair-wised combination is ?ltered with dynamic delay depending on sampling distance. The proposed vision system was challenged against image streams from both synthetic and cluttered real physical scenarios. The results demonstrated three major contributions: ?rst, the neural network ful?lled the characteristics of a postulated physiological map of conveying visual information through different neuropile layers; second, the DSNs model can extract useful directional motion cues from cluttered background robustly and timely, which hits at potential of quick implementation in visionbased micro mobile robots; moreover, it also represents better speed response compared to a state-of-the-art elementary motion detector.}
}

@inproceedings{lincoln28089,
           month = {May},
          author = {Gregor H. W. Gebhardt and Kevin Daun and Marius Schnaubelt and Alexander Hendrich and Daniel Kauth and Gerhard Neumann},
            note = {Extended abstract},
       booktitle = {Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems (AAMAS 17)},
           title = {Learning to assemble objects with a robot swarm},
       publisher = {international foundation for autonomous agents and multiagent systems},
           pages = {1547--1549},
            year = {2017},
        keywords = {ARRAY(0x5649bb2a6138)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28089/},
        abstract = {Large populations of simple robots can solve complex tasks, but controlling them is still a challenging problem, due to limited communication and computation power. In order to assemble objects, have shown that a human controller can solve such a task. Instead, we investigate how to learn the assembly of multiple objects with a single central controller. We propose splitting the assembly process in two sub-tasks -- generating a top-level assembly policy and learning an object movement policy. The assembly policy plans the trajectories for each object and the object movement policy controls the trajectory execution.The resulting system is able to solve assembly tasks with varying object shapes being assembled as shown in multiple simulation scenarios.}
}

@article{lincoln33056,
           month = {May},
          author = {Khaled Goher and Sulaiman Fadlallah},
            note = {The final published version of this article is available online at http://dynamicsystems.asmedigitalcollection.asme.org/article.aspx?articleid=2599257},
           title = {Design, Modelling and Control of a Portable Leg Rehabilitation System},
       publisher = {American Society of Mechanical Engineers},
         journal = {ASME Journal of Dynamic Systems, Measurement and Control},
             doi = {10.1115/1.4035815},
            year = {2017},
        keywords = {ARRAY(0x5649bb29f628)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33056/},
        abstract = {In this work, a novel design of a portable leg rehabilitation system (PLRS) is presented. The main purpose of this paper is to provide a portable system, which allows patients with lower limb disabilities to perform leg and foot rehabilitation exercises anywhere without any embarrassment compared to other devices that lack the portability feature.  The model of the system is identified by inverse kinematics and dynamics analysis. In kinematics analysis, the pattern of motion of both leg and foot holders for different modes of operation has been investigated.  The system is modeled by applying Lagrangian dynamics approach. The mathematical model derived considers calf and foot masses and moment of inertias as important parameters. Therefore, a gait analysis study is conducted to calculate the required parameters to simulate the model.  PD controller and PID controller are applied to the model and compared. The PID controller optimized by Hybrid Spiral-Dynamics Bacteria-Chemotaxis (HSDBC) algorithm provides the best response with a reasonable settling time and minimum overshot. The robustness of the HSDBC-PID controller is tested by applying disturbance force with various amplitudes. A setup is built for the system experimental validation where the system mathematical model is compare with the estimated model using System Identification Toolbox. A significant difference is observed between both models when applying the obtained HSDBC-PID controller for the mathematical model. The results of this experiment are used to update the controller parameters of the HSDBC-optimized PID.}
}

@article{lincoln27519,
          volume = {8},
          number = {1},
           month = {May},
          author = {Pablo G. Esteban and Paul Baxter and Tony Belpaeme and Erik Billing and Haibin Cai and Hoang-Long Cao and Mark Coeckelbergh and Cristina Costescu and Daniel David and Albert De Beir and Yinfeng Fang and Zhaojie Ju and James Kennedy and Honghai Liu and Alexandre Mazel and Amit Pandey and Kathleen Richardson and Emmanue Senft and Serge Thill and Greet Van de Perre and Bram Vanderborght and David Vernon and Hui Yu and Tom Ziemke},
           title = {How to build a supervised autonomous system for robot-enhanced therapy for children with autism spectrum disorder},
       publisher = {Springer/Versita with DeGruyter},
            year = {2017},
         journal = {Paladyn, Journal of Behavioral Robotics},
             doi = {10.1515/pjbr-2017-0002},
        keywords = {ARRAY(0x5649bb28e970)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27519/},
        abstract = {Robot-Assisted Therapy (RAT) has successfully been used to improve social skills in children with autism spectrum disorders (ASD) through remote control of the robot in so-called Wizard of Oz (WoZ) paradigms.However, there is a need to increase the autonomy of the robot both to lighten the burden on human therapists (who have to remain in control and, importantly, supervise the robot) and to provide a consistent therapeutic experience. This paper seeks to provide insight into increasing the autonomy level of social robots in therapy to move beyond WoZ. With the final aim of improved human-human social interaction for the children, this multidisciplinary research seeks to facilitate the use of social robots as tools in clinical situations by addressing the challenge of increasing robot autonomy.We introduce the clinical framework in which the developments are tested, alongside initial data obtained from patients in a first phase of the project using a WoZ set-up mimicking the targeted supervised-autonomy behaviour. We further describe the implemented system architecture capable of providing the robot with supervised autonomy.}
}

@article{lincoln39220,
          volume = {9},
          number = {5},
           month = {May},
          author = {Patrizia Busato and Alessandro Sopegno and Remigio Berruto and Dionysis Bochtis and Angela Calvo},
           title = {A Web-Based Tool for Energy Balance Estimation in Multiple-Crops Production Systems},
            year = {2017},
         journal = {Sustainability},
             doi = {10.3390/su9050789},
           pages = {789},
        keywords = {ARRAY(0x5649bb2a38f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39220/},
        abstract = {Biomass production systems include multiple-crops rotations, various machinery systems, diversified operational practices and several dispersed fields located in a range of distances between the various facilities (e.g., storage and processing facilities). These factors diversify the energy and cost requirements of the system. To that effect, assessment tools dedicated a single-crop production based on average standards cannot provide an insight evaluation of a specific production system, e.g., for a whole farm in terms of energy and cost requirements. This paper is the continuation of previous work, which presents a web-based tool for cost estimation of biomass production and transportation of multiple-crop production. In the present work, the tool is extended to additionally provide the energy balance of the examined systems. The energy input includes the whole supply chain of the biomass, namely crop cultivation, harvesting, handling of biomass and transportation to the processing facilities. A case study involving a real crop production system that feeds a biogas plant of 200 kW was selected for the demonstration of the tool?s applicability. The output of the tool provides a series of indexes dedicated to the energy input and balance. The presented tool can be used for the comparison of the performance, in terms of energy requirements, between various crops, fields, operations practices, and operations systems providing support for decisions on the biomass production system design (e.g., allocation of crops to fields) and operations management (e.g., machinery system selection).}
}

@article{lincoln28034,
          volume = {91},
           month = {May},
          author = {Tom Duckett and Adriana Tapus and Nicola Bellotto},
           title = {Editorial to special issue on the Seventh European Conference on Mobile Robots (ECMR?15)},
       publisher = {Elsevier},
            year = {2017},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2016.12.011},
           pages = {348},
        keywords = {ARRAY(0x5649bb2ca120)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28034/},
        abstract = {This Special Issue is based on a selection of the best papers presented at the Seventh European Conference on Mobile Robots (ECMR?15), September 2nd?4th, 2015, in Lincoln, UK.}
}

@inproceedings{lincoln26737,
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           month = {May},
           title = {Layered direct policy search for learning hierarchical skills},
          author = {F. End and R. Akrour and J. Peters and G. Neumann},
            year = {2017},
        keywords = {ARRAY(0x5649bb2ca0d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26737/},
        abstract = {Solutions to real world robotic tasks often require
complex behaviors in high dimensional continuous state and
action spaces. Reinforcement Learning (RL) is aimed at learning
such behaviors but often fails for lack of scalability. To
address this issue, Hierarchical RL (HRL) algorithms leverage
hierarchical policies to exploit the structure of a task. However,
many HRL algorithms rely on task specific knowledge such
as a set of predefined sub-policies or sub-goals. In this paper
we propose a new HRL algorithm based on information
theoretic principles to autonomously uncover a diverse set
of sub-policies and their activation policies. Moreover, the
learning process mirrors the policys structure and is thus also
hierarchical, consisting of a set of independent optimization
problems. The hierarchical structure of the learning process
allows us to control the learning rate of the sub-policies and
the gating individually and add specific information theoretic
constraints to each layer to ensure the diversification of the subpolicies.
We evaluate our algorithm on two high dimensional
continuous tasks and experimentally demonstrate its ability to
autonomously discover a rich set of sub-policies.}
}

@inproceedings{lincoln26738,
       booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
           month = {May},
           title = {A learning-based shared control architecture for interactive task execution},
          author = {F. B. Farraj and T. Osa and N. Pedemonte and J. Peters and G. Neumann and P. R. Giordano},
       publisher = {IEEE},
            year = {2017},
        keywords = {ARRAY(0x5649bafd7be8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26738/},
        abstract = {Shared control is a key technology for various
robotic applications in which a robotic system and a human
operator are meant to collaborate efficiently. In order to achieve
efficient task execution in shared control, it is essential to
predict the desired behavior for a given situation or context
to simplify the control task for the human operator. To do this
prediction, we use Learning from Demonstration (LfD), which is
a popular approach for transferring human skills to robots. We
encode the demonstrated behavior as trajectory distributions
and generalize the learned distributions to new situations. The
goal of this paper is to present a shared control framework
that uses learned expert distributions to gain more autonomy.
Our approach controls the balance between the controller?s
autonomy and the human preference based on the distributions
of the demonstrated trajectories. Moreover, the learned
distributions are autonomously refined from collaborative task
executions, resulting in a master-slave system with increasing
autonomy that requires less user input with an increasing
number of task executions. We experimentally validated that
our shared control approach enables efficient task executions.
Moreover, the conducted experiments demonstrated that the
developed system improves its performances through interactive
task executions with our shared control.}
}

@inproceedings{lincoln26736,
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           month = {May},
           title = {Empowered skills},
          author = {A. Gabriel and R. Akrour and J. Peters and G. Neumann},
            year = {2017},
        keywords = {ARRAY(0x5649bafd7bd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26736/},
        abstract = {Robot Reinforcement Learning (RL) algorithms
return a policy that maximizes a global cumulative reward
signal but typically do not create diverse behaviors. Hence, the
policy will typically only capture a single solution of a task.
However, many motor tasks have a large variety of solutions
and the knowledge about these solutions can have several
advantages. For example, in an adversarial setting such as
robot table tennis, the lack of diversity renders the behavior
predictable and hence easy to counter for the opponent. In an
interactive setting such as learning from human feedback, an
emphasis on diversity gives the human more opportunity for
guiding the robot and to avoid the latter to be stuck in local
optima of the task. In order to increase diversity of the learned
behaviors, we leverage prior work on intrinsic motivation and
empowerment. We derive a new intrinsic motivation signal by
enriching the description of a task with an outcome space,
representing interesting aspects of a sensorimotor stream. For
example, in table tennis, the outcome space could be given
by the return position and return ball speed. The intrinsic
motivation is now given by the diversity of future outcomes,
a concept also known as empowerment. We derive a new
policy search algorithm that maximizes a trade-off between
the extrinsic reward and this intrinsic motivation criterion.
Experiments on a planar reaching task and simulated robot
table tennis demonstrate that our algorithm can learn a diverse
set of behaviors within the area of interest of the tasks.}
}

@inproceedings{lincoln29190,
          volume = {2017-A},
           month = {April},
          author = {X Zheng and F. Lv and F. Zhao and S. Yue and C. Zhang and Z. Wang and F. Li and H. Jiang and Z. Wang},
            note = {Conference Code:129634},
       booktitle = {38th Annual Custom Integrated Circuits Conference, CICC 2017},
           title = {A 10 GHz 56 fsrms-integrated-jitter and -247 dB FOM ring-VCO based injection-locked clock multiplier with a continuous frequency-tracking loop in 65 nm CMOS},
       publisher = {Institute of Electrical and Electronics Engineers Inc.},
            year = {2017},
             doi = {10.1109/CICC.2017.7993597},
        keywords = {ARRAY(0x5649bafa4cc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29190/},
        abstract = {This paper presents a low jitter ring-VCO based injection-locked clock multiplier (RILCM) with a phase-shift detection based hybrid frequency tracking loop (FTL). A full-swing pseudo-differential delay cell (FS-PDDC) is proposed to lower the device noise to phase noise conversion. To obtain high operation speed, high detection accuracy, and low output disturbance, a compact timing-adjusted phase detector (TPD) tightly combining with a well-matched charge pump (CP) is designed. Additionally, a lock-loss detection and lock recovery (LLD-LR) scheme is devised to equip the RILCM with a similar lock-acquisition ability to conventional PLL, thus excluding the initial frequency setup aid and preventing potential lock loss. Implemented in 65 nm CMOS, the RILCM occupies an active area of 0.07 mm2 and consumes 59.4 mW at 10 GHz. The measured results show that it achieves 56.1 fs rms-jitter and -57.13 dBc spur level. The calculated figure-of-merit (FOM) is -247.3 dB, which is better than previous RILCMs and even comparable to those large-area LC-ILCMs. {\^A}{\copyright} 2017 IEEE.}
}

@article{lincoln27043,
           month = {April},
          author = {James Kennedy and Paul Baxter and Tony Belpaeme},
            note = {THIS ARTICLE IS PART OF THE RESEARCH TOPIC
Affective and Social Signals for HRI},
           title = {The impact of robot tutor nonverbal social behavior on child learning},
       publisher = {Frontiers Media},
         journal = {Frontiers in ICT},
             doi = {10.3389/fict.2017.00006},
            year = {2017},
        keywords = {ARRAY(0x5649bafbc5f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27043/},
        abstract = {Several studies have indicated that interacting with social robots in educational contexts may lead to a greater learning than interactions with computers or virtual agents. As such, an increasing amount of social human?robot interaction research is being conducted in the learning domain, particularly with children. However, it is unclear precisely what social behavior a robot should employ in such interactions. Inspiration can be taken from human?human studies; this often leads to an assumption that the more social behavior an agent utilizes, the better the learning outcome will be. We apply a nonverbal behavior metric to a series of studies in which children are taught how to identify prime numbers by a robot with various behavioral manipulations. We find a trend, which generally agrees with the pedagogy literature, but also that overt nonverbal behavior does not account for all learning differences. We discuss the impact of novelty, child expectations, and responses to social cues to further the understanding of the relationship between robot social behavior and learning. We suggest that the combination of nonverbal behavior and social cue congruency is necessary to facilitate learning.}
}

@article{lincoln37428,
          volume = {34},
          number = {3},
           month = {April},
          author = {F.J. Comin and W.A. Lewinger and C. Saaj and M.C. Matthews},
            note = {cited By 3},
           title = {Trafficability Assessment of Deformable Terrain through Hybrid Wheel-Leg Sinkage Detection},
       publisher = {Wiley},
            year = {2017},
         journal = {Journal of Field Robotics},
             doi = {10.1002/rob.21645},
           pages = {451--476},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37428/},
        abstract = {Off?road ground mobile robots are widely used in diverse applications, both in terrestrial and planetary environments. They provide an efficient alternative, with lower risk and cost, to explore or to transport materials through hazardous or challenging terrain. However, nongeometric hazards that cannot be detected remotely pose a serious threat to the mobility of such robots. A prominent example of the negative effects these hazards can have is found on planetary rover exploration missions. They can cause a serious degradation of mission performance at best and complete immobilization and mission failure at worst. To tackle this issue, the work presented in this paper investigates the novel application of an existing enhanced?mobility locomotion concept, a hybrid wheel?leg equipped by a lightweight micro?rover, for in situ characterization of deformable terrain and online detection of nongeometric hazards. This is achieved by combining an improved vision?based approach and a new ranging?based approach to wheel?leg sinkage detection. In addition, the paper proposes an empirical model, and a parametric generalization, to predict terrain trafficability based on wheel?leg sinkage and a well?established semiempirical terramechanics model. The robustness and accuracy of the sinkage detection methods implemented are tested in a variety of conditions, both in the laboratory and in the field, using a single wheel?leg test bed. The sinkage?trafficability model is developed based on experimental data using this test bed and then validated onboard a fully mobile robot through experimentation on a range of dry frictional soils that covers a wide spectrum of macroscopic physical characteristics.}
}

@inproceedings{lincoln26621,
       booktitle = {15th Conference of the European chapter of the Association for Computational Linguistics},
           month = {April},
           title = {Evaluating persuasion strategies and deep reinforcement learning methods for negotiation dialogue agents},
          author = {Simon Keizer and Markus Guhe and Heriberto Cuayahuitl and Ioannis Efstathiou and Klaus-Peter Engelbrecht and Mihai Dobre and Alex Lascarides and Oliver Lemon},
       publisher = {ACL},
            year = {2017},
        keywords = {ARRAY(0x5649bafe3eb0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26621/},
        abstract = {In this paper we present a comparative evaluation of various negotiation strategies within an online version of the game ?Settlers of Catan?. The comparison is based on human subjects playing games against artificial game-playing
agents (?bots?) which implement different negotiation dialogue strategies, using a chat dialogue interface to negotiate trades. Our results suggest that a negotiation strategy that uses persuasion, as well as a strategy that is trained from data using Deep Reinforcement Learning, both lead to an improved win rate against humans, compared to previous rule-based and supervised learning baseline dialogue negotiators.}
}

@inproceedings{lincoln25828,
           month = {April},
          author = {Peter Lightbody and Marc Hanheide and Tomas Krajnik},
       booktitle = {32nd ACM Symposium on Applied Computing},
           title = {A versatile high-performance visual fiducial marker detection system with scalable identity encoding},
       publisher = {Association for Computing Machinery},
             doi = {10.1145/3019612.3019709},
           pages = {1--7},
            year = {2017},
        keywords = {ARRAY(0x5649bafe3e50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25828/},
        abstract = {Fiducial markers have a wide field of applications in robotics, ranging from external localisation of single robots or robotic swarms, over self-localisation in marker-augmented environments, to simplifying perception by tagging objects in a robot?s surrounding. We propose a new family of circular markers allowing for a computationally efficient detection, identification and full 3D position estimation. A key concept of our system is the separation of the detection and identification steps, where the first step is based on a computationally efficient circular marker detection, and the identification step is based on an open-ended ?Necklace code?, which allows for a theoretically infinite number of individually identifiable markers. The experimental evaluation of the system on a real robot indicates that while the proposed algorithm achieves similar accuracy to other state-of-the-art methods, it is faster by two orders of magnitude and it can detect markers from longer distances.}
}

@article{lincoln23128,
          volume = {27},
          number = {2},
           month = {March},
          author = {Oscar Martinez Mozos and Virginia Sandulescu and Sally Andrews and David Ellis and Nicola Bellotto and Radu Dobrescu and Jose Manuel Ferrandez},
           title = {Stress detection using wearable physiological and sociometric sensors},
       publisher = {World Scientific Publishing},
            year = {2017},
         journal = {International Journal of Neural Systems},
             doi = {10.1142/S0129065716500416},
           pages = {1650041},
        keywords = {ARRAY(0x5649bafdd970)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/23128/},
        abstract = {Stress remains a significant social problem for individuals in modern societies. This paper presents a machine learning approach for the automatic detection of stress of people in a social situation by combining two sensor systems that capture physiological and social responses. We compare the performance using different classifiers including support vector machine, AdaBoost, and k-nearest neighbour. Our experimental results show that by combining the measurements from both sensor systems, we could accurately discriminate between stressful and neutral situations during a controlled Trier social stress test (TSST). Moreover, this paper assesses the discriminative ability of each sensor modality individually and considers their suitability for real time stress detection. Finally, we present an study of the most discriminative features for stress detection.}
}

@inproceedings{lincoln25362,
       booktitle = {Wellbeing AI: From Machine Learning to Subjectivity Oriented Computing (AAAI 2017 Spring Symposium)},
           month = {March},
           title = {ENRICHME integration of ambient intelligence and robotics for AAL},
          author = {Nicola Bellotto and Manuel Fernandez-Carmona and Serhan Cosar},
       publisher = {AAAI},
            year = {2017},
        keywords = {ARRAY(0x5649bb143648)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25362/},
        abstract = {Technological advances and affordability of recent smart sensors, as well as the consolidation of common software platforms for the integration of the latter and robotic sensors, are enabling the creation of complex active and assisted living environments for improving the quality of life of the elderly and the less able people. One such example is the integrated system developed by the European project ENRICHME, the aim of which is to monitor and prolong the independent living of old people affected by mild cognitive impairments with a combination of smart-home, robotics and web technologies. This paper presents in particular the design and technological solutions adopted to integrate, process and store the information provided by a set of fixed smart sensors and mobile robot sensors in a domestic scenario, including presence and contact detectors, environmental sensors, and RFID-tagged objects, for long-term user monitoring and}
}

@inproceedings{lincoln25413,
       booktitle = {AAAI 2017 Spring Symposium - Designing the User Experience of Machine Learning Systems},
           month = {March},
           title = {Portable navigations system with adaptive multimodal interface for the blind},
          author = {Jacobus Lock and Grzegorz Cielniak and Nicola Bellotto},
       publisher = {AAAI},
            year = {2017},
        keywords = {ARRAY(0x5649bb114858)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25413/},
        abstract = {Recent advances in mobile technology have the potential to radically change the quality of tools available for people with sensory impairments, in particular the blind. Nowadays almost every smart-phone and tablet is equipped with high resolutions cameras, which are typically used for photos and videos, communication purposes, games and virtual reality applications. Very little has been proposed to exploit these sensors for user localisation and navigation instead. To this end, the ?Active Vision with Human-in-the-Loop for the Visually Impaired? (ActiVis) project aims to develop a novel electronic travel aid to tackle the ?last 10 yards problem? and enable the autonomous navigation of blind users in unknown environments, ultimately enhancing or replacing existing solutions, such as guide dogs and white canes. This paper describes some of the key project?s challenges, in particular with respect to the design of the user interface that translate visual information from the camera to guiding instructions for the blind person, taking into account limitations due to the visual impairment and proposing a multimodal interface that embeds human-machine co-adaptation.}
}

@article{lincoln33059,
           month = {March},
          author = {Khaled Goher and Sulaiman Fadlallah},
            note = {This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.},
           title = {Bacterial foraging-optimized PID control of a two-wheeled machine with a two-directional handling mechanism},
       publisher = {Springer},
         journal = {Robotics and Biomimetics},
             doi = {10.1186/s40638-017-0057-3},
            year = {2017},
        keywords = {ARRAY(0x5649bafc4068)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33059/},
        abstract = {This paper presents the performance of utilizing a bacterial foraging optimization algorithm on a PID control scheme for controlling a five DOF two-wheeled robotic machine with two-directional handling mechanism. The system under investigation provides solutions for industrial robotic applications that require a limited-space working environment. The system nonlinear mathematical model, derived using Lagrangian modelling approach, is simulated in MATLAB/Simulink? environment. Bacterial foraging-optimized PID control with decoupled nature is designed and implemented. Various working scenarios with multiple initial conditions are used to test the robustness and the system performance. Simulation results revealed the effectiveness of the bacterial foraging-optimized PID control method in improving the system performance compared to the PID control scheme.}
}

@article{lincoln27044,
          volume = {17},
          number = {3},
           month = {March},
          author = {Maha Salem and Astrid Weiss and Paul Baxter},
           title = {New frontiers in human-robot interaction [special section on interdisciplinary human-centred approaches]},
       publisher = {John Benjamins Publishers},
            year = {2017},
         journal = {Interaction Studies},
             doi = {10.1075/is.17.3.05sal},
           pages = {405--407},
        keywords = {ARRAY(0x5649bb1239d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27044/},
        abstract = {-}
}

@article{lincoln33040,
          volume = {22},
          number = {6},
           month = {March},
          author = {Khaled Goher and Kong Chenhui and Sulaiman Fadlallah and Abdullah Al Shabibi and Nabeel Al Rawahi},
           title = {Transient dynamic impact suppression of a Baja chassis using frontal and rear shock absorbers},
       publisher = {Taylor and Francis},
            year = {2017},
         journal = {International Journal of Crashworthiness  ?},
             doi = {10.1080/13588265.2017.1301081},
           pages = {676--688},
        keywords = {ARRAY(0x5649bb132028)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33040/},
        abstract = {This paper investigates the behaviour of impact loading on a Baja vehicle chassis with frontal and rear shock absorbers, using transient dynamic analysis under different assumptions of contact conditions. Using a Baja car, a transient dynamic impact is performed in ANSYS Workbench 14.0, where the maximum deformation, stress and strains are calculated over duration of the particular impact. The mathematical model of the chassis is derived based on Kelvin model in order to design the best parameters of stiffness and damping coefficient in shock absorbers to minimise the deformation of the frame with the same impact. To study the effects of shock absorber under loading on a vehicle chassis, multiple finite element simulations are performed with different methodologies. Each methodology uses a different assumption on loading and boundary conditions, which leads to different results.}
}

@inproceedings{lincoln25866,
           month = {March},
          author = {Marc Hanheide and Denise Hebesberger and Tomas Krajnik},
       booktitle = {Int. Conf. on Human-Robot Interaction (HRI)},
         address = {Vienna},
           title = {The when, where, and how: an adaptive robotic info-terminal for care home residents ? a long-term study},
       publisher = {ACM},
             doi = {10.1145/2909824.3020228},
            year = {2017},
        keywords = {ARRAY(0x5649bb13d420)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25866/},
        abstract = {Adapting to users' intentions is a key requirement for autonomous robots in general, and in care settings in particular. In this paper, a comprehensive long-term study of a mobile robot providing information services to residents, visitors, and staff of a care home is presented with a focus on adapting to the when and where the robot should be offering its services to best accommodate the users' needs. Rather than providing a fixed schedule, the presented system takes the opportunity of long-term deployment to explore the space of possibilities of interaction while concurrently exploiting the model learned to provide better services. But in order to provide effective services to users in a care home, not only then when and where are relevant, but also the way how the information is provided and accessed. Hence, also the usability of the deployed system is studied specifically, in order to provide a most comprehensive overall assessment of a robotic info-terminal implementation in a care setting. Our results back our hypotheses, (i) that learning a spatiotemporal model of users' intentions improves efficiency and usefulness of the system, and (ii) that the specific information sought after is indeed dependent on the location the info-terminal is offered.}
}

@inproceedings{lincoln30192,
           month = {March},
          author = {Emmanuel Senft and Severin Lemaignan and Paul E. Baxter and Tony Belpaeme},
       booktitle = {ACM/IEEE International Conference on Human-Robot Interaction - HRI '17},
         address = {Vienna, Austria},
           title = {Leveraging human inputs in interactive machine learning for human robot interaction},
             doi = {10.1145/3029798.3038385},
           pages = {281--282},
            year = {2017},
        keywords = {ARRAY(0x5649bb134550)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/30192/},
        abstract = {A key challenge of HRI is allowing robots to be adaptable, especially as robots are expected to penetrate society at large and to interact in unexpected environments with non- technical users. One way of providing this adaptability is to use Interactive Machine Learning, i.e. having a human supervisor included in the learning process who can steer the action selection and the learning in the desired direction. We ran a study exploring how people use numeric rewards to evaluate a robot's behaviour and guide its learning. From the results we derive a number of challenges when design- ing learning robots: what kind of input should the human provide? How should the robot communicate its state or its intention? And how can the teaching process by made easier for human supervisors?}
}

@inproceedings{lincoln25867,
       booktitle = {Proc ACM/IEEE Int. Conf. on Human-Robot Interaction (HRI) Late Breaking Reports},
           month = {March},
           title = {Patterns of use: how older adults with progressed dementia interact with a robot},
          author = {Denise Hebesberger and Christian Dondrup and Christoph Gisinger and Marc Hanheide},
         address = {Vienna},
       publisher = {ACM/IEEE},
            year = {2017},
        keywords = {ARRAY(0x5649bb13d4f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25867/},
        abstract = {Older adults represent a new user group of robots that are deployed in their private homes or in care facilities. In the presented study tangible aspects of older adults' interaction with an autonomous robot were focused. The robot was deployed as a companion in physical therapy for older adults with progressed dementia. Interaction was possible via a mounted touch screen. The menu was structured in a single layer and icons were big and with strong contrast. Employing a detailed observation protocol, interaction frequencies and contexts were assessed. Thereby, it was found that most of the interaction was encouraged by the therapists and that two out of 12 older adults with progressed dementia showed self-inducted interactions.}
}

@article{lincoln25744,
          volume = {41},
          number = {3},
           month = {March},
          author = {G. J. Maeda and G. Neumann and M. Ewerton and R. Lioutikov and O. Kroemer and J. Peters},
            note = {Special Issue on Assistive and Rehabilitation Robotics},
           title = {Probabilistic movement primitives for coordination of multiple human?robot collaborative tasks},
       publisher = {Springer},
            year = {2017},
         journal = {Autonomous Robots},
             doi = {10.1007/s10514-016-9556-2},
           pages = {593--612},
        keywords = {ARRAY(0x5649bb13d510)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25744/},
        abstract = {This paper proposes an interaction learning method for collaborative and assistive robots based on movement primitives. The method allows for both action recognition and human?robot movement coordination. It uses imitation learning to construct a mixture model of human?robot interaction primitives. This probabilistic model allows the assistive trajectory of the robot to be inferred from human observations. The method is scalable in relation to the number of tasks and can learn nonlinear correlations between the trajectories that describe the human?robot interaction. We evaluated the method experimentally with a lightweight robot arm in a variety of assistive scenarios, including the coordinated handover of a bottle to a human, and the collaborative assembly of a toolbox. Potential applications of the method are personal caregiver robots, control of intelligent prosthetic devices, and robot coworkers in factories.}
}

@article{lincoln25239,
          volume = {88},
           month = {February},
          author = {Tomas Krajnik and Pablo Cristoforis and Keerthy Kusumam and Peer Neubert and Tom Duckett},
           title = {Image features for visual teach-and-repeat navigation in changing environments},
       publisher = {Elsevier},
            year = {2017},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2016.11.011},
           pages = {127--141},
        keywords = {ARRAY(0x5649bb13d558)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25239/},
        abstract = {We present an evaluation of standard image features in the context of long-term visual teach-and-repeat navigation of mobile robots, where the environment exhibits significant changes in appearance caused by seasonal weather variations and daily illumination changes. We argue that for long-term autonomous navigation, the viewpoint-, scale- and rotation- invariance of the standard feature extractors is less important than their robustness to the mid- and long-term environment appearance changes. Therefore, we focus our evaluation on the robustness of image registration to variable lighting and naturally-occurring seasonal changes. We combine detection and description components of different image extractors and evaluate their performance on five datasets collected by mobile vehicles in three different outdoor environments over the course of one year. Moreover, we propose a trainable feature descriptor based on a combination of evolutionary algorithms and Binary Robust Independent Elementary Features, which we call GRIEF (Generated BRIEF). In terms of robustness to seasonal changes, the most promising results were achieved by the SpG/CNN and the STAR/GRIEF feature, which was slightly less robust, but faster to calculate.}
}

@article{lincoln25412,
          volume = {88},
           month = {February},
          author = {Jo{\~a}o Machado Santos and Tom{\'a}{\v s} Krajn{\'i}k and Tom Duckett},
           title = {Spatio-temporal exploration strategies for long-term autonomy of mobile robots},
       publisher = {Elsevier},
            year = {2017},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2016.11.016},
           pages = {116--126},
        keywords = {ARRAY(0x5649bb11e360)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25412/},
        abstract = {We present a study of spatio-temporal environment representations and exploration strategies for long-term deployment of mobile robots in real-world, dynamic environments. We propose a new concept for life-long mobile robot spatio-temporal exploration that aims at building, updating and maintaining the environment model during the long-term deployment. The addition of the temporal dimension to the explored space makes the exploration task a never-ending data-gathering process, which we address by application of information-theoretic exploration techniques to world representations that model the uncertainty of environment states as probabilistic functions of time. We evaluate the performance of different exploration strategies and temporal models on real-world data gathered over the course of several months. The combination of dynamic environment representations with information-gain exploration principles allows to create and maintain up-to-date models of continuously changing environments, enabling efficient and self-improving long-term operation of mobile robots.}
}

@inproceedings{lincoln25360,
       booktitle = {VISAPP - International Conference on Computer Vision Theory and Applications},
           month = {February},
           title = {Volume-based human re-identification with RGB-D cameras},
          author = {Serhan Cosar and Claudio Coppola and Nicola Bellotto},
            year = {2017},
        keywords = {ARRAY(0x5649bb11e3d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25360/},
        abstract = {This paper presents an RGB-D based human re-identification approach using novel biometrics features from the body's volume. Existing work based on RGB images or skeleton features have some limitations for real-world robotic applications, most notably in dealing with occlusions and orientation of the user. Here, we propose novel features that allow performing re-identification when the person is facing side/backward or the person is partially occluded. The proposed approach has been tested for various scenarios including different views, occlusion and the public BIWI RGBD-ID dataset.}
}

@inproceedings{lincoln25361,
           month = {February},
          author = {Daniele Liciotti and Tom Duckett and Nicola Bellotto and Emanuele Frontoni and Primo Zingaretti},
       booktitle = {ICPRAM - 6th International Conference on Pattern Recognition Applications and Methods},
           title = {HMM-based activity recognition with a ceiling RGB-D camera},
       publisher = {Science and Technology Publications},
             doi = {10.5220/0006202305670574},
           pages = {567--574},
            year = {2017},
        keywords = {ARRAY(0x5649bb13d450)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25361/},
        abstract = {Automated recognition of Activities of Daily Living allows to identify possible health problems and apply corrective strategies in Ambient Assisted Living (AAL). Activities of Daily Living analysis can provide very useful information for elder care and long-term care services. This paper presents an automated RGB-D video analysis system that recognises human ADLs activities, related to classical daily actions. The main goal is to predict the probability of an analysed subject action. Thus, the abnormal behaviour can be detected. The activity detection and recognition is performed using an affordable RGB-D camera. Human activities, despite their unstructured nature, tend to have a natural hierarchical structure; for instance, generally making a coffee involves a three-step process of turning on the coffee machine, putting sugar in cup and opening the fridge for milk. Action sequence recognition is then handled using a discriminative Hidden Markov Model (HMM). RADiaL, a dataset with RGB-D images and 3D position of each person for training as well as evaluating the HMM, has been built and made publicly available.}
}

@article{lincoln39217,
          volume = {18},
          number = {3},
           month = {February},
          author = {Xanthoula Eirini Pantazi and Dimitrios Moshou and Roberto Oberti and Jon West and Abdul Mounem Mouazen and Dionysis Bochtis},
           title = {Detection of biotic and abiotic stresses in crops by using hierarchical self organizing classifiers},
            year = {2017},
         journal = {Precision Agriculture},
             doi = {doi:10.1007/s11119-017-9507-8},
           pages = {383--393},
        keywords = {ARRAY(0x5649bb143118)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39217/},
        abstract = {Hyperspectral signatures can provide abundant information regarding health status of crops; however it is difficult to discriminate between biotic and abiotic stress. In this study, the case of simultaneous occurrence of yellow rust disease symptoms and nitrogen stress was investigated by using hyperspectral features from a ground based hyperspectral imaging system. Hyperspectral images of healthy and diseased plant canopies were taken at Rothamsted Research, UK by a Specim V10 spectrograph. Five wavebands of 20 nm width were utilized for accurate identification of each of the stress and healthy plant conditions. The technique that was developed used a hybrid classification scheme consisting of hierarchical self organizing classifiers. Three different architectures were considered: counter-propagation artificial neural networks, supervised Kohonen networks (SKNs) and XY-fusion. A total of 12 120 spectra were collected. From these 3 062 (25.3\%) were used for testing. The results of biotic and abiotic stress identification appear to be promising, reaching more than 95\% for all three architectures. The proposed approach aimed at sensor based detection of diseased and stressed plants so that can be treated site specifically contributing to a more effective and precise application of fertilizers and fungicides according to specific plant?s needs.}
}

@inproceedings{lincoln33062,
           month = {February},
          author = {Khaled Goher and Amur Al Yahmadi},
       booktitle = {IEEE-EMBS Conference on Biomedical Engineering and Sciences},
           title = {Kinematic Analysis of the Sit-to-Stand Mechanism of a Reconfigurable Wheelchair},
       publisher = {IEEE},
             doi = {10.1109/iecbes.2016.7843558},
           pages = {788--791},
            year = {2017},
        keywords = {ARRAY(0x5649bb1146d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/33062/},
        abstract = {In this paper; the authors presents kinematics analysis of a sit to stand mechanism of a reconfigurable wheelchair. A reconfigurable wheelchair is a device designed and built for the purpose of rehabilitation and self-assistance for a disabled 25 kg child. In addition to the sit-to-stand facility; the developed wheelchair has two additional features: upper body laying by adjusting the back seat and knee and ankle exercising mechanism. This flexible configuration will allow the user to use the wheelchair as a mobility device as well as for rehabilitation purposes without need any external support.  The mechanism is identified and a position analysis for the transform between sit to stand posture is obtained. MATLAB software is used to simulate the pattern of motion of both the input link and the follower. Proceeding in the investigation, velocity and acceleration analyses are derived for the reconfigurable wheelchair. Based on the previous analysis, the linear velocity and acceleration equations of the moving links are obtained.}
}

@inproceedings{lincoln26739,
       booktitle = {Thirty-First AAAI Conference on Artificial Intelligence},
           month = {February},
           title = {The kernel Kalman rule: efficient nonparametric inference with recursive least squares},
          author = {G. H. W. Gebhardt and A. Kupcsik and G. Neumann},
       publisher = {AAAI},
            year = {2017},
        keywords = {ARRAY(0x5649bb147170)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26739/},
        abstract = {Nonparametric inference techniques provide promising tools
for probabilistic reasoning in high-dimensional nonlinear systems.
Most of these techniques embed distributions into reproducing
kernel Hilbert spaces (RKHS) and rely on the kernel
Bayes? rule (KBR) to manipulate the embeddings. However,
the computational demands of the KBR scale poorly
with the number of samples and the KBR often suffers from
numerical instabilities. In this paper, we present the kernel
Kalman rule (KKR) as an alternative to the KBR. The derivation
of the KKR is based on recursive least squares, inspired
by the derivation of the Kalman innovation update. We apply
the KKR to filtering tasks where we use RKHS embeddings
to represent the belief state, resulting in the kernel Kalman filter
(KKF). We show on a nonlinear state estimation task with
high dimensional observations that our approach provides a
significantly improved estimation accuracy while the computational
demands are significantly decreased.}
}

@inproceedings{lincoln26740,
       booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
           month = {February},
           title = {Policy search with high-dimensional context variables},
          author = {V. Tangkaratt and H. van Hoof and S. Parisi and G. Neumann and J. Peters and M. Sugiyama},
       publisher = {Association for the Advancement of Artificial Intelligence},
            year = {2017},
        keywords = {ARRAY(0x5649bb1471b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26740/},
        abstract = {Direct contextual policy search methods learn to improve policy
parameters and simultaneously generalize these parameters
to different context or task variables. However, learning
from high-dimensional context variables, such as camera images,
is still a prominent problem in many real-world tasks.
A naive application of unsupervised dimensionality reduction
methods to the context variables, such as principal component
analysis, is insufficient as task-relevant input may be ignored.
In this paper, we propose a contextual policy search method in
the model-based relative entropy stochastic search framework
with integrated dimensionality reduction. We learn a model of
the reward that is locally quadratic in both the policy parameters
and the context variables. Furthermore, we perform supervised
linear dimensionality reduction on the context variables
by nuclear norm regularization. The experimental results
show that the proposed method outperforms naive dimensionality
reduction via principal component analysis and
a state-of-the-art contextual policy search method.}
}

@article{lincoln25963,
          volume = {5},
           month = {February},
          author = {Jiawei Xu and Shigang Yue and Federica Menchinelli and Kun Guo},
           title = {What has been missed for predicting human attention in viewing driving clips?},
       publisher = {PeerJ},
            year = {2017},
         journal = {PeerJ},
             doi = {10.7717/peerj.2946},
           pages = {e2946},
        keywords = {ARRAY(0x5649bb1472c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25963/},
        abstract = {Recent research progress on the topic of human visual attention allocation in scene perception and its simulation is based mainly on studies with static images. However, natural vision requires us to extract visual information that constantly changes due to egocentric movements or dynamics of the world. It is unclear to what extent spatio-temporal regularity, an inherent regularity in dynamic vision, affects human gaze distribution and saliency computation in visual attention models. In this free-viewing eye-tracking study we manipulated the spatio-temporal regularity of traffic videos by presenting them in normal video sequence, reversed video sequence, normal frame sequence, and randomised frame sequence. The recorded human gaze allocation was then used as the ?ground truth? to examine the predictive ability of a number of state-of-the-art visual attention models. The analysis revealed high inter-observer agreement across individual human observers, but all the tested attention models performed significantly worse than humans. The inferior predictability of the models was evident from indistinguishable gaze prediction irrespective of stimuli presentation sequence, and weak central fixation bias. Our findings suggest that a realistic visual attention model for the processing of dynamic scenes should incorporate human visual sensitivity with spatio-temporal regularity and central fixation bias.}
}

@article{lincoln26731,
          volume = {2},
          number = {2},
           month = {January},
          author = {Takayuki Osa and Amir M. Ghalamzan Esfahani and Rustam Stolkin and Rudolf Lioutikov and Jan Peters and Gerhard Neumann},
           title = {Guiding trajectory optimization by demonstrated distributions},
       publisher = {IEEE},
            year = {2017},
         journal = {IEEE Robotics and Automation Letters (RA-L)},
             doi = {10.1109/LRA.2017.2653850},
           pages = {819--826},
        keywords = {ARRAY(0x5649bb0fa900)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/26731/},
        abstract = {Trajectory optimization is an essential tool for motion
planning under multiple constraints of robotic manipulators.
Optimization-based methods can explicitly optimize a trajectory
by leveraging prior knowledge of the system and have been used
in various applications such as collision avoidance. However, these
methods often require a hand-coded cost function in order to
achieve the desired behavior. Specifying such cost function for
a complex desired behavior, e.g., disentangling a rope, is a nontrivial
task that is often even infeasible. Learning from demonstration
(LfD) methods offer an alternative way to program robot
motion. LfD methods are less dependent on analytical models
and instead learn the behavior of experts implicitly from the
demonstrated trajectories. However, the problem of adapting the
demonstrations to new situations, e.g., avoiding newly introduced
obstacles, has not been fully investigated in the literature. In this
paper, we present a motion planning framework that combines
the advantages of optimization-based and demonstration-based
methods. We learn a distribution of trajectories demonstrated by
human experts and use it to guide the trajectory optimization
process. The resulting trajectory maintains the demonstrated
behaviors, which are essential to performing the task successfully,
while adapting the trajectory to avoid obstacles. In simulated
experiments and with a real robotic system, we verify that our
approach optimizes the trajectory to avoid obstacles and encodes
the demonstrated behavior in the resulting trajectory}
}

@inproceedings{lincoln25919,
       booktitle = {1st Global Power and Propulsion Forum 2017},
           month = {January},
           title = {Model-based compensation of sensor failure in industrial gas turbine},
          author = {Vili Panov and Sepehr Maleki},
       publisher = {Global Power and Propulsion Society},
            year = {2017},
        keywords = {ARRAY(0x5649bb0ceb68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/25919/},
        abstract = {This study investigates application of analytical sensor
redundancy to improve reliability of gas turbine control
system. Analytical redundancy, which uses a reference
engine model to provide redundant estimates of a measured
engine variables, has been utilized as a basis for the proposed
sensor fault detection and accommodation method.
Model-based compensation of measurement fault is
usually resolved by introducing virtual engine sensors, which
are obtained via accurate engine modelling. In this paper, a
real-time dynamic gas turbine engine model is used in order
to generate the redundant virtual measurements. The engine
model accuracy directly determines the validity of the modelbased
approach for sensor fault diagnosis, and hence a model
with auto-tuning capability is deployed as a reference for the
gas turbine.
The proposed fault detection technique examines the
residuals between the redundant channels. Once the
discrepancy between the virtual and the sensor measurement
exceeds the prescribed tolerance levels, the sensor fault
diagnosis determines the state of the switching logic in the
dual lane control configuration. The deployed logic is also
used for reconfiguration of the auto-tuning process. When a
sensor fault occurs, the estimation process is affected, and
hence the tuning process must be adjusted to account for this
deficiency.
Single and multiple sensor failures are simulated during
the gas turbine transient manoeuvre to assess capability of
the proposed model-based detection and accommodation
method. Hard (large in-range) and soft sensor failures (small
in-range or drift) are injected during the numerical simulation
and results are presented.}
}

@article{lincoln24215,
          volume = {9},
          number = {1},
           month = {January},
          author = {James Kennedy and Paul Baxter and Tony Belpaeme},
           title = {Nonverbal immediacy as a characterisation of social behaviour for human-robot interaction},
       publisher = {Springer},
            year = {2017},
         journal = {International Journal of Social Robotics},
             doi = {10.1007/s12369-016-0378-3},
           pages = {109--128},
        keywords = {ARRAY(0x5649bb28b9b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/24215/},
        abstract = {An increasing amount of research has started
to explore the impact of robot social behaviour on the
outcome of a goal for a human interaction partner, such
as cognitive learning gains. However, it remains unclear
from what principles the social behaviour for such robots
should be derived. Human models are often used, but
in this paper an alternative approach is proposed. First,
the concept of nonverbal immediacy from the communication
literature is introduced, with a focus on how it
can provide a characterisation of social behaviour, and
the subsequent outcomes of such behaviour. A literature
review is conducted to explore the impact on learning
of the social cues which form the nonverbal immediacy
measure. This leads to the production of a series
of guidelines for social robot behaviour. The resulting
behaviour is evaluated in a more general context, where
both children and adults judge the immediacy of humans
and robots in a similar manner, and their recall of
a short story is tested. Children recall more of the story
when the robot is more immediate, which demonstrates
an e?ffect predicted by the literature. This study provides
validation for the application of nonverbal immediacy
to child-robot interaction. It is proposed that nonverbal
immediacy measures could be used as a means of
characterising robot social behaviour for human-robot
interaction.}
}

@article{lincoln38410,
          volume = {50},
          number = {12},
          author = {N. Ajmeri and C.-W. Hang and S. Parsons and M.P. Singh},
            note = {cited By 1},
           title = {Aragorn: Eliciting and Maintaining Secure Service Policies},
       publisher = {IEEE},
            year = {2017},
         journal = {Computer},
             doi = {10.1109/MC.2017.4451210},
           pages = {50--58},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38410/},
        abstract = {Services are configured via policies that capture expected behaviors, but stakeholder requirements can change, making policy errors a surprisingly common occurrence. Aragorn applies formal argumentation to produce policies that balance stakeholder concerns.}
}

@article{lincoln38547,
          volume = {36},
          number = {5-7},
          author = {M.Q. Azhar and Elizabeth Sklar},
            note = {cited By 1},
           title = {A study measuring the impact of shared decision making in a human-robot team},
            year = {2017},
         journal = {International Journal of Robotics Research},
             doi = {10.1177/0278364917710540},
           pages = {461--482},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38547/}
}

@inproceedings{lincoln27647,
       booktitle = {IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},
           title = {Automatic detection of human interactions from RGB-D data for social activity classification},
          author = {Claudio Coppola and Serhan Cosar and Diego Faria and Nicola Bellotto},
       publisher = {IEEE},
            year = {2017},
             doi = {10.1109/ROMAN.2017.8172405},
        keywords = {ARRAY(0x5649bb32fa20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/27647/},
        abstract = {We present a system for the temporal detection of social interactions. Many of the works until now have succeeded in recognising activities from clipped videos in datasets, but for robotic applications, it is important to be able to move to more realistic data. For this reason, it is important to be able to detect temporally the intervals of time in which humans are performing an individual activity or a social one. Recognition of the human activities is a key feature for analysing the human behaviour. In particular, recognition of social activities could be useful to trigger human-robot interactions or to detect situations of potential danger. Based on that, this research has three goals: (1) define a new set of descriptors able to represent the phenomena; (2) develop a computational model able to discern the intervals in which a pair of people are interacting or performing individual activities; (3) provide a public dataset with RGB-D videos where social interactions and individual activities happen in a continuous stream. Results show that using the proposed approach allows to reach a good performance in the temporal segmentation of social activities.}
}

@inproceedings{lincoln28779,
       booktitle = {IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)},
           title = {Entropy-based abnormal activity detection fusing RGB-D and domotic sensors},
          author = {Manuel Fernandez-Carmona and Serhan Cosar and Claudio Coppola and Nicola Bellotto},
       publisher = {IEEE},
            year = {2017},
             doi = {10.1109/MFI.2017.8170405},
        keywords = {ARRAY(0x5649bb32d6a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/28779/},
        abstract = {The automatic detection of anomalies in Active and Assisted Living (AAL) environments is important for monitoring the wellbeing and safety of the elderly at home. The integration of smart domotic sensors (e.g. presence detectors) with those ones equipping modern mobile robots (e.g. RGBD camera) provides new opportunities for addressing this challenge. In this paper, we propose a novel solution to combine local activity levels detected by a single RGBD camera with the global activity perceived by a network of domotic sensors. Our approach relies on a new method for computing such a global activity using various presence detectors, based on the concept of entropy from information theory. This entropy effectively shows how active a particular room or environment?s area is. The solution includes also a new application of Hybrid Markov Logic Networks (HMLNs) to merge different information sources for local and global anomaly detection. The system has been tested with RGBD data and a comprehensive domotic dataset containing data entries from 37 different domotic sensors (presence, temperature, light, energy consumption, door contact), which is made publicly available. The experimental results show the effectiveness of our approach and the potential for complex anomaly detection in AAL settings.}
}

@article{lincoln38412,
          volume = {10454},
          author = {Z. Huang and S. Wane and Simon Parsons},
            note = {cited By 3},
           title = {Towards automated strawberry harvesting: Identifying the picking point},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-64107-2{$_1$}{$_8$}},
           pages = {222--236},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38412/}
}

@article{lincoln32866,
          volume = {4},
          number = {1},
          author = {Nazanin Mansouri and Khaled Goher and Seyed Ebrahim Hosseini},
            note = {{\copyright} The Author(s) 2017},
           title = {Ethical framework of assistive devices: review and reflection},
       publisher = {Springer},
            year = {2017},
         journal = {Robotics and Biomimetics},
             doi = {10.1186/s40638-017-0074-2},
        keywords = {ARRAY(0x5649bb321ff0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/32866/},
        abstract = {The population of ageing is growing significantly over the world, and there is an emerging demand for better healthcare services and more care centres. Innovations of Information and Communication Technology has resulted in development of various types of assistive robots to fulfil elderly?s needs and independency, whilst carrying out daily routine tasks. This makes it vital to have a clear understanding of elderly?s needs and expectations from assistive robots. This paper addresses current ethical issues to understand elderly?s prime needs. Also, we consider other general ethics with the purpose of applying these theories to form a proper ethics framework. In the ethics framework, the ethical concerns of senior citizens will be prioritized to satisfy elderly?s needs and also to diminish related expenses to healthcare services.}
}

@article{lincoln38411,
          volume = {271},
          author = {J. Niu and S. Parsons},
            note = {cited By 0},
           title = {A genetic algorithmic approach to automated auction mechanism design},
       publisher = {Springer},
            year = {2017},
         journal = {Lecture Notes in Business Information Processing},
             doi = {10.1007/978-3-319-54229-4\_9},
           pages = {127--142},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38411/},
        abstract = {In this paper, we present a genetic algorithmic approach to automated auction mechanism design in the context of cat games. This is a follow-up to one piece of our prior work in the domain, the reinforcement learning-based grey-box approach [14]. Our experiments show that given the same search space the grey-box approach is able to produce better auction mechanisms than the genetic algorithmic approach. The comparison can also shed light on the design and evaluation of similar search solutions to other domain problems.}
}

@article{lincoln38548,
          number = {978331},
          author = {J. Raphael and Elizabeth Sklar and S. Maskell},
            note = {cited By 1},
           title = {An intersection-centric auction-based traffic signal control framework},
         journal = {Understanding Complex Systems},
             doi = {10.1007/978-3-319-46331-5\_6},
           pages = {121--142},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38548/}
}

@inproceedings{lincoln39635,
       booktitle = {14th Symposium on Advanced Space Technologies in Robotics and Automation,},
           title = {Robust Traction Control and Path Planning Algorithms for Planetary Micro-rover Swarms},
          author = {C.M. Saaj and H. Ibrahim},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39635/}
}

@article{lincoln38549,
          volume = {10454},
          author = {E. Schneider and Elizabeth Sklar and S. Parsons},
            note = {cited By 2},
           title = {Mechanism selection for multi-robot task allocation},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-64107-2},
           pages = {421--435},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38549/}
}

@article{lincoln38413,
          volume = {10454},
          author = {E. Schneider and Elizabeth Sklar and Simon Parsons},
            note = {cited By 2},
           title = {Mechanism selection for multi-robot task allocation},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-64107-2{$_3$}{$_3$}},
           pages = {421--435},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38413/}
}

@unpublished{lincoln39634,
       booktitle = {14th Symposium on Advanced Space Technologies in Robotics and Automation},
           title = {Optimised collision-free trajectory and controller design for robotic manipulators},
          author = { Seddaoui and C. M Saaj},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39634/}
}

@inproceedings{lincoln29189,
          volume = {2017-A},
          author = {X. Zheng and C. Zhang and F. Lv and F. Zhao and S. Yue and Z. Wang and F. Li and H. Jiang and Z. Wang},
            note = {Conference Code:129634},
       booktitle = {38th Annual Custom Integrated Circuits Conference, CICC 2017},
           title = {A 4-40 Gb/s PAM4 transmitter with output linearity optimization in 65 nm CMOS},
       publisher = {Institute of Electrical and Electronics Engineers Inc.},
             doi = {10.1109/CICC.2017.7993640},
            year = {2017},
        keywords = {ARRAY(0x5649bb0978f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/29189/},
        abstract = {This paper presents a 4-40 Gb/s current mode PAM4 transmitter with an optimized eye linearity. By embedding an additional mixed combiner and an extra current source into the output driver and developing a coherent scaled-replica based bias generator, the channel-length modulation caused tail-current variations for both DC and AC coupling modes can be effectively compensated. Implemented in 65 nm CMOS, the transmitter occupies an area of 1.02 mm2 and consumes 102 mW at 40 Gb/s. After applying the proposed linearity optimization, the measured eye linearity can be optimized from 1.28 to 1.01 with a single-end swing of 480 mV in AC coupling mode. {\^A}{\copyright} 2017 IEEE.}
}

@article{lincoln38550,
          volume = {10454},
          author = {Tsvetan Zhivkov and Elizabeth Sklar and E. Schneider},
            note = {cited By 2},
           title = {Measuring the effects of communication quality on multi-robot team performance},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-319-64107-2},
           pages = {408--420},
            year = {2017},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38550/}
}

