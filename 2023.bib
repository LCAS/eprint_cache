@article{lincoln56590,
          volume = {126},
          number = {D},
           month = {November},
          author = {Dmitry Popov and Anatol Pahkevich and Alexandr Klimchik},
           title = {Adaptive technique for physical human?robot interaction handling using proprioceptive sensors},
       publisher = {Elsevier},
            year = {2023},
         journal = {Engineering Applications of Artificial Intelligence},
             doi = {10.1016/j.engappai.2023.107141},
        keywords = {ARRAY(0x55be9b6e5388)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56590/},
        abstract = {The work focuses on the development of an adaptive technique for the physical interaction handling between a human and a robot, as well as its experimental validation. The proposed technique is based on the deep residual neural network and dedicated finite state machine, where the states are the robot behavior modes and transitions are the switchings between the states that depend on the interaction parameters and characteristics. It ensures the human operator safety and improves the human?robot collaboration performance by implementing various scenarios. In the scope of this technique, the parameters of human?robot interaction are used to select an appropriate robot reaction strategy using data from internal robot sensors only, i.e. proprioceptive sensors. These parameters define the interaction force vector and its application point on the robot surface, which allow to classify the interaction within the set of predefined categories. This classification distinguishes interactions applied at the tool or intermediate link (Tool/Link), having soft or hard nature (Soft/Hard), as well as having different intention (Intl/Accd) or duration (Short/Long). Based on identified category and the current robot state, the algorithm chooses an appropriate robot reaction. To confirm the efficiency the developed technique, an experimental study was conducted, which involved the collaboration between the real industrial manipulator KUKA LBR iiwa and the human operator.}
}

@article{lincoln55015,
          volume = {72},
          number = {8},
           month = {October},
          author = {Mithun Poozhiyil and Manu Nair and Mini Rai and Alexander Hall and Connor Meringolo and Mark Shilton and Steven Kay and Danilo Forte and Martin Sweeting and Nikki Antoniou and Victoria Irwin},
           title = {Active Debris Removal: A Review and Case Study on LEOPARD Phase 0-A Mission},
       publisher = {Elsevier},
            year = {2023},
         journal = {Advances in Space Research},
             doi = {10.1016/j.asr.2023.06.015},
        keywords = {ARRAY(0x55be9b6ce630)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55015/},
        abstract = {The growing number of space debris is alarming as it threatens space-borne services. Hence, there is an increasing demand to remove space debris to ensure sustainability and protect valuable orbital assets. Over the past few years, the research community, agencies and industries have studied many passive and active debris removal methods. However, the current technology readiness for space debris removal is still low. This paper first presents a comparative study of various space debris removal technologies to address the knowledge gap and quantify the challenges. This paper reviews the current state-of-the-art space technologies relevant to Active Debris Removal (ADR) missions. Detailed trade-off analysis is then presented based on the Low Earth Orbit Pursuit for Active Removal of Debris (LEOPARD) Phase 0-A study; this study is part of the United Kingdom (UK) Space Agency?s Active Debris Removal programme. The ADR mission scenario considered in this paper comprises a chaser spacecraft equipped with recommended technologies to capture non-cooperative targets safely. The final capture technology for the LEOPARD mission consists of an active robotic manipulator and a passive net capture mechanism. An analysis of the coupled-body dynamics of the chaser spacecraft carrying the robot manipulator and the targeted debris is carried out in simulation using SimscapeTM. The chaser spacecraft comprises Airbus?s Versatile In-Space and Planetary Arm (VISPA) mounted on a base spacecraft from Surrey Satellite Technology Ltd. (SSTL); the targeted debris is SSTL?s Tactical Operational Satellite (TOPSAT). The simulation results show dynamic changes in the chaser robot and the target satellite while performing non-cooperative capture. The simulation study accounted for various operational scenarios where the target is stationary or in motion. Further, for different modes of operation, the worst-case end-effector capture force limits were determined using open-loop control to execute a safe capture. Overall, the results presented in the paper advance the current state-of-the-art of robotic ADR and offer a significant leap in designing close-range motion and force control for stabilising the coupled multi-body system during capture and post-capture phases. In summary, this paper pinpoints the technological gaps, identifies barriers to realising ADR missions and offers solutions to catalyse technology maturity for protecting the space ecosystem.}
}

@inproceedings{lincoln55399,
       booktitle = {TAROS},
           month = {October},
           title = {Open source hardware robotics interfacing board},
          author = {Kshitij Gaikwad and Rakshit Soni and Charles Fox and Chris Waltham},
            year = {2023},
        keywords = {ARRAY(0x55be9b69d4d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55399/},
        abstract = {Robotics research still struggles with reproducibility. The ROS ecosystem  enables reuse of software, but not hardware. Researchers waste time porting systems between hardware platforms to reproduce research between labs.  Researchers in developing counties in particular often cannot afford the proprietary robots used by others. If a published robotics system is dependent on any component that is only available from a single supplier, then all work building on it is at risk if that supplier vanishes, de-lists or changes the product. Open Source Hardware (OSH, {$\backslash$}cite\{pearce2012building\}) is hardware whose designs and build instructions are public, easy, and low-cost so that anyone is free to build and modify them, enabling large community collaborations.  Combined open software and hardware stacks allow any researcher to download, build, exactly replicate, then extend the published work which they read about.}
}

@inproceedings{lincoln55400,
       booktitle = {TAROS},
           month = {October},
           title = {Skid-steer friction calibration protocol for digital twin creation},
          author = {Rachel Trimble and Charles Fox},
            year = {2023},
        keywords = {ARRAY(0x55be9b6bf080)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55400/},
        abstract = {Mobile robots require digital twins to test and learn algorithms while minimising the difficulty, expense and risk of physical trials.  Most mobile robots use wheels, which are notoriously difficult to simulate accurately due to friction.  Physics engines approximate complex tribology using simplified models which can result in unrealistic behaviors such as  inability to turn or sliding sideways down small slopes.  Methods exist to characterise friction properties of skid steer vehicles {$\backslash$}cite\{khaleghian2017technical\} but use has been limited because they require expensive measurement equipment or physics  models not available in common simulators.  We present a new simple protocol to obtain dynamic friction parameters from physical four-wheeled skid-steer robots for use in the Gazebo robot simulator using ODE (Open Dynamics Engine), assuming only that calibrated IMU (Inertial Measurement Unit) and odometry, and vehicle and wheel weights and geometry are available.}
}

@inproceedings{lincoln56560,
           month = {September},
          author = {Harry Rogers and Beatriz De La Iglesia and Tahmina Zebin and Grzegorz Cielniak and Ben Magri},
       booktitle = {2023 IEEE 19th International Conference on Automation Science and Engineering (CASE)},
           title = {An Agricultural Precision Sprayer Deposit Identification System},
       publisher = {IEEE},
             doi = {10.1109/CASE56687.2023.10260374},
           pages = {1--6},
            year = {2023},
        keywords = {ARRAY(0x55be9b6fcc08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56560/},
        abstract = {Data-driven Artificial Intelligence systems are playing an increasingly significant role in the advancement of precision agriculture. Currently, precision sprayers lack fully automated methods to evaluate the effectiveness of their operation, e.g. whether spray has landed on target weeds. In this paper, using an agricultural spot spraying system images were collected from an RGB camera to locate spray deposits on weeds or lettuces. We present an interpretable deep learning pipeline to identify spray deposits on lettuces and weeds without using existing methods such as tracers or water-sensitive papers. We implement a novel stratification and sampling methodology to improve results from a baseline. Using a binary classification head after transfer learning networks, spray deposits are identified with over 90\% Area Under the Receiver Operating Characteristic (AUROC). This work offers a data-driven approach for an automated evaluation methodology for the effectiveness of precision sprayers.}
}

@inproceedings{lincoln56559,
           month = {September},
          author = {Fetullah Atas and Grzegorz Cielniak and Lars Grimstad},
       booktitle = {European Conference on Mobile Robots (ECMR)},
           title = {Navigating in 3D Uneven Environments through Supervoxels and Nonlinear MPC},
       publisher = {IEEE},
             doi = {10.1109/ECMR59166.2023.10256342},
           pages = {1--8},
            year = {2023},
        keywords = {ARRAY(0x55be9b433bc0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56559/},
        abstract = {Navigating uneven and rough terrains presents difficulties, including stability, traversability, sensing, and robustness, making autonomous navigation in these terrains a challenging task. This study introduces a new approach for mobile robots to navigate uneven terrains. The method uses a compact graph of traversable regions on point cloud maps, created through the utilization of supervoxel representation of point clouds. By using this supervoxel graph, the method navigates the robot to any reachable goal pose by utilizing a navigation function and Nonlinear Model Predictive Controller (NMPC). The NMPC ensures kinodynamically feasible and collision-free motion plans, while the supervoxel-based geometric planning generates near-optimal plans by exploiting the terrain information. We conducted extensive navigation experiments in real and simulated 3D uneven terrains and found that the approach performs reliably. Additionally, we compared resulting motion plans to some state-of-the-art sampling-based motion planners in which our method outperformed them in terms of execution time and resulting path lengths. The method can also be adapted to meet specific behavior, like the shortest route or the path with the least slope route. The source code is available in a GitHub repository.}
}

@inproceedings{lincoln56036,
       booktitle = {European Conference on Mobile Robots (ECMR)},
           month = {September},
           title = {Learned Long-Term Stability Scan Filtering for Robust Robot Localisation in Continuously Changing Environments},
          author = {Ibrahim Hroob and Sergio Molina Mellado and Riccardo Polvara and Grzegorz Cielniak and Marc Hanheide},
       publisher = {IEEE},
            year = {2023},
             doi = {10.1109/ECMR59166.2023.10256419},
        keywords = {ARRAY(0x55be9b329ec8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56036/},
        abstract = {In field robotics, particularly in the agricultural sector, precise localization presents a challenge due to the constantly changing nature of the environment. Simultaneous Localization and Mapping algorithms can provide an effective estimation of a robot?s position, but their long-term performance may be impacted by false data associations. Additionally, alternative strategies such as the use of RTK-GPS can also have limitations, such as dependence on external infrastructure. To address these challenges, this paper introduces a novel stability scan filter. This filter can learn and infer the motion status of objects in the environment, allowing it to identify the most stable objects and use them as landmarks for robust robot localization in a continuously changing environment. The proposed method involves an unsupervised point-wise labelling of LiDAR frames by utilizing temporal observations of the environment, as well as a regression network called Long-Term Stability Network (LTSNET) to learn and infer 3D LiDAR points long-term motion status. Experiments demonstrate the ability of the stability scan filter to infer the motion stability of objects on a real agricultural long-term dataset. Results show that by only utilizing points belonging to long-term stable objects, the localization system exhibits reliable and robust localization performance for longterm missions compared to using the entire LiDAR frame points.}
}

@inproceedings{lincoln56743,
       booktitle = {The WRC Symposium on Advanced Robotics and Automation, China 2023},
           month = {September},
           title = {Developing a Comprehensive Model for the Prevention of Tension Neck Syndrome: A Focus on Musculoskeletal Disorder Prevention Strategies},
          author = {Behnaz Sohani and Adigun Ifeoluwa Joshua and Aliyu Aliyu and Amir Rahmani and Goher Khaled},
       publisher = {IEEE Xplore},
            year = {2023},
             doi = {10.1109/WRCSARA60131.2023.10261803},
        keywords = {ARRAY(0x55be9b6b13a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56743/},
        abstract = {Tension Neck Syndrome Musculoskeletal Disorder (TNS MSD) causes discomfort in the muscles around the neck and shoulder, especially of the elderly. It is one of the leading causes of early retirement. This paper provides initial results on the e?cacy of a novel ergonomic-oriented neck support designed to mitigate and alleviate TNS MSD and focuses on the design of an adaptive neck supporter by integrating a soft actuator massager to help deliver a soothing massage. The design was carried out using simulations, prototyping, and measurements.  The massager and adaptive neck supporter prototype were validated by Finite Element Analysis prior to fabrication to assess the feasibility of the design concept. After the massager prototype was fabricated, it was tested to validate the initial concept. Future work will be focused on fabricating the full-scale adaptive neck supporter prototype as well as upgrading and optimising the design concept.}
}

@inproceedings{lincoln56545,
       booktitle = {14th International Conference, ICVS 2023},
           month = {September},
           title = {Key Point-Based Orientation Estimation of Strawberries for Robotic Fruit Picking},
          author = {Justin Le Louedec and Grzegorz Cielniak},
       publisher = {Springer Cham},
            year = {2023},
             doi = {10.1007/978-3-031-44137-0\_13},
        keywords = {ARRAY(0x55be9b40f380)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56545/},
        abstract = {Selective robotic harvesting can help address labour shortages affecting modern global agriculture. For an accurate and efficient picking process, a robotic harvester requires the precise location and orientation of the fruit to effectively plan the trajectory of the end effector. The current methods for estimating fruit orientation employ either complete 3D information registered from multiple views or rely on fully-supervised learning techniques, requiring difficult-to-obtain manual annotation of the reference orientation. In this paper, we introduce a novel key-point-based fruit orientation estimation method for the prediction of 3D orientation from 2D images directly. The proposed technique can work without full 3D orientation annotations but can also exploit such information for improved accuracy. We evaluate our work on two separate datasets of strawberry images obtained from real-world scenarios. Our method achieves state-of-the-art performance with an average error as low as 8?, improving predictions by {$\sim$}30\% compared to previous work presented in [18]. Furthermore, our method is suited for real-time robotic applications with fast inference times of {$\sim$}30ms.}
}

@inproceedings{lincoln55016,
       booktitle = {Future Steel Forum},
           month = {September},
           title = {Green Steel: A New Frontier for In-Space Manufacturing and Circular Economy},
          author = {Mini Rai and Dirk Schaefer and Manu Nair and Mithun Poozhiyil and Shan Dulanty},
            year = {2023},
        keywords = {ARRAY(0x55be9b35a8d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55016/},
        abstract = {Since the launch of Sputnik in 1957, chrome and nickel steel alloys have been widely used for building satellites and launchers for manned and unmanned missions. Their high resistance to extreme temperatures makes them ideal for spacecraft heatshields. The James Webb Space telescope used steel molds to construct its 6.5m primary mirror containing pressed beryllium powder. Steel tubes are also used for building a telescope?s cooling system. Likewise, solar sails use steel booms to ensure proper deployment. Various other sub-systems on board the International Space Station and other spacecraft are made of steel and other high-value materials.  These examples give an insight into the application of steel and its unprecedented needs in the booming Space industry.
Although humankind continues to benefit tremendously from advancements in Space Science and Technology, there is a growing concern over space sustainability. Millions of Space debris, large and small, orbiting Earth threaten the space ecosystem. To address this alarming issue, many investors, regulators and insurers have stepped in to support Active Debris Removal missions to clean up Space. However, the current approach is to deorbit space debris, but the remnants returned to Earth are non-biodegradable objects, polluting the oceans and affecting marine lives. Space trash is an immense resource that should be reused for manufacturing newer systems in orbit. The feedstock needed for on-demand manufacturing of new or replacement parts and components can be produced by recycling materials in orbit, including those previously used for packaging or current space debris. This includes the abundance of steel and other metals on the orbiting space debris. However, research on recycling space debris and additive manufacturing in Space is still in its infancy, hindering the goal of achieving an in-space circular economy. 
Considering the importance of net-zero manufacturing on the ground and in Space, recycling materials from space debris for on-demand manufacturing in orbit would be environmentally friendly and economically profitable. This paper presents the technological challenges in recovering and reusing steel and other high-value materials floating around the Earth?s orbits. Further, the benefits of in-orbit recycling operations for implementing on-demand design and fabrication services will be introduced. The state-of-the-art additive manufacturing in Space, the technological gaps, and the step towards manufacturing green steel from space debris will be covered. Such capabilities will significantly reduce launch costs and carbon footprint by decreasing the number of launches and the need for ground-based fabrication. The paradigm shift toward in-space manufacturing aligns well with our curiosity to continue to explore the universe and improve lives on Earth whilst achieving a sustainable circular economy on Earth and in Space.}
}

@inproceedings{lincoln56183,
       booktitle = {TAROS},
           month = {September},
           title = {An assessment of self-supervised learning for data efficient potato instance segmentation},
          author = {Bradley Hurst and Nicola Bellotto and Petra Bosilj},
       publisher = {Springer},
            year = {2023},
        keywords = {ARRAY(0x55be9b2f17b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56183/},
        abstract = {This work examines the viability of self-supervised learning approaches in the field of agri-robotics, specifically focusing on the segmentation of densely packed potato tubers in storage. The work assesses the impact of both the quantity and quality of data on self-supervised training, employing a limited set of both annotated and unannotated data. Mask R-CNN with a ResNet50 backbone is used for instance segmentation to evaluate self-supervised training performance. The results indicate that the self-supervised methods employed have a modest yet beneficial impact on the downstream task. A simpler approach yields more effective results with a larger dataset, whereas a more intricate method shows superior performance with a refined, smaller self-supervised dataset.}
}

@inproceedings{lincoln56229,
       booktitle = {The 23rd Towards Autonomous Robotic Systems (TAROS) Conference},
           month = {September},
           title = {Towards an Abstract Lightweight Multi-robot ROS Simulator for Rapid Experimentation},
          author = {Laurence Roberts-Elliott and Gautham Das and Alan Millard},
            year = {2023},
        keywords = {ARRAY(0x55be9b2e8358)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56229/},
        abstract = {Modern robot simulators are commonly highly complex, offering 3D graphics, and simulation of physics, sensors, and actuators. The computational complexity of simulating large multi-robot systems in these simulators can be prohibitively high. To achieve faster-than-realtime simulation of a multi-robot system for rapid experimentation, we present `move\_base\_abstract', a ROS package providing a high-level abstraction of robot navigation as a ``drop-in'' replacement for the standard `move\_base' navigation, and a bespoke integrated minimal simulator. This bespoke simulator is compatible with ROS and strips the simulation of robots down to the representation of robot poses in 2D space, control of robots via navigation goals, and control of simulation time over ROS topic messages.
Replication of an existing MRS simulated study using `move\_base\_abstract' executed 2.87 times faster than the real-time that was simulated in the study, and analysis of the results of this replication shows room for further optimisations.}
}

@inproceedings{lincoln55397,
       booktitle = {TAROS},
           month = {September},
           title = {Evaluation of OSMC open source motor driver{$\backslash$}{$\backslash$} for reproducible robotics research},
          author = {Elijah Alabi and Fanta Camara and Charles Fox},
            year = {2023},
        keywords = {ARRAY(0x55be9b402e10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55397/},
        abstract = {There is a growing need for open source hardware subcomponents to be evaluated.  Most robotic systems are ultimately based upon motors which are driven to move either to certain positions, as in robot arms, or to certain velocities, as in wheeled mobile robots. We evaluate a state of the art OSH driver, OSMC, for such systems, and contribute new Open Source Software (OSS) to control it. Our findings suggest that OSMC is now mature enough to replace closed-source motor drivers in medium-size robots such as agri-robots and last mile delivery vehicles.}
}

@inproceedings{lincoln55398,
       booktitle = {TAROS},
           month = {September},
           title = {Simultaneous Base and Arm Trajectories for Multi-Target Mobile Agri-Robot},
          author = {Josh Davy and Charles Fox},
       publisher = {TAROS},
            year = {2023},
        keywords = {ARRAY(0x55be9b48f630)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55398/},
        abstract = {Many agricultural robotics tasks require an end effector to hold stationary above individual plants in the field for short periods. Examples include precision harvesting, imaging and spraying. This  effector may be mounted on a mobile base such as a large tractor or small robot, driving in the field.  We consider how to optimise control of the base and the end actuator together, to minimise total time taken to visit the plants.  Our approach is based on low level combination of simple motion primitives, with mid level target clustering, and higher level planning. For the high level, three strategies are compared and evaluated in simulation: baseline stop-and-spray, constant velocity, and variable velocity. The baseline strategy is common in existing systems, and is shown to be outperformed by the new methods. The application considered here is weed spraying, but the methods are applicable to many tasks.}
}

@article{lincoln56199,
          volume = {7},
          number = {1},
           month = {September},
          author = {Fanta Camara and Chris Waltham and Grey Churchill and Charles Fox},
           title = {OpenPodcar: An Open Source Vehicle for Self-Driving Car Research},
       publisher = {Ubiquity Press},
            year = {2023},
         journal = {Journal of Open Hardware},
             doi = {10.5334/joh.46},
           pages = {1--17},
        keywords = {ARRAY(0x55be9b2a1530)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56199/},
        abstract = {OpenPodcar is a low-cost, open source hardware and software, autonomous vehicle research platform based on an off-the-shelf, hard-canopy, mobility scooter donor vehicle. Hardware and software build instructions are provided to convert the donor vehicle into a low-cost and fully autonomous platform. The open platform consists of (a) hardware components: CAD designs, bill of materials, and build instructions; (b) Arduino, ROS and Gazebo control and simulation software files which provide standard ROS interfaces and simulation of the vehicle; and (c) higher-level ROS software implementations and configurations of standard robot autonomous planning and control, including the move{$\backslash$}\_base interface with Timed-Elastic-Band planner which enacts commands to drive the vehicle from a current to a desired pose around obstacles. The vehicle is large enough to transport a human passenger or similar load at speeds up to 15km/h, for example for use as a last-mile autonomous taxi service or to transport delivery containers similarly around a city center. It is small and safe enough to be parked in a standard research lab and be used for realistic human-vehicle interaction studies. System build cost from new components is around USD7,000 in total in 2022. OpenPodcar thus provides a good balance between real world utility, safety, cost and research convenience.}
}

@article{lincoln55642,
          volume = {212},
          number = {108054},
           month = {September},
          author = {Jonathan Cox and Nikolaos Tsagkopoulos and Zden{\v e}k Rozsyp{\'a}lek and Tom{\'a}{\v s} Krajn{\'i}k and Elizabeth Sklar and Marc Hanheide},
           title = {Visual teach and generalise (VTAG){--}Exploiting perceptual aliasing for scalable autonomous robotic navigation in horticultural environments},
       publisher = {Elsevier},
            year = {2023},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2023.108054},
        keywords = {ARRAY(0x55be9b28fda8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55642/},
        abstract = {Nowadays, most agricultural robots rely on precise and expensive localisation, typically based on global navigation satellite systems (GNSS) and real-time kinematic (RTK) receivers. Unfortunately, the precision of GNSS localisation significantly decreases in environments where the signal paths between the receiver and the satellites are obstructed. This precision hampers deployments of these robots in, e.g., polytunnels or forests. An attractive alternative to GNSS is vision-based localisation and navigation. However, perceptual aliasing and landmark deficiency, typical for agricultural environments, cause traditional image processing techniques, such as feature matching, to fail. We propose an approach for an affordable pure vision-based navigation system which is not only robust to perceptual aliasing, but it actually exploits the repetitiveness of agricultural environments. Our system extends the classic concept of visual teach and repeat to visual teach and generalise (VTAG). Our teach and generalise method uses a deep learning-based image registration pipeline to register similar images through meaningful generalised representations obtained from different but similar areas. The proposed system uses only a low-cost uncalibrated monocular camera and the robot?s wheel odometry to produce heading corrections to traverse crop rows in polytunnels safely. We evaluate this method at our test farm and at a commercial farm on three different robotic platforms where an operator teaches only a single crop row. With all platforms, the method successfully navigates the majority of rows with most interventions required at the end of the rows, where the camera no longer has a view of any repeating landmarks such as poles, crop row tables or rows which have visually different features to that of the taught row. For one robot which was taught one row 25 m long our approach autonomously navigated the robot a total distance of over 3.5 km, reaching a teach-generalisation gain of 140.}
}

@article{lincoln55903,
          volume = {212},
           month = {September},
          author = {Xinzhou Li and Junfeng Gao and Shichao Jin and Chunxin Jiang and Mingming Zhao and Mingzhou Lu},
           title = {Towards robust registration of heterogeneous multispectral UAV imagery: A two-stage approach for cotton leaf lesion grading},
       publisher = {Elsevier},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2023.108153},
            year = {2023},
        keywords = {ARRAY(0x55be9b2bcac0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55903/},
        abstract = {Multiple source images acquired from diverse sensors mounted on unmanned aerial vehicles (UAVs) offer valuable complementary information for ground vegetation analysis. However, accurately aligning heterogeneous UAV images poses challenges due to differences in geometry, intensity, and noise resulting from varying imaging principles. This paper presents a two-stage registration method aimed at fusing visible RGB and multispectral images for cotton leaf lesion grading. The coarse alignment stage utilizes Scale Invariant Feature Transform (SIFT), while the refined alignment stage employs a novel correlation coefficient-based template matching. The proposed method first employs the EfficientDet network to detect infected cotton leaves with lesions in RGB images. Subsequently, lesion leaves in multiple spectral imagery (red, green, red edge, and near-infrared bands) are located using the perspective transformation matrix derived from SIFT and the coordinates of lesion leaves in RGB images. Refined registration between RGB and multispectral imagery is achieved through template matching with the new correlation coefficient. The registered reflectance data from the different spectral bands and RGB components are utilized to classify pixels in each infected leaf into lesion, healthy, and soil parts. The lesion grade is determined based on the ratio of lesion pixels to the total corresponding leaf area. Experimental results, compared with manual assessment, demonstrate a lesion leaves detection model with a mAP@0.5 of 91.01\% and a leaf lesion grading accuracy of 92.01\%. These results validate the suitability of the proposed method for UAV RGB and multispectral image registration, enabling automated cotton leaf lesion grading.}
}

@article{lincoln56099,
          volume = {23},
          number = {17},
           month = {August},
          author = {Willow Mandil and Kiyanoush Nazari and Vishnu Rajendran Sugathakumary and Amir Ghalamzan Esfahani},
           title = {Tactile-Sensing Technologies: Trends, Challenges and Outlook in Agri-Food Manipulation},
       publisher = {MDPI},
            year = {2023},
         journal = {Sensors},
             doi = {10.3390/s23177362},
        keywords = {ARRAY(0x55be9b2a5380)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56099/},
        abstract = {Tactile sensing plays a pivotal role in achieving precise physical manipulation tasks and extracting vital physical features. This comprehensive review paper presents an in-depth overview of the growing research on tactile-sensing technologies, encompassing state-of-the-art techniques, future prospects, and current limitations. The paper focuses on tactile hardware, algorithmic complexities, and the distinct features offered by each sensor. This paper has a special emphasis on agri-food manipulation and relevant tactile-sensing technologies. It highlights key areas in agri-food manipulation, including robotic harvesting, food item manipulation, and feature evaluation, such as fruit ripeness assessment, along with the emerging field of kitchen robotics. Through this interdisciplinary exploration, we aim to inspire researchers, engineers, and practitioners to harness the power of tactile-sensing technology for transformative advancements in agri-food robotics. By providing a comprehensive understanding of the current landscape and future prospects, this review paper serves as a valuable resource for driving progress in the field of tactile sensing and its application in agri-food systems.}
}

@article{lincoln56102,
           month = {August},
          author = {Sergio Molina Mellado and Anna Mannucci and Martin Magnusson and Daniel Adolfsson and Henrik Andreasson and Mazin Hamad and Saeed Abdolshah and Ravi Teja Chadalavada and Luigi Palmieri and Timm Linder and Chittaranjan Srinivas Swaminathan and Tomasz Piotr Kucner and Marc Hanheide and Manuel Fernandez-Carmona and Grzegorz Cielniak and Tom Duckett and Federico Pecora and Simon Bokesand and Kai Oliver Arras and Sami Haddadin and Achim J. Lilienthal},
           title = {The ILIAD Safety Stack: Human-Aware Infrastructure-Free Navigation of Industrial Mobile Robots},
       publisher = {Robotics and Automation Society},
         journal = {IEEE Robotics and Automation Magazine},
             doi = {10.1109/MRA.2023.3296983},
           pages = {2--13},
            year = {2023},
        keywords = {ARRAY(0x55be9b672140)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56102/},
        abstract = {Safe yet efficient operation of professional service robots within logistics or production in human-robot shared environments requires a flexible human-aware navigation stack. In this manuscript, we propose the ILIAD safety stack comprising software and hardware designed to achieve safe and efficient motion specifically for industrial vehicles with nontrivial kinematics The stack integrates five interconnected layers for autonomous motion planning and control to enable short- and long-term reasoning. The use-case scenario tested requires an autonomous industrial forklift to safely navigate among pick-and-place locations during normal daily activities involving human workers. Our test-bed in the real world consists of a three-day experiment in a food distribution warehouse. The evaluation is extended in simulation with an ablation study of the impact of different layers to show both the practical and the performance-related impact. The experimental results show a safer and more legible robot when humans are nearby with a trade-off in task efficiency, and that not all layers have the same degree of impact in the system.}
}

@inproceedings{lincoln54568,
       booktitle = {International Joint Conference on Neural Networks (IJCNN)},
           month = {August},
           title = {A Neuro-Symbolic Approach for Enhanced Human Motion Prediction},
          author = {Sariah Mghames and Luca Castri and Marc Hanheide and Nicola Bellotto},
       publisher = {IEEE Xplore},
            year = {2023},
             doi = {10.1109/IJCNN54540.2023.10191970},
        keywords = {ARRAY(0x55be9b2fee88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54568/},
        abstract = {Reasoning on the context of human beings is crucial for many real-world applications especially for those deploying autonomous systems (e.g. robots). In this paper, we present a new approach for context reasoning to further advance the field of human motion prediction. We therefore propose a neuro-symbolic approach for human motion prediction (NeuroSyM), which weights differently the interactions in the neighbourhood by leveraging an intuitive technique for spatial representation called Qualitative Trajectory Calculus (QTC).
 The proposed approach is experimentally tested on medium and long term time horizons using two architectures from the state of art, one of which is  a baseline for human motion prediction and the other is a baseline for generic multivariate time-series prediction. Six datasets of challenging crowded scenarios, collected from both fixed and mobile cameras, were used for testing. Experimental results show that the NeuroSyM approach outperforms in most cases the baseline architectures in terms of prediction accuracy.}
}

@article{lincoln55428,
          volume = {77},
           month = {July},
          author = {Jordi Ganzer and Natalia Criado and Maite Lopez-Sanchez and Simon Parsons and Juan A. Rodriguez-Aguilar},
           title = {A model to support collective reasoning: Formalization, analysis and computational assessment},
       publisher = {AI Access Foundation},
         journal = {Journal of Artificial Intelligence Research (JAIR)},
             doi = {10.1613/jair.1.14409},
            year = {2023},
        keywords = {ARRAY(0x55be9b345040)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55428/},
        abstract = {In this paper we propose a new model to represent human debates and methods to obtain collective conclusions from them. This model overcomes two drawbacks of existing approaches. First, our model does not assume that participants agree on the structure of the debate. It does this by allowing participants to express their opinion about all aspects of the debate.  Second, our model does not assume that participants' opinions are rational, an assumption that significantly limits current approaches. Instead, we define a weaker notion of rationality that characterises coherent opinions, and we consider different scenarios based on the coherence of individual opinions and the level of consensus.  
We provide a formal analysis of different opinion aggregation functions that compute a collective decision based on the individual opinions and the debate structure. In particular, we demonstrate that aggregated opinions can be coherent even if there is a lack of consensus and individual opinions are not coherent. We conclude with an empirical evaluation demonstrating that collective opinions can be computed efficiently for real-sized debates.}
}

@inproceedings{lincoln55464,
       booktitle = {The 18th international conference on Intelligent Autonomous System 2023 (IAS18 ? 2023)},
           month = {July},
           title = {On Optimising Topology of Agricultural Fields for Efficient Robotic Fleet Deployment},
          author = {Zuyuan Zhu and Gautham Das and Marc Hanheide},
       publisher = {The 18th international conference on Intelligent Autonomous System 2023 (IAS18 ? 2023)},
            year = {2023},
        keywords = {ARRAY(0x55be9b276018)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55464/},
        abstract = {Field-deployed robotic fleets can provide solutions that improve operational efficiency, control operational costs, and provide farmers with transparency over the day-to-day operations with scouting operations. The topology of agricultural farms such as polytunnels provides a basic environmental configuration that can be exploited to create a topological map to aid operational planning and robot navigation. However, these environments are optimised for operations by humans or for large farming vehicles and pose a major challenge for multiple moving robots to coordinate their navigation while performing tasks.  The farm environment without any topological modifications for supporting robotic fleet deployments can cause traffic bottlenecks, eventually affecting the overall efficiency of the fleet. In this work, we propose a Genetic Algorithm-based Topological Optimisation (GATO) algorithm that discretises the search space of topological modifications into finite integer combinations. Each solution is encoded as an integer vector that contains the location information of the topology modification. The algorithm is evaluated in a discrete event simulation of the picking and in-field logistics process in a commercial strawberry farm and the results validate the effectiveness of our algorithm in identifying the topological modifications that improve the efficiency of the robotic fleet operations.
robot traffic planning, multi-robot systems, agri-robotics, topological optimisa-
tion, discrete event simulation, genetic algorithm}
}

@inproceedings{lincoln54690,
       booktitle = {18th International Conference on Intelligent Autonomous Systems},
           month = {July},
           title = {S-NET: End-to-end Unsupervised Learning of Long-Term 3D Stable objects},
          author = {Ibrahim Hroob and Sergio Molina Mellado and Riccardo Polvara and Grzegorz Cielniak and Marc Hanheide},
            year = {2023},
        keywords = {ARRAY(0x55be9b393428)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54690/},
        abstract = {In this research, we present an end-to-end data-driven pipeline for determining the long-term stability status of objects within a given environment, specifically distinguishing between static and dynamic objects. Understanding object stability is key for mobile robots since longterm stable objects can be exploited as landmarks for long-term localisation. Our pipeline includes a labelling method that utilizes historical data from the environment to generate training data for a neural network. Rather than utilizing discrete labels, we propose the use of point-wise continuous label values, indicating the spatio-temporal stability of individual points, to train a point cloud regression network named S-NET. Our approach is evaluated on point cloud data from two parking lots in the NCLT dataset, and the results show that our proposed solution,  outperforms direct training of a classification model for static vs dynamic object classification.}
}

@inproceedings{lincoln53780,
           month = {July},
          author = {Karthik Seemakurthy and Petra Bosilj and Erchan Aptoula and Charles Fox},
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           title = {Domain Generalised Fully Convolutional One Stage Detection},
       publisher = {IEEE},
             doi = {10.1109/ICRA48891.2023.10160937},
           pages = {7002--7009},
            year = {2023},
        keywords = {ARRAY(0x55be9b56a0b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53780/},
        abstract = {Abstract{--}Real-time vision in robotics plays an important role in localising and recognising objects. Recently, deep learning approaches have been widely used in robotic vision. However, most of these approaches have assumed that training and test sets come from similar data distributions, which is not valid in many real world applications. This study proposes an approach to address domain generalisation (i.e. out-of distribution generalisation, OODG) where the goal is to train a model via one or more source domains, that will generalise well to unknown target domains using single stage detectors. All existing approaches which deal with OODG either use slow two stage detectors or operate under the covariate shift assumption which may not be useful for real-time robotics. This is the first paper to address domain generalisation in the context of single stage anchor free object detector FCOS without the covariate shift assumption. We focus on improving the generalisation ability of object detection by proposing new regularisation terms to address the domain shift that arises due to both classification and bounding box regression. Also, we include an additional consistency regularisation term to align the local and global level predictions. The proposed approach is implemented as a Domain Generalised Fully Convolutional One Stage (DGFCOS) detection and evaluated using four object detection datasets which provide domain metadata (GWHD, Cityscapes, BDD100K, Sim10K) where it exhibits a consistent performance improvement over the baselines and is able to run in real-time for robotics.}
}

@inproceedings{lincoln53246,
           month = {June},
          author = {Zuyuan Zhu and Gautham Das and Marc Hanheide},
       booktitle = {The 38th ACM/SIGAPP Symposium On Applied Computing},
           title = {Autonomous Topological Optimisation for Multi-robot Systems in Logistics},
       publisher = {Oxford University Press},
             doi = {10.1145/3555776.3577666},
           pages = {791--799},
            year = {2023},
        keywords = {ARRAY(0x55be9b2d9610)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53246/},
        abstract = {Multi-robot systems (MRS) are currently being introduced in many in-field logistics operations in large environments such as warehouses and commercial soft-fruit production. Collision avoidance is a critical problem in MRS as it may introduce deadlocks during the motion planning. In this work, a discretised topological map representation is used for low-cost route planning of individual robots as well as to easily switch the navigation actions depending on the constraints in the environment. However, this topological map could also have bottlenecks which leads to deadlocks and low transportation efficiency when used for an MRS. In this paper, we propose a resource container based Request-Release-Interrupt (RRI) algorithm that constrains each topological node with a capacity of one entity and therefore helps to avoid collisions and detect deadlocks. Furthermore, we integrate a Genetic Algorithm (GA) with Discrete Event Simulation (DES) for optimising the topological map to reduce deadlocks and improve transportation efficiency in logistics tasks. Performance analysis of the proposed algorithms are conducted after running a set of simulations with multiple robots and different maps. The results validate the effectiveness of our algorithms.}
}

@inproceedings{lincoln54842,
       booktitle = {Workshop on Robot Execution Failures and Failure Management Strategies at IEEE ICRA 2023},
           month = {June},
           title = {In-the-Wild Failures in a Long-Term HRI Deployment},
          author = {Francesco Del Duchetto and Ayse Kucukyilmaz and Marc Hanheide},
            year = {2023},
         journal = {Workshop on Robot Execution Failures and Failure Management Strategies at ICRA 2023},
        keywords = {ARRAY(0x55be9b3883d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54842/},
        abstract = {Failures are typical in robotics deployments ``in-the-wild'', especially when robots perform their functions within social human spaces. This paper reports on the failures of an autonomous social robot called Lindsey, which has been used in a public museum for several years, covering over 1300 kilometres through its deployment. We present an analysis of distinctive failures observed during the deployment and focusing on those cases where the robot can leverage human help to resolve the problem situation. A final discussion outlines future research directions needed to ensure robots are equipped with adequate resources to detect and appropriately deal with failures requiring a human-in-the-loop approach.}
}

@article{lincoln54478,
          volume = {12},
          number = {63},
           month = {June},
          author = {Jos{\'e} Carlos Mayoral Ba{\~n}os and P{\r a}l Johan From and Grzegorz Cielniak},
           title = {Towards Safe Robotic Agricultural Applications: Safe Navigation System Design for a Robotic Grass-Mowing Application through the Risk Management Method},
       publisher = {MDPI},
            year = {2023},
         journal = {Robotics},
             doi = {10.3390/robotics12030063},
        keywords = {ARRAY(0x55be9b47c7e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54478/},
        abstract = {Safe navigation is a key objective for autonomous applications, particularly those involving mobile tasks, to avoid dangerous situations and prevent harm to humans. However, the integration of a risk management process is not yet mandatory in robotics development. Ensuring safety using mobile robots is critical for many real-world applications, especially those in which contact with the robot could result in fatal consequences, such as agricultural environments where a mobile device with an industrial cutter is used for grass-mowing. In this paper, we propose an explicit integration of a risk management process into the design of the software for an autonomous grass mower, with the aim of enhancing safety. Our approach is tested and validated in simulated scenarios that assess the effectiveness of different custom safety functionalities in terms of collision prevention, execution time, and the number of required human interventions.}
}

@inproceedings{lincoln55955,
       booktitle = {ICRA2023 Workshop on Robot Software Architectures},
           month = {May},
           title = {Enabling Robot Autonomy through a Modular Software Framework},
          author = {Fetullah Atas and Grzegorz Cielniak and Lars Grimstad},
            year = {2023},
        keywords = {ARRAY(0x55be9b57b238)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55955/},
        abstract = {The complexity of robotic software architectures stems from the need to manage a diverse range of sensory inputs, real-time actuator control, and adaptive capabilities in dynamic environments. In order to guarantee safe operation, robots must be capable of executing tasks concurrently and asynchronously, which poses significant challenges in developing cohesive robotic software architectures. 
It is commonly accepted that there is no universal approach that can address the needs of all robot platforms and applications. A number of established architectures have been developed based on the publish-subscribe and action-client paradigms employed by Robot Operating System (ROS) middleware. Extending on these developments, in this research, we present a novel robotic software architecture that enables seamless integration of different robotics software components, such as Planning, Control, and Perception. The presented architecture is designed to ensure the autonomous navigation of a mobile robot operating in uneven outdoor terrains, while also supporting indoor environments with appropriate customization. Our software has been made available to the robotics community through a GitHub repository.}
}

@inproceedings{lincoln55044,
       booktitle = {ICRA2023 Workshop on TIG-IV: Agri-food Robotics From Farm to Fork},
           month = {May},
           title = {Leaving the Lines Behind: Vision-Based Crop Row Exit for Agricultural Robot Navigation},
          author = {Rajitha De Silva and Grzegorz Cielniak and Junfeng Gao},
            year = {2023},
             doi = {10.48550/arXiv.2306.05869},
            note = {Best Paper Award at TIG-IV workshop at ICRA 2023},
        keywords = {ARRAY(0x55be9b67a490)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55044/},
        abstract = {Usage of purely vision based solutions for row switching is not well explored in existing vision based crop row navigation frameworks. This method only uses RGB images for local feature matching based visual feedback to exit crop row. Depth images were used at crop row end to estimatethe navigation distance within headland. The algorithm was tested on diverse headland areas with soil and vegetation. The proposed method could reach the end of the crop row and then navigate into the headland completely leaving behind the crop row with an error margin of 50 cm.}
}

@inproceedings{lincoln55292,
       booktitle = {International Conference on Robotics and Automation 2023},
           month = {May},
           title = {Statistical Shape Representations for Temporal Registration of Plant Components in 3D},
          author = {Karoline Heiwolt and Cengiz {\"O}ztireli and Grzegorz Cielniak},
       publisher = {Infovaya},
            year = {2023},
        keywords = {ARRAY(0x55be9b59c208)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55292/},
        abstract = {Plants are dynamic organisms and understanding temporal variations in vegetation is an essential problem for robots in the wild. However, associating repeated 3D scans of plants across time is challenging. A key step in this process is re-identifying and tracking the same individual plant components over time. Previously, this has been achieved by comparing their global spatial or topological location. In this work, we demonstrate how using shape features improves temporal organ matching. We present a landmark-free shape compression algorithm, which allows for the extraction of 3D shape features of leaves, characterises leaf shape and curvature efficiently in few parameters, and makes the association of individual leaves in feature space possible. The approach combines 3D contour extraction and further compression using Principal Component Analysis (PCA) to produce a shape space encoding, which is entirely learned from data and retains information about edge contours and 3D curvature. Our evaluation on temporal scan sequences of tomato plants shows, that incorporating shape features improves temporal leaf-matching. A combination of shape, location, and rotation information proves most informative for recognition of leaves over time and yields a true positive rate of 75\%, a 15\% improvement on sate-of-the-art methods. This is essential for robotic crop monitoring, which enables whole-of-lifecycle phenotyping.}
}

@inproceedings{lincoln56182,
           month = {May},
          author = {Anna Astolfi and Marcello Calisti},
       booktitle = {2023 IEEE International Conference on Soft Robotics (RoboSoft)},
           title = {Articulated legs allow energy optimization across different speeds for legged robots with elastically suspended loads},
       publisher = {IEEE Xplore},
             doi = {10.1109/RoboSoft55895.2023.10121949},
           pages = {1--7},
            year = {2023},
        keywords = {ARRAY(0x55be9b509b60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56182/},
        abstract = {Legged robots are a promising technology whose use is limited by their high energy consumption. Biological and biomechanical studies have shown that the vibration generated by elastically suspended masses provides an energy advantage over rigidly carrying the same load. The robotic validation of these findings has only scarcely been explored in the dynamic walking case. In this context, a relationship has emerged between the design parameters and the actuation that generates the optimal gait. Although very relevant, these studies lack a generalizable analysis of different locomotion modes and a possible strategy to obtain optimal locomotion at different speeds. To this end, we propose the use of articulated legs in an extended Spring-Loaded Inverted Pendulum (SLIP) model with an elastically suspended mass. Thanks to this model, we show how stiffness and damping can be modulated through articulated legs by selecting the knee angle at touch-down. Therefore, by choosing different body postures, it is possible to vary the control parameters and reach different energetically optimal speeds. At the same time, this modeling allows the study of the stability of the defined system. The results show how suitable control choices reduce energy expenditure by 16\% at the limit cycle at a chosen speed. The demonstrated strategy could be used in the design and control of legged robots where energy consumption would be dynamically optimal and usage time would be significantly increased.}
}

@inproceedings{lincoln56196,
           month = {May},
          author = {Mohammad Sheikh Sofla and Srikishan Vayakkattil and Marcello Calisti},
       booktitle = {2023 IEEE International Conference on Soft Robotics (RoboSoft)},
           title = {Spatial Position Estimation of Lightweight and Delicate Objects using a Soft haptic Probe},
       publisher = {IEEE},
             doi = {10.1109/RoboSoft55895.2023.10122004},
           pages = {1--6},
            year = {2023},
        keywords = {ARRAY(0x55be9b479e20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56196/},
        abstract = {This paper reports on the use of a soft probe as a haptic exploratory device with Force/Moment (F/M) Readings at its base to determine the position of extremely lightweight and delicate objects. The proposed method uses the mathematical relationships between the deformations of the soft probe and the F/M sensor outputs, to reconstruct the shape of the probe and the position of the touched object. The Cosserat rod theory was utilized in this way under the assumption that only one contact point occurs during the exploration and friction effects are negligible. Soft probes in different sizes were designed and fabricated using a Form3 3D printer and Elastic50A resin, for which the effect of gravity is not negligible. Experimental results verified the performance of the proposed method that achieved a position error between of -0.7-13mm, while different external forces (between 0.01N to 1.5N) were applied along the soft probes to resemble the condition of touching lightweight objects. Eventually, the method is used to estimate position of some points in a delicate card house structure.}
}

@article{lincoln54866,
          volume = {7},
           month = {May},
          author = {Simon Pearson and Steve Brewer and Louise Manning and Luc Bidaut and George Onoufriou and Aiden Durrant and Georgios Leontidis and Charbel Jabbour and Andrea Zisman and Gerard Parr and Jeremy Frey and Roger Maull},
           title = {Decarbonising Our Food Systems: Contextualising Digitalisation For Net Zero},
       publisher = {Frontiers Media},
         journal = {Frontiers in Sustainable Food Systems},
             doi = {10.3389/fsufs.2023.1094299},
            year = {2023},
        keywords = {ARRAY(0x55be9b39d740)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54866/},
        abstract = {The food system is undergoing a digital transformation that connects local and global supply chains to address economic, environmental and societal drivers. Digitalisation enables firms to meet sustainable development goals (SDGs), address climate change and the wider negative externalities of food production such as biodiversity loss, and diffuse pollution. Digitalising at the business and supply chain level through public-private mechanisms for data exchange affords the opportunity for greater collaboration, visualising and measuring activities and their socio-environmental impact, demonstrating compliance with regulatory and market requirements and providing opportunity to capture current practice and future opportunities for process and product improvement. Herein we consider digitalisation as a tool to drive innovation and transition to a decarbonised food system. We consider that deep decarbonisation of the food system can only occur when trusted emissions data are exchanged across supply chains. This requires fusion of standardised emissions measurements within a supply chain data sharing framework. This framework, likely operating as a corporate entity, would provide the foci for measurement standards, data exchange, trusted and certified data and as a multi-stakeholder body, including regulators, that would build trust and collaboration across supply chains. This approach provides a methodology for accurate and trusted emissions data to inform consumer choice and industrial response of individual firms within a supply chain.}
}

@article{lincoln52115,
          volume = {13},
          number = {100051},
           month = {April},
          author = {P. Craigon and J. Sacks and S. Brewer and J. Frey and A. Gutierrez Mendoza and S. Kanza and L. Manning and S. Munday and A. Wintour and S. Pearson},
           title = {Ethics by Design: Responsible Research \& Innovation for AI in the Food Sector},
       publisher = {Elsevier},
            year = {2023},
         journal = {Journal of Responsible Technology},
             doi = {10.1016/j.jrt.2022.100051},
        keywords = {ARRAY(0x55be9b479e38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52115/},
        abstract = {Here we reflect on how a multi-disciplinary working group explored the ethical complexities of the use of new technologies for data sharing in the food supply chain. We used a three-part process of varied design methods, which included collaborative ideation and speculative scenario development, the creation of design fiction objects, and assessment using the Moral-IT deck, a card-based tool. We present, through the lens of the EPSRC's Framework for Responsible Innovation how processes of anticipation, reflection, engagement and action built a plausible, fictional world in which a data trust uses artificial intelligence (AI) to support data sharing and decision-making across the food supply chain. This approach provides rich opportunities for considering ethical challenges to data sharing as part of a reflexive and engaged responsible innovation approach. We reflect on the value and potential of this approach as a method for engaged (co-)design and responsible innovation.}
}

@article{lincoln54257,
          volume = {11},
           month = {April},
          author = {Deema Abdal Hafeth and Stefanos Kollias and Mubeen Ghafoor},
           title = {Semantic Representations with Attention Networks for Boosting Image Captioning},
       publisher = {IEEE},
            year = {2023},
         journal = {IEEE Access},
             doi = {10.1109/ACCESS.2023.3268744},
           pages = {40230--40239},
        keywords = {ARRAY(0x55be9b673ed8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54257/},
        abstract = {Image captioning has shown encouraging outcomes with Transformer-based architectures
that typically use attention-based methods to establish semantic associations between objects in an
image for caption prediction. Nevertheless, when appearance features of objects in an image display low
interdependence, attention-based methods have difficulty in capturing the semantic association between
them. To tackle this problem, additional knowledge beyond the task-specific dataset is often required
to create captions that are more precise and meaningful. In this article, a semantic attention network is
proposed to incorporate general-purpose knowledge into a transformer attention block model. This design
combines visual and semantic properties of internal image knowledge in one place for fusion, serving as
a reference point to aid in the learning of alignments between vision and language and to improve visual
attention and semantic association. The proposed framework is validated on the Microsoft COCO dataset,
and experimental results demonstrate competitive performance against the current state of the art.}
}

@article{lincoln56189,
          volume = {18},
          number = {3},
           month = {April},
          author = {G Picardi and A Astolfi and D Chatzievangelou and J Aguzzi and Marcello Calisti},
           title = {Underwater legged robotics: review and perspectives},
       publisher = {IOP Publishing},
            year = {2023},
         journal = {Bioinspiration \& Biomimetics},
             doi = {10.1088/1748-3190/acc0bb},
        keywords = {ARRAY(0x55be9b462370)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56189/},
        abstract = {Nowadays, there is a growing awareness on the social and economic importance of the ocean. In this context, being able to carry out a diverse range of operations underwater is of paramount importance for many industrial sectors as well as for marine science and to enforce restoration and mitigation actions. Underwater robots allowed us to venture deeper and for longer time into the remote and hostile marine environment. However, traditional design concepts such as propeller driven remotely operated vehicles, autonomous underwater vehicles, or tracked benthic crawlers, present intrinsic limitations, especially when a close interaction with the environment is required. An increasing number of researchers are proposing legged robots as a bioinspired alternative to traditional designs, capable of yielding versatile multi-terrain locomotion, high stability, and low environmental disturbance. In this work, we aim at presenting the new field of underwater legged robotics in an organic way, discussing the prototypes in the state-of-the-art and highlighting technological and scientific challenges for the future. First, we will briefly recap the latest developments in traditional underwater robotics from which several technological solutions can be adapted, and on which the benchmarking of this new field should be set. Second, we will the retrace the evolution of terrestrial legged robotics, pinpointing the main achievements of the field. Third, we will report a complete state of the art on underwater legged robots focusing on the innovations with respect to the interaction with the environment, sensing and actuation, modelling and control, and autonomy and navigation. Finally, we will thoroughly discuss the reviewed literature by comparing traditional and legged underwater robots, highlighting interesting research opportunities, and presenting use case scenarios derived from marine science applications.}
}

@inproceedings{lincoln53113,
       booktitle = {Conference on Causal Learning and Reasoning (CLeaR)},
           month = {April},
           title = {Enhancing Causal Discovery from Robot Sensor Data in Dynamic Scenarios},
          author = {Luca Castri and Sariah Mghames and Marc Hanheide and Nicola Bellotto},
            year = {2023},
        keywords = {ARRAY(0x55be9b60a3e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53113/},
        abstract = {Identifying the main features and learning the causal relationships of a dynamic system from time-series of sensor data are key problems in many real-world robot applications. In this paper, we propose an extension of a state-of-the-art causal discovery method, PCMCI, embedding an additional feature-selection module based on transfer entropy. Starting from a prefixed set of variables, the new algorithm reconstructs the causal model of the observed system by considering only the its main features and neglecting those deemed unnecessary for understanding the evolution of the system. We first validate the method on a toy problem, for which the ground-truth model is available, and then on a real-world robotics scenario using a large-scale time-series dataset of human trajectories. The experiments demonstrate that our solution outperforms the previous state-of-the-art technique in terms of accuracy and computational efficiency, allowing better and faster causal discovery of meaningful models from robot sensor data.}
}

@article{lincoln53715,
          volume = {47},
          number = {4},
           month = {April},
          author = {Amir Masoud Ghalamzan Esfahani},
           title = {Haptic-guided Grasping to Minimise Torque Effort during Robotic Telemanipulation},
       publisher = {Springer},
            year = {2023},
         journal = {Autonomous Robots},
             doi = {10.1007/s10514-023-10096-7},
        keywords = {ARRAY(0x55be9b4cb128)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53715/},
        abstract = {Teleoperating robotic manipulators can be complicated and cognitively demanding for the human operator. Despite these difficulties, teleoperated robotic systems are still popular in several industrial applications, e.g., remote handling of hazardous material. In this context, we present a novel haptic shared control method for minimising the manipulator torque effort during remote manipulative actions in which an operator is assisted in selecting a suitable grasping pose for then displacing an object along a desired trajectory. Minimising torque is important because it reduces the system operating cost and extends the range of objects that can be manipulated. We demonstrate the effectiveness of the proposed approach in a series of representative real-world pick-and-place experiments as well as in human subjects studies. The reported results prove the effectiveness of our shared control vs. a standard teleoperation approach. We also find that haptic-only guidance performs better than visually guidance, although combining them together leads to the best overall results.}
}

@article{lincoln56195,
          volume = {11},
          number = {4},
           month = {March},
          author = {Giacomo Picardi and Mauro De Luca and Giovanni Chimienti and Matteo Cianchetti and Marcello Calisti},
           title = {User-Driven Design and Development of an Underwater Soft Gripper for Biological Sampling and Litter Collection},
       publisher = {MDPI},
            year = {2023},
         journal = {Journal of Marine Science and Engineering},
             doi = {10.3390/jmse11040771},
           pages = {771},
        keywords = {ARRAY(0x55be9b4a74e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56195/},
        abstract = {Implementing manipulation and intervention capabilities in underwater vehicles is of crucial importance for commercial and scientific reasons. Mainstream underwater grippers are designed for the heavy load tasks typical of the industrial sector; however, due to the lack of alternatives, they are frequently used in biological sampling applications to handle irregular, delicate, and deformable specimens with a consequent high risk of damage. To overcome this limitation, the design of grippers for marine science applications should explicitly account for the requirements of end-users. In this paper, we aim at making a step forward and propose to systematically account for the needs of end-users by resorting to design tools used in industry for the conceptualization of new products which can yield great benefits to both applied robotic research and marine science. After the generation of the concept design for the gripper using a reduced version of the House of Quality and the Pugh decision matrix, we reported on its mechanical design, construction, and preliminary testing. The paper reports on the full design pipeline from requirements collection to preliminary testing with the aim of fostering and providing structure to fruitful interdisciplinary collaborations at the interface of robotics and marine science.}
}

@inproceedings{lincoln53771,
       booktitle = {The 37th AAAI conference on Artificial Intelligence},
           month = {March},
           title = {Domain Generalised Faster R-CNN},
          author = {Karthik Seemakurthy and Charles Fox and Erchan Aptoula and Petra Bosilj},
       publisher = {Association for Advancement of Artificial Intelligence},
            year = {2023},
        keywords = {ARRAY(0x55be9b533290)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53771/},
        abstract = {Domain generalisation (i.e. out-of-distribution generalisation) is an open problem in machine learning, where the goal is to train a model via one or more source domains, that will generalise well to unknown target domains. While the topic is attracting increasing interest, it has not been studied in detail in the context of object detection. The established approaches all operate under the covariate shift assumption, where the conditional distributions are assumed to be approximately equal across source domains. This is the first paper to address domain generalisation in the context of object detection, with a rigorous mathematical analysis of domain shift, without the covariate shift assumption. We focus on improving the generalisation ability of object detection by proposing new regularisation terms to address the domain shift that arises due to both classification and bounding box regression. Also, we include an additional consistency regularisation term to align the local and global level predictions. The proposed approach is implemented as a Domain Generalised Faster R-CNN and evaluated using four object detection datasets which provide domain metadata (GWHD, Cityscapes, BDD100K, Sim10K) where it exhibits a consistent performance improvement over the baselines. All the codes for replicating the results in this paper can be found at https://github.com/karthikiitm87/domain-generalisation.git}
}

@inproceedings{lincoln54118,
           month = {March},
          author = {Marina Constantinou and Riccardo Polvara and Evagoras Makridis},
       booktitle = {17th International Technology, Education and Development Conference},
           title = {The technologisation of thematic analysis: a case study into automatising qualitative research},
       publisher = {IATED},
            year = {2023},
         journal = {17th International Technology, Education and Development Conference},
             doi = {10.21125/inted.2023.0323},
           pages = {1092--1098},
        keywords = {ARRAY(0x55be9b41c558)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54118/},
        abstract = {Thematic analysis is the most commonly used form of qualitative analysis used extensively in educational sciences. While the process is straightforward in the sense that a hermeneutic analysis is conducted so as to detect patterns and assign themes emerging from the data acquired, replicability can be challenging. As a result, there is significant debate about what constitutes reliability and rigour in relation to qualitative coding. Traditional thematic analysis in educational sciences requires the development of a codebook and the recruitment of a research team for intercoder reviewing and code testing. Such a process is often lengthy and infeasible when the number of texts to be analysed increases exponentially. To overcome these limitations, in this work, we use an unsupervised text analysis technique called the Latent Dirichlet Allocation (LDA) to identify distinct abstract topics which are then clustered into potential themes. Our results show that thematic analysis in the field of educational sciences using the LDA text analysis technique has prospects of demonstrating rigour and higher thematic coding reliability and validity while offering a valid intra-coder complementary support to the researcher.}
}

@article{lincoln53439,
          volume = {133},
           month = {March},
          author = {L. Manning and S. Brewer and P. Craigon and J. Frey and A. Gutierrez and N. Jacobs and S. Kanza and S. Munday and J. Sacks and S. Pearson},
           title = {Reflexive governance architectures: considering the ethical implications of autonomous technology adoption in food supply chains},
       publisher = {Elsevier},
            year = {2023},
         journal = {Trends in Food Science \& Technology},
             doi = {10.1016/j.tifs.2023.01.015},
           pages = {114--126},
        keywords = {ARRAY(0x55be9b457620)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53439/},
        abstract = {Background: The application of autonomous technology in food supply chains gives rise to a number of ethical considerations associated with the interaction between human and technology, human-technology-plant and human-technology-animal. These considerations and their implications influence technology design, the ways in which technology is applied, how the technology changes food supply chain practices, decision-making and the associated ethical aspects and outcomes.
Scope and approach: Using the concept of reflexive governance, this paper has critiqued existing reflective food-related ethical assessment tools and proposed the structural elements required for reflexive governance architectures which address both the sharing of data, and the use of artificial intelligence (AI) and machine learning in food supply chains. 
Key findings and conclusions: Considering the ethical implications of using autonomous technology in real life contexts is challenging. The current approach, focusing on discrete ethical elements in isolation e.g., ethical aspects or outcomes, normative standards or ethically orientated compliance-based business strategies is not sufficient in itself. Alternatively, the application of more holistic, reflexive governance architectures can inform consideration of ethical aspects, potential ethical outcomes, in particular how they are interlinked and/or interdependent, and the need for mitigation at all lifecycle stages of technology and food product conceptualisation, design, realisation and adoption in the food supply chain. This research is of interest to those who are undertaking ethical deliberation on data sharing, and  the use of AI and machine learning in food supply chains.}
}

@inproceedings{lincoln53114,
       booktitle = {18th International Conference on Computer Vision Theory and Applications (VISAPP)},
           month = {February},
           title = {Evaluation of Computer Vision-Based Person Detection on Low-Cost Embedded Systems},
          author = {Francesco Pasti and Nicola Bellotto},
            year = {2023},
        keywords = {ARRAY(0x55be9b34f510)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53114/},
        abstract = {Person detection applications based on computer vision techniques often rely on complex Convolutional Neural Networks that require powerful hardware in order achieve good runtime performance. The work of this paper has been developed with the aim of implementing a safety system, based on computer vision algorithms, able to detect people in working environments using an embedded device. Possible applications for such safety systems include remote site monitoring and autonomous mobile robots in warehouses and industrial premises. Similar studies already exist in the literature, but they mostly rely on systems like NVidia Jetson that, with a Cuda enabled GPU, are able to provide satisfactory results. This, however, comes with a significant downside as such devices are usually expensive and require significant power consumption. The current paper instead is going to consider various implementations of computer vision-based person detection on two power-efficient and inexpensive devices, namely Raspberry Pi 3 and 4. In order to do so, some solutions based on off-the-shelf algorithms are first explored by reporting experimental results based on relevant performance metrics. Then, the paper presents a newly-created custom architecture, called eYOLO, that tries to solve some limitations of the previous systems. The experimental evaluation demonstrates the good performance of the proposed approach and suggests ways for further improvement.}
}

@inproceedings{lincoln53115,
       booktitle = {AAAI Bridge Program ?AI and Robotics?},
           month = {February},
           title = {Towards Long-term Autonomy: A Perspective from Robot Learning},
          author = {Zhi Yan and Li Sun and Tomas Krajnik and Tom Duckett and Nicola Bellotto},
            year = {2023},
        keywords = {ARRAY(0x55be9b3b92c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53115/},
        abstract = {In the future, service robots are expected to be able to operate autonomously for long periods of time without human intervention. Many work striving for this goal have been emerging with the development of robotics, both hardware and software. Today we believe that an important underpinning of long-term robot autonomy is the ability of robots to learn on site and on-the-fly, especially when they are deployed in changing environments or need to traverse different environments. In this paper, we examine the problem of long-term autonomy from the perspective of robot learning, especially in an online way, and discuss in tandem its premise "data" and the subsequent "deployment".}
}

@inproceedings{lincoln50521,
           month = {January},
          author = {Fetullah Atas and Grzegorz Cielniak and Lars Grimstad},
            note = {ISBN: 978-3-031-22216-0},
       booktitle = {17th International Conference on Intelligent Autonomous Systems},
           title = {Benchmark of Sampling-Based Optimizing Planners for Outdoor Robot Navigation},
       publisher = {Springer},
            year = {2023},
             doi = {10.1007/978-3-031-22216-0\_16},
           pages = {231--243},
        keywords = {ARRAY(0x55be9b2b9398)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50521/},
        abstract = {This paper evaluates Sampling-Based Optimizing (SBO) planners from the Open Motion Planning Library (OMPL) in the context of mobile robot navigation in outdoor environments. Many SBO planners have been proposed, and determining performance differences among these planners for path planning problems can be time-consuming and ambiguous. The probabilistic nature of SBO planners can also complicate this procedure, as different results for the same planning problem can be obtained even in consecutive queries from the same planner. We compare all available SBO planners in OMPL with an automated planning problem generation method designed specifically for outdoor robot navigation scenarios. Several evaluation metrics are chosen, such as the length, smoothness, and success rate of the resulting path, and probability distributions for metrics are presented. With the experimental results obtained, clear recommendations on high-performing planners for mobile robot path planning problems are made, which will be useful to researchers and practitioners in mobile robot planning and navigation.}
}

@article{lincoln52872,
          volume = {7},
          number = {1},
           month = {January},
          author = {Vijja Wichitwechkarn and Charles Fox},
           title = {MACARONS: A Modular and Open-Sourced Automation System for Vertical Farming},
       publisher = {Ubiquity Press},
            year = {2023},
         journal = {Jounral of Open Hardware},
             doi = {10.5334/joh.53},
        keywords = {ARRAY(0x55be9b2e83a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52872/},
        abstract = {The Modular Automated Crop Array Online System (MACARONS) is an extensible, scalable, open hardware system for plant transport in automated horticulture systems such as vertical farms.  It is specified to move trays of plants up to 1060mm \${$\backslash$}times\$ 630mm and 12.5kg at a rate of 100mm/s along the guide rails and 41.7mm/s up the lifts, such as between stations for monitoring and actuating plants. The cost for the construction of one grow unit of MACARONS is 144.96USD which equates to 128.85USD/m\${\^{ }}2\$ of grow area. The designs are released and meets the requirements of CERN-OSH-W, which includes step-by-step graphical build instructions and can be built by a typical technical person in one day at a cost of 1535.50 USD.  Integrated tests are included in the build instructions are used to validate against the specifications, and we report on a successful build.  Through a simple analysis, we demonstrate that MACARONS can operate at a rate sufficient to automate tray loading/unloading, to reduce labour costs in a vertical farm.}
}

@inproceedings{lincoln53116,
       booktitle = {AAAI Bridge Program ?Continual Causality?},
           month = {January},
           title = {From Continual Learning to Causal Discovery in Robotics},
          author = {Luca Castri and Sariah Mghames and Nicola Bellotto},
            year = {2023},
        keywords = {ARRAY(0x55be9b5a2c20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53116/},
        abstract = {Reconstructing accurate causal models of dynamic systems from time-series of sensor data is a key problem in many real-world scenarios. In this paper, we present an overview based on our experience about practical challenges that the causal analysis encounters when applied to autonomous robots and how Continual Learning{\texttt{\char126}}(CL) could help to overcome them. We propose a possible way to leverage the CL paradigm to make causal discovery feasible for robotics applications where the computational resources are limited, while at the same time exploiting the robot as an active agent that helps to increase the quality of the reconstructed causal models.}
}

@article{lincoln56591,
           title = {A procedure for the stiffness identification of parallel robots under measurement limitations},
          author = {Rasool Bina and Ali Kamali E. and Afshin Taghvaeipour and Alexandr Klimchik},
       publisher = {Taylor and Francis},
            year = {2023},
             doi = {10.1080/15397734.2023.2234991},
         journal = {Mechanics Based Design of Structures and Machines},
        keywords = {ARRAY(0x55be9b3cf038)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56591/},
        abstract = {This paper introduces a procedure to obtain reliable stiffness model for parallel robots from experimental data and identify its parameters considering measurement limitations. The efficiency of the proposed identification procedure validated via simulation and experimental studies on a 3-DOF Delta parallel robot. Simulation results showed that the proposed simplification and model reduction keeps more than 95\% of entire stiffness properties (for the worst-case analysis). The experimental results proved that the obtained model on average describes 95\% of compliance errors and for the worst case the error does not overcome 9.8\%.}
}

@article{lincoln56622,
           title = {A kinematic model generates non-circular human proxemics zones},
          author = {Fanta Camara and Charles Fox},
       publisher = {Taylor and Francais},
            year = {2023},
             doi = {10.1080/01691864.2023.2263062},
         journal = {Advanced Robotics},
        keywords = {ARRAY(0x55be9b588048)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56622/},
        abstract = {Hall?s theory of proxemics established distinct spatial zones around humans where they experience comfort or discomfort when interacting with others. Our previous work proposed a new model of proxemics and trust and it showed how to generate proxemics zone sizes using simple equations from human kinematic behaviour. But like most work, this assumed that the zones are circular. In this paper, we refine this model to take the initial heading of the agent into account and find that this results in a non-circular outer boundary of the social zone. These new analytical results from a generative model form a step towards more advanced quantitative proxemics in dual agents? interaction modelling.}
}

@article{lincoln56155,
           title = {Black-grass (Alopecurus myosuroides) in cereal multispectral detection by UAV},
          author = {Jonathan Cox and Dom Li and Charles Fox and Shaun Coutts},
       publisher = {Cambridge University Press},
            year = {2023},
             doi = {10.1017/wsc.2023.41},
         journal = {Weed Science},
        keywords = {ARRAY(0x55be9b311760)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56155/},
        abstract = {Site-specific weed management (on the scale of a few meters or less) has the potential to greatly reduce pesticide use and its associated environmental and economic costs. A prerequisite for site-specific weed management is the availability of accurate maps of the weed population that can be generated quickly and cheaply. Improvements and cost reductions in unmanned aerial vehicles (UAVs) and camera technology mean these tools are now readily available for agricultural use. We used UAVs to collect aerial images captured in both RGB and multispectral formats of 12 cereal fields (wheat [Triticum aestivum L.] and barley [Hordeum vulgare L.]) across eastern England. These data were used to train machine learning models to generate prediction maps of locations of black-grass (Alopecurus myosuroides Huds.), a prolific weed in UK cereal fields. We tested machine learning and data set resampling methods to obtain the most accurate system for predicting the presence and absence of weeds in new out-of-sample fields. The accuracy of the system in predicting the absence of A. myosuroides is 69\% and its presence above 5 g in weight with 77\% accuracy in new out-of-sample fields. This system generates prediction maps that can be used by either agricultural machinery or autonomous robotic platforms for precision weed management. Improvements to the accuracy can be made by increasing the number of fields and samples in the data set and the length of time over which data are collected to gather data across the entire growing season.}
}

@article{lincoln55690,
           title = {Deep learning-based Crop Row Detection for Infield Navigation of Agri-Robots},
          author = {Rajitha De Silva and Grzegorz Cielniak and Gang Wang and Junfeng Gao},
       publisher = {Wiley Periodicals, Inc.},
            year = {2023},
             doi = {10.1002/rob.22238},
         journal = {Journal of Field Robotics},
        keywords = {ARRAY(0x55be9b2ec2c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55690/},
        abstract = {Autonomous navigation in agricultural environments is challenged by varying field conditions that arise in arable fields.
State-of-the-art solutions for autonomous navigation in such environments require expensive hardware such as RTK-GNSS. This paper presents a robust crop row detection algorithm that withstands such field variations using inexpensive cameras. Existing datasets for crop row detection does not represent all the possible field variations. A dataset of sugar beet images was created representing 11 field variations comprised of multiple grow stages, light levels, varying weed
densities, curved crop rows and discontinuous crop rows.
The proposed pipeline segments the crop rows using a deep
learning-based method and employs the predicted segmentation mask for extraction of the central crop using a novel
central crop row selection algorithm. The novel crop row
detection algorithm was tested for crop row detection performance and the capability of visual servoing along a crop
row. The visual servoing-based navigation was tested on a
realistic simulation scenario with the real ground and plant
textures. Our algorithm demonstrated robust vision-based
crop row detection in challenging field conditions outperforming the baseline.}
}

@article{lincoln55459,
           title = {Implementation of a human?aware robot navigation module for cooperative soft?fruit harvesting operations},
          author = {Leonardo Guevara and Marc Hanheide and Simon Parsons},
       publisher = {Wiley},
            year = {2023},
             doi = {10.1002/rob.22227},
         journal = {Journal of Field Robotics},
        keywords = {ARRAY(0x55be9b2ed0f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55459/},
        abstract = {In the last decades, robotic solutions have been introduced in agriculture to improve the efficiency of tasks such as spraying, plowing, and seeding. However, for a more complex task like soft-fruit harvesting, the efficiency of experienced human pickers has not been surpassed yet by robotic solutions. Thus, in the immediate future, human labor will probably be still necessary for picking tasks while robotic platforms could be used as collaborators, supporting the pickers in the transportation of the harvested fruit. This cooperative harvesting strategy creates a human?robot interaction (HRI) that requires significant further development in human-aware safe navigation and effective bidirectional communication of intent. In fact, although agricultural robots are considered small/medium size machinery, they still represent a risk of causing injuries to human collaborators, especially if people are not trained to work with robots or robot operations are not intuitive. Avoiding such injury is the aim of this work which contributes to the development, implementation, and evaluation of a human-aware navigation (HAN) module that can be integrated into the autonomous navigation system of commercial agricultural robots. The proposed module is responsible for the detection and monitoring of humans working around the robot and uses this information to activate safety actions depending on whether the human presence is considered at risk or not. Apart from ensuring a physically safe HRI, the proposed module deals with the comfort level and psychological safety of human coworkers. The latter is possible by using an explicit human?robot communication strategy that lets both know of the other's intentions, increasing the level of trust and reducing inefficient pauses triggered by unnecessary safety actions. The proposed HAN solution was integrated into a commercial agricultural robot and tested in several situations that are expected to happen during cooperative harvesting operations. The results of a usability assessment illustrated the benefits of the proposal in terms of safety, efficiency, and ergonomics.}
}

@article{lincoln56319,
           title = {Cyclic Action Graphs for goal recognition problems with inaccurately initialised fluents},
          author = {Helen Harman and Pieter Simoens},
       publisher = {Springer},
            year = {2023},
             doi = {10.1007/s10115-023-01976-6},
         journal = {Knowledge and Information Systems},
        keywords = {ARRAY(0x55be9b30c268)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56319/},
        abstract = {Goal recognisers attempt to infer an agent?s intentions from a sequence of observed actions. This is an important component of intelligent systems that aim to assist or thwart actors; however, there are many challenges to overcome. For example, the initial state of the environment could be partially unknown, agents can act suboptimally and observations could be missing. Approaches that adapt classical planning techniques to goal recognition have previously been proposed but, generally, they assume the initial world state is accurately defined. In this paper, a state is inaccurate if any fluent?s value is unknown or incorrect. Our aim is to develop a goal recognition approach that is as accurate as the current state of the art algorithms and whose accuracy does not deteriorate when the initial state is inaccurately defined. To cope with this complication, we propose solving goal recognition problems by means of an Action Graph. An Action Graph models the dependencies, i.e., order constraints, between all actions rather than just actions within a plan. Leaf nodes correspond to actions and are connected to their dependencies via operator nodes. After generating an Action Graph, the graph?s nodes are labelled with their distance from each hypothesis goal. This distance is based on the number and type of nodes  traversed to reach the node in question from an action node that results in the goal state being reached. For each observation, the goal probabilities are then updated based on either the distance the observed action?s node is from each goal or the change in distance. Our experimental results, for 15 different domains, demonstrate that our approach is robust to inaccuracies within the defined initial state.}
}

@inproceedings{lincoln53352,
       booktitle = {6th IEEE-RAS International Conference on Soft Robotics (ROBOSOFT)},
           title = {Fabrication and Characterization of a Passive Variable Stiffness Joint based on Shear Thickening Fluids},
          author = {Philip H. Johnson and Mini Rai and Marcello Calisti},
       publisher = {IEEE},
            year = {2023},
             doi = {10.1109/RoboSoft55895.2023.10122061},
        keywords = {ARRAY(0x55be9b2ff4d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53352/},
        abstract = {In soft robotics, variable stiffening is the key to taking full advantage of properties such as compliance, manipulability and deformability. However, many variable stiffness actuators and mechanisms which have been produced so far to control these properties of soft robots are slow, bulky, or require additional complex actuators. This paper presents a novel passive soft joint based upon the intrinsic non-Newtonian behavior of Shear Thickening Fluids (STFs). The joint stiffness is varied by changing the speed at which it is actuated. The joints fabricated for testing have a simple cylindrical structure comprised of a soft silicone shell filled with a STF. Three prototypes with lengths of 20, 40 and 60mm were produced for experimental validation. We characterize the behavior of the joints in compression, expansion and bending, yielding a stiffness variation of more than 5x based on actuation speed in compression testing. This paper is the first step in producing a new category of variable stiffening mechanisms based on STFs which can be incorporated into soft robots without the need for additional actuation. It is envisaged that this new soft joint will find applications in soft manipulators and wearable devices.}
}

@inproceedings{lincoln56659,
       booktitle = {International Symposium on Intelligent and Trustworthy Computing, Communications, and Networking (ITCCN-2023)},
           title = {Python Subset to Digital Logic Dataflow Compiler for Robots and IoT},
          author = {Kristaps Jurkans and Charles Fox},
       publisher = {IEEE Computer Society},
            year = {2023},
        keywords = {ARRAY(0x55be9b30c2b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56659/},
        abstract = {Robots and IoT devices often need to process real-time signals using embedded systems with limited power and clock speeds -- rather than large CPUs or GPUs.  FPGAs offer highly parallel computation, but such computation is difficult to program, both algorithmically and at hardware implementation level.   Programmers of digital signal processing (DSP), machine vision, and neural networks typically work in high level, serial languages such as Python, so would benefit from a tool to automatically convert this code to run on FPGA.   We present a design for a compiler from a serial Python subset to parallel dataflow FPGA, in which the physical connectivity and dataflow of the digital logic mirrors the logical dataflow of the programs.  The subset removes some imperative features from Python and focuses on Python's functional programming elements, which can be more easily compiled into physical digital logic implementations of dataflows.  Some imperative features are retained but interpreted under alternative functional semantics, making them easier to parallelize.  These dataflows can then be pipelined for efficient continuous real-time data processing.  An open-source partial implementation is provided together with a compilable simple neuron program.}
}

@article{lincoln55636,
           title = {Argument Schemes and a Dialogue System for Explainable Planning},
          author = {Quratul-ain Mahesar and Marc Hanheide and Simon Parsons},
       publisher = {Association for Computing Machinery (ACM)},
            year = {2023},
             doi = {10.1002/rob.22227},
         journal = {ACM Transactions on Intelligent Systems and Technology},
        keywords = {ARRAY(0x55be9b305e30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55636/},
        abstract = {Artificial Intelligence (AI) is being increasingly deployed in practical applications. However, there is a major concern whether AI systems will be trusted by humans. In order to establish trust in AI systems, there is a need for users to understand the reasoning behind their solutions. Therefore, systems should be able to explain and justify their output. Explainable AI Planning (XAIP) is a field that involves explaining the outputs, i.e., solution plans produced by AI planning systems to a user. The main goal of a plan explanation is to help humans understand reasoning behind the plans that are produced by the planners. In this paper, we propose an argument scheme-based approach to provide explanations in the domain of AI planning. We present novel argument schemes to create arguments that explain a plan and its key elements; and a set of critical questions that allow interaction between the arguments and enable the user to obtain further information regarding the key elements of the plan. Furthermore, we present a novel dialogue system using the argument schemes and critical questions for providing interactive dialectical explanations.}
}

@inproceedings{lincoln55466,
       booktitle = {32nd IEEE International Conference on Robot and Human Interactive Communication},
           title = {Qualitative Prediction of Multi-Agent Spatial Interactions},
          author = {Sariah Mghames and Luca Castri and Marc Hanheide and Nicola Bellotto},
       publisher = {IEEE},
            year = {2023},
        keywords = {ARRAY(0x55be9b2f1e00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55466/},
        abstract = {Deploying service robots in our daily life, whether in restaurants, warehouses or hospitals, calls for the need to reason on the interactions happening in dense and dynamic scenes. In this paper, we present and benchmark three new  approaches to model and predict multi-agent interactions in dense scenes, including the use of an intuitive qualitative representation. The proposed solutions take into account static and dynamic context to predict individual interactions. They exploit an input- and a temporal-attention mechanism, and are tested on medium and long-term time horizons. The first two approaches integrate different relations from the so-called Qualitative Trajectory Calculus (QTC) within a state-of-the-art deep neural network to create a symbol-driven neural architecture for predicting spatial interactions. The third approach implements a purely data-driven network for motion prediction, the output of which is post-processed to predict QTC spatial interactions. Experimental results on a popular robot dataset of challenging crowded scenarios show that the purely data-driven prediction approach generally outperforms the other two. The three approaches were further evaluated on a different but related human scenarios to assess their generalisation capability.}
}

@inproceedings{lincoln53555,
       booktitle = {HCI International 2023},
           title = {Augmented Reality to Reduce Cognitive Load in Operational Decision-Making},
          author = {Bethan Moncur and Maria J. Galvez Trigo and Letizia Mortara},
            year = {2023},
        keywords = {ARRAY(0x55be9b2f1db8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53555/},
        abstract = {Augmented reality (AR) technologies can overlay digital in- formation onto the real world. This makes them well suited for deci- sion support by providing contextually-relevant information to decision- makers. However, processing large amounts of information simultane- ously, particularly in time-pressured conditions, can result in poor decision- making due to excess cognitive load. This paper presents the results of an exploratory study investigating the effects of AR on cognitive load. A within-subjects experiment was conducted where participants were asked to complete a variable-sized bin packing task with and without the as- sistance of an augmented reality decision support system (AR DSS). Semi-structured interviews were conducted to elicit perceptions about the ease of the task with and without the AR DSS. This was supple- mented by collecting quantitative data to investigate if any changes in perceived ease of the task translated into changes in task performance. The qualitative data suggests that the presence of the AR DSS made the task feel easier to participants; however, there was only a statistically in- significant increase in mean task performance. Analysing the data at the individual level does not provide evidence of a translation of increased perceived ease to increased task performance.}
}

@article{lincoln56100,
           title = {Modular autonomous strawberry-picking robotic system},
          author = {Soran Parsa and Bappaditya Debnath and Muhammad Arshad Khan and Amir Ghalamzan Esfahani},
       publisher = {Wiley},
            year = {2023},
             doi = {10.1002/rob.22229},
         journal = {Journal of Field Robotics},
        keywords = {ARRAY(0x55be9b319370)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56100/},
        abstract = {Challenges in strawberry picking made selective harvesting robotic technology very demanding. However, the elective harvesting of strawberries is a complicated robotic task forming a few scientific research questions. Most available solutions only deal with a specific picking scenario, for example, picking only a single variety of fruit in isolation. Nonetheless, most economically viable (e.g., high?yielding and/or disease?resistant) varieties of strawberry are grown in dense clusters. The current perception technology in such use cases is inefficient. In this work, we developed a novel system capable of harvesting strawberries with several unique features. These features allow the system to deal with very complex picking scenarios, for example, dense clusters. Our concept of a modular system makes our system reconfigurable to adapt to different picking scenarios. We designed, manufactured, and tested a patented picking head with 2.5?degrees of freedom (two independent mechanisms and one dependent cutting system) capable of removing possible occlusions and harvesting the targeted strawberry without any contact with the fruit flesh to avoid damage and bruising. In addition, we developed a novel perception system to localize strawberries and detect their key points, picking points, and determine their ripeness. For this purpose, we introduced two new data sets. Finally, we tested the system in a commercial strawberry growing field and our research farm with three different strawberry varieties. The results show the effectiveness and reliability of the proposed system. The designed picking head was able to remove occlusions and harvest strawberries effectively. The perception system was able to detect and determine the ripeness of strawberries with 95\% accuracy. In total, the system was able to harvest 87\% of all detected strawberries with a success rate of 83\% for all pluckable fruits. We also discuss a series of open research questions in the discussion section.}
}

@article{lincoln54285,
           title = {DeepVerge: Classification of Roadside Verge Biodiversity and Conservation Potential},
          author = {Andrew Perrett and Harry Pollard and Charlie Barnes and Mark Schofield and Lan Qie and Petra Bosilj and James Brown},
       publisher = {Elsevier},
            year = {2023},
         journal = {Computers, Environment and Urban Systems},
        keywords = {ARRAY(0x55be9b2d9ca0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54285/},
        abstract = {Grasslands are increasingly modified by anthropogenic activities and species rich grasslands have become rare habitats in the UK. However, grassy roadside verges often contain conservation priority plant species and should be targeted for protection. Identification of verges with high conservation potential represents a considerable challenge for ecologists, driving the development of automated methods to make up for the shortfall of relevant expertise nationally. Using survey data from 3,900 km of roadside verges alongside publicly available street-view imagery, we present DeepVerge: a deep learning-based method that can automatically survey sections of roadside verge by detecting the presence of positive indicator species. Using images and ground truth survey data from the rural UK county of Lincolnshire, DeepVerge achieved a mean accuracy of 88\% and a mean F1 score of 0.82. Such a method may be used by local authorities to identify new local wildlife sites, and aid management and environmental planning in line with legal and government policy obligations, saving thousands of hours of skilled labour}
}

@article{lincoln55673,
           title = {Survey of maps of dynamics for mobile robots},
          author = {Tomasz Piotr Kucner and Martin Magnusson and Sariah Mghames and Luigi Palmieri and Francesco Verdoja and Chittaranjan Srinivas Swaminathan and Tom{\'a}{\v s} Krajn{\'i}k and Erik Schaffernicht and Nicola Bellotto and Marc Hanheide and Achim J Lilienthal},
       publisher = {Sage Publications},
            year = {2023},
             doi = {10.1177/02783649231190428},
         journal = {The International Journal of Robotics Research (IJRR)},
        keywords = {ARRAY(0x55be9b3193b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55673/},
        abstract = {Robotic mapping provides spatial information for autonomous agents. Depending on the tasks they seek to enable, the maps created range from simple 2D representations of the environment geometry to complex, multilayered semantic maps. This survey article is about maps of dynamics (MoDs), which store semantic information about typical motion patterns in a given environment. Some MoDs use trajectories as input, and some can be built from short, disconnected observations of motion. Robots can use MoDs, for example, for global motion planning, improved localization, or human motion prediction. Accounting for the increasing importance of maps of dynamics, we present a comprehensive survey that organizes the knowledge accumulated in the field and identifies promising directions for future work. Specifically, we introduce field-specific vocabulary, summarize existing work according to a novel taxonomy, and describe possible applications and open research problems. We conclude that the field is mature enough, and we expect that maps of dynamics will be increasingly used to improve robot performance in real-world use cases. At the same time, the field is still in a phase of rapid development where novel contributions could significantly impact this research area.}
}

@article{lincoln56037,
           title = {Bacchus Long?Term (BLT) data set: Acquisition of the agricultural multimodal BLT data set with automated robot deployment},
          author = {Riccardo Polvara and Sergio Molina Mellado and Ibrahim Hroob and Alexios Papadimitriou and Konstantinos Tsiolis and Dimitrios Giakoumis and Spiridon Likothanassis and Dimitrios Tzovaras and Grzegorz Cielniak and Marc Hanheide},
       publisher = {Wiley},
            year = {2023},
             doi = {10.1002/rob.22228},
         journal = {Journal of Field Robotics},
        keywords = {ARRAY(0x55be9b55d340)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56037/},
        abstract = {Achieving a robust long-term deployment with mobile robots in the agriculture domain is both a demanded and challenging task. The possibility to have autonomous platforms in the field performing repetitive tasks, such as monitoring or harvesting crops, collides with the difficulties posed by the always-changing appearance of the environment due to seasonality.
With this scope in mind, we report an ongoing effort in the long-term deployment of an autonomous mobile robot in a vineyard, with the main objective of acquiring what we called the Bacchus Long-Term (BLT) Dataset. This dataset consists of multiple sessions recorded in the same area of a vineyard but at different points in time, covering a total of 7 months to capture the whole canopy growth from March until September. The multimodal dataset recorded is acquired with the main focus put on pushing the development and evaluations of different mapping and localisation algorithms for long-term autonomous robots operation in the agricultural domain.  Hence, besides the dataset, we also present an initial study in long-term localisation using four different sessions belonging to four different months with different plant stages. We identify that state-of-the-art localisation methods can only cope partially with the amount of change in the environment, making the proposed dataset suitable to establish a benchmark on which the robotics community can test its methods. On our side, we anticipate two solutions pointed at extracting stable temporal features for improving long-term 4d localisation results.
The BLT dataset is available at https://lncn.ac/lcas-blt\}\{lncn.ac/lcas-blt.}
}

@article{lincoln55429,
           title = {Selective Harvesting Robots: A Review},
          author = {Vishnu Rajendran Sugathakumary and Bappaditya Debnath and Sariah Mghames and Willow Mandil and Soran Parsa and Simon Parsons and Amir Ghalamzan Esfahani},
       publisher = {Wiley},
            year = {2023},
         journal = {Journal of Field Robotics},
        keywords = {ARRAY(0x55be9b53a3d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55429/},
        abstract = {Climate change and population growth have created significant challenges for global food production, and ensuring food security requires a resilient food-production system. One of the most labour-intensive tasks in agriculture and food production is selective harvesting, which is vulnerable to risks such as a shortage of adequate labour force. To address this challenge, there is a growing need for robots that can deliver precise and efficient harvesting operations. However, developing robots for selective harvesting presents several technological challenges and raises a range of intriguing scientific questions. This paper provides an overview of the available robotic technologies for the selective harvesting of high-value crops and discusses the latest advancements and challenges in the relevant technology domains, including robotic hardware, robot perception, robot planning, and robot control. Additionally, this paper presents several open research questions that can serve as a research focus for further development in this field.}
}

@article{lincoln56198,
          volume = {14136},
          author = {Srikishan Vayakkattil and Grzegorz Cielniak and Marcello Calisti},
       booktitle = {Towards Autonomous Robotic Systems},
           title = {Plant Phenotyping Using DLT Method: Towards Retrieving the Delicate Features in a Dynamic Environment},
       publisher = {Springer},
            year = {2023},
         journal = {Lecture Notes in Computer Science},
             doi = {10.1007/978-3-031-43360-3\_1},
           pages = {3--14},
        keywords = {ARRAY(0x55be9b5373f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56198/},
        abstract = {Passive phenotyping methodologies use various techniques for calibration, which include a variety of sensory information like vision. Contrary to the state-of-the-art, this paper presents the use of a Direct Linear Transformation (DLT) algorithm to find the shape and position of fine and delicate features in plants. The proposed method not only finds a solution to the motion problem but also provides additional information related to the displacement of the traits of the subject plant. This study uses DLTdv digitalisation toolbox to implement the DLT modelling tool which reduces the complications in data processing. The calibration feature of the toolbox also enables the prior assumption of calibrated space in using DLT.}
}

@inproceedings{lincoln56159,
       booktitle = {CVPPA @ ICCV 2023},
           title = {Motion-Based Segmentation Utilising Oscillatory Plant Properties},
          author = {Nikolaus Wagner and Grzegorz Cielniak},
            year = {2023},
        keywords = {ARRAY(0x55be9b522f08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/56159/},
        abstract = {Modern computer vision technology plays an increasingly important role in agriculture. Automated monitoring of plants for example is an essential task in several applications, such as high-throughput phenotyping or plant health monitoring. Under external influences like wind, plants typically exhibit dynamic behaviours which reveal important characteristics of their structure and condition. These behaviours, however, are typically not considered by state-of-the-art automated phenotyping methods which mostly observe static plant properties. 
In this paper, we propose an automated system for monitoring oscillatory plant movement from video sequences. We employ harmonic inversion for the purpose of efficiently and accurately estimating the eigenfrequency and damping parameters of individual plant parts. The achieved accuracy is compared against values obtained by performing the Discrete Fourier Transform (DFT), which we use as a baseline. We demonstrate the applicability of this approach on different plants and plant parts, like wheat ears, hanging vines, as well as stems and stalks, which exhibit a range of oscillatory motions. By utilising harmonic inversion, we are able to consistently obtain more accurate values for the eigenfrequencies compared to those obtained by DFT. We are furthermore able to directly estimate values for the damping coefficient, achieving a similar accuracy as via DFT-based methods, but without the additional computational effort required for the latter. With the approach presented in this paper, it is possible to obtain estimates of mechanical plant characteristics in an automated manner, enabling novel automated acquisition of novel traits for phenotyping.}
}

