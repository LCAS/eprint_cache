@inproceedings{lincoln55016,
       booktitle = {Future Steel Forum},
           month = {September},
           title = {Green Steel: A New Frontier for In-Space Manufacturing and Circular Economy},
          author = {Mini Rai and Dirk Schaefer and Manu Nair and Mithun Poozhiyil and Shan Dulanty},
            year = {2023},
        keywords = {ARRAY(0x563213971628)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55016/},
        abstract = {Since the launch of Sputnik in 1957, chrome and nickel steel alloys have been widely used for building satellites and launchers for manned and unmanned missions. Their high resistance to extreme temperatures makes them ideal for spacecraft heatshields. The James Webb Space telescope used steel molds to construct its 6.5m primary mirror containing pressed beryllium powder. Steel tubes are also used for building a telescope?s cooling system. Likewise, solar sails use steel booms to ensure proper deployment. Various other sub-systems on board the International Space Station and other spacecraft are made of steel and other high-value materials.  These examples give an insight into the application of steel and its unprecedented needs in the booming Space industry.
Although humankind continues to benefit tremendously from advancements in Space Science and Technology, there is a growing concern over space sustainability. Millions of Space debris, large and small, orbiting Earth threaten the space ecosystem. To address this alarming issue, many investors, regulators and insurers have stepped in to support Active Debris Removal missions to clean up Space. However, the current approach is to deorbit space debris, but the remnants returned to Earth are non-biodegradable objects, polluting the oceans and affecting marine lives. Space trash is an immense resource that should be reused for manufacturing newer systems in orbit. The feedstock needed for on-demand manufacturing of new or replacement parts and components can be produced by recycling materials in orbit, including those previously used for packaging or current space debris. This includes the abundance of steel and other metals on the orbiting space debris. However, research on recycling space debris and additive manufacturing in Space is still in its infancy, hindering the goal of achieving an in-space circular economy. 
Considering the importance of net-zero manufacturing on the ground and in Space, recycling materials from space debris for on-demand manufacturing in orbit would be environmentally friendly and economically profitable. This paper presents the technological challenges in recovering and reusing steel and other high-value materials floating around the Earth?s orbits. Further, the benefits of in-orbit recycling operations for implementing on-demand design and fabrication services will be introduced. The state-of-the-art additive manufacturing in Space, the technological gaps, and the step towards manufacturing green steel from space debris will be covered. Such capabilities will significantly reduce launch costs and carbon footprint by decreasing the number of launches and the need for ground-based fabrication. The paradigm shift toward in-space manufacturing aligns well with our curiosity to continue to explore the universe and improve lives on Earth whilst achieving a sustainable circular economy on Earth and in Space.}
}

@inproceedings{lincoln55397,
       booktitle = {TAROS},
           month = {September},
           title = {Evaluation of OSMC open source motor driver{$\backslash$}{$\backslash$} for reproducible robotics research},
          author = {Elijah Alabi and Fanta Camara and Charles Fox},
            year = {2023},
        keywords = {ARRAY(0x56321396e478)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55397/},
        abstract = {There is a growing need for open source hardware subcomponents to be evaluated.  Most robotic systems are ultimately based upon motors which are driven to move either to certain positions, as in robot arms, or to certain velocities, as in wheeled mobile robots. We evaluate a state of the art OSH driver, OSMC, for such systems, and contribute new Open Source Software (OSS) to control it. Our findings suggest that OSMC is now mature enough to replace closed-source motor drivers in medium-size robots such as agri-robots and last mile delivery vehicles.}
}

@inproceedings{lincoln55398,
       booktitle = {TAROS},
           month = {September},
           title = {Simultaneous Base and Arm Trajectories for Multi-Target Mobile Agri-Robot},
          author = {Josh Davy and Charles Fox},
       publisher = {TAROS},
            year = {2023},
        keywords = {ARRAY(0x56321396e460)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55398/},
        abstract = {Many agricultural robotics tasks require an end effector to hold stationary above individual plants in the field for short periods. Examples include precision harvesting, imaging and spraying. This  effector may be mounted on a mobile base such as a large tractor or small robot, driving in the field.  We consider how to optimise control of the base and the end actuator together, to minimise total time taken to visit the plants.  Our approach is based on low level combination of simple motion primitives, with mid level target clustering, and higher level planning. For the high level, three strategies are compared and evaluated in simulation: baseline stop-and-spray, constant velocity, and variable velocity. The baseline strategy is common in existing systems, and is shown to be outperformed by the new methods. The application considered here is weed spraying, but the methods are applicable to many tasks.}
}

@inproceedings{lincoln55399,
       booktitle = {TAROS},
           month = {September},
           title = {Open source hardware robotics interfacing board},
          author = {Kshitij Gaikwad and Rakshit Soni and Charles Fox and Chris Waltham},
            year = {2023},
        keywords = {ARRAY(0x5632139716b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55399/},
        abstract = {Robotics research still struggles with reproducibility. The ROS ecosystem  enables reuse of software, but not hardware. Researchers waste time porting systems between hardware platforms to reproduce research between labs.  Researchers in developing counties in particular often cannot afford the proprietary robots used by others. If a published robotics system is dependent on any component that is only available from a single supplier, then all work building on it is at risk if that supplier vanishes, de-lists or changes the product. Open Source Hardware (OSH, {$\backslash$}cite\{pearce2012building\}) is hardware whose designs and build instructions are public, easy, and low-cost so that anyone is free to build and modify them, enabling large community collaborations.  Combined open software and hardware stacks allow any researcher to download, build, exactly replicate, then extend the published work which they read about.}
}

@inproceedings{lincoln55400,
       booktitle = {TAROS},
           month = {September},
           title = {Skid-steer friction calibration protocol for digital twin creation},
          author = {Rachel Trimble and Charles Fox},
            year = {2023},
        keywords = {ARRAY(0x5632139716a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55400/},
        abstract = {Mobile robots require digital twins to test and learn algorithms while minimising the difficulty, expense and risk of physical trials.  Most mobile robots use wheels, which are notoriously difficult to simulate accurately due to friction.  Physics engines approximate complex tribology using simplified models which can result in unrealistic behaviors such as  inability to turn or sliding sideways down small slopes.  Methods exist to characterise friction properties of skid steer vehicles {$\backslash$}cite\{khaleghian2017technical\} but use has been limited because they require expensive measurement equipment or physics  models not available in common simulators.  We present a new simple protocol to obtain dynamic friction parameters from physical four-wheeled skid-steer robots for use in the Gazebo robot simulator using ODE (Open Dynamics Engine), assuming only that calibrated IMU (Inertial Measurement Unit) and odometry, and vehicle and wheel weights and geometry are available.}
}

@article{lincoln55642,
          volume = {212},
          number = {108054},
           month = {September},
          author = {Jonathan Cox and Nikolaos Tsagkopoulos and Zden{\v e}k Rozsyp{\'a}lek and Tom{\'a}{\v s} Krajn{\'i}k and Elizabeth Sklar and Marc Hanheide},
           title = {Visual teach and generalise (VTAG){--}Exploiting perceptual aliasing for scalable autonomous robotic navigation in horticultural environments},
       publisher = {Elsevier},
            year = {2023},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2023.108054},
        keywords = {ARRAY(0x563213971700)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55642/},
        abstract = {Nowadays, most agricultural robots rely on precise and expensive localisation, typically based on global navigation satellite systems (GNSS) and real-time kinematic (RTK) receivers. Unfortunately, the precision of GNSS localisation significantly decreases in environments where the signal paths between the receiver and the satellites are obstructed. This precision hampers deployments of these robots in, e.g., polytunnels or forests. An attractive alternative to GNSS is vision-based localisation and navigation. However, perceptual aliasing and landmark deficiency, typical for agricultural environments, cause traditional image processing techniques, such as feature matching, to fail. We propose an approach for an affordable pure vision-based navigation system which is not only robust to perceptual aliasing, but it actually exploits the repetitiveness of agricultural environments. Our system extends the classic concept of visual teach and repeat to visual teach and generalise (VTAG). Our teach and generalise method uses a deep learning-based image registration pipeline to register similar images through meaningful generalised representations obtained from different but similar areas. The proposed system uses only a low-cost uncalibrated monocular camera and the robot?s wheel odometry to produce heading corrections to traverse crop rows in polytunnels safely. We evaluate this method at our test farm and at a commercial farm on three different robotic platforms where an operator teaches only a single crop row. With all platforms, the method successfully navigates the majority of rows with most interventions required at the end of the rows, where the camera no longer has a view of any repeating landmarks such as poles, crop row tables or rows which have visually different features to that of the taught row. For one robot which was taught one row 25 m long our approach autonomously navigated the robot a total distance of over 3.5 km, reaching a teach-generalisation gain of 140.}
}

@inproceedings{lincoln54690,
       booktitle = {18th International Conference on Intelligent Autonomous Systems},
           month = {July},
           title = {S-NET: End-to-end Unsupervised Learning of Long-Term 3D Stable objects},
          author = {Ibrahim Hroob and Sergio Molina Mellado and Riccardo Polvara and Grzegorz Cielniak and Marc Hanheide},
            year = {2023},
        keywords = {ARRAY(0x563213973e90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54690/},
        abstract = {In this research, we present an end-to-end data-driven pipeline for determining the long-term stability status of objects within a given environment, specifically distinguishing between static and dynamic objects. Understanding object stability is key for mobile robots since longterm stable objects can be exploited as landmarks for long-term localisation. Our pipeline includes a labelling method that utilizes historical data from the environment to generate training data for a neural network. Rather than utilizing discrete labels, we propose the use of point-wise continuous label values, indicating the spatio-temporal stability of individual points, to train a point cloud regression network named S-NET. Our approach is evaluated on point cloud data from two parking lots in the NCLT dataset, and the results show that our proposed solution,  outperforms direct training of a classification model for static vs dynamic object classification.}
}

@inproceedings{lincoln53780,
           month = {July},
          author = {Karthik Seemakurthy and Petra Bosilj and Erchan Aptoula and Charles Fox},
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           title = {Domain Generalised Fully Convolutional One Stage Detection},
       publisher = {IEEE},
             doi = {10.1109/ICRA48891.2023.10160937},
           pages = {7002--7009},
            year = {2023},
        keywords = {ARRAY(0x563213971640)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53780/},
        abstract = {Abstract{--}Real-time vision in robotics plays an important role in localising and recognising objects. Recently, deep learning approaches have been widely used in robotic vision. However, most of these approaches have assumed that training and test sets come from similar data distributions, which is not valid in many real world applications. This study proposes an approach to address domain generalisation (i.e. out-of distribution generalisation, OODG) where the goal is to train a model via one or more source domains, that will generalise well to unknown target domains using single stage detectors. All existing approaches which deal with OODG either use slow two stage detectors or operate under the covariate shift assumption which may not be useful for real-time robotics. This is the first paper to address domain generalisation in the context of single stage anchor free object detector FCOS without the covariate shift assumption. We focus on improving the generalisation ability of object detection by proposing new regularisation terms to address the domain shift that arises due to both classification and bounding box regression. Also, we include an additional consistency regularisation term to align the local and global level predictions. The proposed approach is implemented as a Domain Generalised Fully Convolutional One Stage (DGFCOS) detection and evaluated using four object detection datasets which provide domain metadata (GWHD, Cityscapes, BDD100K, Sim10K) where it exhibits a consistent performance improvement over the baselines and is able to run in real-time for robotics.}
}

@inproceedings{lincoln53246,
           month = {June},
          author = {Zuyuan Zhu and Gautham Das and Marc Hanheide},
       booktitle = {The 38th ACM/SIGAPP Symposium On Applied Computing},
           title = {Autonomous Topological Optimisation for Multi-robot Systems in Logistics},
       publisher = {Oxford University Press},
             doi = {10.1145/3555776.3577666},
           pages = {791--799},
            year = {2023},
        keywords = {ARRAY(0x563213971658)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53246/},
        abstract = {Multi-robot systems (MRS) are currently being introduced in many in-field logistics operations in large environments such as warehouses and commercial soft-fruit production. Collision avoidance is a critical problem in MRS as it may introduce deadlocks during the motion planning. In this work, a discretised topological map representation is used for low-cost route planning of individual robots as well as to easily switch the navigation actions depending on the constraints in the environment. However, this topological map could also have bottlenecks which leads to deadlocks and low transportation efficiency when used for an MRS. In this paper, we propose a resource container based Request-Release-Interrupt (RRI) algorithm that constrains each topological node with a capacity of one entity and therefore helps to avoid collisions and detect deadlocks. Furthermore, we integrate a Genetic Algorithm (GA) with Discrete Event Simulation (DES) for optimising the topological map to reduce deadlocks and improve transportation efficiency in logistics tasks. Performance analysis of the proposed algorithms are conducted after running a set of simulations with multiple robots and different maps. The results validate the effectiveness of our algorithms.}
}

@inproceedings{lincoln54842,
       booktitle = {Workshop on Robot Execution Failures and Failure Management Strategies at IEEE ICRA 2023},
           month = {June},
           title = {In-the-Wild Failures in a Long-Term HRI Deployment},
          author = {Francesco Del Duchetto and Ayse Kucukyilmaz and Marc Hanheide},
            year = {2023},
         journal = {Workshop on Robot Execution Failures and Failure Management Strategies at ICRA 2023},
        keywords = {ARRAY(0x563213973ec0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54842/},
        abstract = {Failures are typical in robotics deployments ``in-the-wild'', especially when robots perform their functions within social human spaces. This paper reports on the failures of an autonomous social robot called Lindsey, which has been used in a public museum for several years, covering over 1300 kilometres through its deployment. We present an analysis of distinctive failures observed during the deployment and focusing on those cases where the robot can leverage human help to resolve the problem situation. A final discussion outlines future research directions needed to ensure robots are equipped with adequate resources to detect and appropriately deal with failures requiring a human-in-the-loop approach.}
}

@article{lincoln54478,
          volume = {12},
          number = {63},
           month = {June},
          author = {Jos{\'e} Carlos Mayoral Ba{\~n}os and P{\r a}l Johan From and Grzegorz Cielniak},
           title = {Towards Safe Robotic Agricultural Applications: Safe Navigation System Design for a Robotic Grass-Mowing Application through the Risk Management Method},
       publisher = {MDPI},
            year = {2023},
         journal = {Robotics},
             doi = {10.3390/robotics12030063},
        keywords = {ARRAY(0x563213973ed8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54478/},
        abstract = {Safe navigation is a key objective for autonomous applications, particularly those involving mobile tasks, to avoid dangerous situations and prevent harm to humans. However, the integration of a risk management process is not yet mandatory in robotics development. Ensuring safety using mobile robots is critical for many real-world applications, especially those in which contact with the robot could result in fatal consequences, such as agricultural environments where a mobile device with an industrial cutter is used for grass-mowing. In this paper, we propose an explicit integration of a risk management process into the design of the software for an autonomous grass mower, with the aim of enhancing safety. Our approach is tested and validated in simulated scenarios that assess the effectiveness of different custom safety functionalities in terms of collision prevention, execution time, and the number of required human interventions.}
}

@inproceedings{lincoln55044,
       booktitle = {ICRA2023 Workshop on TIG-IV: Agri-food Robotics From Farm to Fork},
           month = {May},
           title = {Leaving the Lines Behind: Vision-Based Crop Row Exit for Agricultural Robot Navigation},
          author = {Rajitha De Silva and Grzegorz Cielniak and Junfeng Gao},
            year = {2023},
             doi = {10.48550/arXiv.2306.05869},
            note = {Best Paper Award at TIG-IV workshop at ICRA 2023},
        keywords = {ARRAY(0x563213973f08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55044/},
        abstract = {Usage of purely vision based solutions for row switching is not well explored in existing vision based crop row navigation frameworks. This method only uses RGB images for local feature matching based visual feedback to exit crop row. Depth images were used at crop row end to estimatethe navigation distance within headland. The algorithm was tested on diverse headland areas with soil and vegetation. The proposed method could reach the end of the crop row and then navigate into the headland completely leaving behind the crop row with an error margin of 50 cm.}
}

@inproceedings{lincoln55292,
       booktitle = {International Conference on Robotics and Automation 2023},
           month = {May},
           title = {Statistical Shape Representations for Temporal Registration of Plant Components in 3D},
          author = {Karoline Heiwolt and Cengiz {\"O}ztireli and Grzegorz Cielniak},
       publisher = {Infovaya},
            year = {2023},
        keywords = {ARRAY(0x563213973f20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55292/},
        abstract = {Plants are dynamic organisms and understanding temporal variations in vegetation is an essential problem for robots in the wild. However, associating repeated 3D scans of plants across time is challenging. A key step in this process is re-identifying and tracking the same individual plant components over time. Previously, this has been achieved by comparing their global spatial or topological location. In this work, we demonstrate how using shape features improves temporal organ matching. We present a landmark-free shape compression algorithm, which allows for the extraction of 3D shape features of leaves, characterises leaf shape and curvature efficiently in few parameters, and makes the association of individual leaves in feature space possible. The approach combines 3D contour extraction and further compression using Principal Component Analysis (PCA) to produce a shape space encoding, which is entirely learned from data and retains information about edge contours and 3D curvature. Our evaluation on temporal scan sequences of tomato plants shows, that incorporating shape features improves temporal leaf-matching. A combination of shape, location, and rotation information proves most informative for recognition of leaves over time and yields a true positive rate of 75\%, a 15\% improvement on sate-of-the-art methods. This is essential for robotic crop monitoring, which enables whole-of-lifecycle phenotyping.}
}

@article{lincoln54866,
          volume = {7},
           month = {May},
          author = {Simon Pearson and Steve Brewer and Louise Manning and Luc Bidaut and George Onoufriou and Aiden Durrant and Georgios Leontidis and Charbel Jabbour and Andrea Zisman and Gerard Parr and Jeremy Frey and Roger Maull},
           title = {Decarbonising Our Food Systems: Contextualising Digitalisation For Net Zero},
       publisher = {Frontiers Media},
         journal = {Frontiers in Sustainable Food Systems},
             doi = {10.3389/fsufs.2023.1094299},
            year = {2023},
        keywords = {ARRAY(0x563213973f50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54866/},
        abstract = {The food system is undergoing a digital transformation that connects local and global supply chains to address economic, environmental and societal drivers. Digitalisation enables firms to meet sustainable development goals (SDGs), address climate change and the wider negative externalities of food production such as biodiversity loss, and diffuse pollution. Digitalising at the business and supply chain level through public-private mechanisms for data exchange affords the opportunity for greater collaboration, visualising and measuring activities and their socio-environmental impact, demonstrating compliance with regulatory and market requirements and providing opportunity to capture current practice and future opportunities for process and product improvement. Herein we consider digitalisation as a tool to drive innovation and transition to a decarbonised food system. We consider that deep decarbonisation of the food system can only occur when trusted emissions data are exchanged across supply chains. This requires fusion of standardised emissions measurements within a supply chain data sharing framework. This framework, likely operating as a corporate entity, would provide the foci for measurement standards, data exchange, trusted and certified data and as a multi-stakeholder body, including regulators, that would build trust and collaboration across supply chains. This approach provides a methodology for accurate and trusted emissions data to inform consumer choice and industrial response of individual firms within a supply chain.}
}

@article{lincoln52115,
          volume = {13},
          number = {100051},
           month = {April},
          author = {P. Craigon and J. Sacks and S. Brewer and J. Frey and A. Gutierrez Mendoza and S. Kanza and L. Manning and S. Munday and A. Wintour and S. Pearson},
           title = {Ethics by Design: Responsible Research \& Innovation for AI in the Food Sector},
       publisher = {Elsevier},
            year = {2023},
         journal = {Journal of Responsible Technology},
             doi = {10.1016/j.jrt.2022.100051},
        keywords = {ARRAY(0x563213973f80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52115/},
        abstract = {Here we reflect on how a multi-disciplinary working group explored the ethical complexities of the use of new technologies for data sharing in the food supply chain. We used a three-part process of varied design methods, which included collaborative ideation and speculative scenario development, the creation of design fiction objects, and assessment using the Moral-IT deck, a card-based tool. We present, through the lens of the EPSRC's Framework for Responsible Innovation how processes of anticipation, reflection, engagement and action built a plausible, fictional world in which a data trust uses artificial intelligence (AI) to support data sharing and decision-making across the food supply chain. This approach provides rich opportunities for considering ethical challenges to data sharing as part of a reflexive and engaged responsible innovation approach. We reflect on the value and potential of this approach as a method for engaged (co-)design and responsible innovation.}
}

@article{lincoln54257,
          volume = {11},
           month = {April},
          author = {Deema Abdal Hafeth and Stefanos Kollias and Mubeen Ghafoor},
           title = {Semantic Representations with Attention Networks for Boosting Image Captioning},
       publisher = {IEEE},
            year = {2023},
         journal = {IEEE Access},
             doi = {10.1109/ACCESS.2023.3268744},
           pages = {40230--40239},
        keywords = {ARRAY(0x563213973fb0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54257/},
        abstract = {Image captioning has shown encouraging outcomes with Transformer-based architectures
that typically use attention-based methods to establish semantic associations between objects in an
image for caption prediction. Nevertheless, when appearance features of objects in an image display low
interdependence, attention-based methods have difficulty in capturing the semantic association between
them. To tackle this problem, additional knowledge beyond the task-specific dataset is often required
to create captions that are more precise and meaningful. In this article, a semantic attention network is
proposed to incorporate general-purpose knowledge into a transformer attention block model. This design
combines visual and semantic properties of internal image knowledge in one place for fusion, serving as
a reference point to aid in the learning of alignments between vision and language and to improve visual
attention and semantic association. The proposed framework is validated on the Microsoft COCO dataset,
and experimental results demonstrate competitive performance against the current state of the art.}
}

@inproceedings{lincoln53113,
       booktitle = {Conference on Causal Learning and Reasoning (CLeaR)},
           month = {April},
           title = {Enhancing Causal Discovery from Robot Sensor Data in Dynamic Scenarios},
          author = {Luca Castri and Sariah Mghames and Marc Hanheide and Nicola Bellotto},
            year = {2023},
        keywords = {ARRAY(0x563213973fe0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53113/},
        abstract = {Identifying the main features and learning the causal relationships of a dynamic system from time-series of sensor data are key problems in many real-world robot applications. In this paper, we propose an extension of a state-of-the-art causal discovery method, PCMCI, embedding an additional feature-selection module based on transfer entropy. Starting from a prefixed set of variables, the new algorithm reconstructs the causal model of the observed system by considering only the its main features and neglecting those deemed unnecessary for understanding the evolution of the system. We first validate the method on a toy problem, for which the ground-truth model is available, and then on a real-world robotics scenario using a large-scale time-series dataset of human trajectories. The experiments demonstrate that our solution outperforms the previous state-of-the-art technique in terms of accuracy and computational efficiency, allowing better and faster causal discovery of meaningful models from robot sensor data.}
}

@article{lincoln53715,
          volume = {47},
          number = {4},
           month = {April},
          author = {Amir Masoud Ghalamzan Esfahani},
           title = {Haptic-guided Grasping to Minimise Torque Effort during Robotic Telemanipulation},
       publisher = {Springer},
            year = {2023},
         journal = {Autonomous Robots},
             doi = {10.1007/s10514-023-10096-7},
        keywords = {ARRAY(0x563213974010)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53715/},
        abstract = {Teleoperating robotic manipulators can be complicated and cognitively demanding for the human operator. Despite these difficulties, teleoperated robotic systems are still popular in several industrial applications, e.g., remote handling of hazardous material. In this context, we present a novel haptic shared control method for minimising the manipulator torque effort during remote manipulative actions in which an operator is assisted in selecting a suitable grasping pose for then displacing an object along a desired trajectory. Minimising torque is important because it reduces the system operating cost and extends the range of objects that can be manipulated. We demonstrate the effectiveness of the proposed approach in a series of representative real-world pick-and-place experiments as well as in human subjects studies. The reported results prove the effectiveness of our shared control vs. a standard teleoperation approach. We also find that haptic-only guidance performs better than visually guidance, although combining them together leads to the best overall results.}
}

@inproceedings{lincoln53771,
       booktitle = {The 37th AAAI conference on Artificial Intelligence},
           month = {March},
           title = {Domain Generalised Faster R-CNN},
          author = {Karthik Seemakurthy and Charles Fox and Erchan Aptoula and Petra Bosilj},
       publisher = {Association for Advancement of Artificial Intelligence},
            year = {2023},
        keywords = {ARRAY(0x563213974040)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53771/},
        abstract = {Domain generalisation (i.e. out-of-distribution generalisation) is an open problem in machine learning, where the goal is to train a model via one or more source domains, that will generalise well to unknown target domains. While the topic is attracting increasing interest, it has not been studied in detail in the context of object detection. The established approaches all operate under the covariate shift assumption, where the conditional distributions are assumed to be approximately equal across source domains. This is the first paper to address domain generalisation in the context of object detection, with a rigorous mathematical analysis of domain shift, without the covariate shift assumption. We focus on improving the generalisation ability of object detection by proposing new regularisation terms to address the domain shift that arises due to both classification and bounding box regression. Also, we include an additional consistency regularisation term to align the local and global level predictions. The proposed approach is implemented as a Domain Generalised Faster R-CNN and evaluated using four object detection datasets which provide domain metadata (GWHD, Cityscapes, BDD100K, Sim10K) where it exhibits a consistent performance improvement over the baselines. All the codes for replicating the results in this paper can be found at https://github.com/karthikiitm87/domain-generalisation.git}
}

@inproceedings{lincoln54118,
           month = {March},
          author = {Marina Constantinou and Riccardo Polvara and Evagoras Makridis},
       booktitle = {17th International Technology, Education and Development Conference},
           title = {The technologisation of thematic analysis: a case study into automatising qualitative research},
       publisher = {IATED},
            year = {2023},
         journal = {17th International Technology, Education and Development Conference},
             doi = {10.21125/inted.2023.0323},
           pages = {1092--1098},
        keywords = {ARRAY(0x563213974070)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54118/},
        abstract = {Thematic analysis is the most commonly used form of qualitative analysis used extensively in educational sciences. While the process is straightforward in the sense that a hermeneutic analysis is conducted so as to detect patterns and assign themes emerging from the data acquired, replicability can be challenging. As a result, there is significant debate about what constitutes reliability and rigour in relation to qualitative coding. Traditional thematic analysis in educational sciences requires the development of a codebook and the recruitment of a research team for intercoder reviewing and code testing. Such a process is often lengthy and infeasible when the number of texts to be analysed increases exponentially. To overcome these limitations, in this work, we use an unsupervised text analysis technique called the Latent Dirichlet Allocation (LDA) to identify distinct abstract topics which are then clustered into potential themes. Our results show that thematic analysis in the field of educational sciences using the LDA text analysis technique has prospects of demonstrating rigour and higher thematic coding reliability and validity while offering a valid intra-coder complementary support to the researcher.}
}

@article{lincoln53439,
          volume = {133},
           month = {March},
          author = {L. Manning and S. Brewer and P. Craigon and J. Frey and A. Gutierrez and N. Jacobs and S. Kanza and S. Munday and J. Sacks and S. Pearson},
           title = {Reflexive governance architectures: considering the ethical implications of autonomous technology adoption in food supply chains},
       publisher = {Elsevier},
            year = {2023},
         journal = {Trends in Food Science \& Technology},
             doi = {10.1016/j.tifs.2023.01.015},
           pages = {114--126},
        keywords = {ARRAY(0x5632139740a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53439/},
        abstract = {Background: The application of autonomous technology in food supply chains gives rise to a number of ethical considerations associated with the interaction between human and technology, human-technology-plant and human-technology-animal. These considerations and their implications influence technology design, the ways in which technology is applied, how the technology changes food supply chain practices, decision-making and the associated ethical aspects and outcomes.
Scope and approach: Using the concept of reflexive governance, this paper has critiqued existing reflective food-related ethical assessment tools and proposed the structural elements required for reflexive governance architectures which address both the sharing of data, and the use of artificial intelligence (AI) and machine learning in food supply chains. 
Key findings and conclusions: Considering the ethical implications of using autonomous technology in real life contexts is challenging. The current approach, focusing on discrete ethical elements in isolation e.g., ethical aspects or outcomes, normative standards or ethically orientated compliance-based business strategies is not sufficient in itself. Alternatively, the application of more holistic, reflexive governance architectures can inform consideration of ethical aspects, potential ethical outcomes, in particular how they are interlinked and/or interdependent, and the need for mitigation at all lifecycle stages of technology and food product conceptualisation, design, realisation and adoption in the food supply chain. This research is of interest to those who are undertaking ethical deliberation on data sharing, and  the use of AI and machine learning in food supply chains.}
}

@inproceedings{lincoln53114,
       booktitle = {18th International Conference on Computer Vision Theory and Applications (VISAPP)},
           month = {February},
           title = {Evaluation of Computer Vision-Based Person Detection on Low-Cost Embedded Systems},
          author = {Francesco Pasti and Nicola Bellotto},
            year = {2023},
        keywords = {ARRAY(0x5632139740d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53114/},
        abstract = {Person detection applications based on computer vision techniques often rely on complex Convolutional Neural Networks that require powerful hardware in order achieve good runtime performance. The work of this paper has been developed with the aim of implementing a safety system, based on computer vision algorithms, able to detect people in working environments using an embedded device. Possible applications for such safety systems include remote site monitoring and autonomous mobile robots in warehouses and industrial premises. Similar studies already exist in the literature, but they mostly rely on systems like NVidia Jetson that, with a Cuda enabled GPU, are able to provide satisfactory results. This, however, comes with a significant downside as such devices are usually expensive and require significant power consumption. The current paper instead is going to consider various implementations of computer vision-based person detection on two power-efficient and inexpensive devices, namely Raspberry Pi 3 and 4. In order to do so, some solutions based on off-the-shelf algorithms are first explored by reporting experimental results based on relevant performance metrics. Then, the paper presents a newly-created custom architecture, called eYOLO, that tries to solve some limitations of the previous systems. The experimental evaluation demonstrates the good performance of the proposed approach and suggests ways for further improvement.}
}

@inproceedings{lincoln53115,
       booktitle = {AAAI Bridge Program ?AI and Robotics?},
           month = {February},
           title = {Towards Long-term Autonomy: A Perspective from Robot Learning},
          author = {Zhi Yan and Li Sun and Tomas Krajnik and Tom Duckett and Nicola Bellotto},
            year = {2023},
        keywords = {ARRAY(0x563213974100)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53115/},
        abstract = {In the future, service robots are expected to be able to operate autonomously for long periods of time without human intervention. Many work striving for this goal have been emerging with the development of robotics, both hardware and software. Today we believe that an important underpinning of long-term robot autonomy is the ability of robots to learn on site and on-the-fly, especially when they are deployed in changing environments or need to traverse different environments. In this paper, we examine the problem of long-term autonomy from the perspective of robot learning, especially in an online way, and discuss in tandem its premise "data" and the subsequent "deployment".}
}

@inproceedings{lincoln50521,
           month = {January},
          author = {Fetullah Atas and Grzegorz Cielniak and Lars Grimstad},
            note = {ISBN: 978-3-031-22216-0},
       booktitle = {17th International Conference on Intelligent Autonomous Systems},
           title = {Benchmark of Sampling-Based Optimizing Planners for Outdoor Robot Navigation},
       publisher = {Springer},
            year = {2023},
             doi = {10.1007/978-3-031-22216-0\_16},
           pages = {231--243},
        keywords = {ARRAY(0x563213974130)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50521/},
        abstract = {This paper evaluates Sampling-Based Optimizing (SBO) planners from the Open Motion Planning Library (OMPL) in the context of mobile robot navigation in outdoor environments. Many SBO planners have been proposed, and determining performance differences among these planners for path planning problems can be time-consuming and ambiguous. The probabilistic nature of SBO planners can also complicate this procedure, as different results for the same planning problem can be obtained even in consecutive queries from the same planner. We compare all available SBO planners in OMPL with an automated planning problem generation method designed specifically for outdoor robot navigation scenarios. Several evaluation metrics are chosen, such as the length, smoothness, and success rate of the resulting path, and probability distributions for metrics are presented. With the experimental results obtained, clear recommendations on high-performing planners for mobile robot path planning problems are made, which will be useful to researchers and practitioners in mobile robot planning and navigation.}
}

@article{lincoln52872,
          volume = {7},
          number = {1},
           month = {January},
          author = {Vijja Wichitwechkarn and Charles Fox},
           title = {MACARONS: A Modular and Open-Sourced Automation System for Vertical Farming},
       publisher = {Ubiquity Press},
            year = {2023},
         journal = {Jounral of Open Hardware},
             doi = {10.5334/joh.53},
        keywords = {ARRAY(0x563213974160)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52872/},
        abstract = {The Modular Automated Crop Array Online System (MACARONS) is an extensible, scalable, open hardware system for plant transport in automated horticulture systems such as vertical farms.  It is specified to move trays of plants up to 1060mm \${$\backslash$}times\$ 630mm and 12.5kg at a rate of 100mm/s along the guide rails and 41.7mm/s up the lifts, such as between stations for monitoring and actuating plants. The cost for the construction of one grow unit of MACARONS is 144.96USD which equates to 128.85USD/m\${\^{ }}2\$ of grow area. The designs are released and meets the requirements of CERN-OSH-W, which includes step-by-step graphical build instructions and can be built by a typical technical person in one day at a cost of 1535.50 USD.  Integrated tests are included in the build instructions are used to validate against the specifications, and we report on a successful build.  Through a simple analysis, we demonstrate that MACARONS can operate at a rate sufficient to automate tray loading/unloading, to reduce labour costs in a vertical farm.}
}

@inproceedings{lincoln53116,
       booktitle = {AAAI Bridge Program ?Continual Causality?},
           month = {January},
           title = {From Continual Learning to Causal Discovery in Robotics},
          author = {Luca Castri and Sariah Mghames and Nicola Bellotto},
            year = {2023},
        keywords = {ARRAY(0x563213974190)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53116/},
        abstract = {Reconstructing accurate causal models of dynamic systems from time-series of sensor data is a key problem in many real-world scenarios. In this paper, we present an overview based on our experience about practical challenges that the causal analysis encounters when applied to autonomous robots and how Continual Learning{\texttt{\char126}}(CL) could help to overcome them. We propose a possible way to leverage the CL paradigm to make causal discovery feasible for robotics applications where the computational resources are limited, while at the same time exploiting the robot as an active agent that helps to increase the quality of the reconstructed causal models.}
}

@article{lincoln55690,
           title = {Deep learning-based Crop Row Detection for Infield Navigation of Agri-Robots},
          author = {Rajitha De Silva and Grzegorz Cielniak and Gang Wang and Junfeng Gao},
       publisher = {Wiley Periodicals, Inc.},
            year = {2023},
             doi = {10.1002/rob.22238},
         journal = {Journal of Field Robotics},
        keywords = {ARRAY(0x5632139741c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55690/},
        abstract = {Autonomous navigation in agricultural environments is challenged by varying field conditions that arise in arable fields.
State-of-the-art solutions for autonomous navigation in such environments require expensive hardware such as RTK-GNSS. This paper presents a robust crop row detection algorithm that withstands such field variations using inexpensive cameras. Existing datasets for crop row detection does not represent all the possible field variations. A dataset of sugar beet images was created representing 11 field variations comprised of multiple grow stages, light levels, varying weed
densities, curved crop rows and discontinuous crop rows.
The proposed pipeline segments the crop rows using a deep
learning-based method and employs the predicted segmentation mask for extraction of the central crop using a novel
central crop row selection algorithm. The novel crop row
detection algorithm was tested for crop row detection performance and the capability of visual servoing along a crop
row. The visual servoing-based navigation was tested on a
realistic simulation scenario with the real ground and plant
textures. Our algorithm demonstrated robust vision-based
crop row detection in challenging field conditions outperforming the baseline.}
}

@article{lincoln55428,
           title = {A model to support collective reasoning: Formalization, analysis and computational assessment},
          author = {Jordi Ganzer and Natalia Criado and Maite Lopez-Sanchez and Simon Parsons and Juan A. Rodriguez-Aguilar},
       publisher = {AI Access Foundation},
            year = {2023},
         journal = {Journal of Artificial Intelligence Research (JAIR)},
        keywords = {ARRAY(0x5632139741f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55428/},
        abstract = {In this paper we propose a new model to represent human debates and methods to obtain collective conclusions from them. This model overcomes two drawbacks of existing approaches. First, our model does not assume that participants agree on the structure of the debate. It does this by allowing participants to express their opinion about all aspects of the debate.  Second, our model does not assume that participants' opinions are rational, an assumption that significantly limits current approaches. Instead, we define a weaker notion of rationality that characterises coherent opinions, and we consider different scenarios based on the coherence of individual opinions and the level of consensus.  
We provide a formal analysis of different opinion aggregation functions that compute a collective decision based on the individual opinions and the debate structure. In particular, we demonstrate that aggregated opinions can be coherent even if there is a lack of consensus and individual opinions are not coherent. We conclude with an empirical evaluation demonstrating that collective opinions can be computed efficiently for real-sized debates.}
}

@article{lincoln55430,
           title = {Implementation of a human-aware robot navigation module for cooperative soft-fruit harvesting operations},
          author = {Leonardo Guevara and Marc Hanheide and Simon Parsons},
       publisher = {Wiley},
            year = {2023},
             doi = {10.1002/rob.22227},
         journal = {Journal of Field Robotics},
        keywords = {ARRAY(0x563213974220)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55430/},
        abstract = {In the last decades, robotic solutions have been introduced in agriculture to improve the efficiency of traditional tasks such as spraying, plowing, and seeding. However, for a more complex task like soft-fruit harvesting, the efficiency of experienced human pickers has not been surpassed yet by robotic solutions. Thus, in the immediate future, human labor will probably be still necessary for picking tasks while robotic platforms could be used as collaborators, supporting the pickers in the transportation of the harvested fruit. This cooperative harvesting strategy creates a Human-Robot Interaction (HRI) that requires significant further development in human-aware safe navigation and effective bi-directional communication of intent. In fact, although agricultural robots are considered small/medium size machinery, they still represent a risk of causing injuries to human collaborators, especially if people are not trained to work with robots or robot operations are not intuitive. Avoiding such injury is the aim of this work which contributes to the development, implementation, and evaluation of a Human-Aware Navigation (HAN) module that can be integrated into the autonomous navigation system of commercial agricultural robots. The proposed module is responsible for the detection and monitoring of humans working around the robot and uses this information to activate safety actions depending on whether the human presence is considered at risk or not. Apart from ensuring a physically safe HRI, the proposed module deals with the comfort level and psychological safety of human co-workers. The latter is possible by using an explicit human-robot communication strategy that lets both know of the other's intentions, increasing the level of trust and reducing inefficient pauses triggered by unnecessary safety actions. The proposed HAN solution was integrated into a commercial agricultural robot and tested in several situations that are expected to happen during cooperative harvesting operations. The results of an usability assessment illustrated the benefits of the proposal in terms of safety, efficiency, and ergonomics.}
}

@article{lincoln55459,
           title = {Implementation of a human?aware robot navigation module for cooperative soft?fruit harvesting operations},
          author = {Leonardo Guevara and Marc Hanheide and Simon Parsons},
       publisher = {Wiley},
            year = {2023},
             doi = {10.1002/rob.22227},
         journal = {Journal of Field Robotics},
        keywords = {ARRAY(0x563213974250)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55459/},
        abstract = {In the last decades, robotic solutions have been introduced in agriculture to improve the efficiency of tasks such as spraying, plowing, and seeding. However, for a more complex task like soft-fruit harvesting, the efficiency of experienced human pickers has not been surpassed yet by robotic solutions. Thus, in the immediate future, human labor will probably be still necessary for picking tasks while robotic platforms could be used as collaborators, supporting the pickers in the transportation of the harvested fruit. This cooperative harvesting strategy creates a human?robot interaction (HRI) that requires significant further development in human-aware safe navigation and effective bidirectional communication of intent. In fact, although agricultural robots are considered small/medium size machinery, they still represent a risk of causing injuries to human collaborators, especially if people are not trained to work with robots or robot operations are not intuitive. Avoiding such injury is the aim of this work which contributes to the development, implementation, and evaluation of a human-aware navigation (HAN) module that can be integrated into the autonomous navigation system of commercial agricultural robots. The proposed module is responsible for the detection and monitoring of humans working around the robot and uses this information to activate safety actions depending on whether the human presence is considered at risk or not. Apart from ensuring a physically safe HRI, the proposed module deals with the comfort level and psychological safety of human coworkers. The latter is possible by using an explicit human?robot communication strategy that lets both know of the other's intentions, increasing the level of trust and reducing inefficient pauses triggered by unnecessary safety actions. The proposed HAN solution was integrated into a commercial agricultural robot and tested in several situations that are expected to happen during cooperative harvesting operations. The results of a usability assessment illustrated the benefits of the proposal in terms of safety, efficiency, and ergonomics.}
}

@inproceedings{lincoln53352,
       booktitle = {6th IEEE-RAS International Conference on Soft Robotics (ROBOSOFT)},
           title = {Fabrication and Characterization of a Passive Variable Stiffness Joint based on Shear Thickening Fluids},
          author = {Philip H. Johnson and Mini Rai and Marcello Calisti},
       publisher = {IEEE},
            year = {2023},
             doi = {10.1109/RoboSoft55895.2023.10122061},
        keywords = {ARRAY(0x563213974280)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53352/},
        abstract = {In soft robotics, variable stiffening is the key to taking full advantage of properties such as compliance, manipulability and deformability. However, many variable stiffness actuators and mechanisms which have been produced so far to control these properties of soft robots are slow, bulky, or require additional complex actuators. This paper presents a novel passive soft joint based upon the intrinsic non-Newtonian behavior of Shear Thickening Fluids (STFs). The joint stiffness is varied by changing the speed at which it is actuated. The joints fabricated for testing have a simple cylindrical structure comprised of a soft silicone shell filled with a STF. Three prototypes with lengths of 20, 40 and 60mm were produced for experimental validation. We characterize the behavior of the joints in compression, expansion and bending, yielding a stiffness variation of more than 5x based on actuation speed in compression testing. This paper is the first step in producing a new category of variable stiffening mechanisms based on STFs which can be incorporated into soft robots without the need for additional actuation. It is envisaged that this new soft joint will find applications in soft manipulators and wearable devices.}
}

@article{lincoln55636,
           title = {Argument Schemes and a Dialogue System for Explainable Planning},
          author = {Quratul-ain Mahesar and Marc Hanheide and Simon Parsons},
       publisher = {Association for Computing Machinery (ACM)},
            year = {2023},
             doi = {10.1002/rob.22227},
         journal = {ACM Transactions on Intelligent Systems and Technology},
        keywords = {ARRAY(0x5632139742b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55636/},
        abstract = {Artificial Intelligence (AI) is being increasingly deployed in practical applications. However, there is a major concern whether AI systems will be trusted by humans. In order to establish trust in AI systems, there is a need for users to understand the reasoning behind their solutions. Therefore, systems should be able to explain and justify their output. Explainable AI Planning (XAIP) is a field that involves explaining the outputs, i.e., solution plans produced by AI planning systems to a user. The main goal of a plan explanation is to help humans understand reasoning behind the plans that are produced by the planners. In this paper, we propose an argument scheme-based approach to provide explanations in the domain of AI planning. We present novel argument schemes to create arguments that explain a plan and its key elements; and a set of critical questions that allow interaction between the arguments and enable the user to obtain further information regarding the key elements of the plan. Furthermore, we present a novel dialogue system using the argument schemes and critical questions for providing interactive dialectical explanations.}
}

@inproceedings{lincoln54568,
       booktitle = {International Joint Conference on Neural Networks (IJCNN)},
           title = {A Neuro-Symbolic Approach for Enhanced Human Motion Prediction},
          author = {Sariah Mghames and Luca Castri and Marc Hanheide and Nicola Bellotto},
            year = {2023},
             doi = {10.48550/arXiv.2304.11740},
        keywords = {ARRAY(0x5632139742e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54568/},
        abstract = {Reasoning on the context of human beings is crucial for many real-world applications especially for those deploying autonomous systems (e.g. robots). In this paper, we present a new approach for context reasoning to further advance the field of human motion prediction. We therefore propose a neuro-symbolic approach for human motion prediction (NeuroSyM), which weights differently the interactions in the neighbourhood by leveraging an intuitive technique for spatial representation called Qualitative Trajectory Calculus (QTC).
 The proposed approach is experimentally tested on medium and long term time horizons using two architectures from the state of art, one of which is  a baseline for human motion prediction and the other is a baseline for generic multivariate time-series prediction. Six datasets of challenging crowded scenarios, collected from both fixed and mobile cameras, were used for testing. Experimental results show that the NeuroSyM approach outperforms in most cases the baseline architectures in terms of prediction accuracy.}
}

@inproceedings{lincoln55466,
       booktitle = {32nd IEEE International Conference on Robot and Human Interactive Communication},
           title = {Qualitative Prediction of Multi-Agent Spatial Interactions},
          author = {Sariah Mghames and Luca Castri and Marc Hanheide and Nicola Bellotto},
       publisher = {IEEE},
            year = {2023},
        keywords = {ARRAY(0x563213974310)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55466/},
        abstract = {Deploying service robots in our daily life, whether in restaurants, warehouses or hospitals, calls for the need to reason on the interactions happening in dense and dynamic scenes. In this paper, we present and benchmark three new  approaches to model and predict multi-agent interactions in dense scenes, including the use of an intuitive qualitative representation. The proposed solutions take into account static and dynamic context to predict individual interactions. They exploit an input- and a temporal-attention mechanism, and are tested on medium and long-term time horizons. The first two approaches integrate different relations from the so-called Qualitative Trajectory Calculus (QTC) within a state-of-the-art deep neural network to create a symbol-driven neural architecture for predicting spatial interactions. The third approach implements a purely data-driven network for motion prediction, the output of which is post-processed to predict QTC spatial interactions. Experimental results on a popular robot dataset of challenging crowded scenarios show that the purely data-driven prediction approach generally outperforms the other two. The three approaches were further evaluated on a different but related human scenarios to assess their generalisation capability.}
}

@inproceedings{lincoln53555,
       booktitle = {HCI International 2023},
           title = {Augmented Reality to Reduce Cognitive Load in Operational Decision-Making},
          author = {Bethan Moncur and Maria J. Galvez Trigo and Letizia Mortara},
            year = {2023},
        keywords = {ARRAY(0x563213974340)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53555/},
        abstract = {Augmented reality (AR) technologies can overlay digital in- formation onto the real world. This makes them well suited for deci- sion support by providing contextually-relevant information to decision- makers. However, processing large amounts of information simultane- ously, particularly in time-pressured conditions, can result in poor decision- making due to excess cognitive load. This paper presents the results of an exploratory study investigating the effects of AR on cognitive load. A within-subjects experiment was conducted where participants were asked to complete a variable-sized bin packing task with and without the as- sistance of an augmented reality decision support system (AR DSS). Semi-structured interviews were conducted to elicit perceptions about the ease of the task with and without the AR DSS. This was supple- mented by collecting quantitative data to investigate if any changes in perceived ease of the task translated into changes in task performance. The qualitative data suggests that the presence of the AR DSS made the task feel easier to participants; however, there was only a statistically in- significant increase in mean task performance. Analysing the data at the individual level does not provide evidence of a translation of increased perceived ease to increased task performance.}
}

@article{lincoln54285,
           title = {DeepVerge: Classification of Roadside Verge Biodiversity and Conservation Potential},
          author = {Andrew Perrett and Harry Pollard and Charlie Barnes and Mark Schofield and Lan Qie and Petra Bosilj and James Brown},
       publisher = {Elsevier},
            year = {2023},
         journal = {Computers, Environment and Urban Systems},
        keywords = {ARRAY(0x563213974370)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/54285/},
        abstract = {Grasslands are increasingly modified by anthropogenic activities and species rich grasslands have become rare habitats in the UK. However, grassy roadside verges often contain conservation priority plant species and should be targeted for protection. Identification of verges with high conservation potential represents a considerable challenge for ecologists, driving the development of automated methods to make up for the shortfall of relevant expertise nationally. Using survey data from 3,900 km of roadside verges alongside publicly available street-view imagery, we present DeepVerge: a deep learning-based method that can automatically survey sections of roadside verge by detecting the presence of positive indicator species. Using images and ground truth survey data from the rural UK county of Lincolnshire, DeepVerge achieved a mean accuracy of 88\% and a mean F1 score of 0.82. Such a method may be used by local authorities to identify new local wildlife sites, and aid management and environmental planning in line with legal and government policy obligations, saving thousands of hours of skilled labour}
}

@article{lincoln55673,
           title = {Survey of maps of dynamics for mobile robots},
          author = {Tomasz Piotr Kucner and Martin Magnusson and Sariah Mghames and Luigi Palmieri and Francesco Verdoja and Chittaranjan Srinivas Swaminathan and Tom{\'a}{\v s} Krajn{\'i}k and Erik Schaffernicht and Nicola Bellotto and Marc Hanheide and Achim J Lilienthal},
       publisher = {Sage Publications},
            year = {2023},
             doi = {10.1177/02783649231190428},
         journal = {The International Journal of Robotics Research (IJRR)},
        keywords = {ARRAY(0x5632139743a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55673/},
        abstract = {Robotic mapping provides spatial information for autonomous agents. Depending on the tasks they seek to enable, the maps created range from simple 2D representations of the environment geometry to complex, multilayered semantic maps. This survey article is about maps of dynamics (MoDs), which store semantic information about typical motion patterns in a given environment. Some MoDs use trajectories as input, and some can be built from short, disconnected observations of motion. Robots can use MoDs, for example, for global motion planning, improved localization, or human motion prediction. Accounting for the increasing importance of maps of dynamics, we present a comprehensive survey that organizes the knowledge accumulated in the field and identifies promising directions for future work. Specifically, we introduce field-specific vocabulary, summarize existing work according to a novel taxonomy, and describe possible applications and open research problems. We conclude that the field is mature enough, and we expect that maps of dynamics will be increasingly used to improve robot performance in real-world use cases. At the same time, the field is still in a phase of rapid development where novel contributions could significantly impact this research area.}
}

@article{lincoln55015,
           title = {Active Debris Removal: A Review and Case Study on LEOPARD Phase 0-A Mission},
          author = {Mithun Poozhiyil and Manu Nair and Mini Rai and Alexander Hall and Connor Meringolo and Mark Shilton and Steven Kay and Danilo Forte and Martin Sweeting and Nikki Antoniou and Victoria Irwin},
       publisher = {Elsevier},
            year = {2023},
             doi = {10.1016/j.asr.2023.06.015},
         journal = {Advances in Space Research},
        keywords = {ARRAY(0x5632139743d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55015/},
        abstract = {The growing number of space debris is alarming as it threatens space-borne services. Hence, there is an increasing demand to remove space debris to ensure sustainability and protect valuable orbital assets. Over the past few years, the research community, agencies and industries have studied many passive and active debris removal methods. However, the current technology readiness for space debris removal is still low. This paper first presents a comparative study of various space debris removal technologies to address the knowledge gap and quantify the challenges. This paper reviews the current state-of-the-art space technologies relevant to Active Debris Removal (ADR) missions. Detailed trade-off analysis is then presented based on the Low Earth Orbit Pursuit for Active Removal of Debris (LEOPARD) Phase 0-A study; this study is part of the United Kingdom (UK) Space Agency?s Active Debris Removal programme. The ADR mission scenario considered in this paper comprises a chaser spacecraft equipped with recommended technologies to capture non-cooperative targets safely. The final capture technology for the LEOPARD mission consists of an active robotic manipulator and a passive net capture mechanism. An analysis of the coupled-body dynamics of the chaser spacecraft carrying the robot manipulator and the targeted debris is carried out in simulation using SimscapeTM. The chaser spacecraft comprises Airbus?s Versatile In-Space and Planetary Arm (VISPA) mounted on a base spacecraft from Surrey Satellite Technology Ltd. (SSTL); the targeted debris is SSTL?s Tactical Operational Satellite (TOPSAT). The simulation results show dynamic changes in the chaser robot and the target satellite while performing non-cooperative capture. The simulation study accounted for various operational scenarios where the target is stationary or in motion. Further, for different modes of operation, the worst-case end-effector capture force limits were determined using open-loop control to execute a safe capture. Overall, the results presented in the paper advance the current state-of-the-art of robotic ADR and offer a significant leap in designing close-range motion and force control for stabilising the coupled multi-body system during capture and post-capture phases. In summary, this paper pinpoints the technological gaps, identifies barriers to realising ADR missions and offers solutions to catalyse technology maturity for protecting the space ecosystem.}
}

@article{lincoln55429,
           title = {Selective Harvesting Robots: A Review},
          author = {Vishnu Rajendran Sugathakumary and Bappaditya Debnath and Sariah Mghames and Willow Mandil and Soran Parsa and Simon Parsons and Amir Ghalamzan Esfahani},
       publisher = {Wiley},
            year = {2023},
         journal = {Journal of Field Robotics},
        keywords = {ARRAY(0x563213974400)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/55429/},
        abstract = {Climate change and population growth have created significant challenges for global food production, and ensuring food security requires a resilient food-production system. One of the most labour-intensive tasks in agriculture and food production is selective harvesting, which is vulnerable to risks such as a shortage of adequate labour force. To address this challenge, there is a growing need for robots that can deliver precise and efficient harvesting operations. However, developing robots for selective harvesting presents several technological challenges and raises a range of intriguing scientific questions. This paper provides an overview of the available robotic technologies for the selective harvesting of high-value crops and discusses the latest advancements and challenges in the relevant technology domains, including robotic hardware, robot perception, robot planning, and robot control. Additionally, this paper presents several open research questions that can serve as a research focus for further development in this field.}
}

