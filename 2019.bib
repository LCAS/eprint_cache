@article{lincoln39226,
          volume = {6},
          number = {4},
           month = {December},
          author = {Ch. Achillas and Dionysis Bochtis and D. Aidonis and V. Marinoudi and D. Folinas},
           title = {Voice-driven fleet management system for agricultural operations},
       publisher = {Elsevier},
            year = {2019},
         journal = {Information Processing in Agriculture},
             doi = {10.1016/j.inpa.2019.03.001},
           pages = {471--478},
        keywords = {ARRAY(0x5585d78f78e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39226/},
        abstract = {Food consumption is constantly increasing at global scale. In this light, agricultural production also needs to increase in order to satisfy the relevant demand for agricultural products. However, due to by environmental and biological factors (e.g. soil compaction) the weight and size of the machinery cannot be further physically optimized. Thus, only marginal improvements are possible to increase equipment effectiveness. On the contrary, late technological advances in ICT provide the ground for significant improvements in agri-production efficiency. In this work, the V-Agrifleet tool is presented and demonstrated. V-Agrifleet is developed to provide a ?hands-free? interface for information exchange and an ?Olympic view? to all coordinated users, giving them the ability for decentralized decision-making. The proposed tool can be used by the end-users (e.g. farmers, contractors, farm associations, agri-products storage and processing facilities, etc.) order to optimize task and time management. The visualized documentation of the fleet performance provides valuable information for the evaluation management level giving the opportunity for improvements in the planning of next operations. Its vendor-independent architecture, voice-driven interaction, context awareness functionalities and operation planning support constitute V-Agrifleet application a highly innovative agricultural machinery operational aiding system.}
}

@article{lincoln37181,
          volume = {113},
           month = {December},
          author = {George Onoufriou and Ronald Bickerton and Simon Pearson and Georgios Leontidis},
            note = {Partners included: Tesco and IMS-Evolve},
           title = {Nemesyst: A Hybrid Parallelism Deep Learning-Based Framework Applied for Internet of Things Enabled Food Retailing Refrigeration Systems},
       publisher = {Elsevier},
            year = {2019},
         journal = {Computers in Industry},
             doi = {10.1016/j.compind.2019.103133},
           pages = {103133},
        keywords = {ARRAY(0x5585d78f5570)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37181/},
        abstract = {Deep Learning has attracted considerable attention across multiple application domains, including computer vision, signal processing and natural language processing. Although quite a few single node deep learning frameworks exist, such as tensorflow, pytorch and keras, we still lack a complete process- ing structure that can accommodate large scale data processing, version control, and deployment, all while staying agnostic of any specific single node framework. To bridge this gap, this paper proposes a new, higher level framework, i.e. Nemesyst, which uses databases along with model sequentialisation to allow processes to be fed unique and transformed data at the point of need. This facilitates near real-time application and makes models available for further training or use at any node that has access to the database simultaneously. Nemesyst is well suited as an application framework for internet of things aggregated control systems, deploying deep learning techniques to optimise individual machines in massive networks. To demonstrate this framework, we adopted a case study in a novel domain; deploying deep learning to optimise the high speed control of electrical power consumed by a massive internet of things network of retail refrigeration systems in proportion to load available on the UK Na- tional Grid (a demand side response). The case study demonstrated for the first time in such a setting how deep learning models, such as Recurrent Neural Networks (vanilla and Long-Short-Term Memory) and Generative Adversarial Networks paired with Nemesyst, achieve compelling performance, whilst still being malleable to future adjustments as both the data and requirements inevitably change over time.}
}

@inproceedings{lincoln40135,
       booktitle = {EDUROBOTICS 2018},
           month = {December},
           title = {Engaging Learners in Dialogue Interactivity Development for Mobile Robots},
          author = {Paul Baxter and Francesco Del Duchetto and Marc Hanheide},
       publisher = {Springer, Cham},
            year = {2019},
             doi = {10.1007/978-3-030-18141-3\_12},
        keywords = {ARRAY(0x5585d78f5558)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40135/},
        abstract = {The use of robots in educational and STEM engagement activities is widespread. In this paper we describe a system developed for engaging learners with the design of dialogue-based interactivity for mobile robots. With an emphasis on a web-based solution that is grounded in both a real robot system and a real application domain (a museum guide robot) our intent is to enhance the benefits to both driving research through potential user-group engagement, and enhancing motivation by providing a real application context for the learners involved. The proposed system is designed to be highly scalable to both many simultaneous users and to users of different age groups, and specifically enables direct deployment of implemented systems onto both real and simulated robots. Our observations from preliminary events, involving both children and adults, support the view that the system is both usable and successful in supporting engagement with the dialogue interactivity problem presented to the participants, with indications that this engagement can persist over an extended period of time.}
}

@article{lincoln39137,
           month = {December},
          author = {Qinbing Fu and Cheng Hu and Jigen Peng and Claire Rind and Shigang Yue},
           title = {A Robust Collision Perception Visual Neural Network with Specific Selectivity to Darker Objects},
       publisher = {IEEE},
         journal = {IEEE Transactions on Cybernetics},
             doi = {10.1109/TCYB.2019.2946090},
           pages = {1--15},
            year = {2019},
        keywords = {ARRAY(0x5585d78f7978)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39137/},
        abstract = {Building an ef?cient and reliable collision perception visual system is a challenging problem for future robots and autonomous vehicles. The biological visual neural networks, which have evolved over millions of years in nature and are working perfectly in the real world, could be ideal models for designing arti?cial vision systems. In the locust?s visual pathways, a lobula giant movement detector (LGMD), that is, the LGMD2, has been identi?ed as a looming perception neuron that responds most strongly to darker approaching objects relative to their backgrounds; similar situations which many ground vehicles and robots are often faced with. However, little has been done on modeling the LGMD2 and investigating its potential in robotics and vehicles. In this article, we build an LGMD2 visual neural network which possesses the similar collision selectivity of an LGMD2 neuron in locust via the modeling of biased-ON and -OFF pathways splitting visual signals into parallel ON/OFF channels. With stronger inhibition (bias) in the ON pathway, this model responds selectively to darker looming objects. The proposed model has been tested systematically with a range of stimuli including real-world scenarios. It has also been implemented in a micro-mobile robot and tested with real-time experiments. The experimental results have veri?ed the effectiveness and robustness of the proposed model for detecting darker looming objects against various dynamic and cluttered backgrounds.}
}

@article{lincoln35842,
          volume = {23},
           month = {December},
          author = {Bruce Grieve and Tom Duckett and Martin Collison and Lesley Boyd and Jon West and Yin Hujun and Farshad Arvin and Simon Pearson},
           title = {The challenges posed by global broadacre crops in delivering smart agri-robotic solutions: A fundamental rethink is required.},
       publisher = {Elsevier},
            year = {2019},
         journal = {Global Food Security},
             doi = {10.1016/j.gfs.2019.04.011},
           pages = {116--124},
        keywords = {ARRAY(0x5585d78f7960)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35842/},
        abstract = {Threats to global food security from multiple sources, such as population growth, ageing farming populations, meat consumption trends, climate-change effects on abiotic and biotic stresses, the environmental impacts of agriculture are well publicised. In addition, with ever increasing tolerance of pest, diseases and weeds there is growing pressure on traditional crop genetic and protective chemistry technologies of the ?Green Revolution?. To ease the burden of these challenges, there has been a move to automate and robotise aspects of the farming process. This drive has focussed typically on higher value sectors, such as horticulture and viticulture, that have relied on seasonal manual labour to maintain produce supply. In developed economies, and increasingly developing nations, pressure on labour supply has become unsustainable and forced the need for greater mechanisation and higher labour productivity. This paper creates the case that for broadacre crops, such as cereals, a wholly new approach is necessary, requiring the establishment of an integrated biology \& physical engineering infrastructure, which can work in harmony with current breeding, chemistry and agronomic solutions. For broadacre crops the driving pressure is to sustainably intensify production; increase yields and/or productivity whilst reducing environmental impact. Additionally, our limited understanding of the complex interactions between the variations in pests, weeds, pathogens, soils, water, environment and crops is inhibiting growth in resource productivity and creating yield gaps. We argue that for agriculture to deliver knowledge based sustainable intensification requires a new generation of Smart Technologies, which combine sensors and robotics with localised and/or cloud-based Artificial Intelligence (AI).}
}

@article{lincoln44909,
          volume = {85},
           month = {December},
          author = {Sepehr Maleki and Chris Bingham},
           title = {Robust hierarchical clustering for novelty identification in sensor networks: With applications to industrial systems},
       publisher = {Elsevier},
            year = {2019},
         journal = {Applied Soft Computing Journal},
             doi = {10.1016/j.asoc.2019.105771},
           pages = {105771},
        keywords = {ARRAY(0x5585d78f79c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/44909/},
        abstract = {The paper proposes a new, robust cluster-based classification technique for Novelty Identification
in sensor networks that possess a high degree of correlation among data streams. During normal
operation, a uniform cluster across objects (sensors) is generated that indicates the absence of
novelties. Conversely, in presence of novelty, the associated sensor is clustered distinctly from the
remaining sensors, thereby isolating the data stream which exhibits the novelty. It is shown how
small perturbations (stemming from noise, for instance) can affect the performance of traditional
clustering methods, and that the proposed variant exhibits a robustness to such influences. Moreover,
the proposed method is compared with a recently reported technique, and shown that it performs
365\% faster computationally. To provide an application case study, the technique is used to identify
emerging fault modes in a sensor network on a sub-15MW industrial gas turbine in presence of other
abrupt, but normal changes that visually might otherwise be interpreted as malfunctions.}
}

@article{lincoln47556,
          volume = {100},
           month = {November},
          author = {Mohammed Al-Khafajiy and Thar Baker and Hilal Al-Libawy and Zakaria Maamar and Moayad Aloqaily and Yaser Jararweh},
           title = {Improving fog computing performance via Fog-2-Fog collaboration},
       publisher = {Elsevier},
            year = {2019},
         journal = {Future Generation Computer Systems},
             doi = {10.1016/j.future.2019.05.015},
           pages = {266--280},
        keywords = {ARRAY(0x5585d78fc368)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47556/},
        abstract = {In the Internet of Things (IoT) era, a large volume of data is continuously emitted from a plethora of connected devices. The current network paradigm, which relies on centralised data centres (aka Cloud computing), has become inefficient to respond to IoT latency concern. To address this concern, fog computing allows data processing and storage ?close? to IoT devices. However, fog is still not efficient due to spatial and temporal distribution of these devices, which leads to fog nodes? unbalanced loads. This paper proposes a new fog-2-fog (f2f) collaboration model that promotes offloading incoming requests among fog nodes, according to their load and processing capabilities, via a novel load balancing known as Fog Resource manAgeMEnt Scheme (FRAMES). A formal mathematical model of  f2f and FRAMES has been formulated, and a set of experiments has been carried out demonstrating the technical doability of f2f collaboration. The performance of the proposed fog load balancing model is compared to other load balancing models.}
}

@article{lincoln36668,
          volume = {366},
           month = {November},
          author = {Heriberto Cuayahuitl and Donghyeon Lee and Seonghan Ryu and Yongjin Cho and Sungja Choi and Satish Indurthi and Seunghak Yu and Hyungtak Choi and Inchul Hwang and Jihie Kim},
           title = {Ensemble-Based Deep Reinforcement Learning for Chatbots},
       publisher = {Elsevier},
            year = {2019},
         journal = {Neurocomputing},
             doi = {10.1016/j.neucom.2019.08.007},
           pages = {118--130},
        keywords = {ARRAY(0x5585d78f7900)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36668/},
        abstract = {Trainable chatbots that exhibit fluent and human-like conversations remain a big challenge in artificial intelligence. Deep Reinforcement Learning (DRL) is promising for addressing this challenge, but its successful application remains an open question. This article describes a novel ensemble-based approach applied to value-based DRL chatbots, which use finite action sets as a form of meaning representation. In our approach, while dialogue actions are derived from sentence clustering, the training datasets in our ensemble are derived from dialogue clustering. The latter aim to induce specialised agents that learn to interact in a particular style. In order to facilitate neural chatbot training using our proposed approach, we assume dialogue data in raw text only ? without any manually-labelled data. Experimental results using chitchat data reveal that (1) near human-like dialogue policies can be induced, (2) generalisation to unseen data is a difficult problem, and (3) training an ensemble of chatbot agents is essential for improved performance over using a single agent. In addition to evaluations using held-out data, our results are further supported by a human evaluation that rated dialogues in terms of fluency, engagingness and consistency ? which revealed that our proposed dialogue rewards strongly correlate with human judgements.}
}

@inproceedings{lincoln36370,
           month = {November},
          author = {Mohamed Sorour and Khaled Elgeneidy and Aravinda Srinivasan and Marc Hanheide},
       booktitle = {2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           title = {Grasping Unknown Objects Based on Gripper Workspace Spheres},
       publisher = {IEEE},
            year = {2019},
         journal = {Proceedings of the 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019)},
             doi = {10.1109/IROS40897.2019.8967989},
           pages = {1541--1547},
        keywords = {ARRAY(0x5585d78f7918)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36370/},
        abstract = {In this paper, we present a novel grasp planning algorithm for unknown objects given a registered point cloud of the target from different views. The proposed methodology requires no prior knowledge of the object, nor offline learning. In our approach, the gripper kinematic model is used to generate a point cloud of each finger workspace, which is then filled with spheres. At run-time, first the object is segmented, its major axis is computed, in a plane perpendicular to which, the main grasping action is constrained. The object is then
uniformly sampled and scanned for various gripper poses that assure at least one object point is located in the workspace of each finger. In addition, collision checks with the object or the table are performed using computationally inexpensive gripper shape approximation. Our methodology is both time efficient (consumes less than 1.5 seconds in average) and versatile. Successful experiments have been conducted on a simple jaw gripper (Franka Panda gripper) as well as a complex, high Degree of Freedom (DoF) hand (Allegro hand).}
}

@article{lincoln39027,
          volume = {9},
          number = {23},
           month = {November},
          author = {Luca Baronti and Mark Alston and Nikos Mavrakis and Amir Masoud Ghalamzan Esfahani and Marco Castellani},
           title = {Primitive Shape Fitting in Point Clouds Using the Bees Algorithm},
       publisher = {MDPI},
            year = {2019},
         journal = {Advances in Automation and Robotics},
             doi = {10.3390/app9235198},
        keywords = {ARRAY(0x5585d78fc398)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39027/},
        abstract = {In this study, the problem of fitting shape primitives to point cloud scenes was tackled 2 as a parameter optimisation procedure and solved using the popular Bees Algorithm. Tested on three sets of clean and differently blurred point cloud models, the Bees Algorithm obtained performances comparable to those obtained using the state-of-the-art RANSAC method, and superior to those obtained by an evolutionary algorithm. Shape fitting times were compatible with the real-time application. The main advantage of the Bees Algorithm over standard methods is that it doesn?t rely on ad hoc assumptions about the nature of the point cloud model like RANSAC approximation tolerance.}
}

@inproceedings{lincoln36758,
       booktitle = {IEEE Intelligent Transportation Systems Conference},
           month = {November},
           title = {A heuristic model for pedestrian intention estimation},
          author = {Fanta Camara and Natasha Merat and Charles Fox},
       publisher = {IEEE},
            year = {2019},
             doi = {10.1109/ITSC.2019.8917195},
        keywords = {ARRAY(0x5585d78fc3b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36758/},
        abstract = {Understanding pedestrian behaviour and controlling interactions with pedestrians is of critical importance for autonomous vehicles, but remains a complex and challenging problem. This study infers pedestrian intent during possible road-crossing interactions, to assist autonomous vehicle decisions to yield or not yield when approaching them, and tests a simple heuristic model of intent on pedestrian-vehicle trajectory data for the first time. It relies on a heuristic approach based
on the observed positions of the agents over time. The method can predict pedestrian crossing intent, crossing or stopping, with 96\% accuracy by the time the pedestrian reaches the curbside, on the standard Daimler pedestrian dataset. This result is important in demarcating scenarios which have a clear winner and can be predicted easily with the simple heuristic, from those which may require more complex game-theoretic models to predict and control.}
}

@inproceedings{lincoln42331,
       booktitle = {The 2019 IEEE International Geoscience and Remote Sensing Symposium (IGARSS2019)},
           month = {November},
           title = {Learning spectral and spatial features based on generative adversarial network for hyperspectral image super-resolution},
          author = {Ruituo Jiang and Xu Li and Ang Gao and Lixin Li and Hongying Meng and Shigang Yue and Lei Zhang},
            year = {2019},
             doi = {10.1109/IGARSS.2019.8900228},
        keywords = {ARRAY(0x5585d78fc3e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42331/},
        abstract = {Super-resolution (SR) of hyperspectral images (HSIs) aims to enhance the spatial/spectral resolution of hyperspectral imagery and the super-resolved results will benefit many remote sensing applications. A generative adversarial network for HSIs super-resolution (HSRGAN) is proposed in this paper. Specifically, HSRGAN constructs spectral and spatial blocks with residual network in generator to effectively learn spectral and spatial features from HSIs. Furthermore, a new loss function which combines the pixel-wise loss and adversarial loss together is designed to guide the generator to recover images approximating the original HSIs and with finer texture details. Quantitative and qualitative results demonstrate that the proposed HSRGAN is superior to the state of the art methods like SRCNN and SRGAN for HSIs spatial SR.}
}

@inproceedings{lincoln37261,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019) Workshops},
           month = {November},
           title = {Towards game theoretic AV controllers: measuring pedestrian behaviour in Virtual Reality},
          author = {Fanta Camara and Patrick Dickinson and Natasha Merat and Charles Fox},
       publisher = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019) Workshops},
            year = {2019},
        keywords = {ARRAY(0x5585d78fc3f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37261/},
        abstract = {Understanding pedestrian interaction is of great importance for autonomous vehicles (AVs). The present study investigates pedestrian behaviour during crossing scenarios with an autonomous vehicle using Virtual Reality. The self-driving car is driven by a game theoretic controller which adapts its driving style to pedestrian crossing behaviour. We found that subjects value collision avoidance about 8 times more than saving 0.02 seconds. A previous lab study found time saving to be more important than collision avoidance in a highly unrealistic board game style version of the game. The present result suggests that the VR simulation reproduces real world road-crossings better than the lab study and provides a reliable test-bed for the development of game theoretic models for AVs.}
}

@inproceedings{lincoln37750,
       booktitle = {International Conference on Intelligent Robots and Systems (IROS)},
           month = {November},
           title = {Semantically Assisted Loop Closure in SLAM Using NDT Histograms},
          author = {Anestis Zaganidis and Alexandros Zerntev and Tom Duckett and Grzegorz Cielniak},
            year = {2019},
        keywords = {ARRAY(0x5585d78fc428)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37750/},
        abstract = {Precise knowledge of pose is of great importance for reliable operation of mobile robots in outdoor environments. Simultaneous localization and mapping (SLAM) is the online construction of a map during exploration of an environment. One of the components of SLAM is loop closure detection, identifying that the same location has been visited and is present on the existing map, and localizing against it. We have shown in previous work that using semantics from a deep segmentation network in conjunction with the Normal Distributions Transform point cloud registration improves the robustness, speed and accuracy of lidar odometry. In this work we extend the method for loop closure detection, using the labels already available from local registration into NDT Histograms, and we present a SLAM pipeline based on Semantic assisted NDT and PointNet++. We experimentally demonstrate on sequences from the KITTI benchmark that the map descriptor we propose outperforms NDT Histograms without semantics, and we validate its use on a SLAM task.}
}

@inproceedings{lincoln36793,
       booktitle = {International Workshop on Assistive Engineering and Information Technology (AEIT 2019)},
           month = {November},
           title = {Bone-Conduction Audio Interface to Guide People with Visual Impairments},
          author = {Jacobus Lock and Iain Gilchrist and Grzegorz Cielniak and Nicola Bellotto},
            year = {2019},
        keywords = {ARRAY(0x5585d78fc458)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36793/},
        abstract = {The ActiVis project's aim is to build a mobile guidance aid to help people with limited vision find objects in an unknown environment. This system uses bone-conduction headphones to transmit audio signals to the user and requires an effective non-visual interface. To this end, we propose a new audio-based interface that uses a spatialised signal to convey a target?s position on the horizontal plane. The vertical position on the median plan is given by adjusting the tone?s pitch to overcome the audio localisation limitations of bone-conduction headphones. This interface is validated through a set of experiments with blindfolded and visually impaired participants.}
}

@article{lincoln43351,
          volume = {121},
           month = {November},
          author = {Cheng Zhao and Li Sun and Zhi Yan and Gerhard Neumann and Tom Duckett and Rustam Stolkin},
           title = {Learning Kalman Network: A deep monocular visual odometry for on-road driving},
       publisher = {Elsevier},
            year = {2019},
         journal = {Robotics and Autonomous Systems},
             doi = {10.1016/j.robot.2019.07.004},
           pages = {103234},
        keywords = {ARRAY(0x5585d78fc488)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/43351/},
        abstract = {This paper proposes a Learning Kalman Network (LKN) based monocular visual odometry (VO), i.e. LKN-VO, for on-road driving. Most existing learning-based VO focus on ego-motion estimation by comparing the two most recent consecutive frames. By contrast, the LKN-VO incorporates a learning ego-motion estimation through the current measurement, and a discriminative state estimator through a sequence of previous measurements. Superior to the model-based monocular VO, a more accurate absolute scale can be learned by LKN without any geometric constraints. In contrast to the model-based Kalman Filter (KF), the optimal model parameters of LKN can be obtained from dynamic and deterministic outputs of the neural network without elaborate human design. LKN is a hybrid approach where we achieve the non-linearity of the observation model and the transition model though deep neural networks, and update the state following the Kalman probabilistic mechanism. In contrast to the learning-based state estimator, a sparse representation is further proposed to learn the correlations within the states from the car?s movement behaviour, thereby applying better filtering on the 6DOF trajectory for on-road driving. The experimental results show that the proposed LKN-VO outperforms both model-based and learning state-estimator-based monocular VO on the most well-cited on-road driving datasets, i.e. KITTI and Apolloscape. In addition, LKN-VO is integrated with dense 3D mapping, which can be deployed for simultaneous localization and mapping in urban environments.}
}

@inproceedings{lincoln37348,
           month = {October},
          author = {Francesco Del Duchetto and Paul Baxter and Marc Hanheide},
       booktitle = {International Conference on Robot \& Human Interactive Communication (RO-MAN)},
         address = {New Delhi},
           title = {Lindsey the Tour Guide Robot - Usage Patterns in a Museum Long-Term Deployment},
       publisher = {IEEE},
             doi = {10.1109/RO-MAN46459.2019.8956329},
            year = {2019},
        keywords = {ARRAY(0x5585d78fc4b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37348/},
        abstract = {The long-term deployment of autonomous robots co-located with humans in real-world scenarios remains a challenging problem. In this paper, we present the ``Lindsey'' tour guide robot system in which we attempt to increase the social capability of current state-of-the-art robotic technologies. The robot is currently deployed at a museum displaying local archaeology where it is providing guided tours and information to visitors. The robot is operating autonomously daily, navigating around the museum and engaging with the public, with on-site assistance from roboticists only in cases of hardware/software malfunctions. In a deployment lasting seven months up to now, it has travelled nearly 300km and has delivered more than 2300 guided tours. First, we describe the robot framework and the management interfaces implemented. We then analyse the data collected up to now with the goal of understanding and modelling the visitors' behavior in terms of their engagement with the technology. These data suggest that while short-term engagement is readily gained, continued engagement with the robot tour guide is likely to require more refined and robust socially interactive behaviours. The deployed system presents us with an opportunity to empirically address these issues.}
}

@article{lincoln36962,
          volume = {4},
          number = {4},
           month = {October},
          author = {Tomas Krajnik and Tomas Vintr and Sergi Molina Mellado and Jaime Pulido Fentanes and Grzegorz Cielniak and Oscar Martinez Mozos and George Broughton and Tom Duckett},
           title = {Warped Hypertime Representations for Long-Term Autonomy of Mobile Robots},
       publisher = {IEEE},
            year = {2019},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2019.2926682},
           pages = {3310--3317},
        keywords = {ARRAY(0x5585d78fc4e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36962/},
        abstract = {This letter presents a novel method for introducing time into discrete and continuous spatial representations used in mobile robotics, by modeling long-term, pseudo-periodic variations caused by human activities or natural processes. Unlike previous approaches, the proposed method does not treat time and space separately, and its continuous nature respects both the temporal and spatial continuity of the modeled phenomena. The key idea is to extend the spatial  model with a set of wrapped time dimensions that represent the periodicities of the observed events. By performing clustering over this extended representation, we obtain a model that allows the prediction of probabilistic distributions of future states and events in both discrete and continuous spatial representations. We apply the proposed algorithm to several long-term datasets acquired by mobile robots and show that the method enables a robot to predict future states of representations with different dimensions. The experiments further show that the method achieves more accurate predictions than the previous state of the art.}
}

@article{lincoln36914,
          volume = {66},
           month = {October},
          author = {Ruth Madigan and Sina Nordhoff and Charles Fox and Roja Ezzati Amina and Tyron Louw and Marc Wilbrink and Anna Schieben and Natasha Merat},
           title = {Understanding interactions between Automated Road Transport Systems and other road users: A video analysis},
       publisher = {Elsevier},
            year = {2019},
         journal = {Transportation Research Part F},
             doi = {10.1016/j.trf.2019.09.006},
           pages = {196--213},
        keywords = {ARRAY(0x5585d78fc518)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36914/},
        abstract = {If automated vehicles (AVs) are to move efficiently through the traffic environment, there is a need for them to interact and communicate with other road users in a comprehensible and predictable manner. For this reason, an understanding of the interaction requirements of other road users is needed. The current study investigated these requirements through an analysis of 22 hours of video footage of the CityMobil2 AV demonstrations in La Rochelle (France) and Trikala (Greece). Manual and automated video-analysis techniques were used to identify typical interactions patterns between AVs and other road users. Results indicate that road infrastructure and road user factors had a major impact on the type of interactions that arose between AVs and other road users. Road infrastructure features such as road width, and the presence or absence of zebra crossings had an impact on road users? trajectory decisions while approaching an AV. Where possible, pedestrians and cyclists appeared to leave as much space as possible between their trajectories and that of the AV. However, in situations where the infrastructure did not allow for the separation of traffic, risky behaviours were more likely to emerge, with cyclists, in particular, travelling closely alongside the AVs on narrow paths of the road, rather than waiting for the AV to pass. In addition, the types of interaction varied considerably across socio-demographic groups, with females and older users more likely to show cautionary behaviour around the AVs than males, or younger road users. Overall, the results highlight the importance of implementing the correct infrastructure to support the safe introduction of AVs, while also ensuring that the behaviour of the AV matches other road users? expectations as closely as possible in order to avoid traffic conflicts.}
}

@article{lincoln38234,
          volume = {4},
          number = {35},
           month = {October},
          author = {Emmanuel Senft and S{\'e}verin Lemaignan and Paul Baxter and Madeleine Bartlett and Tony Belpaeme},
           title = {Teaching robots social autonomy from in situ human guidance},
       publisher = {American Association for the Advancement of Science},
            year = {2019},
         journal = {Science Robotics},
             doi = {10.1126/scirobotics.aat1186},
           pages = {eaat1186},
        keywords = {ARRAY(0x5585d78fc548)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38234/},
        abstract = {Striking the right balance between robot autonomy and human control is a core challenge in social robotics, in both technical and ethical terms. On the one hand, extended robot autonomy offers the potential for increased human productivity and for the off-loading of physical and cognitive tasks. On the other hand, making the most of human technical and social expertise, as well as maintaining accountability, is highly desirable. This is particularly relevant in domains such as medical therapy and education, where social robots hold substantial promise, but where there is a high cost to poorly performing autonomous systems, compounded by ethical concerns. We present a field study in which we evaluate SPARC (supervised progressively autonomous robot competencies), an innovative approach addressing this challenge whereby a robot progressively learns appropriate autonomous behavior from in situ human demonstrations and guidance. Using online machine learning techniques, we demonstrate that the robot could effectively acquire legible and congruent social policies in a high-dimensional child-tutoring situation needing only a limited number of demonstrations while preserving human supervision whenever desirable. By exploiting human expertise, our technique enables rapid learning of autonomous social and domain-specific policies in complex and nondeterministic environments. Last, we underline the generic properties of SPARC and discuss how this paradigm is relevant to a broad range of difficult human-robot interaction scenarios.}
}

@inproceedings{lincoln46192,
       booktitle = {IEEE/MTS Oceans},
           month = {October},
           title = {Surveying and cleaning plastic pollution in the sediment: SILVER+ approach},
          author = {Giacomo Picardi and Saverio Iacoponi and Mrudul Chellapurath and Cecilia Laschi and Marcello Calisti},
         address = {Marsellie},
            year = {2019},
             doi = {10.1109/OCEANSE.2019.8867331},
        keywords = {ARRAY(0x5585d78fc578)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46192/},
        abstract = {Nowadays there is growing awareness on the issue of plastic pollution in the oceans. The use of robotic platforms might help increasing our understanding on the problem and possibly contribute to the solution. Recent studies pointed out that the majority of plastic litter eventually sinks to the bottom of the sea, but traditional swimming robots are unsuitable to carry out a systematic survey to validate this claim due to their limitations in the interaction with the seabed. For this reason we developed SILVER+, a platform for investigating the presence of micro and macro plastics litter in the sediment and possibly undertaking cleaning actions. SILVER stands for Seabed Interaction Legged Vehicle for Exploration and Research and it features an hexapod robot, SILVER2, which harnesses the interaction with the seabed to move and operate in the benthic environment. In this paper we present the general architecture of the SILVER+ platform, the design and development of SILVER2 and the results of preliminary tests to assess the effectiveness of the platform to effectively operate in the benthic environment.}
}

@article{lincoln37631,
           month = {October},
          author = {Ayse Kucukyilmaz and Illimar Issak},
           title = {Online Identification of Interaction Behaviors from Haptic Data during Collaborative Object Transfer},
       publisher = {IEEE},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2019.2945261},
           pages = {1--1},
            year = {2019},
        keywords = {ARRAY(0x5585d78fc5a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37631/},
        abstract = {Joint object transfer is a complex task, which is less structured and less specific than what is existing in several industrial settings. When two humans are involved in such a task, they cooperate through different modalities to understand the interaction states during operation and mutually adapt to one another?s actions. Mutual adaptation implies that both partners can identify how well they collaborate (i.e. infer about the interaction state) and act accordingly. These interaction states can define whether the partners work in harmony, face conflicts, or remain passive during interaction. Understanding how two humans work together during physical interactions is important when exploring the ways a robotic assistant should operate under similar settings. This study acts as a first step to implement an automatic classification mechanism during ongoing collaboration to identify the interaction state during object co-manipulation. 
The classification is done on a dataset consisting of data from 40 subjects, who are partnered to form 20 dyads. The dyads experiment in a physical human-human interaction (pHHI) scenario to move an object in an haptics-enabled virtual environment to reach predefined goal configurations. In this study, we propose a sliding-window approach for feature extraction and demonstrate the online classification methodology to identify interaction patterns. We evaluate our approach using 1) a support vector machine classifier (SVMc) and 2) a Gaussian Process classifier (GPc) for multi-class classification, and achieve over 80\% accuracy with both classifiers when identifying general interaction types.}
}

@article{lincoln36072,
          volume = {251},
           month = {October},
          author = {Andrey Postnikov and Ibrahim Albayati and Simon Pearson and Chris Bingham and Ronald Bickerton and Argyrios Zolotas},
           title = {Facilitating static firm frequency response with aggregated networks of commercial food refrigeration systems},
       publisher = {Elsevier},
            year = {2019},
         journal = {Applied Energy},
             doi = {10.1016/j.apenergy.2019.113357},
           pages = {113357},
        keywords = {ARRAY(0x5585d78fc5d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36072/},
        abstract = {Aggregated electrical loads from massive numbers of distributed retail refrigeration systems could have a significant role in frequency balancing services. To date, no study has realised effective engineering applications of static firm frequency response to these aggregated networks. Here, the authors present a novel and validated approach that enables large scale control of distributed retail refrigeration assets. The authors show a validated model that simulates the operation of retail refrigerators comprising centralised compressor packs feeding multiple in-store display cases. The model was used to determine an optimal control strategy that both minimised the engineering risk to the pack during shut down and potential impacts to food safety. The authors show that following a load shedding frequency response trigger the pack should be allowed to maintain operation but with increased suction pressure set-point. This reduces compressor load whilst enabling a continuous flow of refrigerant to food cases. In addition, the authors simulated an aggregated response of up to three hundred compressor packs (over 2 MW capacity), with refrigeration cases on hysteresis and modulation control. Hysteresis control, compared to modulation, led to undesired load oscillations when the system recovers after a frequency balancing event. Transient responses of the system during the event showed significant fluctuations of active power when compressor network responds to both primary and secondary parts of a frequency balancing event. Enabling frequency response within this system is demonstrated by linking the aggregated refrigeration loads with a simplified power grid model that simulates a power loss incident.}
}

@inproceedings{lincoln39415,
       booktitle = {70th International Astronautical Congress},
           month = {October},
           title = {Towards On-Orbit Assembly of Large Space Telescopes: Mission Architectures, Concepts, and Analyses},
          author = {Angadh Nanjangud and Craig I. Underwood and Chakravarthini M. Saaj and Alex Young and Peter C. Blacker and Steve Eckersley and Martin Sweeting and Paolo Bianco},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39415/}
}

@article{lincoln36571,
           month = {October},
           title = {Haptic-guided shared control for needle grasping optimization in minimally invasive robotic surgery},
          author = {Mario Selvaggio and Amir Ghalamzan Esfahani and Rocco Moccia and Fanny Ficuciello and Bruno Siciliano},
            year = {2019},
         journal = {IEEE/RSJ International Conference Intelligent Robotic System},
        keywords = {ARRAY(0x5585d78fc638)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36571/},
        abstract = {During suturing tasks performed with minimally invasive surgical robots, configuration singularities and joint limits often force surgeons to interrupt the task and re- grasp the needle using dual-arm movements. This yields an increased operator?s cognitive load, time-to-completion, fatigue and performance degradation. In this paper, we propose a haptic-guided shared control method for grasping the needle with the Patient Side Manipulator (PSM) of the da Vinci robot avoiding such issues. We suggest a cost function consisting of (i) the distance from robot joint limits and (ii) the task-oriented manipulability over the suturing trajectory. We evaluate the cost and its gradient on the needle grasping manifold that allows us to obtain the optimal grasping pose for joint-limit and singularity free movements of the needle during suturing. Then, we compute force cues that are applied to the Master Tool Manipulator (MTM) of the da Vinci to guide the operator towards the optimal grasp. As such, our system helps the operator to choose a grasping configuration allowing the robot to avoid joint limits and singularities during post-grasp suturing movements. We show the effectiveness of our proposed haptic- guided shared control method during suturing using both simulated and real experiments. The results illustrate that our approach significantly improves the performance in terms of needle re-grasping.}
}

@article{lincoln39231,
          volume = {11},
          number = {18},
           month = {September},
          author = {Maria G. Lampridi and Claus G. S{\o}rensen and Dionysis Bochtis},
           title = {Agricultural Sustainability: A Review of Concepts and Methods},
            year = {2019},
         journal = {Sustainability},
             doi = {10.3390/su11185120},
           pages = {5120},
        keywords = {ARRAY(0x5585d78fc668)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39231/},
        abstract = {This paper presents a methodological framework for the systematic literature review of agricultural sustainability studies. The framework synthesizes all the available literature review criteria and introduces a two-level analysis facilitating systematization, data mining, and methodology analysis. The framework was implemented for the systematic literature review of 38 crop agricultural sustainability assessment studies at farm-level for the last decade. The investigation of the methodologies used is of particular importance since there are no standards or norms for the sustainability assessment of farming practices. The chronological analysis revealed that the scientific community?s interest in agricultural sustainability is increasing in the last three years. The most used methods include indicator-based tools, frameworks, and indexes, followed by multicriteria methods. In the reviewed studies, stakeholder participation is proved crucial in the determination of the level of sustainability. It should also be mentioned that combinational use of methodologies is often observed, thus a clear distinction of methodologies is not always possible}
}

@article{lincoln47557,
          volume = {78},
          number = {17},
           month = {September},
          author = {Mohammed Al-Khafajiy and Thar Baker and Carl Chalmers and Muhammad Asim and Hoshang Kolivand and Muhammad Fahim and Atif Waraich},
           title = {Remote health monitoring of elderly through wearable sensors},
       publisher = {Springer},
            year = {2019},
         journal = {Multimedia Tools and Applications},
             doi = {10.1007/s11042-018-7134-7},
           pages = {24681--24706},
        keywords = {ARRAY(0x5585d78fc698)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47557/},
        abstract = {Due to a rapidly increasing aging population and its associated challenges in health and social care, Ambient Assistive Living has become the focal point for both researchers and industry alike. The need to manage or even reduce healthcare costs while improving the quality of service is high government agendas. Although, technology has a major role to play in achieving these aspirations, any solution must be designed, implemented and validated using appropriate domain knowledge. In order to overcome these challenges, the remote real-time monitoring of a person?s health can be used to identify relapses in conditions, therefore, enabling early intervention. Thus, the development of a smart healthcare monitoring system, which is capable of observing elderly people remotely, is the focus of the research presented in this paper. The technology outlined in this paper focuses on the ability to track a person?s physiological data to detect specific disorders which can aid in Early Intervention Practices. This is achieved by accurately processing and analysing the acquired sensory data while transmitting the detection of a disorder to an appropriate career. The finding reveals that the proposed system can improve clinical decision supports while facilitating Early Intervention Practices. Our extensive simulation results indicate a superior performance of the proposed system: low latency (96\% of the packets are received with less than 1 millisecond) and low packets-lost (only 2.2\% of total packets are dropped). Thus, the system runs efficiently and is cost-effective in terms of data acquisition and manipulation.}
}

@article{lincoln47560,
          volume = {56},
           month = {August},
          author = {Zakaria Maamar and Thar Baker and Noura Faci and Mohammed Al-Khafajiy and Emir Ugljanin and Yacine Atif and Mohamed Sellami},
           title = {Weaving cognition into the internet-of-things: Application to water leaks},
       publisher = {Elsevier},
            year = {2019},
         journal = {Cognitive Systems Research},
             doi = {10.1016/j.cogsys.2019.04.001},
           pages = {233--245},
        keywords = {ARRAY(0x5585d78fc6c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47560/},
        abstract = {Despite the growing interest in the Internet-of-Things, many organizations remain reluctant to integrating things into their business processes. Different reasons justify this reluctance including things? limited capabilities to act upon the cyber-physical surrounding in which they operate. To address this specific limitation, this paper examines thing empowerment with cognitive capabilities that would make them for instance, selective of the next business processes in which they would participate. The selection is based on things? restrictions like limitedness and goals to achieve like improved reputation. For demonstration purposes, water leaks are used as a case study. A BPEL-based business process driving the fixing of water leaks is implemented involving different cognitive things like moisture sensor.}
}

@article{lincoln36279,
          volume = {184},
           month = {August},
          author = {Vasso Marinoudi and Claus Sorensen and Simon Pearson and Dionysis Bochtis},
           title = {Robotics and labour in agriculture. A context consideration},
       publisher = {Elsevier},
            year = {2019},
         journal = {Biosystems Engineering},
             doi = {10.1016/j.biosystemseng.2019.06.013},
           pages = {111--121},
        keywords = {ARRAY(0x5585d78fc6f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36279/},
        abstract = {Over the last century, agriculture transformed from a labour-intensive industry towards mechanisation and power-intensive production systems, while over the last 15 years agri- cultural industry has started to digitise. Through this transformation there was a continuous labour outflow from agriculture, mainly from standardized tasks within production process. Robots and artificial intelligence can now be used to conduct non-standardised tasks (e.g. fruit picking, selective weeding, crop sensing) previously reserved for human workers and at economically feasible costs. As a consequence, automation is no longer restricted to stan- dardized tasks within agricultural production (e.g. ploughing, combine harvesting). In addition, many job roles in agriculture may be augmented but not replaced by robots. Robots in many instances will work collaboratively with humans. This new robotic ecosystem creates complex ethical, legislative and social impacts. A key question, we consider here, is what are the short and mid-term effects of robotised agriculture on sector jobs and employment? The presented work outlines the conditions, constraints, and inherent re- lationships between labour input and technology input in bio-production, as well as, pro- vides the procedural framework and research design to be followed in order to evaluate the effect of adoption automation and robotics in agriculture.}
}

@article{lincoln37396,
          volume = {42},
          number = {8},
           month = {August},
          author = {A. Seddaoui and Mini Saaj},
            note = {cited By 0},
           title = {Combined nonlinear H? controller for a controlled-floating space robot},
       publisher = {Aerospace Research Central},
            year = {2019},
         journal = {Journal of Guidance, Control, and Dynamics},
             doi = {10.2514/1.G003811},
           pages = {1878--1885},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37396/}
}

@article{lincoln39389,
          volume = {42},
          number = {8},
           month = {August},
          author = {Asma Seddaoui and Chakravarthini M. Saaj},
           title = {Combined Nonlinear H? Controller for a Controlled-Floating Space Robot},
       publisher = {Aerospace Research Central},
            year = {2019},
         journal = {Journal of Guidance, Control, and Dynamics},
             doi = {10.2514/1.G003811},
           pages = {1878--1885},
        keywords = {ARRAY(0x5585d78fc758)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39389/}
}

@inproceedings{lincoln42330,
       booktitle = {2019 IEEE International Conference on Image Processing (ICIP2019)},
           month = {August},
           title = {Learning spatial and spectral features via 2D-1D generative adversarial network for hyperspectral image super-resolution},
          author = {Ruituo Jiang and Xu Li and Shaohui Mei and Shigang Yue and Lei Zhang},
            year = {2019},
             doi = {10.1109/ICIP.2019.8803200},
         journal = {2019 IEEE International Conference on Image Processing (ICIP2019)},
        keywords = {ARRAY(0x5585d78fc788)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/42330/},
        abstract = {Three-dimensional (3D) convolutional networks have been proven to be able to explore spatial context and spectral information simultaneously for super-resolution (SR). However, such kind of network can?t be practically designed very
?deep? due to the long training time and GPU memory limitations involved in 3D convolution. Instead, in this paper, spatial context and spectral information in hyperspectral images (HSIs) are explored using Two-dimensional (2D) and Onedimenional (1D) convolution, separately. Therefore, a novel 2D-1D generative adversarial network architecture (2D-1DHSRGAN) is proposed for SR of HSIs. Specifically, the generator network consists of a spatial network and a spectral network, in which spatial network is trained with the least absolute deviations loss function to explore spatial context by 2D convolution and spectral network is trained with the spectral angle mapper (SAM) loss function to extract spectral information by 1D convolution. Experimental results over two real HSIs demonstrate that the proposed 2D-1D-HSRGAN clearly outperforms several state-of-the-art algorithms.}
}

@inproceedings{lincoln36396,
           month = {August},
          author = {Sergi Molina and Grzegorz Cielniak and Tom Duckett},
       booktitle = {International Conference on Robotics and Automation (ICRA)},
           title = {Go with the Flow: Exploration and Mapping of Pedestrian Flow Patterns from Partial Observations},
       publisher = {IEEE},
             doi = {10.1109/ICRA.2019.8794434},
           pages = {9725--9731},
            year = {2019},
        keywords = {ARRAY(0x5585d78fc7b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36396/},
        abstract = {Understanding how people are likely to behave in an environment is a key requirement for efficient and safe robot navigation. However, mobile platforms are subject to spatial and temporal constraints, meaning that only partial observations of human activities are typically available to a robot, while the activity patterns of people in a given environment may also change at different times. To address these issues we present as the main contribution an exploration strategy for acquiring models of pedestrian flows, which decides not only the locations to explore but also the times when to explore them. The approach is driven by the uncertainty from multiple Poisson processes built from past observations. The approach is evaluated using two long-term pedestrian datasets, comparing its performance against uninformed exploration strategies. The results show that when using the uncertainty in the exploration policy, model accuracy increases, enabling faster learning of human motion patterns.}
}

@inproceedings{lincoln37413,
          volume = {2019-M},
           month = {August},
          author = {A. Seddaoui and C. Saaj and S. Eckersley},
            note = {cited By 0},
       booktitle = {2019 International Conference on Robotics and Automation (ICRA)},
           title = {Adaptive H? Controller for Precise Manoeuvring of a Space Robot},
       publisher = {IEEE},
            year = {2019},
         journal = {Proceedings - IEEE International Conference on Robotics and Automation},
             doi = {10.1109/ICRA.2019.8794374},
           pages = {4746--4752},
        keywords = {ARRAY(0x5585d78fc7e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37413/},
        abstract = {A space robot working in a controlled-floating mode can be used for performing in-orbit telescope assembly through simultaneously controlling the motion of the spacecraft base and its robotic arm. Handling and assembling optical mirrors requires the space robot to achieve slow and precise manoeuvres regardless of the disturbances and errors in the trajectory. The robustness offered by the nonlinear H ? controller, in the presence of environmental disturbances and parametric uncertainties, makes it a viable solution. However, using fixed tuning parameters for this controller does not always result in the desired performance as the arm's trajectory is not known a priori for orbital assembly missions. In this paper, a complete study on the impact of the different tuning parameters is performed and a new adaptive H ? controller is developed based on bounded functions. The simulation results presented show that the proposed adaptive H ? controller guarantees robustness and precise tracking using a minimal amount of forces and torques for assembly operations using a small space robot.}
}

@inproceedings{lincoln38253,
           month = {August},
          author = {Tomas Vintr and Zhi Yan and Tom Duckett and Tomas Krajnik},
       booktitle = {2019 International Conference on Robotics and Automation (ICRA)},
           title = {Spatio-temporal representation for long-term anticipation of human presence in service robotics},
       publisher = {IEEE},
             doi = {10.1109/ICRA.2019.8793534},
           pages = {2620--2626},
            year = {2019},
        keywords = {ARRAY(0x5585d78fc818)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38253/},
        abstract = {We propose an efficient spatio-temporal model for mobile autonomous robots operating in human populated
environments. Our method aims to model periodic temporal patterns of people presence, which are based on peoples?
routines and habits. The core idea is to project the time onto a set of wrapped dimensions that represent the periodicities of people presence. Extending a 2D spatial model with this multi-dimensional representation of time results in a memory efficient spatio-temporal model. This model is capable of long-term predictions of human presence, allowing mobile robots to schedule their services better and to plan their paths. The experimental evaluation, performed over datasets gathered by a robot over a period of several weeks, indicates that the proposed
 method achieves more accurate predictions than the previous state of the art used in robotics.}
}

@article{lincoln39230,
          volume = {12},
          number = {15},
           month = {August},
          author = {Efthymios Rodias and Remigio Berruto and Dionysis Bochtis and Alessandro Sopegno and Patrizia Busato},
           title = {Green, Yellow, and Woody Biomass Supply-Chain Management: A Review},
            year = {2019},
         journal = {Energies},
             doi = {10.3390/en12153020},
           pages = {3020},
        keywords = {ARRAY(0x5585d78fc848)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39230/},
        abstract = {Various sources of biomass contribute significantly in energy production globally given a series of constraints in its primary production. Green biomass sources (such as perennial grasses), yellow biomass sources (such as crop residues), and woody biomass sources (such as willow) represent the three pillars in biomass production by crops. In this paper, we conducted a comprehensive review on research studies targeted to advancements at biomass supply-chain management in connection to these three types of biomass sources. A framework that classifies the works in problem-based and methodology-based approaches was followed. Results show the use of modern technological means and tools in current management-related problems. From the review, it is evident that the presented up-to-date trends on biomass supply-chain management and the potential for future advanced approach applications play a crucial role on business and sustainability efficiency of biomass supply chain}
}

@article{lincoln35584,
          volume = {25},
          number = {3},
           month = {August},
          author = {Qinbing Fu and Hongxin Wang and Cheng Hu and Shigang Yue},
           title = {Towards Computational Models and Applications of Insect Visual Systems for Motion Perception: A Review},
       publisher = {MIT Press},
            year = {2019},
         journal = {Artificial life},
             doi = {10.1162/artl\_a\_00297},
           pages = {263--311},
        keywords = {ARRAY(0x5585d78fc878)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35584/},
        abstract = {Motion perception is a critical capability determining a variety of aspects of insects' life, including avoiding predators, foraging and so forth. A good number of motion detectors have been identified in the insects' visual pathways. Computational modelling of these motion detectors has not only been providing effective solutions to artificial intelligence, but also benefiting the understanding of complicated biological visual systems. These biological mechanisms through millions of years of evolutionary development will have formed solid modules for constructing dynamic vision systems for future intelligent machines. This article reviews the computational motion perception models originating from biological research of insects' visual systems in the literature. These motion perception models or neural networks comprise the looming sensitive neuronal models of lobula giant movement detectors (LGMDs) in locusts, the translation sensitive neural systems of direction selective neurons (DSNs) in fruit flies, bees and locusts, as well as the small target motion detectors (STMDs) in dragonflies and hover flies. We also review the applications of these models to robots and vehicles. Through these modelling studies, we summarise the methodologies that generate different direction and size selectivity in motion perception. At last, we discuss about multiple systems integration and hardware realisation of these bio-inspired motion perception models.}
}

@article{lincoln35606,
          volume = {16},
          number = {4},
           month = {August},
          author = {Khaled Goher and Sulaiman Fadlallah},
           title = {Control of a Two-wheeled Machine with Two-directions Handling Mechanism Using PID and PD-FLC Algorithms},
       publisher = {Springer},
            year = {2019},
         journal = {International Journal of Automation and Computing},
             doi = {10.1007/s11633-019-1172-0},
           pages = {511--533},
        keywords = {ARRAY(0x5585d78fc8a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35606/},
        abstract = {This paper presents a novel five degrees of freedom (DOF) two-wheeled robotic machine (TWRM) that delivers solutions
for both industrial and service robotic applications by enlarging the vehicle?s workspace and increasing its flexibility. Designing a two-wheeled robot with five degrees of freedom creates a high challenge for the control, therefore the modelling and design of such robot should be precise with a uniform distribution of mass over the robot and the actuators. By employing the Lagrangian modelling approach, the TWRM?s mathematical model is derived and simulated in Matlab/Simulink?. For stabilizing the system?s highly nonlinear model, two control approaches were developed and implemented: proportional-integral-derivative (PID) and fuzzy logic control (FLC)
strategies. Considering multiple scenarios with different initial conditions, the proposed control strategies? performance has been assessed.}
}

@article{lincoln47558,
          volume = {78},
          number = {14},
           month = {July},
          author = {Mohammed Al-Khafajiy and Hoshang Kolivand and Thar Baker and David Tully and Atif Waraich},
           title = {Smart hospital emergency system via mobile-based requesting services},
       publisher = {Springer},
            year = {2019},
         journal = {Multimedia Tools and Applications},
             doi = {10.1007/s11042-019-7274-4},
           pages = {20087--20111},
        keywords = {ARRAY(0x5585d78fc8d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47558/},
        abstract = {In recent years, the UK?s emergency call and response has shown elements of great strain as of today. The strain on emergency call systems estimated by a 9 million calls (including both landline and mobile) made in 2014 alone. Coupled with an increasing population and cuts in government funding, this has resulted in lower percentages of emergency response vehicles at hand and longer response times. In this paper, we highlight the main challenges of emergency services and overview of previous solutions. In addition, we propose a new system call Smart Hospital Emergency System (SHES). The main aim of SHES is to save lives through improving communications between patient and emergency services. Utilising the latest of technologies and algorithms within SHES is aiming to increase emergency communication throughput, while reducing emergency call systems issues and making the process of emergency response more efficient. Utilising health data held within a personal smartphone, and internal tracked data (GPU, Accelerometer, Gyroscope etc.), SHES aims to process the mentioned data efficiently, and securely, through automatic communications with emergency services, ultimately reducing communication bottlenecks. Live video-streaming through real-time video communication protocols is also a focus of SHES to improve initial communications between emergency services and patients. A prototype of this system has been developed. The system has been evaluated by a preliminary usability, reliability, and communication performance study.}
}

@inproceedings{lincoln36661,
           month = {July},
          author = {Barkan Ugurlu and Merve Acer and Duygun E. Barkana and Ikilem Gocek and Ayse Kucukyilmaz and Yunus Z. Arslan and Halil Basturk and Evren Samur and Emre Ugur and Ramazan Unal and Ozkan Bebek},
       booktitle = {2019 IEEE 16th International Conference on Rehabilitation Robotics (ICORR)},
           title = {A Soft+Rigid Hybrid Exoskeleton Concept in Scissors-Pendulum Mode: A Suit for Human State Sensing and an Exoskeleton for Assistance},
       publisher = {IEEE},
             doi = {10.1109/ICORR.2019.8779394},
           pages = {518--523},
            year = {2019},
        keywords = {ARRAY(0x5585d78fc908)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36661/},
        abstract = {In this paper, we present a novel concept that can enable the human aware control of exoskeletons through the
integration of a soft suit and a robotic exoskeleton. Unlike the state-of-the-art exoskeleton controllers which mostly rely on lumped human-robot models, the proposed concept makes use of the independent state measurements concerning the human user and the robot. The ability to observe the human state independently is the key factor in this approach. In order to realize such a system from the hardware point of view, we propose a system integration frame that combines a soft suit for human state measurement and a rigid exoskeleton for human assistance. We identify the technological requirements that are necessary for the realization of such a system with a particular emphasis on soft suit integration. We also propose a template model, named scissor pendulum, that may encapsulate the dominant dynamics of the human-robot combined model to synthesize a controller for human state regulation. A series of simulation experiments were conducted to check the controller performance. As a result, satisfactory human state regulation was attained, adequately confirming that the proposed system could potentially improve exoskeleton-aided applications.}
}

@inproceedings{lincoln36870,
          volume = {11673},
           month = {July},
          author = {Sercan Sari and Ayse Kucukyilmaz},
       booktitle = {Mobile Web and Intelligent Information Systems},
           title = {VR-Fit: Walking-in-Place Locomotion with Real Time Step Detection for VR-Enabled Exercise},
       publisher = {Springer},
            year = {2019},
             doi = {10.1007/978-3-030-27192-3\_20},
           pages = {255--266},
        keywords = {ARRAY(0x5585d78fc938)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36870/},
        abstract = {With recent advances in mobile and wearable technologies, virtual reality (VR) found many applications in daily use. Today, a mobile device can be converted into a low-cost immersive VR kit thanks to the availability of do-it-yourself viewers in the shape of simple cardboards and compatible software for 3D rendering. These applications involve interacting with stationary scenes or moving in between spaces within a VR environment. VR locomotion can be enabled through a variety of methods, such as head movement tracking, joystick-triggered motion and through mapping natural movements to translate to virtual locomotion. In this study, we implemented a walk-in-place (WIP) locomotion method for a VR-enabled exercise application. We investigate the utility of WIP for exercise purposes, and compare it with joystick-based locomotion in terms of step performance and subjective qualities of the activity, such as enjoyment, encouragement for exercise and ease of use. Our technique uses vertical accelerometer data to estimate steps taken during walking or running, and locomotes the user?s avatar accordingly in virtual space. We evaluated our technique in a controlled experimental study with 12 people. Results indicate that the way users control the simulated locomotion affects how they interact with the VR simulation, and influence the subjective sense of immersion and the perceived quality of the interaction. In particular, WIP encourages users to move further, and creates a more enjoyable and interesting experience in comparison to joystick-based navigation.}
}

@article{lincoln39229,
          volume = {9},
          number = {7},
           month = {July},
          author = {Naoum Tsolakis and Dimitrios Bechtsis and Dionysis Bochtis},
           title = {AgROS: A Robot Operating System Based Emulation Tool for Agricultural Robotics},
            year = {2019},
         journal = {Agronomy},
             doi = {10.3390/agronomy9070403},
           pages = {403},
        keywords = {ARRAY(0x5585d78fc968)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39229/},
        abstract = {This research aims to develop a farm management emulation tool that enables agrifood producers to effectively introduce advanced digital technologies, like intelligent and autonomous unmanned ground vehicles (UGVs), in real-world field operations. To that end, we first provide a critical taxonomy of studies investigating agricultural robotic systems with regard to: (i) the analysis approach, i.e., simulation, emulation, real-world implementation; (ii) farming operations; and (iii) the farming type. Our analysis demonstrates that simulation and emulation modelling have been extensively applied to study advanced agricultural machinery while the majority of the extant research efforts focuses on harvesting/picking/mowing and fertilizing/spraying activities; most studies consider a generic agricultural layout. Thereafter, we developed AgROS, an emulation tool based on the Robot Operating System, which could be used for assessing the efficiency of real-world robot systems in customized fields. The AgROS allows farmers to select their actual field from a map layout, import the landscape of the field, add characteristics of the actual agricultural layout (e.g., trees, static objects), select an agricultural robot from a predefined list of commercial systems, import the selected UGV into the emulation environment, and test the robot?s performance in a quasi-real-world environment. AgROS supports farmers in the ex-ante analysis and performance evaluation of robotized precision farming operations while lays the foundations for realizing ?digital twins? in agriculture}
}

@inproceedings{lincoln35684,
       booktitle = {The 2019 International Joint Conference on Neural Networks (IJCNN)},
           month = {July},
           title = {Visual Cue Integration for Small Target Motion Detection in Natural Cluttered Backgrounds},
          author = {Hongxin Wang and Jigen Peng and Qinbing Fu and Huatian Wang and Shigang Yue},
       publisher = {IEEE},
            year = {2019},
        keywords = {ARRAY(0x5585d78fc998)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35684/},
        abstract = {The robust detection of small targets against cluttered background is important for future arti?cial visual systems in searching and tracking applications. The insects? visual systems have demonstrated excellent ability to avoid predators, ?nd prey or identify conspeci?cs ? which always appear as small dim speckles in the visual ?eld. Build a computational model of the insects? visual pathways could provide effective solutions to detect small moving targets. Although a few visual system models have been proposed, they only make use of small-?eld visual features for motion detection and their detection results often contain a number of false positives. To address this issue, we develop a new visual system model for small target motion detection against cluttered moving backgrounds. Compared to the existing models, the small-?eld and wide-?eld visual features are separately extracted by two motion-sensitive neurons to detect small target motion and background motion. These two types of motion information are further integrated to ?lter out false positives. Extensive experiments showed that the proposed model can outperform the existing models in terms of detection rates.}
}

@inproceedings{lincoln35685,
       booktitle = {The 2019 International Joint Conference on Neural Networks},
           month = {July},
           title = {Angular Velocity Estimation of Image Motion Mimicking the Honeybee Tunnel Centring Behaviour},
          author = {Huatian Wang and Qinbing Fu and Hongxin Wang and Jigen Peng and Paul Baxter and Cheng Hu and Shigang Yue},
       publisher = {IEEE},
            year = {2019},
        keywords = {ARRAY(0x5585d78fc9c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35685/},
        abstract = {Insects use visual information to estimate angular velocity of retinal image motion, which determines a variety of ?ight behaviours including speed regulation, tunnel centring and visual navigation. For angular velocity estimation, honeybees show large spatial-independence against visual stimuli, whereas the previous models have not ful?lled such an ability. To address this issue, we propose a bio-plausible model for estimating the image motion velocity based on behavioural experiments of the honeybee ?ying through patterned tunnels. The proposed model contains mainly three parts, the texture estimation layer for spatial information extraction, the delay-and-correlate layer for temporal information extraction and the decoding layer for angular velocity estimation. This model produces responses that are largely independent of the spatial frequency in grating experiments. And the model has been implemented in a virtual bee for tunnel centring simulations. The results coincide with both electro-physiological neuron spike and behavioural path recordings, which indicates our proposed method provides a better explanation of the honeybee?s image motion detection mechanism guiding the tunnel centring behaviour.}
}

@inproceedings{lincoln37347,
           month = {July},
          author = {Manuel Fernandez Carmona and Tejas Parekh and Marc Hanheide},
       booktitle = {TAROS 2019: Towards Autonomous Robotic Systems},
           title = {Making the Case for Human-Aware Navigation in Warehouses},
       publisher = {Springer, Cham},
             doi = {10.1007/978-3-030-25332-5\_38},
           pages = {449--453},
            year = {2019},
        keywords = {ARRAY(0x5585d78fc9f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37347/},
        abstract = {This work addresses the performance of several local planners for navigation of autonomous pallet trucks in the presence of humans in a simulated warehouse as well as a complementary approach developed within the ILIAD project. 
Our focus is to stress the open problem of a safe manoeuvrability of pallet trucks in the presence of moving humans. 
We propose a variation of ROS navigation stack that includes in the planning process a model of the human robot interaction.}
}

@inproceedings{lincoln35954,
       booktitle = {International Joint Conference on Neural Networks (IJCNN)},
           month = {July},
           title = {Deep Reinforcement Learning for Chatbots Using Clustered Actions and Human-Likeness Rewards},
          author = {Heriberto Cuayahuitl and Donghyeon Lee and Seonghan Ryu and Sungja Choi and Inchul Hwang and Jihie Kim},
       publisher = {IEEE},
            year = {2019},
             doi = {10.1109/IJCNN.2019.8852376},
        keywords = {ARRAY(0x5585d78fca28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35954/},
        abstract = {Training chatbots using the reinforcement learning paradigm is challenging due to high-dimensional states, infinite action spaces and the difficulty in specifying the reward function. We address such problems using clustered actions instead of infinite actions, and a simple but promising reward function based on human-likeness scores derived from human-human dialogue data. We train Deep Reinforcement Learning (DRL) agents using chitchat data in raw text{--}without any manual annotations. Experimental results using different splits of training data report the following. First, that our agents learn reasonable policies in the environments they get familiarised with, but their performance drops substantially when they are exposed to a test set of unseen dialogues. Second, that the choice of sentence embedding size between 100 and 300 dimensions is not significantly different on test data. Third, that our proposed human-likeness rewards are reasonable for training chatbots as long as they use lengthy dialogue histories of ?10 sentences.}
}

@inproceedings{lincoln36187,
       booktitle = {The 2019 IEEE International Conference on Advanced Robotics and Mechatronics (ICARM)},
           month = {July},
           title = {ColCOS{\ensuremath{\Phi}}: A Multiple Pheromone Communication System for Swarm Robotics and Social Insects Research},
          author = {Xuelong Sun and Tian liu and Cheng Hu and Qinbing Fu and Shigang Yue},
       publisher = {IEEE},
            year = {2019},
        keywords = {ARRAY(0x5585d78fca58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36187/},
        abstract = {In the last few decades we have witnessed how the pheromone of social insect has become a rich inspiration source of swarm robotics. By utilising the virtual pheromone in physical swarm robot system to coordinate individuals and realise direct/indirect inter-robot communications like the social insect, stigmergic behaviour has emerged. However, many studies only take one single pheromone into account in solving swarm problems, which is not the case in real insects. In the real social insect world, diverse behaviours, complex collective performances and ?exible transition from one state to another are guided by different kinds of pheromones and their interactions. Therefore, whether multiple pheromone based strategy can inspire swarm robotics research, and inversely how the performances of swarm robots controlled by multiple pheromones bring inspirations to explain the social insects? behaviours will become an interesting question. Thus, to provide a reliable system to undertake the multiple pheromone study, in this paper, we speci?cally proposed and realised a multiple pheromone communication system called ColCOS{\ensuremath{\Phi}}. This system consists of a virtual pheromone sub-system wherein the multiple pheromone is represented by a colour image displayed on a screen, and the micro-robots platform designed for swarm robotics applications. Two case studies are undertaken to verify the effectiveness of this system: one is the multiple pheromone based on an ant?s forage and another is the interactions of aggregation and alarm pheromones. The experimental results demonstrate the feasibility of ColCOS{\ensuremath{\Phi}} and its great potential in directing swarm robotics and social insects research.}
}

@inproceedings{lincoln39422,
       booktitle = {20th Annual Conference, TAROS 2019},
           month = {July},
           title = {System Design and Control of a Di-Wheel Rover},
          author = {John Koleosho and Chakravarthini Saaj},
       publisher = {Springer},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39422/}
}

@article{lincoln47561,
          volume = {6},
           month = {June},
          author = {Khouloud Boukadi and Noura Faci and Zakaria Maamar and Emir Ugljanin and Mohamed Sellami and Thar Baker and Mohammed Al-Khafajiy},
           title = {Norm-based and commitment-driven agentification of the Internet of Things},
       publisher = {Elsevier},
            year = {2019},
         journal = {Internet of Things},
             doi = {10.1016/j.iot.2019.02.002},
           pages = {100042},
        keywords = {ARRAY(0x5585d78fcab8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47561/},
        abstract = {There are no doubts that the Internet-of-Things (IoT) has conquered the ICT industry to the extent that many governments and organizations are already rolling out many anywhere,anytime online services that IoT sustains. However, like any emerging and disruptive technology, multiple obstacles are slowing down IoT practical adoption including the passive nature and privacy invasion of things. This paper examines how to empower things with necessary capabilities that would make them proactive and responsive. This means things can, for instance reach out to collaborative peers, (un)form dynamic communities when necessary, avoid malicious peers, and be ?questioned? for their actions. To achieve such empowerment, this paper presents an approach for agentifying things using norms along with commitments that operationalize these norms. Both norms and commitments are specialized into social (i.e., application independent) and business (i.e., application dependent), respectively. Being proactive, things could violate commitments at run-time, which needs to be detected through monitoring. In this paper, thing agentification is illustrated with a case study about missing children and demonstrated with a testbed that uses different IoT-related technologies such as Eclipse Mosquitto broker and Message Queuing Telemetry Transport protocol. Some experiments conducted upon this testbed are also discussed.}
}

@article{lincoln36203,
          volume = {26},
          number = {2},
           month = {June},
          author = {Hoang-Long Cao and Pablo G. Esteban and Madeleine Bartlett and Paul Baxter and Tony Belpaeme and Erik Billing and Haibin Cai and Mark Coeckelbergh and Cristina Costescu and Daniel David and Albert De Beir and Daniel Hernandez and James Kennedy and Honghai Liu and Silviu Matu and Alexandre Mazel and Amit Pandey and Kathleen Richardson and Emmanuel Senft and Serge Thill and Greet Van de Perre and Bram Vanderborght and David Vernon and Kutoma Wakanuma and Hui Yu and Xiaolong Zhou and Tom Ziemke},
           title = {Robot-Enhanced Therapy: Development and Validation of Supervised Autonomous Robotic System for Autism Spectrum Disorders Therapy},
       publisher = {IEEE},
            year = {2019},
         journal = {IEEE Robotics \& Automation Magazine},
             doi = {doi:10.1109/MRA.2019.2904121},
           pages = {49--58},
        keywords = {ARRAY(0x5585d78fcae8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36203/},
        abstract = {Robot-assisted therapy (RAT) offers potential advantages for improving the social skills of children with autism spectrum disorders (ASDs). This article provides an overview of the developed technology and clinical results of the EC-FP7-funded Development of Robot-Enhanced therapy for children with AutisM spectrum disorders (DREAM) project, which aims to develop the next level of RAT in both clinical and technological perspectives, commonly referred to as robot-enhanced therapy (RET). Within this project, a supervised autonomous robotic system is collaboratively developed by an interdisciplinary consortium including psychotherapists, cognitive scientists, roboticists, computer scientists, and ethicists, which allows robot control to exceed classical remote control methods, e.g., Wizard of Oz (WoZ), while ensuring safe and ethical robot behavior. Rigorous clinical studies are conducted to validate the efficacy of RET. Current results indicate that RET can obtain an equivalent performance compared to that of human standard therapy for children with ASDs. We also discuss the next steps of developing RET robotic systems.}
}

@inproceedings{lincoln36395,
          volume = {11649},
           month = {June},
          author = {Alexander Gabriel and Serhan Cosar and Nicola Bellotto and Paul Baxter},
       booktitle = {Towards Autonomous Robotic Systems},
           title = {A Dataset for Action Recognition in the Wild},
       publisher = {Springer},
            year = {2019},
             doi = {doi:10.1007/978-3-030-23807-0\_30},
           pages = {362--374},
        keywords = {ARRAY(0x5585d78fcb18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36395/},
        abstract = {The development of autonomous robots for agriculture depends on a successful approach to recognize user needs as well as datasets reflecting the characteristics of the domain. Available datasets for 3D Action Recognition generally feature controlled lighting and framing while recording subjects from the front. They mostly reflect good recording conditions and therefore fail to account for the highly variable conditions the robot would have to work with in the field, e.g. when providing in-field logistic support for human fruit pickers as in our scenario. Existing work on Intention Recognition mostly labels plans or actions as intentions, but neither of those fully capture the extend of human intent. In this work, we argue for a holistic view on human Intention Recognition and propose a set of recording conditions, gestures and behaviors that better reflect the environment and conditions an agricultural robot might find itself in. We demonstrate the utility of the dataset by means of evaluating two human detection methods: bounding boxes and skeleton extraction.}
}

@misc{lincoln36226,
           month = {June},
           title = {Patient, carer and staff perceptions of robotics in rehabilitation: protocol of a systematic review and qualitative meta-synthesis},
          author = {Despina Laparidou and Ffion Curtis and Khaled Goher and Ayse Kucukyilmaz and Marion Walker and Joseph Akanuwe and Niro Siriwardena},
       publisher = {PROSPERO International prospective register of systematic reviews},
            year = {2019},
        keywords = {ARRAY(0x5585d78fcb48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36226/},
        abstract = {Registration of a systematic review and qualitative meta-synthesis protocol.}
}

@inproceedings{lincoln36285,
       booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
           month = {June},
           title = {Projections for Approximate Policy Iteration Algorithms},
          author = {R. Akrour and J. Pajarinen and Gerhard Neumann and J. Peters},
       publisher = {Proceedings of Machine Learning Research},
            year = {2019},
           pages = {181--190},
        keywords = {ARRAY(0x5585d78fcb78)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36285/},
        abstract = {Approximate policy iteration is a class of reinforcement learning (RL) algorithms where the policy is encoded using a function approximator and which has been especially prominent in RL with continuous action spaces. In this class of RL algorithms, ensuring increase of the policy return during policy update often requires to constrain the change in action distribution. Several approximations exist in the literature to solve this constrained policy update problem. In this paper, we propose to improve over such solutions by introducing a set of projections that transform the constrained problem into an unconstrained one which is then solved by standard gradient descent. Using these projections, we empirically demonstrate that our approach can improve the policy update solution and the control over exploration of existing approximate policy iteration algorithms.}
}

@inproceedings{lincoln36286,
          volume = {97},
           month = {June},
          author = {Philipp Becker and Harit Pandya and Gregor Gebhardt and Cheng Zhao and C. James Taylor and Gerhard Neumann},
          series = {Proceedings of Machine Learning Research},
       booktitle = {Proceedings of the 36th International Conference on Machine Learning},
         address = {Long Beach, California, USA},
           title = {Recurrent Kalman Networks: Factorized Inference in High-Dimensional Deep Feature Spaces},
       publisher = {Proceedings of Machine Learning Research},
            year = {2019},
           pages = {544--552},
        keywords = {ARRAY(0x5585d78fcba8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36286/},
        abstract = {In order to integrate uncertainty estimates into deep time-series modelling, Kalman Filters (KFs) (Kalman et al., 1960) have been integrated with deep learning models, however, such approaches typically rely on approximate inference tech- niques such as variational inference which makes learning more complex and often less scalable due to approximation errors. We propose a new deep approach to Kalman filtering which can be learned directly in an end-to-end manner using backpropagation without additional approximations. Our approach uses a high-dimensional factorized latent state representation for which the Kalman updates simplify to scalar operations and thus avoids hard to backpropagate, computationally heavy and potentially unstable matrix inversions. Moreover, we use locally linear dynamic models to efficiently propagate the latent state to the next time step. The resulting network architecture, which we call Recurrent Kalman Network (RKN), can be used for any time-series data, similar to a LSTM (Hochreiter \& Schmidhuber, 1997) but uses an explicit representation of uncertainty. As shown by our experiments, the RKN obtains much more accurate uncertainty estimates than an LSTM or Gated Recurrent Units (GRUs) (Cho et al., 2014) while also showing a slightly improved prediction performance and outperforms various recent generative models on an image imputation task.}
}

@article{lincoln37436,
          volume = {6},
          number = {3},
           month = {June},
          author = {S.M. Mustaza and Y. Elsayed and C. Lekakou and C. Saaj and J. Fras},
            note = {cited By 1},
           title = {Dynamic modeling of fiber-reinforced soft manipulator: A visco-hyperelastic material-based continuum mechanics approach},
       publisher = {Mary Ann Liebert},
            year = {2019},
         journal = {Soft Robotics},
             doi = {10.1089/soro.2018.0032},
           pages = {305--317},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37436/},
        abstract = {Robot-assisted surgery is gaining popularity worldwide and there is increasing scientific interest to explore the potential of soft continuum robots for minimally invasive surgery. However, the remote control of soft robots is much more challenging compared with their rigid counterparts. Accurate modeling of manipulator dynamics is vital to remotely control the diverse movement configurations and is particularly important for safe interaction with the operating environment. However, current dynamic models applied to soft manipulator systems are simplistic and empirical, which restricts the full potential of the new soft robots technology. Therefore, this article provides a new insight into the development of a nonlinear dynamic model for a soft continuum manipulator based on a material model. The continuum manipulator used in this study is treated as a composite material and a modified nonlinear Kelvin?Voigt material model is utilized to embody the visco-hyperelastic dynamics of soft silicone. The Lagrangian approach is applied to derive the equation of motion of the manipulator. Simulation and experimental results prove that this material modeling approach sufficiently captures the nonlinear time- and rate-dependent behavior of a soft manipulator. Material model-based closed-loop trajectory control was implemented to further validate the feasibility of the derived model and increase the performance of the overall system.}
}

@inproceedings{lincoln34950,
       booktitle = {RoboSoft 2019},
           month = {June},
           title = {Characterising 3D-printed Soft Fin Ray Robotic Fingers with Layer Jamming Capability for Delicate Grasping},
          author = {Khaled Elgeneidy and Peter Lightbody and Simon Pearson and Gerhard Neumann},
            year = {2019},
        keywords = {ARRAY(0x5585d78fcc08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34950/},
        abstract = {Motivated by the growing need within the agrifood industry to automate the handling of delicate produce, this paper presents soft robotic fingers utilising the Fin Ray effect to passively and gently adapt to delicate targets. The proposed Soft Fin Ray fingers feature thin ribs and are entirely 3D printed from a flexible material (NinjaFlex) to enhance their shape adaptation, compared to the original Fin Ray fingers. To overcome their reduced force generation, the effects of
the angle and spacing of the flexible ribs were experimentally characterised. The results showed that at large displacements, layer jamming between tilted flexible ribs can significantly enhance the force generation, while minimal contact forces can be still maintained at small displacements for delicate grasping.}
}

@inproceedings{lincoln35548,
           month = {May},
          author = {Petra Bosilj and Iain Gould and Tom Duckett and Grzegorz Cielniak},
       booktitle = {14th International Symposium on Mathematical Morphology},
           title = {Pattern Spectra from Different Component Trees for Estimating Soil Size Distribution},
       publisher = {Springer},
         journal = {International Symposium on Mathematical Morphology},
           pages = {415--427},
            year = {2019},
        keywords = {ARRAY(0x5585d78fcc38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35548/},
        abstract = {We study the pattern spectra in context of soil structure analysis. Good soil structure is vital for sustainable crop growth. Accurate and fast measuring methods can contribute greatly to soil management decisions. However, the current in-field approaches contain a degree of subjectivity, while obtaining quantifiable results through laboratory techniques typically involves sieving the soil which is labour- and time-intensive. We aim to replace this physical sieving process through image analysis, and investigate the effectiveness of pattern spectra to capture the size distribution of the soil aggregates. We calculate the pattern spectra from partitioning hierarchies in addition to the traditional max-tree. The study is posed as an image retrieval problem, and confirms the ability of pattern spectra and suitability of different partitioning trees to re-identify soil samples in different arrangements and scales.}
}

@inproceedings{lincoln35691,
       booktitle = {The 15th International Conference on Artificial Intelligence Applications and Innovations},
           month = {May},
           title = {An LGMD Based Competitive Collision Avoidance Strategy for UAV},
          author = {Jiannan Zhao and Xingzao Ma and Qinbing Fu and Cheng Hu and Shigang Yue},
       publisher = {Springer},
            year = {2019},
             doi = {10.1007/978-3-030-19823-7\_6},
        keywords = {ARRAY(0x5585d78fcc68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35691/},
        abstract = {Building a reliable and e?cient collision avoidance system for unmanned aerial vehicles (UAVs) is still a challenging problem. This research takes inspiration from locusts, which can ?y in dense swarms for hundreds of miles without collision. In the locust?s brain, a visual pathway of LGMD-DCMD (lobula giant movement detector and descending contra-lateral motion detector) has been identi?ed as collision perception system guiding fast collision avoidance for locusts, which is ideal for designing arti?cial vision systems. However, there is very few works investigating its potential in real-world UAV applications. In this paper, we present an LGMD based competitive collision avoidance method for UAV indoor navigation. Compared to previous works, we divided the UAV?s ?eld of view into four sub?elds each handled by an LGMD neuron. Therefore, four individual competitive LGMDs (C-LGMD) compete for guiding the directional collision avoidance of UAV. With more degrees of freedom compared to ground robots and vehicles, the UAV can escape from collision along four cardinal directions (e.g. the object approaching from the left-side triggers a rightward shifting of the UAV). Our proposed method has been validated by both simulations and real-time quadcopter arena experiments.}
}

@inproceedings{lincoln35586,
       booktitle = {15th International Conference on Artificial Intelligence Applications and Innovations},
           month = {May},
           title = {A Visual Neural Network for Robust Collision Perception in Vehicle Driving Scenarios},
          author = {Qinbing Fu and Nicola Bellotto and Huatian Wang and F. Claire Rind and Hongxin Wang and Shigang Yue},
       publisher = {Springer},
            year = {2019},
             doi = {10.1007/978-3-030-19823-7\_5},
        keywords = {ARRAY(0x5585d78fcc98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35586/},
        abstract = {This research addresses the challenging problem of visual collision detection in very complex and dynamic real physical scenes, specifically, the vehicle driving scenarios. This research takes inspiration from a large-field looming sensitive neuron, i.e., the lobula giant movement detector (LGMD) in the locust's visual pathways, which represents high spike frequency to rapid approaching objects. Building upon our previous models, in this paper we propose a novel inhibition mechanism that is capable of adapting to different levels of background complexity. This adaptive mechanism works effectively to mediate the local inhibition strength and tune the temporal latency of local excitation reaching the LGMD neuron. As a result, the proposed model is effective to extract colliding cues from complex dynamic visual scenes. We tested the proposed method using a range of stimuli including simulated movements in grating backgrounds and shifting of a natural panoramic scene, as well as vehicle crash video sequences. The experimental results demonstrate the proposed method is feasible for fast collision perception in real-world situations with potential applications in future autonomous vehicles.}
}

@inproceedings{lincoln35595,
           month = {May},
          author = {Huatian Wang and Qinbing Fu and Hongxin Wang and Jigen Peng and Shigang Yue},
       booktitle = {15th International Conference on Artificial Intelligence Applications and Innovations},
           title = {Constant Angular Velocity Regulation for Visually Guided Terrain Following},
       publisher = {Springer},
             doi = {10.1007/978-3-030-19823-7\_50},
           pages = {597--608},
            year = {2019},
        keywords = {ARRAY(0x5585d78fccc8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35595/},
        abstract = {Insects use visual cues to control their flight behaviours. By estimating the angular velocity of the visual stimuli and regulating it to a constant value, honeybees can perform a terrain following task which keeps the certain height above the undulated ground. For mimicking this behaviour in a bio-plausible computation structure, this paper presents a new angular velocity decoding model based on the honeybee's behavioural experiments. The model consists of three parts, the texture estimation layer for spatial information extraction, the motion detection layer for temporal information extraction and the decoding layer combining information from pervious layers to estimate the angular velocity. Compared to previous methods on this field, the proposed model produces responses largely independent of the spatial frequency and contrast in grating experiments. The angular velocity based control scheme is proposed to implement the model into a bee simulated by the game engine Unity. The perfect terrain following above patterned ground and successfully flying over irregular textured terrain show its potential for micro unmanned aerial vehicles' terrain following.}
}

@article{lincoln35699,
          volume = {19},
          number = {9},
           month = {May},
          author = {Li Sun and Cheng Zhao and Zhi Yan and Pengcheng Liu and Tom Duckett and Rustam Stolkin},
           title = {A Novel Weakly-supervised approach for RGB-D-based Nuclear Waste Object Detection and Categorization},
       publisher = {IEEE},
            year = {2019},
         journal = {IEEE Sensors Journal},
             doi = {10.1109/JSEN.2018.2888815},
           pages = {3487--3500},
        keywords = {ARRAY(0x5585d78fccf8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35699/},
        abstract = {This  paper  addresses  the  problem  of  RGBD-based detection  and  categorization  of   waste  objects  for  nuclear  de- commissioning.  To  enable  autonomous  robotic  manipulation   for nuclear decommissioning, nuclear waste objects must be detected and categorized. However, as a  novel industrial application, large amounts  of  annotated  waste  object  data  are  currently  unavailable. To overcome this problem, we propose a weakly-supervised learning  approach  which   is  able  to  learn  a  deep  convolutional neural  network  (DCNN)  from  unlabelled  RGBD  videos  while requiring  very  few  annotations.  The  proposed  method  also  has the  potential  to  be  
applied  to  other  household  or  industrial applications. We evaluate our approach on the  Washington RGB- D  object  recognition  benchmark,  achieving  the  state-of-the-art performance  among semi-supervised methods. More importantly, we  introduce  a  novel  dataset,  i.e.   Birmingham  nuclear  waste simulants  dataset,  and  evaluate  our  proposed  approach  on  this  novel industrial object recognition challenge. We further propose a  complete  real-time  pipeline   for  RGBD-based  detection  and categorization of nuclear waste simulants. Our weakly-supervised  approach  has  demonstrated  to  be  highly  effective  in  solving  a novel  RGB-D  object  
detection  and  recognition  application  with limited human annotations.}
}

@inproceedings{lincoln39623,
       booktitle = {15th ESA Symposium on Advanced Space Technologies in Robotics and Automation},
           month = {May},
           title = {Robotic Architectures for the On-Orbit Assembly of Large Space Telescopes},
          author = {Angadh Nanjangud and Chakravarthini M Saaj and Peter C. Blacker and Alex Young and Craig I. Underwood and Steve Eckersley and Martin Sweeting and Paolo Bianco},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39623/}
}

@article{lincoln39225,
          volume = {181},
           month = {May},
          author = {Efthymios C. Rodias and Maria Lampridi and Alessandro Sopegno and Remigio Berruto and George Banias and Dionysis Bochtis and Patrizia Busato},
           title = {Optimal energy performance on allocating energy crops},
         journal = {Biosystems Engineering},
             doi = {10.1016/j.biosystemseng.2019.02.007},
           pages = {11--27},
            year = {2019},
        keywords = {ARRAY(0x5585d78fcd58)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39225/},
        abstract = {There is a variety of crops that may be considered as potential biomass production crops. In order to select the best suitable for cultivation crop for a given area, a number of several factors should be taken into account. During the crop selection process, a common framework should be followed focussing on financial or energy performance. Combining multiple crops and multiple fields for the extraction of the best allocation requires a model to evaluate various and complex factors given a specific objective. This paper studies the maximisation of total energy gained from the biomass production by energy crops, reduced by the energy costs of the production process. The tool calculates the energy balance using multiple crops allocated to multiple fields. Both binary programming and linear programming methods are employed to solve the allocation problem. Each crop is assigned to a field (or a combination of crops are allocated to each field) with the aim of maximising the energy balance provided by the production system. For the demonstration of the tool, a hypothetical case study of three different crops cultivated for a decade (Miscanthus x giganteus, Arundo donax, and Panicum virgatum) and allocated to 40 dispersed fields around a biogas plant in Italy is presented. The objective of the best allocation is the maximisation of energy balance showing that the linear solution is slightly better than the binary one in the basic scenario while focussing on suggesting alternative scenarios that would have an optimal energy balance.}
}

@article{lincoln36284,
          volume = {4},
          number = {2},
           month = {April},
          author = {F. Brandherm and J. Peters and Gerhard Neumann and R. Akrour},
           title = {Learning Replanning Policies with Direct Policy Search},
            year = {2019},
         journal = {IEEE Robotics and Automation Letters (RA-L)},
             doi = {10.1109/LRA.2019.2901656},
           pages = {2196 --2203},
        keywords = {ARRAY(0x5585d78fcd88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36284/},
        abstract = {Direct policy search has been successful in learning challenging real world robotic motor skills by learning open-loop movement primitives with high sample efficiency. These primitives can be generalized to different contexts with varying initial configurations and goals. Current state-of-the-art contextual policy search algorithms can however not adapt to changing, noisy context measurements. Yet, these are common characteristics of real world robotic tasks. Planning a trajectory ahead based on an inaccurate context that may change during the motion often results in poor accuracy, especially with highly dynamical tasks. To adapt to updated contexts, it is sensible to learn trajectory replanning strategies. We propose a framework to learn trajectory replanning policies via contextual policy search and demonstrate that they are safe for the robot, that they can be learned efficiently and that they outperform non-replanning policies for problems with partially observable or perturbed context}
}

@article{lincoln41510,
          volume = {159},
           month = {April},
          author = {Yanchao Zhang and Junfeng Gao and Haiyan Cen and Yongliang Lu and Xiaoyue Yu and Yong He and Jan G. Pieters},
           title = {Automated spectral feature extraction from hyperspectral images to differentiate weedy rice and barnyard grass from a rice crop},
       publisher = {Elsevier},
            year = {2019},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2019.02.018},
           pages = {42--49},
        keywords = {ARRAY(0x5585d78fcdb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/41510/},
        abstract = {Barnyard grass (Echinochloa crusgalli) and weedy rice (Oryza sativa f. spontanea) are two common and troublesome weed species in rice (Oryza sativa L.) crop. They cause significant yield loss in rice production while it is difficult to differentiate them for site-specific weed management. In this paper, we aimed to develop a classification model with important spectral features to recognize these two weeds and rice based on hyperspectral imaging techniques. There were 287 plant leaf samples in total which were scanned by the hyperspectral imaging systems within the spectral range from 380nm to 1080nm. After obtaining hyperspectral images, we first developed an algorithmic pipeline to automatically extract spectral features from line scan hyperspectral images. Then the raw spectral features were subjected to wavelet transformation for noise reduction. Random forests and support vector machine models were developed with the optimal hyperparameters to compare their performances in the test set. Moreover, feature selection was explored through successive projection algorithm (SPA). It is shown that the weighted support vector machine with 6 spectral features selected by SPA can achieve 100\%, 100\%, and 92\% recognition rates for barnyard grass, weedy rice and rice, respectively. Furthermore, the selected 6 wavelengths (415nm, 561nm, 687nm, 705nm, 735nm, 1007nm) have the potential to design a customized optical sensor for these two weeds and rice discrimination in practice.}
}

@inproceedings{lincoln47566,
           month = {April},
          author = {Zakaria Maamar and Thar Baker and Noura Faci and Emir Ugljanin and Mohammed Al-Khafajiy and Vanilson Bur{\'e}gio},
       booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
           title = {Towards a seamless coordination of cloud and fog: illustration through the internet-of-things},
       publisher = {ACM},
             doi = {10.1145/3297280.3297477},
           pages = {2008--2015},
            year = {2019},
        keywords = {ARRAY(0x5585d78fcde8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47566/},
        abstract = {With the increasing popularity of the Internet-of-Things (IoT), organizations are revisiting their practices as well as adopting new ones so they can deal with an ever-growing amount of sensed and actuated data that IoT-compliant things generate. Some of these practices are about the use of cloud and/or fog computing. The former promotes "anything-as-a-service" and the latter promotes "process data next to where it is located". Generally presented as competing models, this paper discusses how cloud and fog could work hand-in-hand through a seamless coordination of their respective "duties". This coordination stresses out the importance of defining where the data of things should be sent (either cloud, fog, or cloud\&fog concurrently) and in what order (either cloud then fog, fog then cloud, or fog\&cloud concurrently). Applications' concerns with data such as latency, sensitivity, and freshness dictate both the appropriate recipients and the appropriate orders. For validation purposes, a healthcare-driven IoT application along with an in-house testbed, that features real sensors and fog and cloud platforms, have permitted to carry out different experiments that demonstrate the technical feasibility of the coordination model.}
}

@article{lincoln35601,
          volume = {9},
          number = {4},
           month = {April},
          author = {Maria Lampridi and Dimitrios Kateris and Giorgos Vasileiadis and Simon Pearson and Claus S{\o}rensen and Athanasios Balafoutis and Dionysis Bochtis},
           title = {A Case-Based Economic Assessment of Robotics Employment in Precision Arable Farming},
       publisher = {MDPI},
            year = {2019},
         journal = {Agronomy},
             doi = {10.3390/agronomy9040175},
           pages = {175},
        keywords = {ARRAY(0x5585d78fce18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35601/},
        abstract = {The need to intensify agriculture to meet increasing nutritional needs, in combination with the evolution of unmanned autonomous systems has led to the development of a series of ?smart? farming technologies that are expected to replace or complement conventional machinery and human labor. This paper proposes a preliminary methodology for the economic analysis of the employment of robotic systems in arable farming. This methodology is based on the basic processes for estimating the use cost for agricultural machinery. However, for the case of robotic systems, no average norms for the majority of the operational parameters are available. Here, we propose a novel estimation process for these parameters in the case of robotic systems. As a case study, the operation of light cultivation has been selected due the technological readiness for this type of operation.}
}

@inproceedings{lincoln39625,
       booktitle = {5th CEAS Conference on Guidance, Navigation and Control (EuroGNC)},
           month = {April},
           title = {Controlling a Non-Linear Space Robot using Linear Controllers},
          author = {A.W.I Mohamed and C. M. Saaj and A. Seddaoui and S. Eckersley},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39625/}
}

@article{lincoln39227,
          volume = {11},
          number = {6},
           month = {March},
          author = {Theodora Angelopoulou and Nikolaos Tziolas and Athanasios Balafoutis and George Zalidis and Dionysis Bochtis},
           title = {Remote Sensing Techniques for Soil Organic Carbon Estimation: A Review},
            year = {2019},
         journal = {Remote Sensing},
             doi = {10.3390/rs11060676},
           pages = {676},
        keywords = {ARRAY(0x5585d78fce78)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39227/},
        abstract = {Towards the need for sustainable development, remote sensing (RS) techniques in the Visible-Near Infrared?Shortwave Infrared (VNIR?SWIR, 400?2500 nm) region could assist in a more direct, cost-effective and rapid manner to estimate important indicators for soil monitoring purposes. Soil reflectance spectroscopy has been applied in various domains apart from laboratory conditions, e.g., sensors mounted on satellites, aircrafts and Unmanned Aerial Systems. The aim of this review is to illustrate the research made for soil organic carbon estimation, with the use of RS techniques, reporting the methodology and results of each study. It also aims to provide a comprehensive introduction in soil spectroscopy for those who are less conversant with the subject. In total, 28 journal articles were selected and further analysed. It was observed that prediction accuracy reduces from Unmanned Aerial Systems (UASs) to satellite platforms, though advances in machine learning techniques could further assist in the generation of better calibration models. There are some challenges concerning atmospheric, radiometric and geometric corrections, vegetation cover, soil moisture and roughness that still need to be addressed. The advantages and disadvantages of each approach are highlighted and future considerations are also discussed at the end.}
}

@article{lincoln35035,
          volume = {20},
           month = {March},
          author = {Simon Pearson and David May and Georgios Leontidis and Mark Swainson and Steve Brewer and Luc Bidaut and Jeremy Frey and Gerard Parr and Roger Maull and Andrea Zisman},
           title = {Are Distributed Ledger Technologies the Panacea for Food Traceability?},
       publisher = {Elsevier},
            year = {2019},
         journal = {Global Food Security},
             doi = {10.1016/j.gfs.2019.02.002},
           pages = {145--149},
        keywords = {ARRAY(0x5585d78fcea8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35035/},
        abstract = {Distributed Ledger Technology (DLT), such as blockchain, has the potential to transform supply chains. It can provide a cryptographically secure and immutable record of transactions and associated metadata (origin, contracts, process steps, environmental variations, microbial records, etc.) linked across whole supply chains. The ability to trace food items within and along a supply chain is legally required by all actors within the chain. It is critical to food safety, underpins trust and global food trade. However, current food traceability systems are not linked between all actors within the supply chain. Key metadata on the age and process history of a food is rarely transferred when a product is bought and sold through multiple steps within the chain. Herein, we examine the potential of massively scalable DLT to securely link the entire food supply chain, from producer to end user. Under such a paradigm, should a food safety or quality issue ever arise, authorized end users could instantly and accurately trace the origin and history of any particular food item. This novel and unparalleled technology could help underpin trust for the safety of all food, a critical component of global food security. In this paper, we investigate the (I) data requirements to develop DLT technology across whole supply chains, (ii) key challenges and barriers to optimizing the complete system, and (iii) potential impacts on production efficiency, legal compliance, access to global food markets and the safety of food. Our conclusion is that while DLT has the potential to transform food systems, this can only be fully realized through the global development and agreement on suitable data standards and governance. In addition, key technical issues need to be resolved including challenges with DLT scalability, privacy and data architectures.}
}

@article{lincoln36281,
          volume = {20},
          number = {54},
           month = {February},
          author = {Maximilian H{\"u}ttenrauch and Sosic Adrian and Gerhard Neumann},
           title = {Deep Reinforcement Learning for Swarm Systems},
       publisher = {Journal of Machine Learning Research},
            year = {2019},
         journal = {Journal of Machine Learning Research},
           pages = {1--31},
        keywords = {ARRAY(0x5585d78fced8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36281/},
        abstract = {Recently, deep reinforcement learning (RL) methods have been applied successfully to multi-agent scenarios. Typically, the observation vector for decentralized decision making is represented by a concatenation of the (local) information an agent gathers about other agents. However, concatenation scales poorly to swarm systems with a large number of homogeneous agents as it does not exploit the fundamental properties inherent to these systems: (i) the agents in the swarm are interchangeable and (ii) the exact number of agents in the swarm is irrelevant. Therefore, we propose a new state representation for deep multi-agent RL based on mean embeddings of distributions, where we treat the agents as samples and use the empirical mean embedding as input for a decentralized policy. We define different feature spaces of the mean embedding using histograms, radial basis functions and neural networks trained end-to-end. We evaluate the representation on two well-known problems from the swarm literature in a globally and locally observable setup. For the local setup we furthermore introduce simple communication protocols. Of all approaches, the mean embedding representation using neural network features enables the richest information exchange between neighboring agents, facilitating the development of complex collective strategies.}
}

@inproceedings{lincoln47568,
           month = {February},
          author = {Mohammed Al-Khafajiy and Thar Baker and Hilal Al-Libawy and Atif Waraich and Carl Chalmers and Omar Alfandi},
       booktitle = {2018 11th International Conference on Developments in eSystems Engineering (DeSE)},
           title = {Fog Computing Framework for Internet of Things Applications},
       publisher = {IEEE},
             doi = {doi:10.1109/DeSE.2018.00017},
           pages = {71--77},
            year = {2019},
        keywords = {ARRAY(0x5585d78fcf08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47568/},
        abstract = {Within the Internet of Things (IoT) era, a big volume of data is generated/gathered every second from billions of connected devices. The current network paradigm, which relies on centralised data centres (a.k.a. Cloud computing), becomes impractical solution for IoT data storing and processing due to the long distance between the data source (e.g., sensors) and designated data centres. In other words, by the time the data reaches a far data centre, the importance of the data would be vanished. Therefore, the network topologies have been evolved to permit data processing and storage at the edge of the network, introducing what so-called "Fog computing". The later will obviously lead to improvements in quality of service (QoS) via processing and responding quickly and efficiently to varieties of data processing requests. Therefore, understanding Fog computing architecture and its role in improving QoS is a paramount research topic. In this research, we are proposing a Fog computing architecture and framework to improve QoS for IoT applications. Proposed system supports cooperation among Fog nodes in a given location, in order to permit data processing in a shared mode, hence satisfies QoS and serves largest number of service requests. The proposed framework could have the potential in achieving sustainable network paradigm and highlights significant benefits of Fog computing into the computing ecosystem.}
}

@inproceedings{lincoln37442,
          volume = {Part F},
           month = {February},
          author = {L. Jackson and C. Saaj and A. Seddaoui and C. Whiting and S. Eckersley and M. Ferris},
            note = {cited By 0},
       booktitle = {5th International Conference on Mechatronics and Robotics Engineering},
           title = {Design of a small space robot for on-orbit assembly missions},
       publisher = {ACM},
            year = {2019},
         journal = {ACM International Conference Proceeding Series},
             doi = {10.1145/3314493.3314520},
           pages = {107--112},
        keywords = {ARRAY(0x5585d78fcf38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/37442/},
        abstract = {Intelligent robots have revolutionised terrestrial assembly and servicing processes, while low-cost small satellites have transformed the economics of space. This paper dovetails both technologies and proposes an innovative design for a small space robot that is potentially capable of assembly operations in-orbit. The drive for such missions stems from the growing commercial interests and scientific benefits offered by massive structures in space, such as the future large aperture astronomical or Earth Observation telescopes. However, limitations in the lifting capacity of launch vehicles currently impose severe restrictions on the size of the self-deployable monolithic telescope structure that can be carried. As a result, there is a growing demand for advancing the capabilities of space robots to assemble modular components in-orbit. To assess the feasibility of a small space robot for future in-space assembly missions, a detailed design is outlined and analysed in this paper. The trade-off between the manipulator configuration and its base spacecraft sizing is presented. This coherent design exercise is driven by various mission requirements that consider the constraints of a small spacecraft as well as its extreme operating environment.}
}

@article{lincoln38395,
          volume = {28},
          number = {1},
           month = {February},
          author = {J. Ganzer-Ripoll and N. Criado and M. Lopez-Sanchez and Simon Parsons and J.A. Rodriguez-Aguilar},
            note = {cited By 0},
           title = {Combining Social Choice Theory and Argumentation: Enabling Collective Decision Making},
            year = {2019},
         journal = {Group Decision and Negotiation},
             doi = {10.1007/s10726-018-9594-6},
           pages = {127--173},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38395/}
}

@incollection{lincoln39234,
          volume = {953},
           month = {February},
          author = {Dimitrios Bechtsis and Vasileios Moisiadis and Naoum Tsolakis and Dimitrios Vlachos and Dionysis Bochtis},
       booktitle = {Information and Communication Technologies in Modern Agricultural Development},
           title = {Unmanned Ground Vehicles in Precision Farming Services: An Integrated Emulation Modelling Approach},
       publisher = {Springer},
            year = {2019},
             doi = {doi:10.1007/978-3-030-12998-9\_13},
           pages = {177--190},
        keywords = {ARRAY(0x5585d78f93a0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39234/},
        abstract = {Autonomous systems are a promising alternative for safely executing precision farming activities in a 24/7 perspective. In this context Unmanned Ground Vehicles (UGVs) are used in custom agricultural fields, with sophisticated sensors and data fusion techniques for real-time mapping and navigation. The aim of this study is to present a simulation software tool for providing effective and efficient farming activities in orchard fields and demonstrating the applicability of simulation in routing algorithms, hence increasing productivity, while dynamically addressing operational and tactical level uncertainties. The three dimensional virtual world includes the field layout and the static objects (orchard trees, obstacles, physical boundaries) and is constructed in the open source Gazebo simulation software while the Robot Operating System (ROS) and the implemented algorithms are tested using a custom vehicle. As a result a routing algorithm is executed and enables the UGV to pass through all the orchard trees while dynamically avoiding static and dynamic obstacles. Unlike existing sophisticated tools, the developed mechanism could accommodate an extensive variety of agricultural activities and could be transparently transferred from the simulation environment to real world ROS compatible UGVs providing user-friendly and highly customizable navigation.}
}

@incollection{lincoln39235,
          volume = {953},
           month = {February},
          author = {Claus Aage Gr{\o}n S{\o}rensen and Dimitrios Kateris and Dionysis Bochtis},
       booktitle = {Information and Communication Technologies in Modern Agricultural Development},
           title = {ICT Innovations and Smart Farming},
       publisher = {Springer},
            year = {2019},
             doi = {doi:10.1007/978-3-030-12998-9\_1},
           pages = {1--19},
        keywords = {ARRAY(0x5585d78f93d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39235/},
        abstract = {Agriculture plays a vital role in the global economy with the majority of the rural population in developing countries depending on it. The depletion of natural resources makes the improvement of the agricultural production more important but also more difficult than ever. This is the reason that although the demand is constantly growing, Information and Communication Technology (ICT) offers to producers the adoption of sustainability and improvement of their daily living conditions. ICT offers timely and updated relevant information such as weather forecast, market prices, the occurrence of new diseases and varieties, etc. The new knowledge offers a unique opportunity to bring the production enhancing technologies to the farmers and empower themselves with modern agricultural technology and act accordingly for increasing the agricultural production in a cost effective and profitable manner. The use of ICT itself or combined with other ICT systems results in productivity improvement and better resource use and reduces the time needed for farm management, marketing, logistics and quality assurance.}
}

@article{lincoln39224,
          volume = {178},
           month = {February},
          author = {Efthymios C. Rodias and Alessandro Sopegno and Remigio Berruto and Dionysis Bochtis and Eugenio Cavallo and Patrizia Busato},
           title = {A combined simulation and linear programming method for scheduling organic fertiliser application},
       publisher = {Elsevier},
            year = {2019},
         journal = {Biosystems Engineering},
             doi = {10.1016/j.biosystemseng.2018.11.002},
           pages = {233--243},
        keywords = {ARRAY(0x5585d78f9400)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39224/},
        abstract = {Logistics have been used to analyse agricultural operations, such as chemical application, mineral or organic fertilisation and harvesting-handling operations. Recently, due to national or European commitments concerning livestock waste management, this waste is being applied in many crops instead of other mineral fertilisers. The organic fertiliser produced has a high availability although most of the crops it is applied to have strict timeliness issues concerning its application. Here, organic fertilizer (as liquid manure) distribution logistic system is modelled by using a combined simulation and linear programming method. The method applies in certain crops and field areas taking into account specific agronomical, legislation and other constraints with the objective of minimising the optimal annual cost. Given their direct connection with the organic fertiliser distribution, the operations of cultivation and seeding were included. In a basic scenario, the optimal cost was assessed for both crops in total cultivated area of 120 ha. Three modified scenarios are presented. The first regards one more tractor as being available and provides a reduction of 3.8\% in the total annual cost in comparison with the basic scenario. In the second and third modified scenarios fields having high nitrogen demand next to the farm are considered with one or two tractors and savings of 2.5\% and 6.1\%, respectively, compared to the basic scenario are implied. Finally, it was concluded that the effect of distance from the manure production to the location of the fields could reduce costs by 6.5\%.}
}

@article{lincoln35398,
          volume = {11},
          number = {2},
           month = {January},
          author = {Yongchao Zhu and Xuan Li and Simon Pearson and Dongli Wu and Ruijing Sun and Sarah Johnson and James Wheeler and Shibo Fang},
           title = {Evaluation of Fengyun-3C Soil Moisture Products Using In-Situ Data from the Chinese Automatic Soil Moisture Observation Stations: A Case Study in Henan Province, China},
            year = {2019},
         journal = {Water},
             doi = {doi:10.3390/w11020248},
           pages = {248},
        keywords = {ARRAY(0x5585d78f9430)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35398/},
        abstract = {Soil moisture (SM) products derived from passive satellite missions are playing an increasingly important role in agricultural applications, especially crop monitoring and disaster warning. Evaluating the dependability of satellite-derived soil moisture products on a large scale is crucial. In this study, we assessed the level 2 (L2) SM product from the Chinese Fengyun-3C (FY-3C) radiometer against in-situ measurements collected from the Chinese Automatic Soil Moisture Observation Stations (CASMOS) during a one-year period from 1 January 2016 to 31 December 2016 across Henan in China. In contrast, we also investigated the skill of the Advanced Microwave Scanning Radiometer 2 (AMSR2) and Soil Moisture Active/Passive (SMAP) SM products simultaneously. Four statistical parameters were used to evaluate these products? reliability: mean difference, root-mean-square error (RMSE), unbiased RMSE (ubRMSE), and the correlation coefficient. Our assessment results revealed that the FY-3C L2 SM product generally showed a poor correlation with the in-situ SM data from CASMOS on both temporal and spatial scales. The AMSR2 L3 SM product of JAXA (Japan Aerospace Exploration Agency) algorithm had a similar level of skill as FY-3C in the study area. The SMAP L3 SM product outperformed the FY-3C temporally but showed lower performance in capturing the SM spatial variation. A time-series analysis indicated that the correlations and estimated error varied systematically through the growing periods of the key crops in our study area. FY-3C L2 SM data tended to overestimate soil moisture during May, August, and September when the crops reached maximum vegetation density and tended to underestimate the soil moisture content during the rest of the year. The comparison between the statistical parameters and the ground vegetation water content (VWC) further showed that the FY-3C SM product performed much better under a low VWC condition ({\ensuremath{<}}0.3 kg/m2) than a high VWC condition ({\ensuremath{>}}0.3 kg/m2), and the performance generally decreased with increased VWC. To improve the accuracy of the FY-3C SM product, an improved algorithm that can better characterize the variations of the ground VWC should be applied in the future.}
}

@article{lincoln40818,
          volume = {325},
           month = {January},
          author = {Gautham Das and Philip J. Vance and Dermot Kerr and Sonya A. Coleman and Thomas M. McGinnity and Jian K. Liu},
           title = {Computational modelling of salamander retinal ganglion cells using machine learning approaches},
       publisher = {Elsevier},
            year = {2019},
         journal = {Neurocomputing},
             doi = {10.1016/j.neucom.2018.10.004},
           pages = {101--112},
        keywords = {ARRAY(0x5585d78f9460)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40818/},
        abstract = {Artificial vision using computational models that can mimic biological vision is an area of ongoing research. One of the main themes within this research is the study of the retina and in particular, retinal ganglion cells which are responsible for encoding the visual stimuli. A common approach to modelling the internal processes of retinal ganglion cells is the use of a linear ? non-linear cascade model, which models the cell?s response using a linear filter followed by a static non-linearity. However, the resulting model is generally restrictive as it is often a poor estimator of the neuron?s response. In this paper we present an alternative to the linear ? non-linear model by modelling retinal ganglion cells using a number of machine learning techniques which have a proven track record for learning complex non-linearities in many different domains. A comparison of the model predicted spike rate shows that the machine learning models perform better than the standard linear ? non-linear approach in the case of temporal white noise stimuli.}
}

@inproceedings{lincoln36201,
       booktitle = {2nd UK-RAS Robotics and Autonomous Systems Conference},
           month = {January},
           title = {Towards a Dataset of Activities for Action Recognition in Open Fields},
          author = {Alexander Gabriel and Nicola Bellotto and Paul Baxter},
       publisher = {UK-RAS},
            year = {2019},
           pages = {64--67},
        keywords = {ARRAY(0x5585d78f9490)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36201/},
        abstract = {In an agricultural context, having autonomous robots that can work side-by-side with human workers provide a range of productivity benefits. In order for this to be achieved safely and effectively, these autonomous robots require the ability to understand a range of human behaviors in order to facilitate task communication and coordination. The recognition of human actions is a key part of this, and is the focus of this paper. Available datasets for Action Recognition generally feature controlled lighting and framing while recording subjects from the front. They mostly reflect good recording conditions but fail to model the data a robot will have to work with in the field, such as varying distance and lighting conditions. In this work, we propose a set of recording conditions, gestures and behaviors that better reflect the environment an agricultural
robot might find itself in and record a dataset with a range of sensors that demonstrate these conditions.}
}

@article{lincoln35570,
           month = {January},
           title = {Choosing grasps to enable collision-free post-grasp manipulations},
          author = {Tommaso Pardi and Rustam Stolkin and Amir Ghalamzan Esfahani},
       publisher = {IEEE},
            year = {2019},
             doi = {10.1109/HUMANOIDS.2018.8625027},
         journal = {IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids)},
        keywords = {ARRAY(0x5585d78f94c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/35570/},
        abstract = {Consider the task of grasping the handle of a door, and then pushing it until the door opens. These two fundamental robotics problems (selecting secure grasps of a hand on an object, e.g. the door handle, and planning collision-free trajectories of a robot arm that will move that object along a desired path) have predominantly been studied separately from one another. Thus, much of the grasping literature overlooks the fundamental purpose of grasping objects, which is typically to make them move in desirable ways. Given a desired post-grasp trajectory of the object, different choices of grasp will often determine whether or not collision-free post-grasp motions of the arm can be found, which will deliver that trajectory. We address this problem by examining a number of possible stable grasping configurations on an object. For each stable grasp, we explore the motion space of the manipulator which would be needed for post-grasp motions, to deliver the object along the desired trajectory. A criterion, based on potential fields in the post-grasp motion space, is used to assign a collision-cost to each grasp. A grasping configuration is then selected which enables the desired post-grasp object motion while minimising the proximity of all robot parts to obstacles during motion. We demonstrate our method with peg-in-hole and pick-and-place experiments in cluttered scenes, using a Franka Panda robot. Our approach is effective in selecting appropriate grasps, which enable both stable grasp and also desired post-grasp movements without collisions. We also show that, when grasps are selected based on grasp stability alone, without consideration for desired post-grasp manipulations, the corresponding post-grasp movements of the manipulator may result in collisions.}
}

@inproceedings{lincoln45010,
       booktitle = {2nd UK-RAS ROBOTICS AND AUTONOMOUS SYSTEMS CONFERENCE},
           month = {January},
           title = {Establishing Continuous Communication through Dynamic Team Behaviour Switching},
          author = {Tsvetan Zhivkov and Eric Schneider and Elizabeth Sklar},
       publisher = {UK-RAS19 Conference},
            year = {2019},
             doi = {10.31256/UKRAS19.22},
        keywords = {ARRAY(0x5585d78f94f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/45010/},
        abstract = {Maintaining continuous communication is an important factor that contributes to the success of multi-robot systems. Most research involving multi-robot teams is conducted in controlled laboratory settings, where continuous communication is assumed, typically because there is a wireless network (wifi) that keeps all the robots connected. But for multi-robot teams to operate successfully ?in the wild?, it is crucial to consider how communication can be maintained when signals fail or robots move out of range. This paper presents a novel ?leader-follower behaviour? with dynamic role switching and messaging that supports uninterrupted communication, regardless of network perturbations. A series of experiments were conducted in which it is shown how network perturbations effect performance, comparing a baseline with the new leaderfollower behaviour. The experiments record metrics on team success, given the two conditions. These results are significant for real-world multi-robot systems applications that require continuous communication amongst team members.}
}

@inproceedings{lincoln39207,
       booktitle = {Smart Industry Workshop 2019},
           month = {January},
           title = {MODEL BASED 3D POINT CLOUD SEGMENTATION FOR AUTOMATED SELECTIVE BROCCOLI HARVESTING},
          author = {Hector Montes and Tom Duckett and Grzegorz Cielniak},
            year = {2019},
        keywords = {ARRAY(0x5585d78f9520)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39207/},
        abstract = {Segmentation of 3D objects in cluttered scenes is a highly relevant problem. Given a 3D point cloud produced by a depth sensor, the goal is to separate objects of interest in the foreground from other elements in the background. We research 3D imaging methods to accurately segment and identify broccoli plants in the field. The ability to separate parts into different sets of sensor readings is an important task towards this goal. Our research is focused on the broccoli head segmentation problem as a first step towards size estimation of each broccoli crop in order to establish whether or not it is suitable for cutting.}
}

@inproceedings{lincoln47567,
           month = {January},
          author = {Mohammed Al-Khafajiy and Thar Baker and Atif Waraich and Dhiya Al-Jumeily and Abir Hussain},
       booktitle = {2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC Companion)},
           title = {IoT-Fog Optimal Workload via Fog Offloading},
       publisher = {IEEE},
             doi = {doi:10.1109/UCC-Companion.2018.00081},
           pages = {359--364},
            year = {2019},
        keywords = {ARRAY(0x5585d78f9550)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47567/},
        abstract = {Billions of devises are expected to be connected to the Internet of Things network in the near future, therefore, a considerable amount of data will be generated, and gathered every second. The current network paradigm, which relies on centralised data-centres (a.k.a. Cloud computing), becomes impractical solution for IoT data due to the long distance between the data source and designated data-center. In other words, the amount of time taken by data to travel to a data-centre makes the importance of the data vanished. Therefore, the network topology have been evolved to permit data processing at the edge of the network, introducing what so-called "Fog computing". The later will obviously lead to improvements in quality of service via efficient and quick responding to sensors requests. In this paper, we are proposing a fog computing architecture and framework to enhance QoS via request offloading method. The proposed method employ a collaboration strategy among fog nodes in order to permit data processing in a shared mode, hence satisfies QoS and serves largest number of IoT requests. The proposed framework could have the potential in achieving sustainable network paradigm and highlights significant benefits of fog computing into the computing ecosystem.}
}

@inproceedings{lincoln34713,
       booktitle = {International Conference on Intelligent Robots and Systems (IROS 2018)},
           month = {January},
           title = {Contact Detection and Size Estimation Using a Modular Soft Gripper with Embedded Flex Sensors},
          author = {Khaled Elgeneidy and Gerhard Neumann and Simon Pearson and Michael Jackson and Niels Lohse},
            year = {2019},
        keywords = {ARRAY(0x5585d78f9580)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34713/},
        abstract = {Grippers made from soft elastomers are able to passively and gently adapt to their targets allowing deformable objects to be grasped safely without causing bruise or damage. However, it is difficult to regulate the contact forces due to the lack of contact feedback for such grippers. In this paper, a modular soft gripper is presented utilizing interchangeable soft pneumatic actuators with embedded flex sensors as fingers of the gripper. The fingers can be assembled in different configurations using 3D printed connectors. The paper investigates the potential of utilizing the simple sensory feedback from the flex and pressure sensors to make additional meaningful inferences regarding the contact state and grasped object size. We study the effect of the grasped object size and contact type on the combined feedback from the embedded flex sensors of opposing fingers. Our results show that a simple linear relationship exists between the grasped object size and the final flex sensor reading at fixed input conditions, despite the variation in object weight and contact type. Additionally, by simply monitoring the time series response from the flex sensor, contact can be detected by comparing the response to the known free-bending response at the same input conditions. Furthermore, by utilizing the measured internal pressure supplied to the soft fingers, it is possible to distinguish between power and pinch grasps, as the contact type affects the rate of change in the flex sensor readings against the internal pressure.}
}

@inproceedings{lincoln36001,
       booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {January},
           title = {Learning Monocular Visual Odometry with Dense 3D Mapping from Dense 3D Flow},
          author = {Cheng Zhao and Li Sun and Pulak Purkait and Tom Duckett and Rustam Stolkin},
       publisher = {IEEE},
            year = {2019},
             doi = {10.1109/IROS.2018.8594151},
        keywords = {ARRAY(0x5585d78f95b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36001/},
        abstract = {This paper introduces a fully deep learning approach to monocular SLAM, which can perform simultaneous localization using a neural network for learning visual odometry (L-VO) and dense 3D mapping. Dense 2D flow and a depth image are generated from monocular images by sub-networks, which are then used by a 3D flow associated layer in the L-VO network to generate dense 3D flow. Given this 3D flow, the dual-stream L-VO network can then predict the 6DOF relative pose and furthermore reconstruct the vehicle trajectory. In order to learn the correlation between motion directions, the Bivariate Gaussian modeling is employed in the loss function. The L-VO network achieves an overall performance of 2.68 \% for average translational error and 0.0143?/m for average rotational error on the KITTI odometry benchmark. Moreover, the learned depth is leveraged to generate a dense 3D map. As a result, an entire visual SLAM system, that is, learning monocular odometry combined with dense 3D mapping, is achieved.}
}

@misc{lincoln34922,
           month = {January},
           title = {Use and citation of  paper "Fox et al (2018), ?When should the chicken cross the road? Game theory for autonomous vehicle - human interactions conference paper?" by the Law Commission to review and potentially change the law of the UK on autonomous vehicles.   Cited in their consultation report,  "Automated Vehicles: A joint preliminary consultation paper" on p174, ref 651.},
          author = {Charles Fox},
            year = {2019},
         journal = {Automated Vehicles: A joint preliminary consultation paper},
        keywords = {ARRAY(0x5585d78f95e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34922/},
        abstract = {Topic of this consultation: The Centre for Connected and Automated Vehicles (CCAV) has
asked the Law Commission of England and Wales and the Scottish Law Commission to
examine options for regulating automated road vehicles. It is a three-year project, running from
March 2018 to March 2021. This preliminary consultation paper focuses on the safety of
passenger vehicles.
Driving automation refers to a broad range of vehicle technologies. Examples range from
widely-used technologies that assist human drivers (such as cruise control) to vehicles that
drive themselves with no human intervention. We concentrate on automated driving systems
which do not need human drivers for at least part of the journey.
This paper looks at are three key themes. First, we consider how safety can be assured before
and after automated driving systems are deployed. Secondly, we explore criminal and civil
liability. Finally, we examine the need to adapt road rules for artificial intelligence.}
}

@article{lincoln34502,
          volume = {156},
           month = {January},
          author = {Rafael Ceasar Tieppo and Thiago Lib{\'o}rio Romanelli and Marcos Milan and Claus Aage Gr{\o}n S{\o}rensen and Dionysis Bochtis},
           title = {Modeling cost and energy demand in agricultural machinery fleets for soybean and maize cultivated using a no-tillage system},
       publisher = {Elsevier},
            year = {2019},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2018.11.032},
           pages = {282--292},
        keywords = {ARRAY(0x5585d78f9610)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34502/},
        abstract = {Climate, area expansion and the possibility to grow soybean and maize within a same season using the no-tillage system and mechanized agriculture are factors that promoted the agriculture growth in Mato Grosso State ? Brazil. Mechanized operations represent around 23\% of production costs for maize and soybean, demanding a considerably powerful machinery. Energy balance is a tool to verify the sustainability level of mechanized system. Regarding the sustainability components profit and environment, this study aims to develop a deterministic model for agricultural machinery costs and energy demand for no-tillage system production of soybean and maize crops. In addition, scenario simulation aids to analyze the influence of fleet sizing regarding cost and energy demand. The development of the deterministic model consists on equations and data retrieved from literature. A simulation was developed for no-tillage soybean production system in Brazil, considering three basic mechanized operations (sowing, spraying and harvesting). Thereby, for those operations, three sizes of machinery commercially available and regularly used (small, medium, large) and seven levels of cropping area (500, 1000, 2000, 4000, 6000, 8000 and 10,000ha) were used. The developed model was consistent for predictions of power demand, fuel consumption and costs. We noticed that the increase in area size implies in more working time for the machinery, which decreases the cost difference among the combinations. The greatest difference for the smallest area (500ha) was 22.1 and 94.8\% for sowing and harvesting operations, respectively. For 4000 and 10,000ha, the difference decreased to 1.30 and 0.20\%. Simulated scenarios showed the importance of determining operational cost and energy demand when energy efficiency is desired.}
}

@inproceedings{lincoln40837,
       booktitle = {2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           title = {Improving Local Trajectory Optimisation using Probabilistic Movement Primitives},
          author = {Ashith Babu and Peter Lightbody and Gautham Das and Pengcheng Liu and Sebastian Gomez-Gonzalez and Gerhard Neumann},
       publisher = {IEEE},
            year = {2019},
           pages = {2666--2671},
             doi = {10.1109/IROS40897.2019.8967980},
        keywords = {ARRAY(0x5585d78f9640)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/40837/},
        abstract = {Local trajectory optimisation techniques are a powerful tool for motion planning. However, they often get stuck in local optima depending on the quality of the initial solution and consequently, often do not find a valid (i.e. collision free) trajectory. Moreover, they often require fine tuning of a cost function to obtain the desired motions. In this paper, we address both problems by combining local trajectory optimisation with learning from demonstrations. The human expert demonstrates how to reach different target end-effector locations in different ways. From these demonstrations, we estimate a trajectory distribution, represented by a Probabilistic Movement Primitive (ProMP). For a new target location, we sample different trajectories from the ProMP and use these trajectories as initial solutions for the local optimisation. As the ProMP generates versatile initial solutions for the optimisation, the chance of finding poor local minima is significantly reduced. Moreover, the learned trajectory distribution is used to specify the smoothness costs for the optimisation, resulting in solutions of similar shape as the demonstrations. We demonstrate the effectiveness of our approach in several complex obstacle avoidance scenarios.}
}

@article{lincoln38396,
          volume = {11649},
          author = {T. Flyr and Simon Parsons},
            note = {cited By 0},
           title = {Towards Adversarial Training for Mobile Robots},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-23807-0\_17},
           pages = {197--208},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38396/}
}

@inproceedings{lincoln39418,
       booktitle = {20th Annual Conference, TAROS 2019},
           title = {The Downsizing of a Free-Flying Space Robot},
          author = {Lucy Jackson and Chakravarthini M. Saaj and Asma Seddaoui and Calem Whiting and Steve Eckersley and Mark Ferris},
       publisher = {Springer},
            year = {2019},
           pages = {480--483},
             doi = {10.1007/978-3-030-25332-5},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39418/}
}

@inproceedings{lincoln39621,
          volume = {11650},
          author = {John Koleosho and Chakravarthini  M. Saaj},
       booktitle = {Towards Autonomous Robotic Systems},
           title = {System Design and Control of a Di-Wheel Rover},
       publisher = {Springer},
             doi = {10.1007/978-3-030-25332-5\_35},
           pages = {409--421},
            year = {2019},
        keywords = {ARRAY(0x5585d78f96d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39621/},
        abstract = {Traditionally, wheeled rovers are used for planetary surface exploration and six-wheeled chassis designs based on the Rocker-Bogie suspension system have been tested successfully on Mars. However, it is difficult to explore craters and crevasses using large six or four-wheeled rovers. Innovative designs based on smaller Di-Wheel Rovers might be better suited for such challenging terrains. A Di-Wheel Rover is a self - balancing two-wheeled mobile robot that can move in all directions within a two-dimensional plane, as well as stand upright by balancing on two wheels.

This paper presents the outcomes of a feasibility study on a Di-Wheel Rover for planetary exploration missions. This includes developing its chassis design based on the hardware and software requirements, prototyping, and subsequent testing. The main contribution of this paper is the design of a self-balancing control system for the Di-Wheel Rover. This challenging design exercise was successfully completed through extensive experimentation thereby validating the performance of the Di-Wheel Rover. The details on the structural design, tuning controller gains based on an inverted pendulum model, and testing on different ground surfaces are described in this paper. The results presented in this paper give a new insight into designing low-cost Di-Wheel Rovers and clearly, there is a potential to use Di-Wheel Rovers for future planetary exploration.}
}

@inproceedings{lincoln36413,
       booktitle = {Proc. of the Int. Conf. on Image Analysis and Processing (ICIAP)},
           title = {ActiVis: Mobile Object Detection and Active Guidance for People with Visual Impairments},
          author = {Jacobus Lock and A. G. Tramontano and S. Ghidoni and Nicola Bellotto},
            year = {2019},
        keywords = {ARRAY(0x5585d78f9700)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36413/},
        abstract = {The ActiVis project aims to deliver a mobile system that is able to guide a person with visual impairments towards a target object or area in an unknown indoor environment. For this, it uses new developments in object detection, mobile computing, action generation and human-computer interfacing to interpret the user's surroundings and present effective guidance directions. Our approach to direction generation uses a Partially Observable Markov Decision Process (POMDP) to track the system's state and output the optimal location to be investigated. This system includes an object detector and an audio-based guidance interface to provide a complete active search pipeline. The ActiVis system was evaluated in a set of experiments showing better performance than a simpler unguided case.}
}

@inproceedings{lincoln34596,
       booktitle = {14th International Conference on Computer Vision Theory and Applications (VISAPP)},
           title = {Active Object Search with a Mobile Device for People with Visual Impairments},
          author = {Jacobus Lock and Grzegorz Cielniak and Nicola Bellotto},
       publisher = {VISIGRAPP},
            year = {2019},
           pages = {476--485},
             doi = {10.5220/0007582304760485},
        keywords = {ARRAY(0x5585d78f9730)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/34596/},
        abstract = {Modern smartphones can provide a multitude of services to assist people with visual impairments, and their cameras in particular can be useful for assisting with tasks, such as reading signs or searching for objects in unknown environments. Previous research has looked at ways to solve these problems by processing the camera's video feed, but very little work has been done in actively guiding the user towards specific points of interest, maximising the effectiveness of the underlying visual algorithms. In this paper, we propose a control algorithm based on a Markov Decision Process that uses a smartphone?s camera to generate real-time instructions to guide a user towards a target object. The solution is part of a more general active vision application for people with visual impairments. An initial implementation of the system on a smartphone was experimentally evaluated with participants with healthy eyesight to determine the performance of the control algorithm. The results show the effectiveness of our solution and its potential application to help people with visual impairments find objects in unknown environments.}
}

@inproceedings{lincoln39624,
       booktitle = {15th ESA Symposium on Advanced Space Technologies in Robotics and Automation},
           title = {A Self-Reconfigurable Undulating Grasper for Asteroid Mining},
          author = {Suzanna Lucarotti and Chakravarthini M. Saaj and Elie Allouis and Paolo Bianco},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39624/}
}

@article{lincoln36283,
           title = {Compatible natural gradient policy search},
          author = {J. Pajarinen and H.L. Thai and R. Akrour and J. Peters and Gerhard Neumann},
       publisher = {Springer},
            year = {2019},
             doi = {10.1007/s10994-019-05807-0},
         journal = {Machine Learning},
        keywords = {ARRAY(0x5585d78f9790)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/36283/},
        abstract = {Trust-region methods have yielded state-of-the-art results in policy search. A common approach is to use KL-divergence to bound the region of trust resulting in a natural gradient policy update. We show that the natural gradient and trust region optimization are equivalent if we use the natural parameterization of a standard exponential policy distribution in combination with compatible value function approximation. Moreover, we show that standard natural gradient updates may reduce the entropy of the policy according to a wrong schedule leading to premature convergence. To control entropy reduction we introduce a
new policy search method called compatible policy search (COPOS) which bounds entropy loss. The experimental results show that COPOS yields state-of-the-art results in challenging continuous control tasks and in discrete partially observable tasks.}
}

@article{lincoln38400,
          volume = {11327},
          author = {A.R. Panisson and ?. Sarkadi and P. McBurney and Simon Parsons and R.H. Bordini},
            note = {cited By 0},
           title = {On the Formal Semantics of Theory of Mind in Agent Communication},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-17294-7{$_2$}},
           pages = {18--32},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38400/}
}

@misc{lincoln38397,
           title = {Sentiment-stance-specificity (SSS) dataset: Identifying support-based entailment among opinions},
          author = {P. Rajendran and D. Bollegala and Simon Parsons},
            year = {2019},
           pages = {619--626},
            note = {cited By 0},
         journal = {LREC 2018 - 11th International Conference on Language Resources and Evaluation},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38397/}
}

@article{lincoln38399,
          volume = {11327},
          author = {{\c S}. Sarkadi and A.R. Panisson and R.H. Bordini and P. McBurney and S. Parsons},
            note = {cited By 0},
           title = {Towards an Approach for Modelling Uncertain Theory of Mind in Multi-Agent Systems},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-17294-7{$_1$}},
           pages = {3--17},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38399/},
        abstract = {Applying Theory of Mind to multi-agent systems enables agents to model and reason about other agents? minds. Recent work shows that this ability could increase the performance of agents, making them more efficient than agents that lack this ability. However, modelling others agents? minds is a difficult task, given that it involves many factors of uncertainty, e.g., the uncertainty of the communication channel, the uncertainty of reading other agents correctly, and the uncertainty of trust in other agents. In this paper, we explore how agents acquire and update Theory of Mind under conditions of uncertainty. To represent uncertain Theory of Mind, we add probability estimation on a formal semantics model for agent communication based on the BDI architecture and agent communication languages.}
}

@article{lincoln38401,
          volume = {32},
          number = {4},
          author = {{\c S}. Sarkadi and A.R. Panisson and R.H. Bordini and P. McBurney and S. Parsons and M. Chapman},
            note = {cited By 0},
           title = {Modelling deception using theory of mind in multi-agent systems},
            year = {2019},
         journal = {AI Communications},
             doi = {10.3233/AIC-190615},
           pages = {287--302},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38401/},
        abstract = {Agreement, cooperation and trust would be straightforward if deception did not ever occur in communicative interactions. Humans have deceived one another since the species began. Do machines deceive one another or indeed humans? If they do, how may we detect this? To detect machine deception, arguably requires a model of how machines may deceive, and how such deception may be identified. Theory of Mind (ToM) provides the opportunity to create intelligent machines that are able to model the minds of other agents. The future implications of a machine that has the capability to understand other minds (human or artificial) and that also has the reasons and intentions to deceive others are dark from an ethical perspective. Being able to understand the dishonest and unethical behaviour of such machines is crucial to current research in AI. In this paper, we present a high-level approach for modelling machine deception using ToM under factors of uncertainty and we propose an implementation of this model in an Agent-Oriented Programming Language (AOPL). We show that the Multi-Agent Systems (MAS) paradigm can be used to integrate concepts from two major theories of deception, namely Information Manipulation Theory 2 (IMT2) and Interpersonal Deception Theory (IDT), and how to apply these concepts in order to build a model of computational deception that takes into account ToM. To show how agents use ToM in order to deceive, we define an epistemic agent mechanism using BDI-like architectures to analyse deceptive interactions between deceivers and their potential targets and we also explain the steps in which the model can be implemented in an AOPL. To the best of our knowledge, this work is one of the first attempts in AI that (i) uses ToM along with components of IMT2 and IDT in order to analyse deceptive interactions and (ii) implements such a model.}
}

@article{lincoln38398,
          volume = {11763},
          author = {I. Sassoon and N. K{\"o}kciyan and E. Sklar and Simon Parsons},
            note = {cited By 0},
           title = {Explainable argumentation for wellness consultation},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-30391-4{$_1$}{$_1$}},
           pages = {186--202},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38398/}
}

@article{lincoln38539,
          volume = {11763},
          author = {I. Sassoon and N. K{\"o}kciyan and Elizabeth Sklar and S. Parsons},
            note = {cited By 0},
           title = {Explainable argumentation for wellness consultation},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-30391-4},
           pages = {186--202},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38539/}
}

@inproceedings{lincoln39420,
       booktitle = {Towards Autonomous Robotic Systems Conference},
           title = {Collision-Free Optimal Trajectory Generator for a Controlled Floating Space Robot},
          author = {Asma Seddaoui and Chakravarthini M. Saaj and Steve Eckersley},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/39420/}
}

@article{lincoln38537,
          volume = {11650},
          author = {D. Zhang and E. Schneider and Elizabeth Sklar},
            note = {cited By 0},
           title = {A cross-landscape evaluation of multi-robot team performance in static task-allocation domains},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-25332-5},
           pages = {261--272},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38537/}
}

@article{lincoln38538,
          volume = {11650},
          author = {Tsvetan Zhivkov and E. Schneider and Elizabeth Sklar},
            note = {cited By 0},
           title = {MRComm: Multi-robot communication testbed},
         journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
             doi = {10.1007/978-3-030-25332-5},
           pages = {346--357},
            year = {2019},
             url = {https://eprints.lincoln.ac.uk/id/eprint/38538/}
}

