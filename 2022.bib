@article{lincoln52940,
          volume = {205},
           month = {December},
          author = {Chao Qi and Murilo Sandroni and Jesper Cairo Westergaard and Ea H{\o}egh Riis Sundmark and Merethe Bagge and Erik Alexandersson and Junfeng Gao},
           title = {In-field classification of the asymptomatic biotrophic phase of potato late blight based on deep learning and proximal hyperspectral imaging},
       publisher = {Elsevier},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2022.107585},
            year = {2022},
        keywords = {ARRAY(0x559d32b2ac98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52940/},
        abstract = {Effective detection of potato late blight (PLB) is an essential aspect of potato cultivation. However, it is a challenge to detect late blight in asymptomatic biotrophic phase in fields with conventional imaging approaches because of the lack of visual symptoms in the canopy. Hyperspectral imaging can capture spectral signals from a wide range of wavelengths also outside the visual wavelengths. Here, we propose a deep learning classification architecture for hyperspectral images by combining 2D convolutional neural network (2D-CNN) and 3D-CNN with deep cooperative attention networks (PLB-2D-3D-A). First, 2D-CNN and 3D-CNN are used to extract rich spectral space features, and then the attention mechanism AttentionBlock and SE-ResNet are used to emphasize the salient features in the feature maps and increase the generalization ability of the model. The dataset is built with 15,360 images (64x64x204), cropped from 240 raw images captured in an experimental field with over 20 potato genotypes. The accuracy in the test dataset of 2000 images reached 0.739 in the full band and 0.790 in the specific bands (492 nm, 519 nm, 560 nm, 592 nm, 717 nm and 765 nm). This study shows an encouraging result for classification of the asymptomatic biotrophic phase of PLB disease with deep learning and proximal hyperspectral imaging.}
}

@inproceedings{lincoln51680,
           month = {December},
          author = {Adrian Salazar-Gomez and Madeleine Darbyshire and Junfeng Gao and Elizabeth Sklar and Simon Parsons},
       booktitle = {2022 IEEE/RSJ International Conference on Intelligent Robots and Systems},
           title = {Beyond mAP: Towards practical object detection for weed spraying in precision agriculture},
       publisher = {IEEE Press},
             doi = {10.1109/IROS47612.2022.9982139},
           pages = {9232--9238},
            year = {2022},
        keywords = {ARRAY(0x559d32b306f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/51680/},
        abstract = {The evolution of smaller and more powerful GPUs over the last 2 decades has vastly increased the opportunity to apply robust deep learning-based machine vision approaches to real-time use cases in practical environments. One exciting application domain for such technologies is precision agriculture, where the ability to integrate on-board machine vision with data-driven actuation means that farmers can make decisions about crop care and harvesting at the level of the individual plant rather than the whole field. This makes sense both economically and environmentally. This paper assesses the feasibility of precision spraying weeds via a comprehensive evaluation of weed detection accuracy and speed using two separate datasets, two types of GPU, and several state-of-the-art object detection algorithms. A simplified model of precision spraying is used to determine whether the weed detection accuracy achieved could result in a sufficiently high weed hit rate combined with a significant reduction in herbicide usage. The paper introduces two metrics to capture these aspects of the real-world deployment of precision weeding and demonstrates their utility through experimental results.}
}

@article{lincoln52689,
          volume = {31},
           month = {November},
          author = {Asier Lopez Zorrilla and M. Ines Torres and Heriberto Cuayahuitl},
           title = {Audio Embedding-Aware Dialogue Policy Learning},
       publisher = {IEEE},
            year = {2022},
         journal = {IEEE TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING},
             doi = {10.1109/TASLP.2022.3225658},
           pages = {525--538},
        keywords = {ARRAY(0x559d32c3cce0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52689/},
        abstract = {Following the success of Natural Language Processing (NLP) transformers pretrained via self-supervised learning, similar models have been proposed recently for speech processing such as Wav2Vec2, HuBERT and UniSpeech-SAT. An interesting yet unexplored area of application of these models is Spoken Dialogue Systems, where the users? audio signals are typically just mapped to word-level features derived from an Automatic Speech Recogniser (ASR), and then processed using NLP techniques to generate system responses. This paper reports a comprehensive comparison of dialogue policies trained using ASR-based transcriptions and extended with the aforementioned audio processing transformers in the DSTC2 task. Whilst our dialogue policies are trained with supervised and policy-based deep reinforcement learning, they are assessed using both automatic task completion metrics and a human evaluation. Our results reveal that using audio embeddings is more beneficial than detrimental in most of our trained dialogue policies, and that the benefits are stronger for supervised learning than reinforcement learning.}
}

@article{lincoln53298,
          volume = {14},
          number = {22},
           month = {November},
          author = {Mohamad Al Al Mdfaa and Geesara Kulathunga and Alexandr Klimchik},
           title = {3D-SiamMask: Vision-Based Multi-Rotor Aerial-Vehicle Tracking for a Moving Object},
       publisher = {MDPI},
            year = {2022},
         journal = {Remote Sensing},
             doi = {10.3390/rs14225756},
           pages = {5756},
        keywords = {ARRAY(0x559d326855d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53298/},
        abstract = {This paper aims to develop a multi-rotor-based visual tracker for a specified moving object. Visual object-tracking algorithms for multi-rotors are challenging due to multiple issues such as occlusion, quick camera motion, and out-of-view scenarios. Hence, algorithmic changes are required for dealing with images or video sequences obtained by multi-rotors. Therefore, we propose two approaches: a generic object tracker and a class-specific tracker. Both tracking settings require the object bounding box to be selected in the first frame. As part of the later steps, the object tracker uses the updated template set and the calibrated RGBD sensor data as inputs to track the target object using a Siamese network and a machine-learning model for depth estimation. The class-specific tracker is quite similar to the generic object tracker but has an additional auxiliary object classifier. The experimental study and validation were carried out in a robot simulation environment. The simulation environment was designed to serve multiple case scenarios using Gazebo. According to the experiment results, the class-specific object tracker performed better than the generic object tracker in terms of stability and accuracy. Experiments show that the proposed generic tracker achieves promising results on three challenging datasets. Our tracker runs at approximately 36 fps on GPU. {\copyright} 2022 by the authors.}
}

@inproceedings{lincoln52220,
       booktitle = {6th Conference on Robot Learning},
           month = {November},
           title = {Proactive slip control by learned slip model and trajectory adaptation},
          author = {Kiyanoush Nazari and Willow Mandil and Amir Ghalamzan Esfahani},
            year = {2022},
         journal = {Conference of Robot Learning},
        keywords = {ARRAY(0x559d329de670)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52220/},
        abstract = {This paper presents a novel control approach to dealing with object slip during robotic manipulative movements. Slip is a major cause of failure in many robotic grasping and manipulation tasks. Existing works increase grip force to avoid/control slip. However, this may not be feasible when (i) the robot cannot increase the gripping force? the max gripping force is already applied or (ii) in- creased force damages the grasped object, such as soft fruit. Moreover, the robot fixes the gripping force when it forms a stable grasp on the surface of an object, and changing the gripping force during real-time manipulation may not be an effective control policy. We propose a novel control approach to slip avoidance including a learned action-conditioned slip predictor and a constrained optimiser avoiding a predicted slip given a desired robot action. We show the effectiveness of the proposed trajectory adaptation method with the receding horizon controller with a series of real-robot test cases. Our experimental results show our proposed data-driven predictive controller can control slip for objects unseen in training.}
}

@inproceedings{lincoln52266,
       booktitle = {International Conference on Social Robotics (ICSR)},
           month = {October},
           title = {Causal Discovery of Dynamic Models for Predicting Human Spatial Interactions},
          author = {Luca Castri and Sariah Mghames and Marc Hanheide and Nicola Bellotto},
       publisher = {Springer},
            year = {2022},
        keywords = {ARRAY(0x559d32b27848)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52266/},
        abstract = {Exploiting robots for activities in human-shared environments, whether warehouses, shopping centres or hospitals, calls for such robots to understand the underlying physical interactions between nearby agents and objects. In particular, modelling cause-and-effect relations between the latter can help to predict unobserved human behaviours and anticipate the outcome of specific robot interventions. In this paper, we propose an application of causal discovery methods to model human-robot spatial interactions, trying to understand human behaviours from real-world sensor data in two possible scenarios: humans interacting with the environment, and humans interacting with obstacles. New methods and practical solutions are discussed to exploit, for the first time, a state-of-the-art causal discovery algorithm in some challenging human environments, with potential application in many service robotics scenarios. To demonstrate the utility of the causal models obtained from real-world datasets, we present a comparison between causal and non-causal prediction approaches. Our results show that the causal model correctly captures the underlying interactions of the considered scenarios and improves its prediction accuracy.}
}

@inproceedings{lincoln52350,
       booktitle = {Perception and Navigation for Autonomous Robotics in Unstructured and Dynamic Environments},
           month = {October},
           title = {Collection and Evaluation of a Long-Term 4D Agri-Robotic Dataset},
          author = {Riccardo Polvara and Sergio Molina Mellado and Ibrahim Hroob and Grzegorz Cielniak and Marc Hanheide},
            year = {2022},
             doi = {10.5281/zenodo.7135175},
        keywords = {ARRAY(0x559d32c6f158)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52350/},
        abstract = {Long-term autonomy is one of the most demanded capabilities looked into a robot. The possibility to perform the same task over and over on a long temporal horizon, offering a high standard of reproducibility and robustness, is appealing. Long-term autonomy can play a crucial role in the adoption of robotics systems for precision agriculture, for example in assisting humans in monitoring and harvesting crops in a large orchard. With this scope in mind, we report an ongoing effort in the long-term deployment of an autonomous mobile robot in a vineyard for data collection across multiple months. The main aim is to collect data from the same area at different points in time so to be able to analyse the impact of the environmental changes in the mapping and localisation tasks.
In this work, we present a map-based localisation study taking 4 data sessions. We identify expected failures when the pre-built map visually differs from the environment's current appearance and we anticipate LTS-Net, a solution pointed at extracting stable temporal features for improving long-term 4D localisation results.}
}

@article{lincoln52212,
           month = {October},
           title = {Multi-agent task allocation for harvest management},
          author = {Helen Harman and Elizabeth Sklar},
       publisher = {Frontiers},
            year = {2022},
             doi = {10.3389/frobt.2022.864745},
         journal = {Frontiers in Robotics and AI},
        keywords = {ARRAY(0x559d329bb820)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52212/},
        abstract = {Multi-agent task allocation methods seek to distribute a set of tasks fairly amongst a set of agents. In real-world settings, such as soft fruit farms, human labourers undertake harvesting tasks. The harvesting workforce is typically organised by farm manager(s) who assign workers to the fields that are ready to be harvested and team leaders who manage the workers in the fields. Creating these assignments is a dynamic and complex problem, as the skill of the workforce and the yield (quantity of ripe fruit picked) are variable and not entirely predictable. The work presented here posits that multi-agent task allocation methods can assist farm managers and team leaders to manage the harvesting workforce effectively and efficiently. There are three key challenges faced when adapting multi-agent approaches to this problem: (i) staff time (and thus cost) should be minimised; (ii) tasks must be distributed fairly to keep staff motivated; and (iii) the approach must be able to handle incremental (incomplete) data as the season progresses. An adapted variation of Round Robin (RR) is proposed for the problem of assigning workers to fields, and market-based task allocation mechanisms are applied to the challenge of assigning tasks to workers within the fields. To evaluate the approach introduced here, experiments are performed based on data that was supplied by a large commercial soft fruit farm for the past two harvesting seasons. The results demonstrate that our approach produces appropriate worker-to-field allocations. Moreover, simulated experiments demonstrate that there is a ?sweet spot? with respect to the ratio between two types of in-field workers.}
}

@inproceedings{lincoln52845,
       booktitle = {2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {October},
           title = {Elevation State-Space: Surfel-Based Navigation in Uneven Environments for Mobile Robots},
          author = {Fetullah Atas and Grzegorz Cielniak and Grimstad Lars},
       publisher = {IEEE},
            year = {2022},
        keywords = {ARRAY(0x559d32c5fc00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52845/},
        abstract = {This paper introduces a new method for robot motion planning and navigation in uneven environments through a surfel representation of underlying point clouds. The proposed method addresses the shortcomings of state-of-the-art navigation methods by incorporating both kinematic and physical constraints of a robot with standard motion planning algorithms (e.g., those from the Open Motion Planning Library), thus enabling efficient sampling-based planners for challenging uneven terrain navigation on raw point cloud maps. Unlike techniques based on Digital Elevation Maps (DEMs), our novel surfel-based state-space formulation and implementation are based on raw point cloud maps, allowing for the modeling of overlapping surfaces such as bridges, piers, and tunnels. Experimental results demonstrate the robustness of the proposed method for robot navigation in real and simulated unstructured environments. The proposed approach also optimizes planners' performances by boosting their success rates up to 5x for challenging unstructured terrain planning and navigation, thanks to our surfel-based approach's robot constraint-aware sampling strategy. Finally, we provide an open-source implementation of the proposed method to benefit the robotics community.}
}

@inproceedings{lincoln50442,
           month = {October},
          author = {Abdalkarim Mohtasib and Gerhard Neumann and Heriberto Cuayahuitl},
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           title = {Robot Policy Learning from Demonstration Using Advantage Weighting and Early Termination},
       publisher = {IEEE},
             doi = {10.1109/IROS47612.2022.9981056},
           pages = {7414--7420},
            year = {2022},
        keywords = {ARRAY(0x559d32b047b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50442/},
        abstract = {Learning robotic tasks in the real world is still highly challenging and effective practical solutions remain to be found. Traditional methods used in this area are imitation learning and reinforcement learning, but they both have limitations when applied to real robots. Combining reinforcement learning with pre-collected demonstrations is a promising approach that can help in learning control policies to solve robotic tasks. In this paper, we propose an algorithm that uses novel techniques to leverage offline expert data using offline and online training to obtain faster convergence and improved performance. The proposed algorithm (AWET) weights the critic losses with a novel agent advantage weight to improve over the expert data. In addition, AWET makes use of an automatic early termination technique to stop and discard policy rollouts that are not similar to expert trajectories---to prevent drifting far from the expert data. In an ablation study, AWET showed improved and promising performance when compared to state-of-the-art baselines on four standard robotic tasks.}
}

@article{lincoln52098,
          volume = {9},
           month = {October},
          author = {Manu Harikrishnan Nair and Mini Chrakravarthini Rai and Mithun Poozhiyil},
           title = {Design Engineering a Walking Robotic Manipulator for In-Space Assembly Missions},
       publisher = {Frontiers Media},
            year = {2022},
         journal = {Frontiers in Robotics and AI},
             doi = {10.3389/frobt.2022.995813},
           pages = {995813},
        keywords = {ARRAY(0x559d32b36098)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52098/},
        abstract = {In-Space Services aim to introduce sustainable futuristic technology to support the current and growing orbital ecosystem. As the scale of space missions grows, there is a need for more extensive infrastructures in orbit. In-Space Assembly missions would hold one of the key responsibilities in meeting the increasing demand. In the forthcoming decades, newer infrastructures in the Earth?s orbits, which are much more advanced than the International Space Station are needed for in-situ manufacturing, servicing, and astronomical and observational stations. The prospect of in-orbit commissioning a Large Aperture Space Telescope (LAST) has fuelled scientific and commercial interests in deep-space astronomy and Earth Observation. However, the in-situ assembly of such large-scale, high-value assets in extreme environments, like space, is highly challenging and requires advanced robotic solutions. This paper introduces an innovative dexterous walking robotic system for in-orbit assembly missions and considers the Large Aperture Space
Telescope system with an aperture of 25m as the use case. The top-level assembly requirements are identified with a deep insight into the critical functionalities and challenges to overcome while assembling the modular LAST. The design and sizing of an End-over-end Walking Robot (E-Walker) are discussed based on the design of the LAST and the specifications of the spacecraft platform. The E-Walker?s detailed design engineering includes the structural finite element analysis results for space and earth-analogue design and the corresponding actuator selection methods. Results of the modal analysis demonstrate the deflections in the E-Walker links and end-effector in the open-loop due to the extremities present in the space environment. The design and structural analysis of E-Walker?s scaled-down prototype is also presented to showcase its feasibility in supporting both in-orbit and terrestrial activities requiring robotic capabilities over an enhanced workspace. Further, the mission concept of operations is presented based on two E-Walkers that carry out the assembly of the mirror modules. The mission discussed was shortlisted after conducting an extensive trade-off study in the literature. Simulated results prove the dual E-Walker robotic system?s efficacy for accomplishing complex in-situ assembly operations through task-sharing.}
}

@article{lincoln52159,
           month = {October},
           title = {Unfreezing autonomous vehicles with game theory, proxemics, and trust},
          author = {Fanta Camara and Charles Fox},
       publisher = {Frontiers Media},
            year = {2022},
             doi = {10.3389/fcomp.2022.969194},
         journal = {Frontiers in Computer Science},
        keywords = {ARRAY(0x559d329dbde8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52159/},
        abstract = {Recent years have witnessed the rapid deployment of robotic systems in
public places such as roads, pavements, workplaces and care homes. Robot
navigation in environments with static objects is largely solved, but navigating
around humans in dynamic environments remains an active research question
for autonomous vehicles (AVs). To navigate in human social spaces, self-driving
cars and other robots must also show social intelligence. This involves
predicting and planning around pedestrians, understanding their personal
space, and establishing trust with them. Most current AVs, for legal and
safety reasons, consider pedestrians to be obstacles, so these AVs always
stop for or replan to drive around them. But this highly safe nature may lead
pedestrians to take advantage over them and slow their progress, even to a
complete halt. We provide a review of our recent research on predicting and
controlling human?AV interactions, which combines game theory, proxemics
and trust, and uni?es these ?elds via quantitative, probabilistic models and
robot controllers, to solve this ?freezing robot? problem.}
}

@inproceedings{lincoln50057,
           month = {October},
          author = {Helen Harman and Elizabeth Sklar},
       booktitle = {Advances in Practical Applications of Agents, Multi-Agent Systems, and Complex Systems Simulation. The PAAMS Collection},
           title = {Multi-Agent Task Allocation Techniques for Harvest Team Formation},
       publisher = {Springer},
             doi = {10.1007/978-3-031-18192-4\_18},
           pages = {217--228},
            year = {2022},
        keywords = {ARRAY(0x559d329b6f08)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50057/},
        abstract = {With increasing demands for soft fruit and shortages of seasonal workers, farms are seeking innovative solutions for efficiently managing their workforce. The harvesting workforce is typically organised by farm managers who assign workers to the fields that are ready to be harvested. They aim to minimise staff time (and costs) and distribute work fairly, whilst still picking all ripe fruit within the fields that need to be harvested. This paper posits that this problem can be addressed using multi-criteria, multi-agent task allocation techniques. The work presented compares the application of Genetic Algorithms (GAs) vs auction-based approaches to the challenge of assigning workers with various skill sets to fields with various estimated yields. These approaches are evaluated alongside a previously suggested method and the teams that were manually created by a farm manager during the 2021 harvesting season. Results indicate that the GA approach produces more efficient team allocations than the alternatives assessed.}
}

@unpublished{lincoln50259,
       booktitle = {4th International Conference on�Control and Robotics (ICCR 2022)},
           month = {October},
           title = {Peduncle Gripping and Cutting Force for Strawberry Harvesting Robotic end-effector Design},
          author = {Rajendran Sugathakumary Vishnu and Soran Parsa and Simon Parsons and Amir Ghalamzan Esfahani},
            year = {2022},
         journal = {4th International Conference on Control and Robotics (ICCR 2022)},
        keywords = {ARRAY(0x559d32b5c8c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50259/},
        abstract = {Robotic harvesting of strawberries has gained much interest in the recent past. Although there are many innovations, they haven?t yet reached a level that is comparable to an expert human picker. The end effector unit plays a major role in defining the efficiency of such a robotic harvesting system. Even though there are reports on various end effectors for strawberry harvesting, but there they lack a picture of certain parameters that the researchers can rely upon to develop new end effectors. These parameters include the limit of gripping force that can be applied on the peduncle for effective gripping, the force required to cut the strawberry peduncle, etc. These estimations would be helpful in the design cycle of the end effectors that target to grip and cut the strawberry peduncle during the harvesting action. This paper studies the estimation and analysis of these parameters experimentally. It has been estimated that the peduncle gripping force can be limited to 10 N. This enables an end effector to grip a strawberry of mass up to 50 grams with a manipulation acceleration of 50 m/s2 without squeezing the peduncle. The study on peduncle cutting force reveals that a force of 15 N is sufficient to cut strawberry peduncle using a blade with a wedge angle of 16.60 at 300 orientation.}
}

@inproceedings{lincoln52805,
           month = {September},
          author = {Hao Luan and Mu Hua and Jigen Peng and Shigang Yue and Shengyong Chen and Qinbing Fu},
       booktitle = {2022 International Joint Conference on Neural Networks (IJCNN)},
           title = {Accelerating Motion Perception Model Mimics the Visual Neuronal Ensemble of Crab},
       publisher = {IEEE},
             doi = {10.1109/IJCNN55064.2022.9892540},
           pages = {1--8},
            year = {2022},
        keywords = {ARRAY(0x559d32c5a0b0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52805/},
        abstract = {In nature, crabs have a panoramic vision for the localization and perception of accelerating motion from local segments to global view in order to guide reactive behaviours including escape. The visual neuronal ensemble in crab plays crucial roles in such capability, however, has never been investigated and modelled as an artificial vision system. To bridge this gap, we propose an accelerating motion perception model (AMPM) mimicking the visual neuronal ensemble in crab. The AMPM includes two main parts, wherein the pre-synaptic network from the previous modelling work simulates 16 MLG1 neurons covering the entire view to localize moving objects. The emphasis herein is laid on the original modelling of MLG1s? post-synaptic network to perceive accelerating motions from a global view, which employs a novel spatial-temporal difference encoder (STDE), and an adaptive spiking threshold temporal difference encoder (AT-TDE). Specifically, the STDE transforms ?time-to-travel? between activations of two successive segments of MLG1 into excitatory post-synaptic current (EPSC), which decays with the elapse of time. The AT-TDE in two directional, i.e., counter-clockwise and clockwise accelerating detectors guarantees ?non-firing? to con-stant movements. Accordingly, the accelerating motion can be effectively localized and perceived by the whole network. The systematic experiments verified the feasibility and robustness of the proposed method. The model responses to translational accelerating motion also fit many of the explored physiological features of direction selective neurons in the lobula complex of crab (i.e. lobula complex direction cells, LCDCs). This modelling study not only provides a reasonable hypothesis for such biological neural pathways, but is also critical for developing a new neuromorphic sensor strategy.}
}

@inproceedings{lincoln49463,
       booktitle = {Model Based Space Systems and Software Engineering MBSE2021},
           month = {September},
           title = {Using Semantic Systems Engineering Techniques to Verity the Large Aperture Space Telescope Mission ? Current Status},
          author = {Joe Gregory and Manu H. Nair and Gianmaria Bullegas and Mini Rai Saaj},
       publisher = {European Space Agency},
            year = {2022},
        keywords = {ARRAY(0x559d329d63c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49463/},
        abstract = {MBSE aims to integrate engineering models across tools and domain boundaries to support traditional systems engineering activities (e.g., requirements elicitation and traceability, design, analysis, verification and validation). However, MBSE does not inherently solve interoperability with the multiple model-based infrastructures involved in a complex systems engineering project. The challenge is to implement digital continuity in the three dimensions of systems engineering: across disciplines, throughout the lifecycle, and along the supply chain. Space systems are ideal candidates for the application of MBSE and semantic modelling as these complex and expensive systems are mission-critical and often co-developed by multiple stakeholders. In this paper, the authors introduce the concept of Semantic Systems Engineering (SES) as an expansion of MBSE practices to include semantic modelling through SWTs. The paper also presents the progress and status of a novel Semantic Systems Engineering Ontology (SESO) in the context of a specific design case study ? the Large Aperture Space Telescope mission.}
}

@inproceedings{lincoln50390,
       booktitle = {23rd Towards Autonomous Robotic Systems (TAROS) Conference},
           month = {September},
           title = {EMap: Real-time Terrain Estimation},
          author = {Jacobus Lock and Fanta Camara and Charles Fox},
       publisher = {Springer},
            year = {2022},
        keywords = {ARRAY(0x559d32bb8978)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50390/},
        abstract = {Terrain mapping has a many use cases in both land surveyance and autonomous vehicles.
Popular methods generate occupancy maps over 3D space, which are sub-optimal in outdoor scenarios with large, clear spaces where gaps in LiDAR readings are common.
A terrain can instead be modelled as a height map over 2D space which can iteratively be updated with incoming LiDAR data, which simplifies computation and allows missing points to be estimated based on the current terrain estimate.
The latter point is of particular interest, since it can reduce the data collection effort required (and its associated costs) and current options are not suitable to real-time operation. 
In this work, we introduce a new method that is capable of performing such terrain mapping and inferencing tasks in real-time.
We evaluate it with a set of mapping scenarios and show it is capable of generating maps with higher accuracy than an OctoMap-based method.}
}

@article{lincoln52104,
          number = {4},
           month = {September},
          author = {Gianmarco Mengaldo and Federico Renda and Steven Brunton and Moritz Bacher and Marcello Calisti and Christian Duriez and Gregory Chirikjian and Cecilia Laschi},
           title = {A concise guide to modelling the physics of embodied intelligence in soft robotics.},
       publisher = {Nature Research},
            year = {2022},
         journal = {Nature Reviews Physics},
             doi = {10.1038/s42254-022-00481-z},
           pages = {595--610},
        keywords = {ARRAY(0x559d3297e6f8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52104/},
        abstract = {Embodied intelligence (intelligence that requires and leverages a physical body) is a well-known paradigm in soft robotics, but its mathematical description and consequent computational modelling remain elusive, with a need for models that can be used for design and control purposes. We argue that filling this gap will enable full uptake of embodied intelligence in soft robots. We provide a concise guide to the main mathematical modelling approaches, and consequent computational modelling strategies, that can be used to describe soft robots and their physical interactions with the surrounding environment, including fluid and solid media. We aim to convey the challenges and opportunities within the context of modelling the physical interactions underpinning embodied intelligence. We emphasize that interdisciplinary work is required, especially in the context of fully coupled robot?environment interaction modelling. Promoting this dialogue across disciplines is a necessary step to further advance the field of soft robotics.}
}

@inproceedings{lincoln49154,
       booktitle = {International Computer Music Conference},
           month = {September},
           title = {Towards Open Source Hardware Robotic Woodwind: an Internal Duct Flute Player},
          author = {James Bennett and Bethan Moncur and Kyle Fogarty and Garry Clawson and Charles Fox},
       publisher = {ICMA},
            year = {2022},
        keywords = {ARRAY(0x559d32c4a6c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49154/},
        abstract = {We present the first open source hardware (OSH) design and build of an automated robotic internal duct flute player, including an artificial lung and pitch calibration system. Using a recorder as an introductory instrument, the system is designed to be as modular as possible, enabling  modification to fit further instruments across the woodwind family. Design considerations include the need to be as open to modification and accessible to as many people and instruments as possible.  The system is split into two physical modules: a blowing module and a fingering module, and three software modules: actuator control, pitch calibration and musical note processing via MIDI.
The system is able to perform beginner level recorder player melodies.}
}

@inproceedings{lincoln49153,
       booktitle = {International Computer Music Conference},
           month = {September},
           title = {RhythmTrain: making rhythmic sight reading training fun},
          author = {Reece Godfrey and Matthew Rimmer and Chris Headleand and Charles Fox},
       publisher = {ICMA},
            year = {2022},
        keywords = {ARRAY(0x559d329e5970)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49153/},
        abstract = {Rhythmic sight-reading forms a barrier to many musicians' progress. It is difficult to practice in isolation, as it is hard to get feedback on accuracy.  Different performers have different starting skills in different styles so it is hard to create a general curriculum for study.  It can be boring to rehearse the same rhythms many times.   We examine theories of motivation, engagement, and fun, and draw them together to design a novel training system, RhythmTrain.   This includes consideration of dynamic difficultly, gamification and juicy design.  The system uses machine learning to learn individual performers' strengths, weaknesses, and interests, and optimises the selection of rhythms presented to maximise their engagement.  An open source implementation is released as part of this publication.}
}

@article{lincoln50417,
          volume = {197},
           month = {September},
          author = {Hamid Reza Karbasian and Javad Abolfazli Esfahani and Aliyu Musa Aliyu and Kyung Chun Kim},
           title = {Numerical analysis of wind turbines blade in deep dynamic stall},
       publisher = {Elsevier},
            year = {2022},
         journal = {Renewable Energy},
             doi = {10.1016/j.renene.2022.07.115},
           pages = {1094--1105},
        keywords = {ARRAY(0x559d329e62d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50417/},
        abstract = {This study numerically investigates kinematics of dynamic stall, which is a crucial matter in wind turbines. Distinct movements of the blade with the same angle of attack (AOA) profile may provoke the flow field due to their kinematic characteristics. This induction can significantly change aerodynamic loads and dynamic stall process in wind turbines. The simulation involves a 3D NACA 0012 airfoil with two distinct pure-heaving and pure-pitching motions. The flow field over this 3D airfoil was simulated using Delayed Detached Eddy Simulations (DDES). The airfoil begins to oscillate at a Reynolds number of Re = 1.35 {$\times$} 105. The given attack angle profile remains unchanged for all cases. It is shown that the flow structures differ notably between pure-heaving and pure-pitching motions, such that the pure-pitching motions induce higher drag force on the airfoil than the pure-heaving motion. Remarkably, heaving motion causes excessive turbulence in the boundary layer, and then the coherent structures seem to be more stable. Hence, pure-heaving motion contains more energetic core vortices, yielding higher lift at post-stall. In contrast to conventional studies on the dynamic stall of wind turbines, current results show that airfoils? kinematics significantly affect the load predictions during the dynamic stall phenomenon.}
}

@inproceedings{lincoln52228,
           month = {September},
          author = {Laurence Roberts-Elliott and Gautham Das and Alan Millard},
       booktitle = {Towards Autonomous Robotic Systems},
         address = {Cham},
           title = {Agent-Based Simulation of Multi-robot Soil Compaction Mapping},
       publisher = {Springer International Publishing},
            year = {2022},
             doi = {10.1007/978-3-031-15908-4\_20},
           pages = {251--265},
        keywords = {ARRAY(0x559d32b07638)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52228/},
        abstract = {Soil compaction, an increase in soil density and decrease in porosity, has a negative effect on crop yields, and damaging environmental impacts. Mapping soil compaction at a high resolution is an important step in enabling precision agriculture practices to address these issues. Autonomous ground-based robotic approaches using proximal sensing have been proposed as alternatives to time-consuming and costly manual soil sampling. Soil compaction has high spatial variance, which can be challenging to capture in a limited time window. A multi-robot system can parallelise the sampling process and reduce the overall sampling time. Multi-robot soil sampling is critically underexplored in literature, and requires selection of methods to efficiently coordinate the sampling. This paper presents a simulation of multi-agent spatial sampling, extending the Mesa agent-based simulation framework, with general applicability, but demonstrated here as a testbed for different methodologies of multi-robot soil compaction mapping. To reduce the necessary number of samples for accurate mapping, while maximising information gained per sample, a dynamic sampling strategy, informed by kriging variance from kriging interpolation of sampled soil compaction values, has been implemented. This is enhanced by task clustering and insertion heuristics for task queuing. Results from the evaluation trials show the suitability of sequential single item auctions in this highly dynamic environment, and high interpolation accuracy resulting from our dynamic sampling, with avenues for improvements in this bespoke sampling methodology in future work.}
}

@article{lincoln51719,
          volume = {36},
          number = {3},
           month = {September},
          author = {Kate Smith and Marc Hanheide},
           title = {Future leaders in agri?food robotics},
       publisher = {Wiley},
            year = {2022},
         journal = {Food Science and Technology},
             doi = {10.1002/fsat.3603\_15.x},
           pages = {62--65},
        keywords = {ARRAY(0x559d32735b20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/51719/},
        abstract = {The AgriFoRwArdS EPSRC Centre for Doctoral Training1 (CDT) is at the fore of nurturing and developing the next cohort of experts in the agri-food robotics sector.

The Centre, established by the University of Lincoln in collaboration with the University of Cambridge and the University of East Anglia and funded by UKRI's Engineering and Physical Sciences Research Council, is providing fully funded opportunities for 50 students to undertake their PhD studies and become the next leaders in the agri-food robotics community.

Through collaboration with industry partners and utilising the expertise of the three partner organisations, the AgriFoRwArdS CDT aims to ensure that its work, and that of its students, helps transform agri-food robotics and the wider food production industry.}
}

@inproceedings{lincoln52230,
           month = {September},
          author = {Ni Wang and Gautham Das and Alan Millard},
       booktitle = {Towards Autonomous Robotic Systems},
         address = {Cham},
           title = {Learning Cooperative Behaviours in Adversarial Multi-agent Systems},
       publisher = {Springer International Publishing},
            year = {2022},
             doi = {10.1007/978-3-031-15908-4\_15},
           pages = {179--189},
        keywords = {ARRAY(0x559d329781e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52230/},
        abstract = {This work extends an existing virtual multi-agent platform called RoboSumo to create TripleSumo---a platform for investigating multi-agent cooperative behaviors in continuous action spaces, with physical contact in an adversarial environment. In this paper we investigate a scenario in which two agents, namely `Bug' and `Ant', must team up and push another agent `Spider' out of the arena. To tackle this goal, the newly added agent `Bug' is trained during an ongoing match between `Ant' and `Spider'. `Bug' must develop awareness of the other agents' actions, infer the strategy of both sides, and eventually learn an action policy to cooperate. The reinforcement learning algorithm Deep Deterministic Policy Gradient (DDPG) is implemented with a hybrid reward structure combining dense and sparse rewards. The cooperative behavior is quantitatively evaluated by the mean probability of winning the match and mean number of steps needed to win.}
}

@article{lincoln52277,
          volume = {33},
           month = {September},
          author = {Nabeel Ali Khan and Mokhtar Mohammadi and Mubeen Ghafoor and Syed Ali Tariq},
           title = {Convolutional Neural Networks Based Time-Frequency Image Enhancement For the Analysis of EEG Signals},
       publisher = {Springer},
            year = {2022},
         journal = {Multidimensional Systems and Signal Processing},
             doi = {10.1007/s11045-022-00822-2},
           pages = {863--877},
        keywords = {ARRAY(0x559d32b68908)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52277/},
        abstract = {Quadratic time-frequency (TF) methods are commonly used for the analysis, modeling, and classification of time-varying non-stationary electroencephalogram (EEG) signals. Commonly employed TF methods suffer from an inherent tradeoff between cross-term suppression and preservation of auto-terms. In this paper, we propose a new convolutional neural network (CNN) based approach to enhancing TF images. The proposed method trains a CNN using the Wigner-Ville distribution as the input image and the ideal time-frequency distribution with the total concentration of signal energy along the IF curves as the output image. The results show significant improvement compared to the other state-of-the-art TF enhancement methods. The codes for reproducing the results can be accessed on the GitHub via https://github.com/nabeelalikhan1/CNN-based-TF-image-enhancement.}
}

@article{lincoln49681,
          volume = {4},
          number = {5},
           month = {August},
          author = {Katherine Margaret Frances James and Daniel James Sargent and Adam Whitehouse and Grzegorz Cielniak},
           title = {High-throughput phenotyping for breeding targets - Current status and future directions of strawberry trait automation},
       publisher = {Wiley},
            year = {2022},
         journal = {Plants, People, Planet},
             doi = {10.1002/ppp3.10275},
           pages = {432--443},
        keywords = {ARRAY(0x559d32b56710)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49681/},
        abstract = {Automated image-based phenotyping has become widely accepted in crop phenotyping, particularly in cereal crops, yet few traits used by breeders in the strawberry industry have been automated. Early phenotypic assessment remains largely qualitative in this area since the manual phenotyping process is laborious and domain experts are constrained by time. Precision agriculture, facilitated by robotic technologies, is increasing in the strawberry industry, and the development of quantitative automated phenotyping methods is essential to ensure that breeding programs remain economically competitive. In this review, we investigate the external morphological traits relevant to the breeding of strawberries that have been automated and assess the potential for automation of traits that are still evaluated manually, highlighting challenges and limitations of the approaches used, particularly when applying high-throughput strawberry phenotyping in real-world environmental conditions.}
}

@inproceedings{lincoln52846,
       booktitle = {2022 15th International Conference on Human System Interaction (HSI)},
           month = {August},
           title = {Towards Safety in Open-field Agricultural Robotic Applications: A Method for Human Risk Assessment using Classifiers},
          author = {C. Mayoral Mayoral and Lars Grimstad and P{\r a}l J. From and Grzegorz Cielniak},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/HSI55341.2022.9869472},
        keywords = {ARRAY(0x559d32a09768)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52846/},
        abstract = {Tractors and heavy machinery have been used for decades to improve the quality and overall agriculture production. Moreover, agriculture is becoming a trend domain for robotics, and as a consequence, the efforts towards automatizing agricultural task increases year by year. However, for autonomous applications, accident prevention is of prior importance for warrantying human safety during operation in any scenario. This paper rephrases human safety as a classification problem using a custom distance criterion where each detected human gets a risk level classification. We propose the use of a neural network trained to detect and classify humans in the scene according to these criteria. The proposed approach learns from real-world data corresponding to an open-field scenario and is assessed with a custom risk assessment method.}
}

@inproceedings{lincoln49872,
       booktitle = {31st IEEE International Conference on Robot \& Human Interactive Communication},
           month = {August},
           title = {Extending Quantitative Proxemics and Trust to HRI},
          author = {Fanta Camara and Charles Fox},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/RO-MAN53752.2022.9900821},
        keywords = {ARRAY(0x559d32c2db18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49872/},
        abstract = {Human-robot interaction (HRI) requires quantitative models of proxemics and trust for robots to use in negotiating with people for space. Hall?s theory of proxemics has been used for decades to describe social interaction distances but has lacked detailed quantitative models and generative explanations to apply to these cases. In the limited case of 
 autonomous vehicle interactions with pedestrians crossing a road, a recent model has explained the quantitative sizes of Hall?s distances to 4\% error and their links to the concept of trust in human interactions. The present study extends this model by generalising several of its assumptions to cover further cases including human-human and human-robot interactions. It tightens the explanations of Hall zones from 4\% to 1\% error and fits several more recent empirical HRI results. This may help to further unify these disparate fields and quantify them to a level which enables real-world operational HRI applications.}
}

@inproceedings{lincoln50385,
       booktitle = {The 5th UK Robotics and Autonomous Systems Conference},
           month = {August},
           title = {Blockchain Crop Assurance and Localisation},
          author = {Garry Clawson and Charles Fox},
       publisher = {UKRAS},
            year = {2022},
        keywords = {ARRAY(0x559d32b32cf0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50385/},
        abstract = {Food supply chain assurance should begin in the field with regular per-plant re-identification and logging.  This is challenging due to localisation and storage requirements. A proof-of-concept solution is provided, using an image-based, super-GNSS precision, robotic localisation per-plant re-identification technique with decentralised storage and blockchain technology. ORB descriptors and RANSAC are used to align in-field stones to previously captured stone images for localisation. Blockchain smart contracts act as a data broker for repeated update and retrieval of an image from a distributed file share system. Results suggest that localisation can be achieved to sub 100mm within a time window of 18 seconds. The implementation is open source and available at: {$\backslash$}url\{https://github.com/garry-clawson/Blockchain-Crop-Assurance-and-Localisation\}}
}

@inproceedings{lincoln53105,
           month = {August},
          author = {Madeleine Darbyshire and Adrian Salazar-Gomez and Callum Lennox and Junfeng Gao and Elizabeth Sklar and Simon Parsons},
       booktitle = {UKRAS22 Conference ?Robotics for Unconstrained Environments?},
           title = {Localising Weeds Using a Prototype Weed Sprayer},
       publisher = {UK-RAS Network},
             doi = {10.31256/Ua7Pr2W},
           pages = {12--13},
            year = {2022},
        keywords = {ARRAY(0x559d32c05918)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53105/},
        abstract = {The application of convolutional neural networks (CNNs) to challenging visual recognition tasks has been shown to be highly effective and robust compared to traditional machine vision techniques. The recent development of small, powerful GPUs has enabled embedded systems to incorporate real-time, CNN-based, visual inference. Agriculture is a domain where this technology could be hugely advantageous. One such application within agriculture is precision spraying where only weeds are targeted with herbicide. This approach promises weed control with significant economic and environmental benefits from re- duced herbicide usage. While existing research has validated that CNN-based vision methods can accurately discern between weeds and crops, this paper explores how such detections can be used to actuate a prototype precision sprayer that incorporates a CNN- based weed detection system and validates spraying performance in a simplified scenario.}
}

@article{lincoln50550,
           month = {August},
           title = {Trustworthy UAV relationships: Applying the Schema Action World taxonomy to UAVs and UAV swarm operations},
          author = {Katie J. Parnell and Joel Fischer and Jed Clark and Adrian Bodenman and Maria J. Galvez Trigo and Mario P. Brito and Mohammad Divband Soorati and Katherine Plant and Sarvapali Ramchurn},
       publisher = {Taylor and Francis},
            year = {2022},
             doi = {10.1080/10447318.2022.2108961},
         journal = {International Journal of Human?Computer Interaction},
        keywords = {ARRAY(0x559d32b36a10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50550/},
        abstract = {Human Factors play a significant role in the development and integration of avionic systems to ensure that they are trusted and can be used effectively. As Unoccupied Aerial Vehicle (UAV) technology becomes increasingly important to the aviation domain this holds true. The study presented in this paper aims to gain an understanding of UAV operators? trust requirements when piloting UAVs by utilising a popular aviation interview methodology (Schema World Action Research Method), in combination with key questions on trust identified from the literature. Interviews were conducted with six UAV operators, with a range of experience, to identify the trust requirements that UAV operators hold and their views on how UAV swarms may alter the trust relationship between the operator and the UAV technology. Both methodological and practical contributions of the research interviews are discussed.}
}

@article{lincoln52106,
          volume = {5},
           month = {August},
          author = {Barbara Mazzolai and Alessio Mondini and Emanuela Del Dottore and Laura Margheri and Koichi Suzumori and Matteo Cianchetti and Thomas Speck and Stoyan Smoukov and Ingo Burget and Tobias Keplinger and Gilberto De Freitas Siqueira and Felix Vanneste and Olivier Goury and Christian Duriez and Thrishantha Nanayakkara and Bram Vanderborght and Joost Brancart and Seppe Terryn and Steven Rich and Ruiyuan Liu and Kenjiro Fukuda and Takao Someya and Marcello Calisti and Cecilia Laschi and Wenguang Sun and Gang Wang and Li Wen and Robert Baines and Patiballa Kalyan Sree and Rebecca Kramer-Bottiglio and Daniela Rus and Peer Fischer and Friedrich Simmel and Andreas Lendlein},
           title = {Roadmap on soft robotics: multifunctionality, adaptability and growth without borders},
       publisher = {IOP Publishing},
            year = {2022},
         journal = {Multifunctional Materials},
             doi = {10.1088/2399-7532/ac4c95},
           pages = {032001},
        keywords = {ARRAY(0x559d32b47668)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52106/},
        abstract = {Soft robotics aims at creating systems with improved performance of movement and adaptability in unknown, challenging, environments and with higher level of safety during interactions with humans. This Roadmap on Soft Robotics covers selected aspects for the design of soft robots significantly linked to the area of multifunctional materials, as these are considered a fundamental component in the design of soft robots for an improvement of their peculiar abilities, such as morphing, adaptivity and growth. The roadmap includes different approaches for components and systems design, bioinspired materials, methodologies for building soft robots, strategies for the implementation and control of their functionalities and behavior, and examples of soft-bodied systems showing abilities across different environments. For each covered topic, the author(s) describe the current status and research directions, current and future challenges, and perspective advances in science and technology to meet the challenges.}
}

@inproceedings{lincoln50291,
           month = {July},
          author = {Iris Jestin and Joel E. Fischer and Maria J. Galvez Trigo and David R. Large and Gary E. Burnett},
       booktitle = {CUI ?22: Conversational User Interfaces Conference},
           title = {Effects of Wording and Gendered Voices on Acceptability of Voice Assistants in Future Autonomous Vehicles},
       publisher = {ACM},
             doi = {10.1145/3543829.3543836},
           pages = {1--11},
            year = {2022},
        keywords = {ARRAY(0x559d32c18350)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50291/},
        abstract = {Voice assistants in future autonomous vehicles may play a major role in supporting the driver during periods of a transfer of control with the vehicle (handover and handback). However, little is known about the effects of different qualities of the voice assistant on its perceived acceptability, and thus its potential to support the driver?s trust in the vehicle. A desktop study was carried out with 18 participants, investigating the effects of three gendered voices and different wording of prompts during handover and handback driving scenarios on measures of acceptability. Participants rated prompts by the voice assistant in nine different driving scenarios, using 5-point Likert style items in a during and post-study questionnaire as well as a short interview at the end. A commanding/formally worded prompt was rated higher on most of the desirable measures of acceptability as compared to an informally worded prompt. The ?Matthew? voice used was perceived to be less artificial and more desirable than the ?Joanna? voice and the gender-ambiguous ?Jordan? voice; however, we caution against interpreting these results as indicative of a general preference of gender, and instead discuss our results to throw light on the complex socio-phonetic nature of voices (including gender) and wording of voice assistants, and the need for careful consideration while designing the same. Results gained facilitate the drawing of insights needed to take better care when designing the voice and wording for voice assistants in future autonomous vehicles.}
}

@inproceedings{lincoln49936,
       booktitle = {11th International Conference on Biomimetic and Biohybrid Systems (Living Machines)},
           month = {July},
           title = {Scaling a hippocampus model with GPU parallelisation and test-driven refactoring},
          author = {Jack Stevenson and Charles Fox},
       publisher = {Springer LNCS},
            year = {2022},
        keywords = {ARRAY(0x559d32983198)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49936/},
        abstract = {The hippocampus is the brain area used for localisation,  mapping and episodic memory.  Humans and animals can outperform robotic systems in these tasks, so functional models of hippocampus may be useful to improve robotic navigation, such as for self-driving cars. 
Previous work developed a biologically plausible model of hippocampus based on Unitary Coherent Particle Filter (UCPF) and Temporal Restricted Boltzmann Machine, which was able to learn to navigate around small test environments.  However it was implemented in serial software, which becomes very slow as the environments and numbers of neurons scale up.  Modern GPUs can parallelize execution of neural networks. 
 The present Neural Software Engineering study develops a GPU accelerated version of the UCPF hippocampus software, using the formal Software Engineering techniques of profiling, optimisation and test-driven refactoring.  Results show that the model can greatly benefit from parallel execution, which may enable it to scale from toy environments and applications to real-world ones such as self-driving car navigation.   The refactored parallel code is released to the community as open source software as part of this publication.}
}

@inproceedings{lincoln52095,
       booktitle = {International Conference on Space Robotics and Automation},
           month = {July},
           title = {Ta-DAH: Task Driven Automated Hardware Design of Free-Flying Space Robots},
          author = {Lucy Elaine Jackson and Celyn Walters and Steve Eckersley and Mini Rai and Simon Hadfield},
       publisher = {World Academy of Science Engineering and Technology},
            year = {2022},
        keywords = {ARRAY(0x559d32a18868)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52095/},
        abstract = {Space robots will play an integral part in exploring the universe and beyond. A correctly designed space robot will
facilitate OOA, satellite servicing and ADR. However, problems arise when trying to design such a system as it is a highly complex multidimensional problem into which there is little research. Current design techniques are slow and specific to terrestrial manipulators. This paper presents a solution to the slow speed of robotic hardware design, and generalizes the technique to free-flying space robots. It presents Ta-DAH Design, an automated design approach that utilises a multi-objective cost function in an iterative and automated pipeline. The design approach leverages prior knowledge and facilitates the faster output of optimal designs. The result is a system that can optimise the size of the base spacecraft, manipulator and some key subsystems for any given task. Presented in this work is the methodology behind Ta-DAH Design and a number optimal space robot designs.}
}

@inproceedings{lincoln48682,
       booktitle = {2022 IEEE International Conference on Robotics and Automation (ICRA)},
           month = {July},
           title = {Self-supervised Representation Learning for Reliable Robotic Monitoring of Fruit Anomalies},
          author = {Taeyeong Choi and Owen Would and Adrian Salazar-Gomez and Grzegorz Cielniak},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/ICRA46639.2022.9811954},
        keywords = {ARRAY(0x559d32c391e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48682/},
        abstract = {Data augmentation can be a simple yet powerful tool for autonomous robots to fully utilise available data for self-supervised
identification of atypical scenes or objects. State-of-the-art augmentation methods arbitrarily embed "structural" peculiarity on typical images so that classifying these artefacts can provide guidance for learning representations for the detection of anomalous visual signals. In this paper, however, we argue that learning such structure-sensitive representations can be a suboptimal approach to some classes of anomaly (e.g., unhealthy fruits) which could be better recognised by a different type of visual element such as "colour". We thus propose Channel Randomisation as a novel data augmentation method for restricting neural networks to learn encoding of "colour irregularity" whilst predicting channel-randomised images to ultimately build reliable fruit-monitoring robots identifying atypical fruit qualities. Our experiments show that (1) this colour-based alternative can better learn representations for consistently accurate identification of fruit anomalies in various fruit species, and also, (2) unlike other methods, the validation accuracy can be utilised as a criterion for early stopping of training in practice due to positive correlation between the performance in the self-supervised colour-differentiation task and the subsequent detection rate of actual anomalous fruits. Also, the proposed approach is evaluated on a new agricultural dataset, Riseholme-2021, consisting of 3.5K strawberry images gathered by a mobile robot, which we share online to encourage active agri-robotics research.}
}

@article{lincoln50054,
           month = {July},
           title = {A survey on deep reinforcement learning for audio?based applications},
          author = {Siddique Latif and Heriberto Cuayahuitl and Farrukh Pervez and Fahad Shamshad and Hafiz Shehbaz Ali and Erik Cambria},
       publisher = {Springer Nature B.V.},
            year = {2022},
             doi = {10.1007/s10462-022-10224-2},
         journal = {Artifcial Intelligence Review},
        keywords = {ARRAY(0x559d3298def8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50054/},
        abstract = {Deep reinforcement learning (DRL) is poised to revolutionise the field of artificial intelligence (AI) by endowing autonomous systems with high levels of understanding of the real world. Currently, deep learning (DL) is enabling DRL to effectively solve various intractable problems in various fields including computer vision, natural language processing, healthcare, robotics, to name a few. Most importantly, DRL algorithms are also being employed in audio signal processing to learn directly from speech, music and other sound signals in order to create audio-based autonomous systems that have many promising applications in the real world. In this article, we conduct a comprehensive survey on the progress of DRL in the audio domain by bringing together research studies across different but related areas in speech and music. We begin with an introduction to the general field of DL and reinforcement learning (RL), then progress to the main DRL methods and their applications in the audio domain. We conclude by presenting important challenges faced by audio-based DRL agents and by highlighting open areas for future research and investigation. The findings of this paper will guide researchers interested in DRL for the audio domain.}
}

@inproceedings{lincoln50876,
       booktitle = {RSS Pioneers Workshop},
           month = {June},
           title = {Learning Pedestrian Social Behaviour for Game-Theoretic Self-Driving Cars},
          author = {Fanta Camara and Charles Fox},
       publisher = {RSS},
            year = {2022},
        keywords = {ARRAY(0x559d32b6d7e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50876/},
        abstract = {Robot navigation in environments with static objects appears to be a solved problem, but navigating around humans in dynamic and unstructured environments remains an active research question. This requires not only advanced path planning methods but also a good perception system, models of multi-agent interactions and realistic hardware for testing. To evolve in human social spaces, robots must also show social intelligence, i.e. the ability to understand human behaviour via explicit and implicit communication cues (e.g. proxemics) for better human-robot interactions (HRI) [28]. Similarly, autonomous vehicles (AVs), also called ?self-driving cars? that are appearing on the roads need a better understanding of pedestrians? social behaviour, especially in urban areas [26]. In particular, previous work showed that pedestrians may take advantage over autonomous vehicles [13] by intentionally and constantly stepping in front of AVs, hence preventing them from making progress on the roads. This inability of current AVs to read the intention of other road users, predict their future behaviour and interact with them is known as ?the big problem with self-driving cars? [1]. Thus, AVs need better decision-making models and must find a good balance between stopping for pedestrians when required and driving to reach their final destination as quickly as possible for their on-board passengers. A comprehensive review of existing pedestrian models for AVs, ranging from low-level sensing, detection and tracking models [9] to high-level interaction and game theoretic models of pedestrian behaviour [10], found that the lower-level models are accurate and mature enough to be deployed on AVs but more research is needed in the higher-level models. Hence, in this work, we focus on modelling, learning and operating pedestrian high-level social behaviour on self-driving cars using game theory and proxemics.}
}

@article{lincoln49926,
          volume = {28},
          number = {2},
           month = {June},
          author = {Archie Drake and Isabel Sassoon and Panos Balatsoukas and Talya Porat and Mark Ashworth and Ellen Wright and Vasa Curcin and Martin Chapman and Nadin Kokciyan and Modgil Sanjay and Elizabeth Sklar and Simon Parsons},
           title = {The relationship of socio-demographic factors and patient attitudes to connected health technologies: a survey of stroke survivors.},
       publisher = {SAGE Publications},
            year = {2022},
         journal = {Health Informatics Journal},
             doi = {10.1177\%2F14604582221102373},
        keywords = {ARRAY(0x559d32a1d578)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49926/},
        abstract = {More evidence is needed on technology implementation for remote monitoring and self-management across the various settings relevant to chronic conditions. This paper describes the findings of a survey designed to explore the relevance of socio-demographic factors to attitudes towards connected health technologies in a community of patients. Stroke survivors living in the UK were invited to answer questions about themselves and about their attitudes to a prototype remote monitoring and self-management app developed around their preferences. Eighty (80) responses were received and analysed, with limitations and results presented in full. Socio-demographic factors were not found to be associated with variations in participants? willingness to use the system and attitudes to data sharing. Individuals? levels of interest in relevant technology was suggested as a more important determinant of attitudes. These observations run against the grain of most relevant literature to date, and tend to underline the importance of prioritising patient-centred participatory research in efforts to advance connected health technologies.}
}

@incollection{lincoln49943,
           month = {June},
          author = {Amir Ghalamzan Esfahani and Gautham Das and Iain Gould and Payam Zarafshan and Vishnu Rajendran Sugathakumary and James Heselden and Amir Badiee and Isobel Wright and Simon Pearson},
       booktitle = {Solar Energy Advancements in Agriculture and Food Production Systems},
          editor = {Shiva Gorjian and Pietro Elia Campana},
           title = {Applications of robotic and solar energy in precision agriculture and smart farming},
       publisher = {Elsevier},
             doi = {10.1016/C2020-0-03304-9},
            year = {2022},
        keywords = {ARRAY(0x559d329db860)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49943/},
        abstract = {Population growth, healthy diet requirements, and changes in food demand towards a more plant-based protein diet increase existing pressures for food production and land-use change. The increasing demand and current agriculture approaches jeopardise the health of soil and biodiversity which will affect the future ecosystem and food production. One of the solutions to the increasing pressure on agriculture is PA which offers to minimize the use of resources, including land, water, energy, herbicides, and pesticides, and maximise the yield. The development of PA requires a multidisciplinary approach including engineering, AI, and robotics. Robots will play a crucial role in delivering PA and will pave the way toward sustainable healthy food production.
While PA is the way forward in the agriculture industry the related devices to collect various supporting data and also the agriculture machinery need to be run by clean energy to ensure sustainable growth in the sector. Among renewable energy sources, solar energy and solar PV have shown a great potential to dominate the future of sustainable energy and agriculture developments. For developing PV in rural and off-grid agriculture farms and lands the use of solar-powered devices is unavoidable. Such a transition to photovoltaic agriculture requires significant changes to agricultural practices and the adoption of smart technologies like IoT, robotics, and WSN.
Future food production needs to adapt to changing consumer behaviour along with the rapidly deteriorating environmental factors. PA is also a response to future food production challenges where one of its key aims is to improve sustainability to minimize the use of diminishing resources and minimize GHG emissions by use of renewable energy sources. Along with these adaptations, the new technologies should be using green energy sources (i.e., solar energy) for meeting the power requirements for sustainable developments of these smart technologies. Since there is a rapid inflow of robotic technologies into the agriculture sector, increasing power demand is inevitable, especially in remote areas where PV-based systems can play a game-changing role. It is expected for the agriculture sector to witness a technological revolution toward sustainable food production which cannot be achieved without solar PV development and support.}
}

@inproceedings{lincoln48058,
           month = {June},
          author = {Maria Galvez Trigo and Penelope Standen and Sue Cobb},
       booktitle = {HCI International Conference 2022},
           title = {Educational robots and their control interfaces: how can we make them more accessible for Special Education?},
       publisher = {Springer},
             doi = {10.1007/978-3-031-05039-8\_2},
           pages = {15--34},
            year = {2022},
        keywords = {ARRAY(0x559d32c7cec8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48058/},
        abstract = {Existing design standards and guidelines provide guidance on what factors to consider to produce interactive systems that are not only usable, but also accessible. However, these standards are usually general, and when it comes to designing an interactive system for children with Learning Difficulties or Disabilities (LD) and/or Autism Spectrum Conditions (ASC) they are often not specific enough, leading to systems that are not fit for that purpose. If we dive into the area of educational robotics, we face even more issues, in part due to the relative novelty of these technologies. In this paper, we present an analysis of 26 existing educational robots and the interfaces used to control them. Furthermore, we present the results of running focus groups and a questionnaire with 32 educators with expertise in Special Education and parents at four different institutions, to explore potential accessibility issues of existing systems and to identify desirable characteristics. We conclude introduc- ing an initial set of design recommendations, to complement existing design standards and guidelines, that would help with producing future more accessible control interfaces for educational robots, with an especial focus on helping pupils with LDs and/or ASC.}
}

@article{lincoln49874,
          volume = {136},
           month = {June},
          author = {Hamdi Yahyaoui and Zakaria Maamar and Mohammed Al-Khafajiy and Hamid Al-Hamadi},
           title = {Trust-based management in IoT federations},
       publisher = {Elsevier},
            year = {2022},
         journal = {Future Generation Computer Systems},
             doi = {10.1016/j.future.2022.06.003},
           pages = {182--192},
        keywords = {ARRAY(0x559d32c15908)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49874/},
        abstract = {This paper presents a trust-based evolutionary game model for managing Internet-of-Things (IoT) federations. The model adopts trust-based payoff to either reward or penalize things based on the behaviors they expose. The model also resorts to monitoring these behaviors to ensure that the share of untrustworthy things in a federation does not hinder the good functioning of trustworthy things in this federation. The trust scores are obtained using direct experience with things and feedback from other things and are integrated into game strategies. These strategies capture the dynamic nature of federations since the population of trustworthy versus untrustworthy things changes over time with the aim of retaining the trustworthy ones. To demonstrate the technical doability of the game strategies along with rewarding/penalizing things, a set of experiments were carried out and results were benchmarked as per the existing literature. The results show a better mitigation of attacks such as bad-mouthing and ballot-stuffing on trustworthy things.}
}

@article{lincoln49961,
          volume = {7},
          number = {3},
           month = {June},
          author = {Francesco Del Duchetto and Marc Hanheide},
           title = {Learning on the Job: Long-Term Behavioural Adaptation in Human-Robot Interactions},
       publisher = {IEEE},
            year = {2022},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2022.3178807},
           pages = {6934--6941},
        keywords = {ARRAY(0x559d32b6b248)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49961/},
        abstract = {In this work, we propose a framework for allowing autonomous robots deployed for extended periods of time in public spaces to adapt their own behaviour online from user interactions. The robot behaviour planning is embedded in a Reinforcement Learning (RL) framework, where the objective is maximising the level of overall user engagement during the interactions. We use the Upper-Confidence-Bound Value-Iteration (UCBVI) algorithm, which gives a helpful way of managing the exploration-exploitation trade-off for real-time interactions. An engagement model trained end-to-end generates the reward function in real-time during policy execution. We test this approach in a public museum in Lincoln (U.K.), where the robot is deployed as a tour guide for the visitors. Results show that after a couple of months of exploration, the robot policy learned to maintain the engagement of users for longer, with an increase of 22.8\% over the initial static policy in the number of items visited during the tour and a 30\% increase in the probability of completing the tour. This work is a promising step toward behavioural adaptation in long-term scenarios for robotics applications in social settings.}
}

@article{lincoln49800,
           month = {June},
           title = {A comparison of neural?based visual recognisers for speech activity detection},
          author = {Sajjadali Raza and Heriberto Cuayahuitl},
       publisher = {Springer},
            year = {2022},
             doi = {10.1007/s10772-021-09956-3},
         journal = {International Journal of Speech Technology},
        keywords = {ARRAY(0x559d329b3508)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49800/},
        abstract = {Existing literature on speech activity detection (SAD) highlights different approaches within neural networks but does not provide a comprehensive comparison to these methods. This is important because such neural approaches often require hardware-intensive resources. In this article, we provide a comparative analysis of three different approaches: classification with still images (CNN model), classification based on previous images (CRNN model), and classification of sequences of images (Seq2Seq model). Our experimental results using the Vid-TIMIT dataset show that the CNN model can achieve an accuracy of 97\% whereas the CRNN and Seq2Seq models increase the classification to 99\%. Further experiments show that the CRNN model is almost as accurate as the Seq2Seq model (99.1\% vs. 99.6\% of classification accuracy, respectively) but 57\% faster to train (326 vs. 761 secs. per epoch).}
}

@article{lincoln49340,
          volume = {197},
           month = {June},
          author = {Xiaodong Li and Rob Lloyd and Sarah Ward and Jonathan Cox and Shaun Coutts and Charles Fox},
           title = {Robotic crop row tracking around weeds using cereal-specific features},
       publisher = {Elsevier},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2022.106941},
            year = {2022},
        keywords = {ARRAY(0x559d32741e48)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49340/},
        abstract = {Crop row following is especially challenging in narrow row cereal crops, such as wheat. Separation between plants within a row disappears at an early growth stage, and canopy closure between rows, when leaves from different rows start to occlude each other, occurs three to four months after the crop emerges. Canopy closure makes it challenging to identify separate rows through computer vision as clear lanes become obscured. Cereal crops are grass species and so their leaves have a predictable shape and orientation. We introduce an image processing pipeline which exploits grass shape to identify and track rows. The key observation exploited is that leaf orientations tend to be vertical along rows and horizontal between rows due to the location of the stems within the rows. Adaptive mean-shift clustering on Hough line segments is then used to obtain lane centroids, and followed by a nearest neighbor data association creating lane line candidates in 2D space. Lane parameters are fit with linear regression and a Kalman filter is used for tracking lanes between frames. The method is achieves sub-50 mm accuracy which is sufficient for placing a typical agri-robot?s wheels between real-world, early-growth wheat crop rows to drive between them, as long as the crop is seeded in a wider spacing such as 180 mm row spacing for an 80 mm wheel width robot.}
}

@article{lincoln50887,
          volume = {3},
           month = {June},
          author = {Simon Pearson and Tania Carolina Camacho-Villa and Ravi Valluru and Oorbessy Gaju and Mini Rai and Iain Gould and Steve Brewer and Elizabeth Sklar},
           title = {Robotics and autonomous systems for net-zero agriculture},
       publisher = {Springer},
            year = {2022},
         journal = {Current Robotics Reports},
             doi = {10.1007/s43154-022-00077-6},
           pages = {57--64},
        keywords = {ARRAY(0x559d32b9d240)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50887/},
        abstract = {Purpose of ReviewThe paper discusses how robotics and autonomous systems (RAS) are being deployed to decarbonise agricultural production. The climate emergency cannot be ameliorated without dramatic reductions in greenhouse gas emis-sions across the agri-food sector. This review outlines the transformational role for robotics in the agri-food system and considers where research and focus might be prioritised.Recent FindingsAgri-robotic systems provide multiple emerging opportunities that facilitate the transition towards net zero agriculture. Five focus themes were identified where robotics could impact sustainable food production systems to (1) increase nitrogen use efficiency, (2) accelerate plant breeding, (3) deliver regenerative agriculture, (4) electrify robotic vehicles, (5) reduce food waste.SummaryRAS technologies create opportunities to (i) optimise the use of inputs such as fertiliser, seeds, and fuel/energy; (ii) reduce the environmental impact on soil and other natural resources; (iii) improve the efficiency and precision of agri-cultural processes and equipment; (iv) enhance farmers? decisions to improve crop care and reduce farm waste. Further and scaled research and technology development are needed to exploit these opportunities.}
}

@article{lincoln49460,
          volume = {3},
           month = {June},
          author = {Simon Pearson and Carolina Camacho?Villa and Ravi Valluru and Gaju Oorbessy and Mini Rai and Iain Gould and Steve Brewer and Elizabeth Sklar},
           title = {Robotics and Autonomous Systems for Net Zero Agriculture},
       publisher = {Springer},
            year = {2022},
         journal = {Current Robotics Reports},
             doi = {10.1007/s43154-022-00077-6},
           pages = {57--64},
        keywords = {ARRAY(0x559d32ba39a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49460/},
        abstract = {The paper discusses how robotics and autonomous systems (RAS) are being deployed to decarbonise
agricultural production. The climate emergency cannot be ameliorated without dramatic reductions in greenhouse gas emissions across the agri-food sector. This review outlines the transformational role for robotics in the agri-food system and considers where research and focus might be prioritised.}
}

@inproceedings{lincoln49183,
       booktitle = {Social Robot Navigation: Advances and Evaluation (SEANavBench 2022)},
           month = {May},
           title = {Game Theory, Proxemics and Trust for Self-Driving Car Social Navigation},
          author = {Fanta Camara and Charles Fox},
       publisher = {Social Robot Navigation: Advances and Evaluation},
            year = {2022},
        keywords = {ARRAY(0x559d32b94870)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49183/},
        abstract = {To navigate in human social spaces, self-driving cars and other robots must show social intelligence. This involves predicting and planning around pedestrians, understanding their personal space, and establishing trust with them. The present paper gives an overview of our ongoing work on modelling and controlling human?self-driving car interactions using game theory, proxemics and trust, and unifying these fields via quantitative models and robot controllers.}
}

@article{lincoln47700,
          volume = {193},
           month = {May},
          author = {Chao Qi and Junfeng Gao and Simon Pearson and Helen Harman and Kunjie Chen and Lei Shu},
           title = {Tea chrysanthemum detection under unstructured environments using the TC-YOLO model},
       publisher = {Elsevier},
         journal = {Expert Systems with Applications},
             doi = {10.1016/j.eswa.2021.116473},
            year = {2022},
        keywords = {ARRAY(0x559d32ba7140)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47700/},
        abstract = {Tea chrysanthemum detection at its flowering stage is one of the key components for selective chrysanthemum harvesting robot development. However, it is a challenge to detect flowering chrysanthemums under unstructured field environments given variations on illumination, occlusion and object scale. In this context, we propose a highly fused and lightweight deep learning architecture based on YOLO for tea chrysanthemum detection (TC-YOLO). First, in the backbone component and neck component, the method uses the Cross-Stage Partially Dense network (CSPDenseNet) and the Cross-Stage Partial ResNeXt network (CSPResNeXt) as the main networks, respectively, and embeds custom feature fusion modules to guide the gradient flow. In the final head component, the method combines the recursive feature pyramid (RFP) multiscale fusion reflow structure and the Atrous Spatial Pyramid Pool (ASPP) module with cavity convolution to achieve the detection task. The resulting model was tested on 300 field images using a data enhancement strategy combining flipping and rotation, showing that under the NVIDIA Tesla P100 GPU environment, if the inference speed is 47.23 FPS for each image (416 {$\times$} 416), TC-YOLO can achieve the average precision (AP) of 92.49\% on our own tea chrysanthemum dataset. Through further validation, it was found that overlap had the least effect on tea chrysanthemum detection, and illumination had the greatest effect on tea chrysanthemum detection. In addition, this method (13.6 M) can be deployed on a single mobile GPU, and it could be further developed as a perception system for a selective chrysanthemum harvesting robot in the future.}
}

@inproceedings{lincoln49037,
       booktitle = {The 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2022)},
           month = {May},
           title = {Multi-agent Task Allocation for Fruit Picker Team Formation (Extended Abstract)},
          author = {Helen Harman and Elizabeth Sklar},
       publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
            year = {2022},
           pages = {1618--1620},
        keywords = {ARRAY(0x559d326806c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49037/},
        abstract = {Multi-agent task allocation methods seek to distribute a set of tasks fairly amongst a set of agents. In real-world settings, such as fruit farms, human labourers undertake harvesting tasks, organised each day by farm manager(s) who assign workers to the fields that are ready to be harvested. The work presented here considers three challenges identified in the adaptation of a multi-agent task allocation methodology applied to the problem of distributing workers to fields. First, the methodology must be fast to compute so that it can be applied on a daily basis. Second, the incremental acquisition of harvesting data used to make decisions about worker-task assignments means that a data-backed approach must be derived from incomplete information as the growing season unfolds. Third, the allocation must take ?fairness? into account and consider worker motivation. Solutions to these challenges are demonstrated, showing statistically significant results based on the operations at a soft fruit farm during their 2020 and 2021 harvesting seasons.}
}

@article{lincoln49062,
          volume = {18},
          number = {4},
           month = {April},
          author = {Magd Badaoui and Pedro Buigues and Denes Berta and Guarav Mandana and Hankang Gu and Tam{\'a}s F{\"o}ldes and Callum Dickson and Viktor Hornak and Mitsunori Kato and Carla Molteni and Simon Parsons and Edina Rosta},
           title = {Combined Free-Energy Calculation and Machine Learning Methods for Understanding Ligand Unbinding Kinetics},
       publisher = {American Chemical Society},
            year = {2022},
         journal = {Journal of Chemical Theory and Computation},
             doi = {10.1021/acs.jctc.1c00924},
           pages = {2543--2555},
        keywords = {ARRAY(0x559d323650b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49062/},
        abstract = {The determination of drug residence times, which define the time an inhibitor is in complex with its
target, is a fundamental part of the drug discovery process. Synthesis and experimental
measurements of kinetic rate constants are, however, expensive, and time-consuming. In this work,
we aimed to obtain drug residence times computationally. Furthermore, we propose a novel
algorithm to identify molecular design objectives based on ligand unbinding kinetics. We designed
an enhanced sampling technique to accurately predict the free energy profiles of the ligand
unbinding process, focusing on the free energy barrier for unbinding. Our method first identifies
unbinding paths determining a corresponding set of internal coordinates (IC) that form contacts
between the protein and the ligand, it then iteratively updates these interactions during a series of
biased molecular-dynamics (MD) simulations to reveal the ICs that are important for the whole of
the unbinding process. Subsequently, we performed finite temperature string simulations to obtain
the free energy barrier for unbinding using the set of ICs as a complex reaction coordinate.
Importantly, we also aimed to enable further design of drugs focusing on improved residence 
times. To this end, we developed a supervised machine learning (ML) approach with inputs from
unbiased ?downhill? trajectories initiated near the transition state (TS) ensemble of the string
unbinding path. We demonstrate that our ML method can identify key ligand-protein interactions
driving the system through the TS. Some of the most important drugs for cancer treatment are
kinase inhibitors. One of these kinase targets is Cyclin Dependent Kinase 2 (CDK2), an appealing
target for anticancer drug development. Here, we tested our method using two different CDK2
inhibitors for potential further development of these compounds. We compared the free energy
barriers obtained from our calculations with those observed in available experimental data. We
highlighted important interactions at the distal ends of the ligands that can be targeted for
improved residence times. Our method provides a new tool to determine unbinding rates, and to
identify key structural features of the inhibitors that can be used as starting points for novel design
strategies in drug discovery.}
}

@inproceedings{lincoln53890,
           month = {April},
          author = {Zhuoling Huang and Elizabeth Sklar and Simon Parsons},
       booktitle = {HRI '20: Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction},
           title = {Design of Automatic Strawberry Harvest Robot Suitable in Complex Environments},
       publisher = {Association for Computing Machinery},
             doi = {10.1145/3371382.3377443},
           pages = {567--569},
            year = {2022},
        keywords = {ARRAY(0x559d32b27b18)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/53890/},
        abstract = {Strawberries are an important cash crop that are grown worldwide. They are also a labour-intensive crop, with harvesting a particularly labour-intensive task because the fruit needs careful handling. This project investigates collaborative human-robot strawberry harvesting, where interacting with a human potentially increases the adaptability of a robot to work in more complex environments. The project mainly concentrates on two aspects of the problem: the identification of the fruit and the picking of the fruit.}
}

@inproceedings{lincoln49117,
       booktitle = {2021 2nd International Symposium on Automation, Information and Computing (ISAIC 2021)},
           month = {April},
           title = {Temperature-based Collision Detection in Extreme Low Light Condition with Bio-inspired LGMD Neural Network},
          author = {Yicheng Zhang and Cheng Hu and Mei Liu and Hao Luan and Fang Lei and Heriberto Cuayahuitl and Shigang Yue},
       publisher = {IOP Publishing Ltd},
            year = {2022},
             doi = {10.1088/1742-6596/2224/1/012004},
        keywords = {ARRAY(0x559d32ba0948)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49117/},
        abstract = {It is an enormous challenge for intelligent vehicles to avoid collision accidents at night because of the extremely poor light conditions. Thermal cameras can capture temperature map at night, even with no light sources and are ideal for collision detection in darkness. However, how to extract collision cues efficiently and effectively from the captured temperature map with limited computing resources is still a key issue to be solved. Recently, a bio-inspired neural network LGMD has been proposed for collision detection successfully, but for daytime and visible light. Whether it can be used for temperature-based collision detection or not remains unknown. In this study, we proposed an improved LGMD-based visual neural network for temperature-based collision detection at extreme light conditions. We show in this study that the insect inspired visual neural network can pick up the expanding temperature differences of approaching objects as long as the temperature difference against its background can be captured by a thermal sensor. Our results demonstrated that the proposed LGMD neural network can detect collisions swiftly based on the thermal modality in darkness; therefore, it can be a critical collision detection algorithm for autonomous vehicles driving at night to avoid fatal collisions with humans, animals, or other vehicles.}
}

@article{lincoln46497,
           month = {April},
           title = {Robotic Exploration for Learning Human Motion Patterns},
          author = {Sergio Molina Mellado and Grzegorz Cielniak and Tom Duckett},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/TRO.2021.3101358},
         journal = {IEEE Transaction on Robotics},
        keywords = {ARRAY(0x559d32c427d0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46497/},
        abstract = {Understanding how people are likely to move is key to efficient and safe robot navigation in human environments. However, mobile robots can only observe a fraction of the environment at a time, while the activity patterns of people may also change at different times. This paper introduces a new methodology for mobile robot exploration to maximise the knowledge of human activity patterns by deciding where and when to collect observations. We introduce an exploration policy driven by the entropy levels in a spatio-temporal map of pedestrian flows, and compare multiple spatio-temporal exploration strategies including both informed and uninformed approaches. The evaluation is performed by simulating mobile robot exploration using real sensory data from three long-term pedestrian datasets. The results show that for certain scenarios the models built with proposed exploration system can better predict the flow patterns than uninformed strategies, allowing the robot to move in a more socially compliant way, and that the exploration ratio is a key factor when it comes to the model prediction accuracy.}
}

@inproceedings{lincoln50609,
           month = {April},
          author = {Soran Parsa and Horia A. Maior and Alex Reeve Elliott Thumwood and Max L Wilson and Marc Hanheide and Amir Ghalamzan Esfahani},
       booktitle = {CHI Conference on Human Factors in Computing Systems Extended Abstracts},
           title = {The Impact of Motion Scaling and Haptic Guidance on Operators? Workload and Performance in Teleoperation},
       publisher = {ACM},
             doi = {10.1145/3491101.3519814},
           pages = {1--7},
            year = {2022},
        keywords = {ARRAY(0x559d32c98b88)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50609/},
        abstract = {The use of human operator managed robotics, especially for safety critical work, includes a shift from physically demanding to mentally challenging work, and new techniques for Human-Robot Interaction are being developed to make teleoperation easier and more accurate. This study evaluates the impact of combining two teleoperation support features (i) scaling the velocity mapping of leader-follower arms (motion scaling), and (ii) haptic-feedback guided shared control (haptic guidance). We used purposely difficult peg-in-the-hole tasks requiring high precision insertion and manipulation, and obstacle avoidance, and evaluated the impact of using individual and combined support features on a) task performance and b) operator workload. As expected, long distance tasks led to higher mental workload and lower performance than short distance tasks. Our results showed that motion scaling and haptic guidance impact workload and improve performance during more difficult tasks, and we discussed this in contrast to participants preference for using different teleoperation features.}
}

@article{lincoln49488,
          volume = {9},
           month = {March},
          author = {Craig R. Carignan and Renaud Detry and Mini Rai Saaj and Giacomo Marani and Joshua D. Vander Hook},
           title = {Editorial: Robotic In-Situ Servicing, Assembly and Manufacturing},
       publisher = {Frontiers Media},
         journal = {Frontiers in Robotics and AI},
             doi = {10.3389/frobt.2022.887506},
            year = {2022},
        keywords = {ARRAY(0x559d32ca2320)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49488/},
        abstract = {This research topic is dedicated to articles focused on robotic manufacturing, assembly, and servicing utilizing in-situ resources, especially for space robotic applications. The purpose was to gather resource material for researchers from a variety of disciplines to identify common themes, formulate problems, and share promising technologies for autonomous large-scale construction, servicing, and assembly robots. The articles under this special topic provide a snapshot of several key technologies under development to support on-orbit robotic servicing, assembly, and manufacturing.}
}

@inproceedings{lincoln48675,
       booktitle = {AAAI - AI for Agriculture and Food Systems},
           month = {February},
           title = {Multiple broccoli head detection and tracking in 3D point clouds for autonomous harvesting},
          author = {Hector A. Montes and Grzegorz Cielniak},
            year = {2022},
        keywords = {ARRAY(0x559d32c024c8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48675/},
        abstract = {This paper explores a tracking method of broccoli heads that combine a Particle Filter and 3D features detectors to track multiple crops in a sequence of 3D data frames. The tracking accuracy is verified based on a data association method that matches detections with tracks over each frame. The particle filter incorporates a simple motion model to produce the posterior particle distribution, and a similarity model as probability function to measure the tracking accuracy. The method is tested with datasets of two broccoli varieties collected in planted fields from two different countries. Our evaluation shows the tracking method reduces the number of false negatives produced by the detectors on their own. In addition, the method accurately detects and tracks the 3D locations of broccoli heads relative to the vehicle at high frame rates}
}

@article{lincoln48358,
           month = {February},
          author = {Fang Lei and Zhiping Peng and Mei Liu and Jigen Peng and Vassilis Cutsuridis and Shigang Yue},
           title = {A Robust Visual System for Looming Cue Detection Against Translating Motion},
       publisher = {IEEE},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
             doi = {10.1109/TNNLS.2022.3149832},
           pages = {1--15},
            year = {2022},
        keywords = {ARRAY(0x559d32c5d4b8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48358/},
        abstract = {Collision detection is critical for autonomous vehicles or robots to serve human society safely. Detecting looming objects robustly and timely plays an important role in collision avoidance systems. The locust lobula giant movement detector (LGMD1) is specifically selective to looming objects which are on a direct collision course. However, the existing LGMD1 models can not distinguish a looming object from a near and fast translatory moving object, because the latter can evoke a large amount of excitation that can lead to false LGMD1 spikes. This paper presents a new visual neural system model (LGMD1) that applies a neural competition mechanism within a framework of separated ON and OFF pathways to shut off the translating response. The competition-based approach responds vigorously to monotonous ON/OFF responses resulting from a looming object. However, it does not respond to paired ON-OFF responses that result from a translating object, thereby enhancing collision selectivity. Moreover, a complementary denoising mechanism ensures reliable collision detection. To verify the effectiveness of the model, we have conducted systematic comparative experiments on synthetic and real datasets. The results show that our method exhibits more accurate discrimination between looming and translational events -- the looming motion can be correctly detected. It also demonstrates that the proposed model is more robust than comparative models.}
}

@article{lincoln49162,
           month = {February},
           title = {A Robust Visual System for Looming Cue Detection Against Translation Motion},
          author = {Fang Lei and Zhiping Peng and Mei Liu and Jigen Peng and Vassilis Cutsuridis and Shigang Yue},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/TNNLS.2022.3149832},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
        keywords = {ARRAY(0x559d32c1b050)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49162/},
        abstract = {Collision detection is critical for autonomous vehicles or robots to serve human society safely. Detecting looming objects robustly and timely plays an important role in collision avoidance systems. The locust lobula giant movement detector (LGMD1) is specifically selective to looming objects which are on a direct collision course. However, the existing LGMD1 models cannot distinguish a looming object from a near and fast translatory moving object, because the latter can evoke a large amount of excitation that can lead to false LGMD1 spikes. This article presents a new visual neural system model (LGMD1) that applies a neural competition mechanism within a framework of separated ON and OFF pathways to shut off the translating response. The competition-based approach responds vigorously to
monotonous ON/OFF responses resulting from a looming object. However, it does not respond to paired ON?OFF responses that result from a translating object, thereby enhancing collision selectivity. Moreover, a complementary denoising mechanism ensures reliable collision detection. To verify the effectiveness of the model, we have conducted systematic comparative experiments on synthetic and real datasets. The results show that our method exhibits more accurate discrimination between looming and translational events{--}the looming motion can be correctly detected. It also demonstrates that the proposed model is more robust than comparative models.}
}

@article{lincoln52103,
          volume = {22},
          number = {1471},
           month = {February},
          author = {Angela Mazzeo and Jacopo Aguzzi and Marcello Calisti and Simonpietro Canese and Michela Angiolillo and Louise Allcock and Fabrizio Vecchi and Sergio Stefanni and Marco Controzzi},
           title = {Marine Robotics for Deep-Sea Specimen Collection: A Taxonomy of Underwater Manipulative Actions},
       publisher = {MDPI},
            year = {2022},
         journal = {Sensors},
             doi = {10.3390/s22041471},
        keywords = {ARRAY(0x559d32b32cd8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52103/},
        abstract = {In order to develop a gripping system or control strategy that improves scientific sampling procedures, knowledge of the process and the consequent definition of requirements is fundamental. Nevertheless, factors influencing sampling procedures have not been extensively described, and selected strategies mostly depend on pilots? and researchers? experience. We interviewed 17 researchers and remotely operated vehicle (ROV) technical operators, through a formal questionnaire or in-person interviews, to collect evidence of sampling procedures based on their direct field experience. We methodologically analyzed sampling procedures to extract single basic actions (called atomic manipulations). Available equipment, environment and species-specific features strongly influenced the manipulative choices. We identified a list of functional and technical requirements for the development of novel end-effectors for marine sampling. Our results indicate that the unstructured and highly variable deep-sea environment requires a versatile system, capable of robust interactions with hard surfaces such as pushing or scraping, precise tuning of gripping force for tasks such as pulling delicate organisms away from hard and soft substrates, and rigid holding, as well as a mechanism for rapidly switching among external tools.}
}

@article{lincoln52102,
          volume = {10},
          number = {1},
           month = {February},
          author = {Jacopo Aguzzi and Sascha Flogel and Simone Marini and Laurenz Thomsen and Jan Albiez and Peter Weiss and Giacomo Picardi and Marcello Calisti and Sergio Stefanni and Luca Mirimin and Fabrizio Vecchi and Cecilia Laschi and Andrew Branch and Evan Clark and Bernard Foing and Armin Wedler and Damianos Chatzievangelou and Michael Tangherlini and Autun Purser and Lewis Dartnell and Roberto Danovaro},
           title = {Developing technological synergies between deep-sea and space research},
       publisher = {University of California},
            year = {2022},
         journal = {Elementa: Science of the Anthropocene},
             doi = {10.1525/elementa.2021.00064},
           pages = {00064},
        keywords = {ARRAY(0x559d329c6bb8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52102/},
        abstract = {Recent advances in robotic design, autonomy and sensor integration create solutions for the exploration of
deep-sea environments, transferable to the oceans of icy moons. Marine platforms do not yet have the mission
autonomy capacity of their space counterparts (e.g., the state of the art Mars Perseverance rover mission),
although different levels of autonomous navigation and mapping, as well as sampling, are an extant capability.
In this setting their increasingly biomimicked designs may allow access to complex environmental scenarios,
with novel, highly-integrated life-detecting, oceanographic and geochemical sensor packages. Here, we lay an
outlook for the upcoming advances in deep-sea robotics through synergies with space technologies within
three major research areas: biomimetic structure and propulsion (including power storage and generation),
artificial intelligence and cooperative networks, and life-detecting instrument design. New morphological and
material designs, with miniaturized and more diffuse sensor packages, will advance robotic sensing systems.
Artificial intelligence algorithms controlling navigation and communications will allow the further
development of the behavioral biomimicking by cooperating networks. Solutions will have to be tested
within infrastructural networks of cabled observatories, neutrino telescopes, and off-shore industry sites
with agendas and modalities that are beyond the scope of our work, but could draw inspiration on the
proposed examples for the operational combination of fixed and mobile platforms.}
}

@inproceedings{lincoln48676,
       booktitle = {AI for Agriculture and Food Systems},
           month = {January},
           title = {Channel Randomisation with Domain Control for Effective Representation Learning of Visual Anomalies in Strawberries},
          author = {Taeyeong Choi and Grzegorz Cielniak},
            year = {2022},
        keywords = {ARRAY(0x559d32b2a2f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48676/},
        abstract = {Channel Randomisation (CH-Rand) has appeared as a key data augmentation technique for anomaly detection on fruit
images because neural networks can learn useful representations of colour irregularity whilst classifying the samples
from the augmented "domain". Our previous study has revealed its success with significantly more reliable performance than other state-of-the-art methods, largely specialised for identifying structural implausibility on non-agricultural objects (e.g., screws). In this paper, we further enhance CH-Rand with additional guidance to generate more informative data for representation learning of anomalies in fruits as most of its fundamental designs are still maintained. To be specific, we first control the "colour space" on which CH-Rand is executed to investigate whether a particular model{--}e.g., HSV , YCbCr, or L*a*b* {--}can better help synthesise realistic anomalies than the RGB, suggested in the original design. In addition, we develop a learning "curriculum" in which CH-Rand shifts its augmented domain to gradually increase the difficulty of the examples for neural networks to classify. To the best of our best knowledge, we are the first to connect the concept of curriculum to self-supervised representation learning for anomaly detection. Lastly, we perform evaluations with the Riseholme-2021 dataset, which contains {\ensuremath{>}} 3.5K real strawberry images at various growth levels along with anomalous examples. Our experimental results show that the trained models with the proposed strategies can achieve over 16\% higher scores of AUC-PR with more than three times less variability than the naive CH-Rand whilst using the same deep networks and data.}
}

@article{lincoln49094,
           month = {January},
           title = {A Looming Spatial Localization Neural Network Inspired by MLG1 Neurons in the Crab Neohelice},
          author = {Hao Luan and Qingbing Fu and Yicheng Zhang and Mu Hua and Shengyong Chen and Shigang Yue},
       publisher = {Frontiers Media},
            year = {2022},
             doi = {10.3389/fnins.2021.787256},
         journal = {Frontiers in Neuroscience},
        keywords = {ARRAY(0x559d32c98360)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49094/},
        abstract = {Similar to most visual animals, the crab Neohelice granulata relies predominantly on visual information to escape from predators, to track prey and for selecting mates. It, therefore, needs specialized neurons to process visual information and determine the spatial location of looming objects. In the crab Neohelice granulata, the Monostratified Lobula Giant type1 (MLG1) neurons have been found to manifest looming sensitivity with finely tuned capabilities of encoding spatial location information. MLG1s neuronal ensemble can not only perceive the location of a looming stimulus, but are also thought to be able to influence the direction of movement continuously, for example, escaping from a threatening, looming target in relation to its position. Such specific characteristics make the MLG1s unique compared to normal looming detection neurons in invertebrates which can not localize spatial looming. Modeling the MLG1s ensemble is not only critical for elucidating the mechanisms underlying the functionality of such neural circuits, but also important for developing new autonomous, efficient, directionally reactive collision avoidance systems for robots and vehicles. However, little computational modeling has been done for implementing looming spatial localization analogous to the specific functionality of MLG1s ensemble. To bridge this gap, we propose a model of MLG1s and their pre-synaptic visual neural network to detect the spatial location of looming objects. The model consists of 16 homogeneous sectors arranged in a circular field inspired by the natural arrangement of 16 MLG1s? receptive fields to encode and convey spatial information concerning looming objects with dynamic expanding edges in different locations of the visual field. Responses of the proposed model to systematic real-world visual stimuli match many of the biological characteristics of MLG1 neurons.
The systematic experiments demonstrate that our proposed MLG1s model works effectively and robustly to perceive and localize looming information, which could be a promising candidate for intelligent machines interacting within dynamic environments free of collision. This study also sheds light upon a new type of neuromorphic visual sensor strategy that can extract looming objects with locational information in a quick and reliable manner.}
}

@article{lincoln52101,
          volume = {22},
          number = {2},
           month = {January},
          author = {Angelo Mazzeo and Jacopo Aguzzi and Marcello Calisti and Simonpietro Canese and Fabrizio Vecchi and Sergio Stefanni and Marco Controzzi},
           title = {Marine Robotics for Deep-Sea Specimen Collection: A Systematic Review of Underwater Grippers},
       publisher = {MDPI},
            year = {2022},
         journal = {Sensors},
             doi = {10.3390/s22020648},
           pages = {648},
        keywords = {ARRAY(0x559d32b24608)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/52101/},
        abstract = {The collection of delicate deep-sea specimens of biological interest with remotely operated vehicle (ROV) industrial grippers and tools is a long and expensive procedure. Industrial grippers were originally designed for heavy manipulation tasks, while sampling specimens requires dexterity and precision. We describe the grippers and tools commonly used in underwater sampling for scientific purposes, systematically review the state of the art of research in underwater gripping technologies, and identify design trends. We discuss the possibility of executing typical manipulations of sampling procedures with commonly used grippers and research prototypes. Our results indicate that commonly used grippers ensure that the basic actions either of gripping or caging are possible, and their functionality is extended by holding proper tools. Moreover, the approach of the research status seems to have changed its focus in recent years: from the demonstration of the validity of a specific technology (actuation, transmission, sensing) for marine applications, to the solution of specific needs of underwater manipulation. Finally, we summarize the environmental and operational requirements that should be considered in the design of an underwater gripper.}
}

@inproceedings{lincoln49913,
       booktitle = {IEEE International Conference on Automation Science and Engineering (CASE)},
           title = {Towards Infield Navigation: leveraging simulated data for crop row detection},
          author = {Rajitha De Silva and Grzegorz Cielniak and Junfeng Gao},
       publisher = {IEEE},
            year = {2022},
        keywords = {ARRAY(0x559d32b44098)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49913/},
        abstract = {Agricultural datasets for crop row detection are often bound by their limited number of images. This restricts
the researchers from developing deep learning based models  for precision agricultural tasks involving crop row detection. We suggest the utilization of small real-world datasets alongwith additional data generated by simulations to yield similar crop row detection performance as that of a model trained with a large real world dataset. Our method could reach the performance of a deep learning based crop row detection model trained with real-world data by using 60\% less labelled realworld data. Our model performed well against field variations such as shadows, sunlight and growth stages. We introduce an automated pipeline to generate labelled images for crop row detection in simulation domain. An extensive comparison is done to analyze the contribution of simulated data towards reaching robust crop row detection in various real-world field scenarios.}
}

@inproceedings{lincoln48515,
       booktitle = {Ital-IA 2022},
           title = {From Human Perception and Action Recognition to Causal Understanding of Human-Robot Interaction in Industrial Environments},
          author = {Stefano Ghidoni and Matteo Terreran and Daniele Evangelista and Emanuele Menegatti and Christian Eitzinger and Enrico Villagrossi and Nicola Pedrocchi and Nicola Castaman and Marcin Malecha and Sariah Mghames and Luca Castri and Marc Hanheide and Nicola Bellotto},
            year = {2022},
        keywords = {ARRAY(0x559d32c7cef8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48515/},
        abstract = {Human-robot collaboration is migrating from lightweight robots in laboratory environments to industrial applications, where heavy tasks and powerful robots are more common. In this scenario, a reliable perception of the humans involved in the process and related intentions and behaviors is fundamental. This paper presents two projects investigating the use of robots in relevant industrial scenarios, providing an overview of how industrial human-robot collaborative tasks can be successfully addressed.}
}

@inproceedings{lincoln49036,
       booktitle = {The 23rd International Workshop on Multi-Agent-Based Simulation (MABS))},
           title = {Challenges for Multi-Agent Based Agricultural Workforce Management},
          author = {Helen Harman and Elizabeth I. Sklar},
       publisher = {Springer},
            year = {2022},
        keywords = {ARRAY(0x559d32c92858)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49036/},
        abstract = {Multi-agent task allocation methods seek to distribute a set of tasks fairly amongst a set of agents. In real-world settings, such as soft fruit farms, human labourers undertake harvesting tasks, assigned by farm managers. The work here explores the application of artificial intelligence planning methodologies to optimise the existing workforce and applies multi-agent based simulation to evaluate the efficacy of the AI strategies. Key challenges threatening the acceptance of such an approach are highlighted and solutions are evaluated experimentally.}
}

@article{lincoln49072,
           title = {Artificial intelligence and ethics within the food sector: developing a common language for technology adoption across the supply chain},
          author = {Louise Manning and Steve Brewer and Peter Craigon and P.J Frey and Anabel Gutierrez and Naomi Jacobs and Samantha Kanza and Samuel Munday and Justin Sacks and Simon Pearson},
       publisher = {Elsevier},
            year = {2022},
         journal = {Trends in Food Science and Technology},
        keywords = {ARRAY(0x559d32c052e8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49072/},
        abstract = {Background:  The use of artificial intelligence (AI) is growing in food supply chains. The ethical language associated with food supply and technology is contextualised and framed by the meaning given to it by stakeholders. Failure to differentiate between these nuanced meanings can create a barrier to technology adoption and reduce the benefit derived.
Scope and approach: The aim of this review paper is to consider the embedded ethical language used by stakeholders who collaborate in the adoption of AI in food supply chains.    Ethical perspectives frame this literature review and provide structure to consider how to shape a common discourse to build trust in, and frame more considered utilisation of, AI in food supply chains to the benefit of users, and wider society. 
Key findings and conclusions: Whilst the nature of data within the food system is much broader than the personal data covered by the European Union General Data Protection Regulation (GDPR), the ethical issues for computational and AI systems are similar and can be considered in terms of particular aspects: transparency, traceability, explainability, interpretability, accessibility, accountability and responsibility. The outputs of this research assist in giving a more rounded understanding of the language used, exploring the ethical interaction of aspects of AI used in food supply chains and also the management activities and actions that can be adopted to improve the applicability of AI technology, increase engagement and derive greater performance benefits. This work has implications for those developing AI governance protocols for the food supply chain as well as supply chain practitioners.}
}

@inproceedings{lincoln51674,
       booktitle = {UKRAS2022 Conference ?Robotics for Unconstrained Environments?},
           title = {Towards Autonomous Task Allocation Using a Robot Team in a Food Factory},
          author = {Amie Owen and Helen Harman and Elizabeth Sklar},
       publisher = {UK-RAS},
            year = {2022},
        keywords = {ARRAY(0x559d32a0e388)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/51674/},
        abstract = {Scheduling of hygiene tasks in a food production environment is a complex challenge which is typically performed manually. Many factors must be considered during scheduling; this includes what training a hygiene operative (i.e. cleaning staff member) has undergone, the availability of hygiene operatives (holiday commitments, sick leave etc.) and the production constraints (how long does the oven take to cool, when does production begin again etc.). This paper seeks to apply multiagent task allocation (MATA) to automate and optimise the process of allocating tasks to hygiene operatives. The intention is that this optimization module will form one part of a proposed larger system. that we propose to develop. A simulation has been created to function as a digital twin of a factory environment, allowing us to evaluate experimentally a variety of task allocation methodologies. Trialled methods include Round Robin (RR), Sequential Single Item (SSI) auctions, Lowest Bid and Least Contested Bid.}
}

@inproceedings{lincoln51673,
       booktitle = {20th International Conference on Practical Applications of Agents and Multi-Agent Systems, PAAMS 2022},
           title = {Towards the application of multi-agent task allocation to hygiene tasks in the food production industry.},
          author = {Amie Owen and Helen Harman and Elizabeth I. Sklar},
       publisher = {Springer Cham},
            year = {2022},
        keywords = {ARRAY(0x559d32c242c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/51673/},
        abstract = {The food production industry faces the complex challenge of scheduling both production and hygiene tasks. These tasks are typically scheduled manually. However, due to the increasing costs of raw materials and the regulations factories must adhere to, inefficiencies can be costly. This paper presents the initial findings of a survey, conducted to learn more about the hygiene tasks within the industry and to inform research on how multi-agent task allocation (MATA) methodologies could automate and improve the scheduling of hygiene tasks. A simulation of a heterogeneous human workforce within a factory environment is presented. This work evaluates experimentally different strategies for applying market-based mechanisms, in particular Sequential Single Item (SSI) auctions, to the problem of allocation hygiene tasks to a heterogeneous workforce.}
}

@article{lincoln49668,
          volume = {12},
          number = {6},
          author = {Abhishesh Pal and Gautham Das and Marc Hanheide and Antonio Candea Leite and Pal From},
           title = {An Agricultural Event Prediction Framework towards Anticipatory Scheduling of Robot Fleets: General Concepts and Case Studies},
       publisher = {MDPI},
         journal = {Agronomy},
             doi = {10.3390/agronomy12061299},
            year = {2022},
        keywords = {ARRAY(0x559d32b07098)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49668/},
        abstract = {Harvesting in soft-fruit farms is labor intensive, time consuming and is severely affected by scarcity of skilled labors. Among several activities during soft-fruit harvesting, human pickers take 20?30\% of overall operation time into the logistics activities. Such an unproductive time, for example, can be reduced by optimally deploying a fleet of agricultural robots and schedule them by anticipating the human activity behaviour (state) during harvesting. In this paper, we propose a framework for spatio-temporal prediction of human pickers? activities while they are picking fruits in agriculture fields. Here we exploit temporal patterns of picking operation and 2D discrete points, called topological nodes, as spatial constraints imposed by the agricultural environment. Both information are used in the prediction framework in combination with a variant of the Hidden Markov Model (HMM) algorithm to create two modules. The proposed methodology is validated with two test cases. In Test Case 1, the first module selects an optimal temporal model called as picking\_state\_progression model that uses temporal features of a picker state (event) to statistically evaluate an adequate number of intra-states also called sub-states. In Test Case 2, the second module uses the outcome from the optimal temporal model in the subsequent spatial model called node\_transition model and performs ?spatio-temporal predictions? of the picker?s movement while the picker is in a particular state. The Discrete Event Simulation (DES) framework, a proven agricultural multi-robot logistics model, is used to simulate the different picking operation scenarios with and without our proposed prediction framework and the results are then statistically compared to each other. Our prediction framework can reduce the so-called unproductive logistics time in a fully manual harvesting process by about 80 percent in the overall picking operation. This research also indicates that the different rates of picking operations involve different numbers of sub-states, and these sub-states are associated with different trends considered in spatio-temporal predictions.}
}

@article{lincoln48499,
           title = {Tea Chrysanthemum Detection by Leveraging Generative Adversarial Networks and Edge Computing},
          author = {Chao Qi and Junfeng Gao and Kunjie Chen and Lei Shu and Simon Pearson},
       publisher = {Frontiers Media},
            year = {2022},
         journal = {Frontiers in plant science},
        keywords = {ARRAY(0x559d32b80908)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48499/},
        abstract = {A high resolution dataset is one of the prerequisites for tea chrysanthemum detection with deep learning algorithms. This is crucial for further developing a selective chrysanthemum harvesting robot. However, generating high resolution datasets of the tea chrysanthemum with complex unstructured environments is a challenge. In this context, we propose a novel generative adversarial network (TC-GAN) that attempts to deal with this challenge. First, we designed a non-linear mapping network for untangling the features of the underlying code. Then, a customized regularisation method was used to provide fine-grained control over the image details. Finally, a gradient diversion design with multi-scale feature extraction capability was adopted to optimize the training process. The proposed TC-GAN was compared with 12 state-of-the-art generative adversarial networks, showing that an optimal average precision (AP) of 90.09\% was achieved with the generated images (512*512) on the developed TC-YOLO object detection model under the NVIDIA Tesla P100 GPU environment. Moreover, the detection model was deployed into the embedded NVIDIA Jetson TX2 platform with 0.1s inference time, and this edge computing device could be further developed into a perception system for selective chrysanthemum picking robots in the future.}
}

