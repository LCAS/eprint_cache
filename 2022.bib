@article{lincoln47700,
          volume = {193},
           month = {May},
          author = {Chao Qi and Junfeng Gao and Simon Pearson and Helen Harman and Kunjie Chen and Lei Shu},
           title = {Tea chrysanthemum detection under unstructured environments using the TC-YOLO model},
       publisher = {Elsevier},
         journal = {Expert Systems with Applications},
             doi = {10.1016/j.eswa.2021.116473},
            year = {2022},
        keywords = {ARRAY(0x558e720c3208)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47700/},
        abstract = {Tea chrysanthemum detection at its flowering stage is one of the key components for selective chrysanthemum harvesting robot development. However, it is a challenge to detect flowering chrysanthemums under unstructured field environments given variations on illumination, occlusion and object scale. In this context, we propose a highly fused and lightweight deep learning architecture based on YOLO for tea chrysanthemum detection (TC-YOLO). First, in the backbone component and neck component, the method uses the Cross-Stage Partially Dense network (CSPDenseNet) and the Cross-Stage Partial ResNeXt network (CSPResNeXt) as the main networks, respectively, and embeds custom feature fusion modules to guide the gradient flow. In the final head component, the method combines the recursive feature pyramid (RFP) multiscale fusion reflow structure and the Atrous Spatial Pyramid Pool (ASPP) module with cavity convolution to achieve the detection task. The resulting model was tested on 300 field images using a data enhancement strategy combining flipping and rotation, showing that under the NVIDIA Tesla P100 GPU environment, if the inference speed is 47.23 FPS for each image (416 {$\times$} 416), TC-YOLO can achieve the average precision (AP) of 92.49\% on our own tea chrysanthemum dataset. Through further validation, it was found that overlap had the least effect on tea chrysanthemum detection, and illumination had the greatest effect on tea chrysanthemum detection. In addition, this method (13.6 M) can be deployed on a single mobile GPU, and it could be further developed as a perception system for a selective chrysanthemum harvesting robot in the future.}
}

@inproceedings{lincoln48682,
       booktitle = {2022 IEEE International Conference on Robotics and Automation (ICRA)},
           month = {May},
           title = {Self-supervised Representation Learning for Reliable Robotic Monitoring of Fruit Anomalies},
          author = {Taeyeong Choi and Owen Would and Adrian Salazar-Gomez and Grzegorz Cielniak},
       publisher = {IEEE},
            year = {2022},
        keywords = {ARRAY(0x558e720c2de8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48682/},
        abstract = {Data augmentation can be a simple yet powerful tool for autonomous robots to fully utilise available data for self-supervised
identification of atypical scenes or objects. State-of-the-art augmentation methods arbitrarily embed "structural" peculiarity on typical images so that classifying these artefacts can provide guidance for learning representations for the detection of anomalous visual signals. In this paper, however, we argue that learning such structure-sensitive representations can be a suboptimal approach to some classes of anomaly (e.g., unhealthy fruits) which could be better recognised by a different type of visual element such as "colour". We thus propose Channel Randomisation as a novel data augmentation method for restricting neural networks to learn encoding of "colour irregularity" whilst predicting channel-randomised images to ultimately build reliable fruit-monitoring robots identifying atypical fruit qualities. Our experiments show that (1) this colour-based alternative can better learn representations for consistently accurate identification of fruit anomalies in various fruit species, and also, (2) unlike other methods, the validation accuracy can be utilised as a criterion for early stopping of training in practice due to positive correlation between the performance in the self-supervised colour-differentiation task and the subsequent detection rate of actual anomalous fruits. Also, the proposed approach is evaluated on a new agricultural dataset, Riseholme-2021, consisting of 3.5K strawberry images gathered by a mobile robot, which we share online to encourage active agri-robotics research.}
}

@article{lincoln49062,
          volume = {18},
          number = {4},
           month = {April},
          author = {Magd Badaoui and Pedro Buigues and Denes Berta and Guarav Mandana and Hankang Gu and Tam{\'a}s F{\"o}ldes and Callum Dickson and Viktor Hornak and Mitsunori Kato and Carla Molteni and Simon Parsons and Edina Rosta},
           title = {Combined Free-Energy Calculation and Machine Learning Methods for Understanding Ligand Unbinding Kinetics},
       publisher = {American Chemical Society},
            year = {2022},
         journal = {Journal of Chemical Theory and Computation},
             doi = {https://doi.org/10.1021/acs.jctc.1c00924},
           pages = {2543--2555},
        keywords = {ARRAY(0x558e720c2dd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49062/},
        abstract = {The determination of drug residence times, which define the time an inhibitor is in complex with its
target, is a fundamental part of the drug discovery process. Synthesis and experimental
measurements of kinetic rate constants are, however, expensive, and time-consuming. In this work,
we aimed to obtain drug residence times computationally. Furthermore, we propose a novel
algorithm to identify molecular design objectives based on ligand unbinding kinetics. We designed
an enhanced sampling technique to accurately predict the free energy profiles of the ligand
unbinding process, focusing on the free energy barrier for unbinding. Our method first identifies
unbinding paths determining a corresponding set of internal coordinates (IC) that form contacts
between the protein and the ligand, it then iteratively updates these interactions during a series of
biased molecular-dynamics (MD) simulations to reveal the ICs that are important for the whole of
the unbinding process. Subsequently, we performed finite temperature string simulations to obtain
the free energy barrier for unbinding using the set of ICs as a complex reaction coordinate.
Importantly, we also aimed to enable further design of drugs focusing on improved residence 
times. To this end, we developed a supervised machine learning (ML) approach with inputs from
unbiased ?downhill? trajectories initiated near the transition state (TS) ensemble of the string
unbinding path. We demonstrate that our ML method can identify key ligand-protein interactions
driving the system through the TS. Some of the most important drugs for cancer treatment are
kinase inhibitors. One of these kinase targets is Cyclin Dependent Kinase 2 (CDK2), an appealing
target for anticancer drug development. Here, we tested our method using two different CDK2
inhibitors for potential further development of these compounds. We compared the free energy
barriers obtained from our calculations with those observed in available experimental data. We
highlighted important interactions at the distal ends of the ligands that can be targeted for
improved residence times. Our method provides a new tool to determine unbinding rates, and to
identify key structural features of the inhibitors that can be used as starting points for novel design
strategies in drug discovery.}
}

@article{lincoln46497,
           month = {April},
           title = {Robotic Exploration for Learning Human Motion Patterns},
          author = {Sergio Molina Mellado and Grzegorz Cielniak and Tom Duckett},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/TRO.2021.3101358},
         journal = {IEEE Transaction on Robotics},
        keywords = {ARRAY(0x558e720c3298)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46497/},
        abstract = {Understanding how people are likely to move is key to efficient and safe robot navigation in human environments. However, mobile robots can only observe a fraction of the environment at a time, while the activity patterns of people may also change at different times. This paper introduces a new methodology for mobile robot exploration to maximise the knowledge of human activity patterns by deciding where and when to collect observations. We introduce an exploration policy driven by the entropy levels in a spatio-temporal map of pedestrian flows, and compare multiple spatio-temporal exploration strategies including both informed and uninformed approaches. The evaluation is performed by simulating mobile robot exploration using real sensory data from three long-term pedestrian datasets. The results show that for certain scenarios the models built with proposed exploration system can better predict the flow patterns than uninformed strategies, allowing the robot to move in a more socially compliant way, and that the exploration ratio is a key factor when it comes to the model prediction accuracy.}
}

@inproceedings{lincoln48675,
       booktitle = {AAAI - AI for Agriculture and Food Systems},
           month = {February},
           title = {Multiple broccoli head detection and tracking in 3D point clouds for autonomous harvesting},
          author = {Hector A. Montes and Grzegorz Cielniak},
            year = {2022},
        keywords = {ARRAY(0x558e720c3280)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48675/},
        abstract = {This paper explores a tracking method of broccoli heads that combine a Particle Filter and 3D features detectors to track multiple crops in a sequence of 3D data frames. The tracking accuracy is verified based on a data association method that matches detections with tracks over each frame. The particle filter incorporates a simple motion model to produce the posterior particle distribution, and a similarity model as probability function to measure the tracking accuracy. The method is tested with datasets of two broccoli varieties collected in planted fields from two different countries. Our evaluation shows the tracking method reduces the number of false negatives produced by the detectors on their own. In addition, the method accurately detects and tracks the 3D locations of broccoli heads relative to the vehicle at high frame rates}
}

@article{lincoln48358,
           month = {February},
          author = {Fang Lei and Zhiping Peng and Mei Liu and Jigen Peng and Vassilis Cutsuridis and Shigang Yue},
           title = {A Robust Visual System for Looming Cue Detection Against Translating Motion},
       publisher = {IEEE},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
             doi = {10.1109/TNNLS.2022.3149832},
           pages = {1--15},
            year = {2022},
        keywords = {ARRAY(0x558e720c32e0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48358/},
        abstract = {Collision detection is critical for autonomous vehicles or robots to serve human society safely. Detecting looming objects robustly and timely plays an important role in collision avoidance systems. The locust lobula giant movement detector (LGMD1) is specifically selective to looming objects which are on a direct collision course. However, the existing LGMD1 models can not distinguish a looming object from a near and fast translatory moving object, because the latter can evoke a large amount of excitation that can lead to false LGMD1 spikes. This paper presents a new visual neural system model (LGMD1) that applies a neural competition mechanism within a framework of separated ON and OFF pathways to shut off the translating response. The competition-based approach responds vigorously to monotonous ON/OFF responses resulting from a looming object. However, it does not respond to paired ON-OFF responses that result from a translating object, thereby enhancing collision selectivity. Moreover, a complementary denoising mechanism ensures reliable collision detection. To verify the effectiveness of the model, we have conducted systematic comparative experiments on synthetic and real datasets. The results show that our method exhibits more accurate discrimination between looming and translational events -- the looming motion can be correctly detected. It also demonstrates that the proposed model is more robust than comparative models.}
}

@inproceedings{lincoln48676,
       booktitle = {AI for Agriculture and Food Systems},
           month = {January},
           title = {Channel Randomisation with Domain Control for Effective Representation Learning of Visual Anomalies in Strawberries},
          author = {Taeyeong Choi and Grzegorz Cielniak},
            year = {2022},
        keywords = {ARRAY(0x558e720c34a8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48676/},
        abstract = {Channel Randomisation (CH-Rand) has appeared as a key data augmentation technique for anomaly detection on fruit
images because neural networks can learn useful representations of colour irregularity whilst classifying the samples
from the augmented "domain". Our previous study has revealed its success with significantly more reliable performance than other state-of-the-art methods, largely specialised for identifying structural implausibility on non-agricultural objects (e.g., screws). In this paper, we further enhance CH-Rand with additional guidance to generate more informative data for representation learning of anomalies in fruits as most of its fundamental designs are still maintained. To be specific, we first control the "colour space" on which CH-Rand is executed to investigate whether a particular model{--}e.g., HSV , YCbCr, or L*a*b* {--}can better help synthesise realistic anomalies than the RGB, suggested in the original design. In addition, we develop a learning "curriculum" in which CH-Rand shifts its augmented domain to gradually increase the difficulty of the examples for neural networks to classify. To the best of our best knowledge, we are the first to connect the concept of curriculum to self-supervised representation learning for anomaly detection. Lastly, we perform evaluations with the Riseholme-2021 dataset, which contains {\ensuremath{>}} 3.5K real strawberry images at various growth levels along with anomalous examples. Our experimental results show that the trained models with the proposed strategies can achieve over 16\% higher scores of AUC-PR with more than three times less variability than the naive CH-Rand whilst using the same deep networks and data.}
}

@inproceedings{lincoln48058,
       booktitle = {HCI International Conference 2022},
           title = {Educational robots and their control interfaces: how can we make them more accessible for Special Education?},
          author = {Maria Galvez Trigo and Penelope Standen and Sue Cobb},
       publisher = {Springer},
            year = {2022},
        keywords = {ARRAY(0x558e720c3220)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48058/},
        abstract = {Existing design standards and guidelines provide guidance on what factors to consider to produce interactive systems that are not only usable, but also accessible. However, these standards are usually general, and when it comes to designing an interactive system for children with Learning Difficulties or Disabilities (LD) and/or Autism Spectrum Conditions (ASC) they are often not specific enough, leading to systems that are not fit for that purpose. If we dive into the area of educational robotics, we face even more issues, in part due to the relative novelty of these technologies. In this paper, we present an analysis of 26 existing educational robots and the interfaces used to control them. Furthermore, we present the results of running focus groups and a questionnaire with 32 educators with expertise in Special Education and parents at four different institutions, to explore potential accessibility issues of existing systems and to identify desirable characteristics. We conclude introduc- ing an initial set of design recommendations, to complement existing design standards and guidelines, that would help with producing future more accessible control interfaces for educational robots, with an especial focus on helping pupils with LDs and/or ASC.}
}

@inproceedings{lincoln48515,
       booktitle = {Ital-IA 2022},
           title = {From Human Perception and Action Recognition to Causal Understanding of Human-Robot Interaction in Industrial Environments},
          author = {Stefano Ghidoni and Matteo Terreran and Daniele Evangelista and Emanuele Menegatti and Christian Eitzinger and Enrico Villagrossi and Nicola Pedrocchi and Nicola Castaman and Marcin Malecha and Sariah Mghames and Luca Castri and Marc Hanheide and Nicola Bellotto},
            year = {2022},
        keywords = {ARRAY(0x558e720c3238)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48515/},
        abstract = {Human-robot collaboration is migrating from lightweight robots in laboratory environments to industrial applications, where heavy tasks and powerful robots are more common. In this scenario, a reliable perception of the humans involved in the process and related intentions and behaviors is fundamental. This paper presents two projects investigating the use of robots in relevant industrial scenarios, providing an overview of how industrial human-robot collaborative tasks can be successfully addressed.}
}

@article{lincoln49072,
           title = {Artificial intelligence and ethics within the food sector: developing a common language for technology adoption across the supply chain},
          author = {Louise Manning and Steve Brewer and Peter Craigon and P.J Frey and Anabel Gutierrez and Naomi Jacobs and Samantha Kanza and Samuel Munday and Justin Sacks and Simon Pearson},
       publisher = {Elsevier},
            year = {2022},
         journal = {Trends in Food Science and Technology},
        keywords = {ARRAY(0x558e720c34d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49072/},
        abstract = {Background:  The use of artificial intelligence (AI) is growing in food supply chains. The ethical language associated with food supply and technology is contextualised and framed by the meaning given to it by stakeholders. Failure to differentiate between these nuanced meanings can create a barrier to technology adoption and reduce the benefit derived.
Scope and approach: The aim of this review paper is to consider the embedded ethical language used by stakeholders who collaborate in the adoption of AI in food supply chains.    Ethical perspectives frame this literature review and provide structure to consider how to shape a common discourse to build trust in, and frame more considered utilisation of, AI in food supply chains to the benefit of users, and wider society. 
Key findings and conclusions: Whilst the nature of data within the food system is much broader than the personal data covered by the European Union General Data Protection Regulation (GDPR), the ethical issues for computational and AI systems are similar and can be considered in terms of particular aspects: transparency, traceability, explainability, interpretability, accessibility, accountability and responsibility. The outputs of this research assist in giving a more rounded understanding of the language used, exploring the ethical interaction of aspects of AI used in food supply chains and also the management activities and actions that can be adopted to improve the applicability of AI technology, increase engagement and derive greater performance benefits. This work has implications for those developing AI governance protocols for the food supply chain as well as supply chain practitioners.}
}

@article{lincoln48499,
           title = {Tea Chrysanthemum Detection by Leveraging Generative Adversarial Networks and Edge Computing},
          author = {Chao Qi and Junfeng Gao and Kunjie Chen and Lei Shu and Simon Pearson},
       publisher = {Frontiers Media},
            year = {2022},
         journal = {Frontiers in plant science},
        keywords = {ARRAY(0x558e720c34f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48499/},
        abstract = {A high resolution dataset is one of the prerequisites for tea chrysanthemum detection with deep learning algorithms. This is crucial for further developing a selective chrysanthemum harvesting robot. However, generating high resolution datasets of the tea chrysanthemum with complex unstructured environments is a challenge. In this context, we propose a novel generative adversarial network (TC-GAN) that attempts to deal with this challenge. First, we designed a non-linear mapping network for untangling the features of the underlying code. Then, a customized regularisation method was used to provide fine-grained control over the image details. Finally, a gradient diversion design with multi-scale feature extraction capability was adopted to optimize the training process. The proposed TC-GAN was compared with 12 state-of-the-art generative adversarial networks, showing that an optimal average precision (AP) of 90.09\% was achieved with the generated images (512*512) on the developed TC-YOLO object detection model under the NVIDIA Tesla P100 GPU environment. Moreover, the detection model was deployed into the embedded NVIDIA Jetson TX2 platform with 0.1s inference time, and this edge computing device could be further developed into a perception system for selective chrysanthemum picking robots in the future.}
}

