@inproceedings{lincoln50442,
       booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
           month = {October},
           title = {Robot Policy Learning from Demonstration Using Advantage Weighting and Early Termination},
          author = {Abdalkarim Mohtasib and Gerhard Neumann and Heriberto Cuayahuitl},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0360)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50442/},
        abstract = {Learning robotic tasks in the real world is still highly challenging and effective practical solutions remain to be found. Traditional methods used in this area are imitation learning and reinforcement learning, but they both have limitations when applied to real robots. Combining reinforcement learning with pre-collected demonstrations is a promising approach that can help in learning control policies to solve robotic tasks. In this paper, we propose an algorithm that uses novel techniques to leverage offline expert data using offline and online training to obtain faster convergence and improved performance. The proposed algorithm (AWET) weights the critic losses with a novel agent advantage weight to improve over the expert data. In addition, AWET makes use of an automatic early termination technique to stop and discard policy rollouts that are not similar to expert trajectories---to prevent drifting far from the expert data. In an ablation study, AWET showed improved and promising performance when compared to state-of-the-art baselines on four standard robotic tasks.}
}

@inproceedings{lincoln50259,
       booktitle = {[14:35] Vishnu Rajendran Sugathakumary (25451641) 2022 4th International Conference on ï¿½Control and Robotics (ICCR 2022)},
           month = {October},
           title = {Peduncle Gripping and Cutting Force for Strawberry Harvesting Robotic end-effector Design},
          author = {Rajendran Sugathakumary Vishnu and Soran Parsa and Simon Parsons and Amir Ghalamzan Esfahani},
            year = {2022},
         journal = {4th International Conference on Control and Robotics (ICCR 2022)},
        keywords = {ARRAY(0x555ae4eaf390)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50259/},
        abstract = {Robotic harvesting of strawberries has gained much interest in the recent past. Although there are many innovations, they haven?t yet reached a level that is comparable to an expert human picker. The end effector unit plays a major role in defining the efficiency of such a robotic harvesting system. Even though there are reports on various end effectors for strawberry harvesting, but there they lack a picture of certain parameters that the researchers can rely upon to develop new end effectors. These parameters include the limit of gripping force that can be applied on the peduncle for effective gripping, the force required to cut the strawberry peduncle, etc. These estimations would be helpful in the design cycle of the end effectors that target to grip and cut the strawberry peduncle during the harvesting action. This paper studies the estimation and analysis of these parameters experimentally. It has been estimated that the peduncle gripping force can be limited to 10 N. This enables an end effector to grip a strawberry of mass up to 50 grams with a manipulation acceleration of 50 m/s2 without squeezing the peduncle. The study on peduncle cutting force reveals that a force of 15 N is sufficient to cut strawberry peduncle using a blade with a wedge angle of 16.60 at 300 orientation.}
}

@inproceedings{lincoln49463,
       booktitle = {Model Based Space Systems and Software Engineering MBSE2021},
           month = {September},
           title = {Using Semantic Systems Engineering Techniques to Verity the Large Aperture Space Telescope Mission ? Current Status},
          author = {Joe Gregory and Manu H. Nair and Gianmaria Bullegas and Mini Rai Saaj},
       publisher = {European Space Agency},
            year = {2022},
        keywords = {ARRAY(0x555ae4eaf378)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49463/},
        abstract = {MBSE aims to integrate engineering models across tools and domain boundaries to support traditional systems engineering activities (e.g., requirements elicitation and traceability, design, analysis, verification and validation). However, MBSE does not inherently solve interoperability with the multiple model-based infrastructures involved in a complex systems engineering project. The challenge is to implement digital continuity in the three dimensions of systems engineering: across disciplines, throughout the lifecycle, and along the supply chain. Space systems are ideal candidates for the application of MBSE and semantic modelling as these complex and expensive systems are mission-critical and often co-developed by multiple stakeholders. In this paper, the authors introduce the concept of Semantic Systems Engineering (SES) as an expansion of MBSE practices to include semantic modelling through SWTs. The paper also presents the progress and status of a novel Semantic Systems Engineering Ontology (SESO) in the context of a specific design case study ? the Large Aperture Space Telescope mission.}
}

@inproceedings{lincoln50390,
       booktitle = {23rd Towards Autonomous Robotic Systems (TAROS) Conference},
           month = {September},
           title = {EMap: Real-time Terrain Estimation},
          author = {Jacobus Lock and Fanta Camara and Charles Fox},
       publisher = {Springer},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb03f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50390/},
        abstract = {Terrain mapping has a many use cases in both land surveyance and autonomous vehicles.
Popular methods generate occupancy maps over 3D space, which are sub-optimal in outdoor scenarios with large, clear spaces where gaps in LiDAR readings are common.
A terrain can instead be modelled as a height map over 2D space which can iteratively be updated with incoming LiDAR data, which simplifies computation and allows missing points to be estimated based on the current terrain estimate.
The latter point is of particular interest, since it can reduce the data collection effort required (and its associated costs) and current options are not suitable to real-time operation. 
In this work, we introduce a new method that is capable of performing such terrain mapping and inferencing tasks in real-time.
We evaluate it with a set of mapping scenarios and show it is capable of generating maps with higher accuracy than an OctoMap-based method.}
}

@article{lincoln49681,
          volume = {4},
          number = {5},
           month = {August},
          author = {Katherine Margaret Frances James and Daniel James Sargent and Adam Whitehouse and Grzegorz Cielniak},
           title = {High-throughput phenotyping for breeding targets - Current status and future directions of strawberry trait automation},
       publisher = {Wiley},
            year = {2022},
         journal = {Plants, People, Planet},
             doi = {10.1002/ppp3.10275},
           pages = {432--443},
        keywords = {ARRAY(0x555ae4eb03d8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49681/},
        abstract = {Automated image-based phenotyping has become widely accepted in crop phenotyping, particularly in cereal crops, yet few traits used by breeders in the strawberry industry have been automated. Early phenotypic assessment remains largely qualitative in this area since the manual phenotyping process is laborious and domain experts are constrained by time. Precision agriculture, facilitated by robotic technologies, is increasing in the strawberry industry, and the development of quantitative automated phenotyping methods is essential to ensure that breeding programs remain economically competitive. In this review, we investigate the external morphological traits relevant to the breeding of strawberries that have been automated and assess the potential for automation of traits that are still evaluated manually, highlighting challenges and limitations of the approaches used, particularly when applying high-throughput strawberry phenotyping in real-world environmental conditions.}
}

@inproceedings{lincoln49872,
       booktitle = {31st IEEE International Conference on Robot \& Human Interactive Communication},
           month = {August},
           title = {Extending Quantitative Proxemics and Trust to HRI},
          author = {Fanta Camara and Charles Fox},
       publisher = {IEEE},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0438)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49872/},
        abstract = {Human-robot interaction (HRI) requires quantitative models of proxemics and trust for robots to use in negotiating with people for space. Hall?s theory of proxemics has been used for decades to describe social interaction distances but has lacked detailed quantitative models and generative explanations to apply to these cases. In the limited case of 
 autonomous vehicle interactions with pedestrians crossing a road, a recent model has explained the quantitative sizes of Hall?s distances to 4\% error and their links to the concept of trust in human interactions. The present study extends this model by generalising several of its assumptions to cover further cases including human-human and human-robot interactions. It tightens the explanations of Hall zones from 4\% to 1\% error and fits several more recent empirical HRI results. This may help to further unify these disparate fields and quantify them to a level which enables real-world operational HRI applications.}
}

@inproceedings{lincoln50385,
       booktitle = {The 5th UK Robotics and Autonomous Systems Conference},
           month = {August},
           title = {Blockchain Crop Assurance and Localisation},
          author = {Garry Clawson and Charles Fox},
       publisher = {UKRAS},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0900)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50385/},
        abstract = {Food supply chain assurance should begin in the field with regular per-plant re-identification and logging.  This is challenging due to localisation and storage requirements. A proof-of-concept solution is provided, using an image-based, super-GNSS precision, robotic localisation per-plant re-identification technique with decentralised storage and blockchain technology. ORB descriptors and RANSAC are used to align in-field stones to previously captured stone images for localisation. Blockchain smart contracts act as a data broker for repeated update and retrieval of an image from a distributed file share system. Results suggest that localisation can be achieved to sub 100mm within a time window of 18 seconds. The implementation is open source and available at: {$\backslash$}url\{https://github.com/garry-clawson/Blockchain-Crop-Assurance-and-Localisation\}}
}

@article{lincoln50550,
           month = {August},
           title = {Trustworthy UAV relationships: Applying the Schema Action World taxonomy to UAVs and UAV swarm operations},
          author = {Katie J. Parnell and Joel Fischer and Jed Clark and Adrian Bodenman and Maria J. Galvez Trigo and Mario P. Brito and Mohammad Divband Soorati and Katherine Plant and Sarvapali Ramchurn},
       publisher = {Taylor and Francis},
            year = {2022},
             doi = {10.1080/10447318.2022.2108961},
         journal = {International Journal of Human?Computer Interaction},
        keywords = {ARRAY(0x555ae4eb0378)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50550/},
        abstract = {Human Factors play a significant role in the development and integration of avionic systems to ensure that they are trusted and can be used effectively. As Unoccupied Aerial Vehicle (UAV) technology becomes increasingly important to the aviation domain this holds true. The study presented in this paper aims to gain an understanding of UAV operators? trust requirements when piloting UAVs by utilising a popular aviation interview methodology (Schema World Action Research Method), in combination with key questions on trust identified from the literature. Interviews were conducted with six UAV operators, with a range of experience, to identify the trust requirements that UAV operators hold and their views on how UAV swarms may alter the trust relationship between the operator and the UAV technology. Both methodological and practical contributions of the research interviews are discussed.}
}

@inproceedings{lincoln49936,
       booktitle = {11th International Conference on Biomimetic and Biohybrid Systems (Living Machines)},
           month = {July},
           title = {Scaling a hippocampus model with GPU parallelisation and test-driven refactoring},
          author = {Jack Stevenson and Charles Fox},
       publisher = {Springer LNCS},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0390)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49936/},
        abstract = {The hippocampus is the brain area used for localisation,  mapping and episodic memory.  Humans and animals can outperform robotic systems in these tasks, so functional models of hippocampus may be useful to improve robotic navigation, such as for self-driving cars. 
Previous work developed a biologically plausible model of hippocampus based on Unitary Coherent Particle Filter (UCPF) and Temporal Restricted Boltzmann Machine, which was able to learn to navigate around small test environments.  However it was implemented in serial software, which becomes very slow as the environments and numbers of neurons scale up.  Modern GPUs can parallelize execution of neural networks. 
 The present Neural Software Engineering study develops a GPU accelerated version of the UCPF hippocampus software, using the formal Software Engineering techniques of profiling, optimisation and test-driven refactoring.  Results show that the model can greatly benefit from parallel execution, which may enable it to scale from toy environments and applications to real-world ones such as self-driving car navigation.   The refactored parallel code is released to the community as open source software as part of this publication.}
}

@inproceedings{lincoln48682,
       booktitle = {2022 IEEE International Conference on Robotics and Automation (ICRA)},
           month = {July},
           title = {Self-supervised Representation Learning for Reliable Robotic Monitoring of Fruit Anomalies},
          author = {Taeyeong Choi and Owen Would and Adrian Salazar-Gomez and Grzegorz Cielniak},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/ICRA46639.2022.9811954},
        keywords = {ARRAY(0x555ae4eb0930)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48682/},
        abstract = {Data augmentation can be a simple yet powerful tool for autonomous robots to fully utilise available data for self-supervised
identification of atypical scenes or objects. State-of-the-art augmentation methods arbitrarily embed "structural" peculiarity on typical images so that classifying these artefacts can provide guidance for learning representations for the detection of anomalous visual signals. In this paper, however, we argue that learning such structure-sensitive representations can be a suboptimal approach to some classes of anomaly (e.g., unhealthy fruits) which could be better recognised by a different type of visual element such as "colour". We thus propose Channel Randomisation as a novel data augmentation method for restricting neural networks to learn encoding of "colour irregularity" whilst predicting channel-randomised images to ultimately build reliable fruit-monitoring robots identifying atypical fruit qualities. Our experiments show that (1) this colour-based alternative can better learn representations for consistently accurate identification of fruit anomalies in various fruit species, and also, (2) unlike other methods, the validation accuracy can be utilised as a criterion for early stopping of training in practice due to positive correlation between the performance in the self-supervised colour-differentiation task and the subsequent detection rate of actual anomalous fruits. Also, the proposed approach is evaluated on a new agricultural dataset, Riseholme-2021, consisting of 3.5K strawberry images gathered by a mobile robot, which we share online to encourage active agri-robotics research.}
}

@inproceedings{lincoln49154,
       booktitle = {International Computer Music Conference},
           month = {July},
           title = {Towards Open Source Hardware Robotic Woodwind: an Internal Duct Flute Player},
          author = {James Bennett and Bethan Moncur and Kyle Fogarty and Garry Clawson and Charles Fox},
       publisher = {ICMA},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0948)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49154/},
        abstract = {We present the first open source hardware (OSH) design and build of an automated robotic internal duct flute player, including an artificial lung and pitch calibration system. Using a recorder as an introductory instrument, the system is designed to be as modular as possible, enabling  modification to fit further instruments across the woodwind family. Design considerations include the need to be as open to modification and accessible to as many people and instruments as possible.  The system is split into two physical modules: a blowing module and a fingering module, and three software modules: actuator control, pitch calibration and musical note processing via MIDI.
The system is able to perform beginner level recorder player melodies.}
}

@inproceedings{lincoln49153,
       booktitle = {International Computer Music Conference},
           month = {July},
           title = {RhythmTrain: making rhythmic sight reading training fun},
          author = {Reece Godfrey and Matthew Rimmer and Chris Headleand and Charles Fox},
       publisher = {ICMA},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0978)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49153/},
        abstract = {Rhythmic sight-reading forms a barrier to many musicians' progress. It is difficult to practice in isolation, as it is hard to get feedback on accuracy.  Different performers have different starting skills in different styles so it is hard to create a general curriculum for study.  It can be boring to rehearse the same rhythms many times.   We examine theories of motivation, engagement, and fun, and draw them together to design a novel training system, RhythmTrain.   This includes consideration of dynamic difficultly, gamification and juicy design.  The system uses machine learning to learn individual performers' strengths, weaknesses, and interests, and optimises the selection of rhythms presented to maximise their engagement.  An open source implementation is released as part of this publication.}
}

@article{lincoln50054,
           month = {July},
           title = {A survey on deep reinforcement learning for audio?based applications},
          author = {Siddique Latif and Heriberto Cuayahuitl and Farrukh Pervez and Fahad Shamshad and Hafiz Shehbaz Ali and Erik Cambria},
       publisher = {Springer Nature B.V.},
            year = {2022},
             doi = {10.1007/s10462-022-10224-2},
         journal = {Artifcial Intelligence Review},
        keywords = {ARRAY(0x555ae4eb0990)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50054/},
        abstract = {Deep reinforcement learning (DRL) is poised to revolutionise the field of artificial intelligence (AI) by endowing autonomous systems with high levels of understanding of the real world. Currently, deep learning (DL) is enabling DRL to effectively solve various intractable problems in various fields including computer vision, natural language processing, healthcare, robotics, to name a few. Most importantly, DRL algorithms are also being employed in audio signal processing to learn directly from speech, music and other sound signals in order to create audio-based autonomous systems that have many promising applications in the real world. In this article, we conduct a comprehensive survey on the progress of DRL in the audio domain by bringing together research studies across different but related areas in speech and music. We begin with an introduction to the general field of DL and reinforcement learning (RL), then progress to the main DRL methods and their applications in the audio domain. We conclude by presenting important challenges faced by audio-based DRL agents and by highlighting open areas for future research and investigation. The findings of this paper will guide researchers interested in DRL for the audio domain.}
}

@article{lincoln49926,
          volume = {28},
          number = {2},
           month = {June},
          author = {Archie Drake and Isabel Sassoon and Panos Balatsoukas and Talya Porat and Mark Ashworth and Ellen Wright and Vasa Curcin and Martin Chapman and Nadin Kokciyan and Modgil Sanjay and Elizabeth Sklar and Simon Parsons},
           title = {The relationship of socio-demographic factors and patient attitudes to connected health technologies: a survey of stroke survivors.},
       publisher = {SAGE Publications},
            year = {2022},
         journal = {Health Informatics Journal},
             doi = {10.1177\%2F14604582221102373},
        keywords = {ARRAY(0x555ae4eb09c0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49926/},
        abstract = {More evidence is needed on technology implementation for remote monitoring and self-management across the various settings relevant to chronic conditions. This paper describes the findings of a survey designed to explore the relevance of socio-demographic factors to attitudes towards connected health technologies in a community of patients. Stroke survivors living in the UK were invited to answer questions about themselves and about their attitudes to a prototype remote monitoring and self-management app developed around their preferences. Eighty (80) responses were received and analysed, with limitations and results presented in full. Socio-demographic factors were not found to be associated with variations in participants? willingness to use the system and attitudes to data sharing. Individuals? levels of interest in relevant technology was suggested as a more important determinant of attitudes. These observations run against the grain of most relevant literature to date, and tend to underline the importance of prioritising patient-centred participatory research in efforts to advance connected health technologies.}
}

@incollection{lincoln49943,
           month = {June},
          author = {Amir Ghalamzan Esfahani and Gautham Das and Iain Gould and Payam Zarafshan and Vishnu Rajendran Sugathakumary and James Heselden and Amir Badiee and Isobel Wright and Simon Pearson},
       booktitle = {Solar Energy Advancements in Agriculture and Food Production Systems},
          editor = {Shiva Gorjian and Pietro Elia Campana},
           title = {Applications of robotic and solar energy in precision agriculture and smart farming},
       publisher = {Elsevier},
             doi = {10.1016/C2020-0-03304-9},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb09f0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49943/},
        abstract = {Population growth, healthy diet requirements, and changes in food demand towards a more plant-based protein diet increase existing pressures for food production and land-use change. The increasing demand and current agriculture approaches jeopardise the health of soil and biodiversity which will affect the future ecosystem and food production. One of the solutions to the increasing pressure on agriculture is PA which offers to minimize the use of resources, including land, water, energy, herbicides, and pesticides, and maximise the yield. The development of PA requires a multidisciplinary approach including engineering, AI, and robotics. Robots will play a crucial role in delivering PA and will pave the way toward sustainable healthy food production.
While PA is the way forward in the agriculture industry the related devices to collect various supporting data and also the agriculture machinery need to be run by clean energy to ensure sustainable growth in the sector. Among renewable energy sources, solar energy and solar PV have shown a great potential to dominate the future of sustainable energy and agriculture developments. For developing PV in rural and off-grid agriculture farms and lands the use of solar-powered devices is unavoidable. Such a transition to photovoltaic agriculture requires significant changes to agricultural practices and the adoption of smart technologies like IoT, robotics, and WSN.
Future food production needs to adapt to changing consumer behaviour along with the rapidly deteriorating environmental factors. PA is also a response to future food production challenges where one of its key aims is to improve sustainability to minimize the use of diminishing resources and minimize GHG emissions by use of renewable energy sources. Along with these adaptations, the new technologies should be using green energy sources (i.e., solar energy) for meeting the power requirements for sustainable developments of these smart technologies. Since there is a rapid inflow of robotic technologies into the agriculture sector, increasing power demand is inevitable, especially in remote areas where PV-based systems can play a game-changing role. It is expected for the agriculture sector to witness a technological revolution toward sustainable food production which cannot be achieved without solar PV development and support.}
}

@inproceedings{lincoln50521,
       booktitle = {17th International Conference on Intelligent Autonomous Systems},
           month = {June},
           title = {Benchmark of Sampling-Based Optimizing Planners for Outdoor Robot Navigation},
          author = {Fetullah Atas and Grzegorz Cielniak and Lars Grimstad},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0a20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50521/},
        abstract = {This paper evaluates Sampling-Based Optimizing (SBO) planners from the Open Motion Planning Library (OMPL) in the context of mobile robot navigation in outdoor environments. Many SBO planners have been proposed, and determining performance differences among these planners for path planning problems can be time-consuming and ambiguous. The probabilistic nature of SBO planners can also complicate this procedure, as different results for the same planning problem can be obtained even in consecutive queries from the same planner. We compare all available SBO planners in OMPL with an automated planning problem generation method designed specifically for outdoor robot navigation scenarios. Several evaluation metrics are chosen, such as the length, smoothness, and success rate of the resulting path, and probability distributions for metrics are presented. With the experimental results obtained, clear recommendations on high-performing planners for mobile robot path planning problems are made, which will be useful to researchers and practitioners in mobile robot planning and navigation.}
}

@article{lincoln49874,
          volume = {136},
           month = {June},
          author = {Hamdi Yahyaoui and Zakaria Maamar and Mohammed Al-Khafajiy and Hamid Al-Hamadi},
           title = {Trust-based management in IoT federations},
       publisher = {Elsevier},
            year = {2022},
         journal = {Future Generation Computer Systems},
             doi = {10.1016/j.future.2022.06.003},
           pages = {182--192},
        keywords = {ARRAY(0x555ae4eb0a50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49874/},
        abstract = {This paper presents a trust-based evolutionary game model for managing Internet-of-Things (IoT) federations. The model adopts trust-based payoff to either reward or penalize things based on the behaviors they expose. The model also resorts to monitoring these behaviors to ensure that the share of untrustworthy things in a federation does not hinder the good functioning of trustworthy things in this federation. The trust scores are obtained using direct experience with things and feedback from other things and are integrated into game strategies. These strategies capture the dynamic nature of federations since the population of trustworthy versus untrustworthy things changes over time with the aim of retaining the trustworthy ones. To demonstrate the technical doability of the game strategies along with rewarding/penalizing things, a set of experiments were carried out and results were benchmarked as per the existing literature. The results show a better mitigation of attacks such as bad-mouthing and ballot-stuffing on trustworthy things.}
}

@article{lincoln49961,
          volume = {7},
          number = {3},
           month = {June},
          author = {Francesco Del Duchetto and Marc Hanheide},
           title = {Learning on the Job: Long-Term Behavioural Adaptation in Human-Robot Interactions},
       publisher = {IEEE},
            year = {2022},
         journal = {IEEE Robotics and Automation Letters},
             doi = {10.1109/LRA.2022.3178807},
           pages = {6934--6941},
        keywords = {ARRAY(0x555ae4eb0a80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49961/},
        abstract = {In this work, we propose a framework for allowing autonomous robots deployed for extended periods of time in public spaces to adapt their own behaviour online from user interactions. The robot behaviour planning is embedded in a Reinforcement Learning (RL) framework, where the objective is maximising the level of overall user engagement during the interactions. We use the Upper-Confidence-Bound Value-Iteration (UCBVI) algorithm, which gives a helpful way of managing the exploration-exploitation trade-off for real-time interactions. An engagement model trained end-to-end generates the reward function in real-time during policy execution. We test this approach in a public museum in Lincoln (U.K.), where the robot is deployed as a tour guide for the visitors. Results show that after a couple of months of exploration, the robot policy learned to maintain the engagement of users for longer, with an increase of 22.8\% over the initial static policy in the number of items visited during the tour and a 30\% increase in the probability of completing the tour. This work is a promising step toward behavioural adaptation in long-term scenarios for robotics applications in social settings.}
}

@article{lincoln49800,
           month = {June},
           title = {A comparison of neural?based visual recognisers for speech activity detection},
          author = {Sajjadali Raza and Heriberto Cuayahuitl},
       publisher = {Springer},
            year = {2022},
             doi = {10.1007/s10772-021-09956-3},
         journal = {International Journal of Speech Technology},
        keywords = {ARRAY(0x555ae4eb0ab0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49800/},
        abstract = {Existing literature on speech activity detection (SAD) highlights different approaches within neural networks but does not provide a comprehensive comparison to these methods. This is important because such neural approaches often require hardware-intensive resources. In this article, we provide a comparative analysis of three different approaches: classification with still images (CNN model), classification based on previous images (CRNN model), and classification of sequences of images (Seq2Seq model). Our experimental results using the Vid-TIMIT dataset show that the CNN model can achieve an accuracy of 97\% whereas the CRNN and Seq2Seq models increase the classification to 99\%. Further experiments show that the CRNN model is almost as accurate as the Seq2Seq model (99.1\% vs. 99.6\% of classification accuracy, respectively) but 57\% faster to train (326 vs. 761 secs. per epoch).}
}

@article{lincoln49340,
          volume = {197},
           month = {June},
          author = {Xiaodong Li and Rob Lloyd and Sarah Ward and Jonathan Cox and Shaun Coutts and Charles Fox},
           title = {Robotic crop row tracking around weeds using cereal-specific features},
       publisher = {Elsevier},
         journal = {Computers and Electronics in Agriculture},
             doi = {10.1016/j.compag.2022.106941},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0ae0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49340/},
        abstract = {Crop row following is especially challenging in narrow row cereal crops, such as wheat. Separation between plants within a row disappears at an early growth stage, and canopy closure between rows, when leaves from different rows start to occlude each other, occurs three to four months after the crop emerges. Canopy closure makes it challenging to identify separate rows through computer vision as clear lanes become obscured. Cereal crops are grass species and so their leaves have a predictable shape and orientation. We introduce an image processing pipeline which exploits grass shape to identify and track rows. The key observation exploited is that leaf orientations tend to be vertical along rows and horizontal between rows due to the location of the stems within the rows. Adaptive mean-shift clustering on Hough line segments is then used to obtain lane centroids, and followed by a nearest neighbor data association creating lane line candidates in 2D space. Lane parameters are fit with linear regression and a Kalman filter is used for tracking lanes between frames. The method is achieves sub-50 mm accuracy which is sufficient for placing a typical agri-robot?s wheels between real-world, early-growth wheat crop rows to drive between them, as long as the crop is seeded in a wider spacing such as 180 mm row spacing for an 80 mm wheel width robot.}
}

@article{lincoln49460,
          volume = {3},
           month = {June},
          author = {Simon Pearson and Carolina Camacho?Villa and Ravi Valluru and Gaju Oorbessy and Mini Rai and Iain Gould and Steve Brewer and Elizabeth Sklar},
           title = {Robotics and Autonomous Systems for Net Zero Agriculture},
       publisher = {Springer},
            year = {2022},
         journal = {Current Robotics Reports},
             doi = {10.1007/s43154-022-00077-6},
           pages = {57--64},
        keywords = {ARRAY(0x555ae4eb0b10)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49460/},
        abstract = {The paper discusses how robotics and autonomous systems (RAS) are being deployed to decarbonise
agricultural production. The climate emergency cannot be ameliorated without dramatic reductions in greenhouse gas emissions across the agri-food sector. This review outlines the transformational role for robotics in the agri-food system and considers where research and focus might be prioritised.}
}

@inproceedings{lincoln49183,
       booktitle = {Social Robot Navigation: Advances and Evaluation (SEANavBench 2022)},
           month = {May},
           title = {Game Theory, Proxemics and Trust for Self-Driving Car Social Navigation},
          author = {Fanta Camara and Charles Fox},
       publisher = {Social Robot Navigation: Advances and Evaluation},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0b40)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49183/},
        abstract = {To navigate in human social spaces, self-driving cars and other robots must show social intelligence. This involves predicting and planning around pedestrians, understanding their personal space, and establishing trust with them. The present paper gives an overview of our ongoing work on modelling and controlling human?self-driving car interactions using game theory, proxemics and trust, and unifying these fields via quantitative models and robot controllers.}
}

@article{lincoln47700,
          volume = {193},
           month = {May},
          author = {Chao Qi and Junfeng Gao and Simon Pearson and Helen Harman and Kunjie Chen and Lei Shu},
           title = {Tea chrysanthemum detection under unstructured environments using the TC-YOLO model},
       publisher = {Elsevier},
         journal = {Expert Systems with Applications},
             doi = {10.1016/j.eswa.2021.116473},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0b70)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/47700/},
        abstract = {Tea chrysanthemum detection at its flowering stage is one of the key components for selective chrysanthemum harvesting robot development. However, it is a challenge to detect flowering chrysanthemums under unstructured field environments given variations on illumination, occlusion and object scale. In this context, we propose a highly fused and lightweight deep learning architecture based on YOLO for tea chrysanthemum detection (TC-YOLO). First, in the backbone component and neck component, the method uses the Cross-Stage Partially Dense network (CSPDenseNet) and the Cross-Stage Partial ResNeXt network (CSPResNeXt) as the main networks, respectively, and embeds custom feature fusion modules to guide the gradient flow. In the final head component, the method combines the recursive feature pyramid (RFP) multiscale fusion reflow structure and the Atrous Spatial Pyramid Pool (ASPP) module with cavity convolution to achieve the detection task. The resulting model was tested on 300 field images using a data enhancement strategy combining flipping and rotation, showing that under the NVIDIA Tesla P100 GPU environment, if the inference speed is 47.23 FPS for each image (416 {$\times$} 416), TC-YOLO can achieve the average precision (AP) of 92.49\% on our own tea chrysanthemum dataset. Through further validation, it was found that overlap had the least effect on tea chrysanthemum detection, and illumination had the greatest effect on tea chrysanthemum detection. In addition, this method (13.6 M) can be deployed on a single mobile GPU, and it could be further developed as a perception system for a selective chrysanthemum harvesting robot in the future.}
}

@inproceedings{lincoln49037,
       booktitle = {The 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2022)},
           month = {May},
           title = {Multi-agent Task Allocation for Fruit Picker Team Formation (Extended Abstract)},
          author = {Helen Harman and Elizabeth Sklar},
       publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
            year = {2022},
           pages = {1618--1620},
        keywords = {ARRAY(0x555ae4eb0ba0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49037/},
        abstract = {Multi-agent task allocation methods seek to distribute a set of tasks fairly amongst a set of agents. In real-world settings, such as fruit farms, human labourers undertake harvesting tasks, organised each day by farm manager(s) who assign workers to the fields that are ready to be harvested. The work presented here considers three challenges identified in the adaptation of a multi-agent task allocation methodology applied to the problem of distributing workers to fields. First, the methodology must be fast to compute so that it can be applied on a daily basis. Second, the incremental acquisition of harvesting data used to make decisions about worker-task assignments means that a data-backed approach must be derived from incomplete information as the growing season unfolds. Third, the allocation must take ?fairness? into account and consider worker motivation. Solutions to these challenges are demonstrated, showing statistically significant results based on the operations at a soft fruit farm during their 2020 and 2021 harvesting seasons.}
}

@article{lincoln49062,
          volume = {18},
          number = {4},
           month = {April},
          author = {Magd Badaoui and Pedro Buigues and Denes Berta and Guarav Mandana and Hankang Gu and Tam{\'a}s F{\"o}ldes and Callum Dickson and Viktor Hornak and Mitsunori Kato and Carla Molteni and Simon Parsons and Edina Rosta},
           title = {Combined Free-Energy Calculation and Machine Learning Methods for Understanding Ligand Unbinding Kinetics},
       publisher = {American Chemical Society},
            year = {2022},
         journal = {Journal of Chemical Theory and Computation},
             doi = {10.1021/acs.jctc.1c00924},
           pages = {2543--2555},
        keywords = {ARRAY(0x555ae4eb0bd0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49062/},
        abstract = {The determination of drug residence times, which define the time an inhibitor is in complex with its
target, is a fundamental part of the drug discovery process. Synthesis and experimental
measurements of kinetic rate constants are, however, expensive, and time-consuming. In this work,
we aimed to obtain drug residence times computationally. Furthermore, we propose a novel
algorithm to identify molecular design objectives based on ligand unbinding kinetics. We designed
an enhanced sampling technique to accurately predict the free energy profiles of the ligand
unbinding process, focusing on the free energy barrier for unbinding. Our method first identifies
unbinding paths determining a corresponding set of internal coordinates (IC) that form contacts
between the protein and the ligand, it then iteratively updates these interactions during a series of
biased molecular-dynamics (MD) simulations to reveal the ICs that are important for the whole of
the unbinding process. Subsequently, we performed finite temperature string simulations to obtain
the free energy barrier for unbinding using the set of ICs as a complex reaction coordinate.
Importantly, we also aimed to enable further design of drugs focusing on improved residence 
times. To this end, we developed a supervised machine learning (ML) approach with inputs from
unbiased ?downhill? trajectories initiated near the transition state (TS) ensemble of the string
unbinding path. We demonstrate that our ML method can identify key ligand-protein interactions
driving the system through the TS. Some of the most important drugs for cancer treatment are
kinase inhibitors. One of these kinase targets is Cyclin Dependent Kinase 2 (CDK2), an appealing
target for anticancer drug development. Here, we tested our method using two different CDK2
inhibitors for potential further development of these compounds. We compared the free energy
barriers obtained from our calculations with those observed in available experimental data. We
highlighted important interactions at the distal ends of the ligands that can be targeted for
improved residence times. Our method provides a new tool to determine unbinding rates, and to
identify key structural features of the inhibitors that can be used as starting points for novel design
strategies in drug discovery.}
}

@inproceedings{lincoln49117,
       booktitle = {2021 2nd International Symposium on Automation, Information and Computing (ISAIC 2021)},
           month = {April},
           title = {Temperature-based Collision Detection in Extreme Low Light Condition with Bio-inspired LGMD Neural Network},
          author = {Yicheng Zhang and Cheng Hu and Mei Liu and Hao Luan and Fang Lei and Heriberto Cuayahuitl and Shigang Yue},
       publisher = {IOP Publishing Ltd},
            year = {2022},
             doi = {10.1088/1742-6596/2224/1/012004},
        keywords = {ARRAY(0x555ae4eb0c00)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49117/},
        abstract = {It is an enormous challenge for intelligent vehicles to avoid collision accidents at night because of the extremely poor light conditions. Thermal cameras can capture temperature map at night, even with no light sources and are ideal for collision detection in darkness. However, how to extract collision cues efficiently and effectively from the captured temperature map with limited computing resources is still a key issue to be solved. Recently, a bio-inspired neural network LGMD has been proposed for collision detection successfully, but for daytime and visible light. Whether it can be used for temperature-based collision detection or not remains unknown. In this study, we proposed an improved LGMD-based visual neural network for temperature-based collision detection at extreme light conditions. We show in this study that the insect inspired visual neural network can pick up the expanding temperature differences of approaching objects as long as the temperature difference against its background can be captured by a thermal sensor. Our results demonstrated that the proposed LGMD neural network can detect collisions swiftly based on the thermal modality in darkness; therefore, it can be a critical collision detection algorithm for autonomous vehicles driving at night to avoid fatal collisions with humans, animals, or other vehicles.}
}

@article{lincoln46497,
           month = {April},
           title = {Robotic Exploration for Learning Human Motion Patterns},
          author = {Sergio Molina Mellado and Grzegorz Cielniak and Tom Duckett},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/TRO.2021.3101358},
         journal = {IEEE Transaction on Robotics},
        keywords = {ARRAY(0x555ae4eb0c30)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/46497/},
        abstract = {Understanding how people are likely to move is key to efficient and safe robot navigation in human environments. However, mobile robots can only observe a fraction of the environment at a time, while the activity patterns of people may also change at different times. This paper introduces a new methodology for mobile robot exploration to maximise the knowledge of human activity patterns by deciding where and when to collect observations. We introduce an exploration policy driven by the entropy levels in a spatio-temporal map of pedestrian flows, and compare multiple spatio-temporal exploration strategies including both informed and uninformed approaches. The evaluation is performed by simulating mobile robot exploration using real sensory data from three long-term pedestrian datasets. The results show that for certain scenarios the models built with proposed exploration system can better predict the flow patterns than uninformed strategies, allowing the robot to move in a more socially compliant way, and that the exploration ratio is a key factor when it comes to the model prediction accuracy.}
}

@article{lincoln49488,
          volume = {9},
           month = {March},
          author = {Craig R. Carignan and Renaud Detry and Mini Rai Saaj and Giacomo Marani and Joshua D. Vander Hook},
           title = {Editorial: Robotic In-Situ Servicing, Assembly and Manufacturing},
       publisher = {Frontiers Media},
         journal = {Frontiers in Robotics and AI},
             doi = {10.3389/frobt.2022.887506},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0c60)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49488/},
        abstract = {This research topic is dedicated to articles focused on robotic manufacturing, assembly, and servicing utilizing in-situ resources, especially for space robotic applications. The purpose was to gather resource material for researchers from a variety of disciplines to identify common themes, formulate problems, and share promising technologies for autonomous large-scale construction, servicing, and assembly robots. The articles under this special topic provide a snapshot of several key technologies under development to support on-orbit robotic servicing, assembly, and manufacturing.}
}

@inproceedings{lincoln48675,
       booktitle = {AAAI - AI for Agriculture and Food Systems},
           month = {February},
           title = {Multiple broccoli head detection and tracking in 3D point clouds for autonomous harvesting},
          author = {Hector A. Montes and Grzegorz Cielniak},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0c90)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48675/},
        abstract = {This paper explores a tracking method of broccoli heads that combine a Particle Filter and 3D features detectors to track multiple crops in a sequence of 3D data frames. The tracking accuracy is verified based on a data association method that matches detections with tracks over each frame. The particle filter incorporates a simple motion model to produce the posterior particle distribution, and a similarity model as probability function to measure the tracking accuracy. The method is tested with datasets of two broccoli varieties collected in planted fields from two different countries. Our evaluation shows the tracking method reduces the number of false negatives produced by the detectors on their own. In addition, the method accurately detects and tracks the 3D locations of broccoli heads relative to the vehicle at high frame rates}
}

@article{lincoln48358,
           month = {February},
          author = {Fang Lei and Zhiping Peng and Mei Liu and Jigen Peng and Vassilis Cutsuridis and Shigang Yue},
           title = {A Robust Visual System for Looming Cue Detection Against Translating Motion},
       publisher = {IEEE},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
             doi = {10.1109/TNNLS.2022.3149832},
           pages = {1--15},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0cc0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48358/},
        abstract = {Collision detection is critical for autonomous vehicles or robots to serve human society safely. Detecting looming objects robustly and timely plays an important role in collision avoidance systems. The locust lobula giant movement detector (LGMD1) is specifically selective to looming objects which are on a direct collision course. However, the existing LGMD1 models can not distinguish a looming object from a near and fast translatory moving object, because the latter can evoke a large amount of excitation that can lead to false LGMD1 spikes. This paper presents a new visual neural system model (LGMD1) that applies a neural competition mechanism within a framework of separated ON and OFF pathways to shut off the translating response. The competition-based approach responds vigorously to monotonous ON/OFF responses resulting from a looming object. However, it does not respond to paired ON-OFF responses that result from a translating object, thereby enhancing collision selectivity. Moreover, a complementary denoising mechanism ensures reliable collision detection. To verify the effectiveness of the model, we have conducted systematic comparative experiments on synthetic and real datasets. The results show that our method exhibits more accurate discrimination between looming and translational events -- the looming motion can be correctly detected. It also demonstrates that the proposed model is more robust than comparative models.}
}

@article{lincoln49162,
           month = {February},
           title = {A Robust Visual System for Looming Cue Detection Against Translation Motion},
          author = {Fang Lei and Zhiping Peng and Mei Liu and Jigen Peng and Vassilis Cutsuridis and Shigang Yue},
       publisher = {IEEE},
            year = {2022},
             doi = {10.1109/TNNLS.2022.3149832},
         journal = {IEEE Transactions on Neural Networks and Learning Systems},
        keywords = {ARRAY(0x555ae4eb0cf0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49162/},
        abstract = {Collision detection is critical for autonomous vehicles or robots to serve human society safely. Detecting looming objects robustly and timely plays an important role in collision avoidance systems. The locust lobula giant movement detector (LGMD1) is specifically selective to looming objects which are on a direct collision course. However, the existing LGMD1 models cannot distinguish a looming object from a near and fast translatory moving object, because the latter can evoke a large amount of excitation that can lead to false LGMD1 spikes. This article presents a new visual neural system model (LGMD1) that applies a neural competition mechanism within a framework of separated ON and OFF pathways to shut off the translating response. The competition-based approach responds vigorously to
monotonous ON/OFF responses resulting from a looming object. However, it does not respond to paired ON?OFF responses that result from a translating object, thereby enhancing collision selectivity. Moreover, a complementary denoising mechanism ensures reliable collision detection. To verify the effectiveness of the model, we have conducted systematic comparative experiments on synthetic and real datasets. The results show that our method exhibits more accurate discrimination between looming and translational events{--}the looming motion can be correctly detected. It also demonstrates that the proposed model is more robust than comparative models.}
}

@inproceedings{lincoln48676,
       booktitle = {AI for Agriculture and Food Systems},
           month = {January},
           title = {Channel Randomisation with Domain Control for Effective Representation Learning of Visual Anomalies in Strawberries},
          author = {Taeyeong Choi and Grzegorz Cielniak},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0d20)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48676/},
        abstract = {Channel Randomisation (CH-Rand) has appeared as a key data augmentation technique for anomaly detection on fruit
images because neural networks can learn useful representations of colour irregularity whilst classifying the samples
from the augmented "domain". Our previous study has revealed its success with significantly more reliable performance than other state-of-the-art methods, largely specialised for identifying structural implausibility on non-agricultural objects (e.g., screws). In this paper, we further enhance CH-Rand with additional guidance to generate more informative data for representation learning of anomalies in fruits as most of its fundamental designs are still maintained. To be specific, we first control the "colour space" on which CH-Rand is executed to investigate whether a particular model{--}e.g., HSV , YCbCr, or L*a*b* {--}can better help synthesise realistic anomalies than the RGB, suggested in the original design. In addition, we develop a learning "curriculum" in which CH-Rand shifts its augmented domain to gradually increase the difficulty of the examples for neural networks to classify. To the best of our best knowledge, we are the first to connect the concept of curriculum to self-supervised representation learning for anomaly detection. Lastly, we perform evaluations with the Riseholme-2021 dataset, which contains {\ensuremath{>}} 3.5K real strawberry images at various growth levels along with anomalous examples. Our experimental results show that the trained models with the proposed strategies can achieve over 16\% higher scores of AUC-PR with more than three times less variability than the naive CH-Rand whilst using the same deep networks and data.}
}

@article{lincoln49094,
           month = {January},
           title = {A Looming Spatial Localization Neural Network Inspired by MLG1 Neurons in the Crab Neohelice},
          author = {Hao Luan and Qingbing Fu and Yicheng Zhang and Mu Hua and Shengyong Chen and Shigang Yue},
       publisher = {Frontiers Media},
            year = {2022},
             doi = {10.3389/fnins.2021.787256},
         journal = {Frontiers in Neuroscience},
        keywords = {ARRAY(0x555ae4eb0d50)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49094/},
        abstract = {Similar to most visual animals, the crab Neohelice granulata relies predominantly on visual information to escape from predators, to track prey and for selecting mates. It, therefore, needs specialized neurons to process visual information and determine the spatial location of looming objects. In the crab Neohelice granulata, the Monostratified Lobula Giant type1 (MLG1) neurons have been found to manifest looming sensitivity with finely tuned capabilities of encoding spatial location information. MLG1s neuronal ensemble can not only perceive the location of a looming stimulus, but are also thought to be able to influence the direction of movement continuously, for example, escaping from a threatening, looming target in relation to its position. Such specific characteristics make the MLG1s unique compared to normal looming detection neurons in invertebrates which can not localize spatial looming. Modeling the MLG1s ensemble is not only critical for elucidating the mechanisms underlying the functionality of such neural circuits, but also important for developing new autonomous, efficient, directionally reactive collision avoidance systems for robots and vehicles. However, little computational modeling has been done for implementing looming spatial localization analogous to the specific functionality of MLG1s ensemble. To bridge this gap, we propose a model of MLG1s and their pre-synaptic visual neural network to detect the spatial location of looming objects. The model consists of 16 homogeneous sectors arranged in a circular field inspired by the natural arrangement of 16 MLG1s? receptive fields to encode and convey spatial information concerning looming objects with dynamic expanding edges in different locations of the visual field. Responses of the proposed model to systematic real-world visual stimuli match many of the biological characteristics of MLG1 neurons.
The systematic experiments demonstrate that our proposed MLG1s model works effectively and robustly to perceive and localize looming information, which could be a promising candidate for intelligent machines interacting within dynamic environments free of collision. This study also sheds light upon a new type of neuromorphic visual sensor strategy that can extract looming objects with locational information in a quick and reliable manner.}
}

@inproceedings{lincoln49913,
       booktitle = {IEEE International Conference on Automation Science and Engineering (CASE)},
           title = {Towards Infield Navigation: leveraging simulated data for crop row detection},
          author = {Rajitha De Silva and Grzegorz Cielniak and Junfeng Gao},
       publisher = {IEEE},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0d80)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49913/},
        abstract = {Agricultural datasets for crop row detection are often bound by their limited number of images. This restricts
the researchers from developing deep learning based models  for precision agricultural tasks involving crop row detection. We suggest the utilization of small real-world datasets alongwith additional data generated by simulations to yield similar crop row detection performance as that of a model trained with a large real world dataset. Our method could reach the performance of a deep learning based crop row detection model trained with real-world data by using 60\% less labelled realworld data. Our model performed well against field variations such as shadows, sunlight and growth stages. We introduce an automated pipeline to generate labelled images for crop row detection in simulation domain. An extensive comparison is done to analyze the contribution of simulated data towards reaching robust crop row detection in various real-world field scenarios.}
}

@inproceedings{lincoln48058,
       booktitle = {HCI International Conference 2022},
           title = {Educational robots and their control interfaces: how can we make them more accessible for Special Education?},
          author = {Maria Galvez Trigo and Penelope Standen and Sue Cobb},
       publisher = {Springer},
            year = {2022},
             doi = {10.1007/978-3-031-05039-8\_2},
        keywords = {ARRAY(0x555ae4eb0db0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48058/},
        abstract = {Existing design standards and guidelines provide guidance on what factors to consider to produce interactive systems that are not only usable, but also accessible. However, these standards are usually general, and when it comes to designing an interactive system for children with Learning Difficulties or Disabilities (LD) and/or Autism Spectrum Conditions (ASC) they are often not specific enough, leading to systems that are not fit for that purpose. If we dive into the area of educational robotics, we face even more issues, in part due to the relative novelty of these technologies. In this paper, we present an analysis of 26 existing educational robots and the interfaces used to control them. Furthermore, we present the results of running focus groups and a questionnaire with 32 educators with expertise in Special Education and parents at four different institutions, to explore potential accessibility issues of existing systems and to identify desirable characteristics. We conclude introduc- ing an initial set of design recommendations, to complement existing design standards and guidelines, that would help with producing future more accessible control interfaces for educational robots, with an especial focus on helping pupils with LDs and/or ASC.}
}

@inproceedings{lincoln48515,
       booktitle = {Ital-IA 2022},
           title = {From Human Perception and Action Recognition to Causal Understanding of Human-Robot Interaction in Industrial Environments},
          author = {Stefano Ghidoni and Matteo Terreran and Daniele Evangelista and Emanuele Menegatti and Christian Eitzinger and Enrico Villagrossi and Nicola Pedrocchi and Nicola Castaman and Marcin Malecha and Sariah Mghames and Luca Castri and Marc Hanheide and Nicola Bellotto},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb0de0)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48515/},
        abstract = {Human-robot collaboration is migrating from lightweight robots in laboratory environments to industrial applications, where heavy tasks and powerful robots are more common. In this scenario, a reliable perception of the humans involved in the process and related intentions and behaviors is fundamental. This paper presents two projects investigating the use of robots in relevant industrial scenarios, providing an overview of how industrial human-robot collaborative tasks can be successfully addressed.}
}

@inproceedings{lincoln50057,
       booktitle = {Advances in Practical Applications of Agents, Multi-Agent Systems, and Complex Systems Simulation. The PAAMS Collection},
           title = {Multi-Agent Task Allocation Techniques for Harvest Team Formation},
          author = {Helen Harman and Elizabeth Sklar},
       publisher = {Springer},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb1e38)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/50057/},
        abstract = {With increasing demands for soft fruit and shortages of seasonal workers, farms are seeking innovative solutions for efficiently managing their workforce. The harvesting workforce is typically organised by farm managers who assign workers to the fields that are ready to be harvested. They aim to minimise staff time (and costs) and distribute work fairly, whilst still picking all ripe fruit within the fields that need to be harvested. This paper posits that this problem can be addressed using multi-criteria, multi-agent task allocation techniques. The work presented compares the application of Genetic Algorithms (GAs) vs auction-based approaches to the challenge of assigning workers with various skill sets to fields with various estimated yields. These approaches are evaluated alongside a previously suggested method and the teams that were manually created by a farm manager during the 2021 harvesting season. Results indicate that the GA approach produces more efficient team allocations than the alternatives assessed.}
}

@inproceedings{lincoln49036,
       booktitle = {The 23rd International Workshop on Multi-Agent-Based Simulation (MABS))},
           title = {Challenges for Multi-Agent Based Agricultural Workforce Management},
          author = {Helen Harman and Elizabeth I. Sklar},
       publisher = {Springer},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb1e68)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49036/},
        abstract = {Multi-agent task allocation methods seek to distribute a set of tasks fairly amongst a set of agents. In real-world settings, such as soft fruit farms, human labourers undertake harvesting tasks, assigned by farm managers. The work here explores the application of artificial intelligence planning methodologies to optimise the existing workforce and applies multi-agent based simulation to evaluate the efficacy of the AI strategies. Key challenges threatening the acceptance of such an approach are highlighted and solutions are evaluated experimentally.}
}

@inproceedings{lincoln49118,
       booktitle = {CUI ?22: Conversational User Interfaces Conference},
           title = {Effects of Wording and Gendered Voices on Acceptability of Voice Assistants in Future Autonomous Vehicles},
          author = {Iris Jestin and Joel E. Fischer and Maria J. Galvez Trigo and David R. Large and Gary E. Burnett},
       publisher = {ACM},
            year = {2022},
             doi = {10.1145/3543829.3543836},
        keywords = {ARRAY(0x555ae4eb1e98)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49118/},
        abstract = {Voice assistants in future autonomous vehicles may play a major role in supporting the driver during periods of a transfer of control with the vehicle (handover and handback). However, little is known about the effects of different qualities of the voice assistant on its perceived acceptability, and thus its potential to support the driver?s trust in the vehicle. A desktop study was carried out with 18 participants, investigating the effects of three gendered voices and different wording of prompts during handover and handback driving scenarios on measures of acceptability. Participants rated prompts by the voice assistant in nine different driving scenarios, using 5-point Likert style items in a during and post-study questionnaire as well as a short interview at the end. A commanding/formally worded prompt was rated higher on most of the desirable measures of acceptability as compared to an informally worded prompt. The ?Matthew? voice used was perceived to be less artificial and more desirable than the ?Joanna? voice and the gender-ambiguous ?Jordan? voice; however, we caution against interpreting these results as indicative of a general preference of gender, and instead discuss our results to throw light on the complex socio-phonetic nature of voices (including gender) and wording of voice assistants, and the need for careful consideration while designing the same. Results gained facilitate the drawing of insights needed to take better care when designing the voice and wording for voice assistants in future autonomous vehicles.}
}

@article{lincoln49072,
           title = {Artificial intelligence and ethics within the food sector: developing a common language for technology adoption across the supply chain},
          author = {Louise Manning and Steve Brewer and Peter Craigon and P.J Frey and Anabel Gutierrez and Naomi Jacobs and Samantha Kanza and Samuel Munday and Justin Sacks and Simon Pearson},
       publisher = {Elsevier},
            year = {2022},
         journal = {Trends in Food Science and Technology},
        keywords = {ARRAY(0x555ae4eb1ec8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49072/},
        abstract = {Background:  The use of artificial intelligence (AI) is growing in food supply chains. The ethical language associated with food supply and technology is contextualised and framed by the meaning given to it by stakeholders. Failure to differentiate between these nuanced meanings can create a barrier to technology adoption and reduce the benefit derived.
Scope and approach: The aim of this review paper is to consider the embedded ethical language used by stakeholders who collaborate in the adoption of AI in food supply chains.    Ethical perspectives frame this literature review and provide structure to consider how to shape a common discourse to build trust in, and frame more considered utilisation of, AI in food supply chains to the benefit of users, and wider society. 
Key findings and conclusions: Whilst the nature of data within the food system is much broader than the personal data covered by the European Union General Data Protection Regulation (GDPR), the ethical issues for computational and AI systems are similar and can be considered in terms of particular aspects: transparency, traceability, explainability, interpretability, accessibility, accountability and responsibility. The outputs of this research assist in giving a more rounded understanding of the language used, exploring the ethical interaction of aspects of AI used in food supply chains and also the management activities and actions that can be adopted to improve the applicability of AI technology, increase engagement and derive greater performance benefits. This work has implications for those developing AI governance protocols for the food supply chain as well as supply chain practitioners.}
}

@article{lincoln49668,
          volume = {12},
          number = {6},
          author = {Abhishesh Pal and Gautham Das and Marc Hanheide and Antonio Candea Leite and Pal From},
           title = {An Agricultural Event Prediction Framework towards Anticipatory Scheduling of Robot Fleets: General Concepts and Case Studies},
       publisher = {MDPI},
         journal = {Agronomy},
             doi = {10.3390/agronomy12061299},
            year = {2022},
        keywords = {ARRAY(0x555ae4eb1ef8)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/49668/},
        abstract = {Harvesting in soft-fruit farms is labor intensive, time consuming and is severely affected by scarcity of skilled labors. Among several activities during soft-fruit harvesting, human pickers take 20?30\% of overall operation time into the logistics activities. Such an unproductive time, for example, can be reduced by optimally deploying a fleet of agricultural robots and schedule them by anticipating the human activity behaviour (state) during harvesting. In this paper, we propose a framework for spatio-temporal prediction of human pickers? activities while they are picking fruits in agriculture fields. Here we exploit temporal patterns of picking operation and 2D discrete points, called topological nodes, as spatial constraints imposed by the agricultural environment. Both information are used in the prediction framework in combination with a variant of the Hidden Markov Model (HMM) algorithm to create two modules. The proposed methodology is validated with two test cases. In Test Case 1, the first module selects an optimal temporal model called as picking\_state\_progression model that uses temporal features of a picker state (event) to statistically evaluate an adequate number of intra-states also called sub-states. In Test Case 2, the second module uses the outcome from the optimal temporal model in the subsequent spatial model called node\_transition model and performs ?spatio-temporal predictions? of the picker?s movement while the picker is in a particular state. The Discrete Event Simulation (DES) framework, a proven agricultural multi-robot logistics model, is used to simulate the different picking operation scenarios with and without our proposed prediction framework and the results are then statistically compared to each other. Our prediction framework can reduce the so-called unproductive logistics time in a fully manual harvesting process by about 80 percent in the overall picking operation. This research also indicates that the different rates of picking operations involve different numbers of sub-states, and these sub-states are associated with different trends considered in spatio-temporal predictions.}
}

@article{lincoln48499,
           title = {Tea Chrysanthemum Detection by Leveraging Generative Adversarial Networks and Edge Computing},
          author = {Chao Qi and Junfeng Gao and Kunjie Chen and Lei Shu and Simon Pearson},
       publisher = {Frontiers Media},
            year = {2022},
         journal = {Frontiers in plant science},
        keywords = {ARRAY(0x555ae4eb1f28)},
             url = {https://eprints.lincoln.ac.uk/id/eprint/48499/},
        abstract = {A high resolution dataset is one of the prerequisites for tea chrysanthemum detection with deep learning algorithms. This is crucial for further developing a selective chrysanthemum harvesting robot. However, generating high resolution datasets of the tea chrysanthemum with complex unstructured environments is a challenge. In this context, we propose a novel generative adversarial network (TC-GAN) that attempts to deal with this challenge. First, we designed a non-linear mapping network for untangling the features of the underlying code. Then, a customized regularisation method was used to provide fine-grained control over the image details. Finally, a gradient diversion design with multi-scale feature extraction capability was adopted to optimize the training process. The proposed TC-GAN was compared with 12 state-of-the-art generative adversarial networks, showing that an optimal average precision (AP) of 90.09\% was achieved with the generated images (512*512) on the developed TC-YOLO object detection model under the NVIDIA Tesla P100 GPU environment. Moreover, the detection model was deployed into the embedded NVIDIA Jetson TX2 platform with 0.1s inference time, and this edge computing device could be further developed into a perception system for selective chrysanthemum picking robots in the future.}
}

